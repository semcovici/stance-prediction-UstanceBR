{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'main_mcnemar' from 'src.eval' (/home/semcovici/pesquisa/stance-prediction-UstanceBR/src/eval/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01meval\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m main_mcnemar\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'main_mcnemar' from 'src.eval' (/home/semcovici/pesquisa/stance-prediction-UstanceBR/src/eval/__init__.py)"
     ]
    }
   ],
   "source": [
    "from src.eval import main_mcnemar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
    "from sklearn.metrics import classification_report\n",
    "from transformers import set_seed\n",
    "import os\n",
    "import sys\n",
    "from tqdm import tqdm \n",
    "\n",
    "tqdm.pandas()\n",
    "\n",
    "\n",
    "sys.path.append('src/')\n",
    "from data.lambdas import int_to_label, label_to_int\n",
    "set_seed(42)\n",
    "\n",
    "# Define paths (adaptado do seu cÃ³digo existente)\n",
    "raw_data_path = 'data/raw/'\n",
    "processed_data_path = 'data/processed/'\n",
    "reports_path = 'reports/'\n",
    "file_format_tmt = processed_data_path + \"{split}_r3_{target}_top_mentioned_timelines_processed.csv\"\n",
    "file_format_users = processed_data_path + 'r3_{target}_{split}_users_processed.csv'\n",
    "file_format_users_scored = processed_data_path + 'r3_{target}_{split}_users_scored_Timeline.csv'\n",
    "file_format_tmt_scored = processed_data_path + '{split}_r3_{target}_top_mentioned_timelines_scored_Texts.csv'\n",
    "\n",
    "# Target list\n",
    "target_list = ['lu']\n",
    "\n",
    "dict_exps = {\n",
    "    \"Timeline\": {\n",
    "        'path_dataset': file_format_users,\n",
    "        \"text_col\": \"Timeline\",\n",
    "        \"batch_size\": 64,\n",
    "        \"epochs\": 1000\n",
    "    },\n",
    "    \"Texts\": {\n",
    "        'path_dataset': file_format_tmt,\n",
    "        \"text_col\": \"Texts\",\n",
    "        \"batch_size\": 64,\n",
    "        \"epochs\": 1000\n",
    "    },\n",
    "}\n",
    "\n",
    "check_if_already_exists = False\n",
    "\n",
    "for exp_name, config in dict_exps.items():\n",
    "    \n",
    "    print(f\"\"\"###########################################\n",
    "# Running: {exp_name} \n",
    "###########################################\"\"\")\n",
    "    \n",
    "    text_col = config['text_col']\n",
    "    path_dataset = config['path_dataset']\n",
    "    \n",
    "    # Processar cada target\n",
    "    for target in target_list:\n",
    "        \n",
    "        print(f\"\"\"######## target: {target}\"\"\")\n",
    "        estimator_name = 'LSTM'\n",
    "        test_results_path = f\"{reports_path}test_results/{estimator_name}_{target}_{exp_name}_test_results.csv\"\n",
    "        train_results_path = f\"{reports_path}train_results/{estimator_name}_{target}_{exp_name}_train_results.csv\"\n",
    "        val_results_path = f\"{reports_path}val_results/{estimator_name}_{target}_{exp_name}_val_results.csv\"\n",
    "        \n",
    "        if os.path.isfile(test_results_path) and os.path.isfile(train_results_path) and check_if_already_exists:\n",
    "            print('# experiment already done')\n",
    "            continue\n",
    "        \n",
    "        # Ler e dividir os dados\n",
    "        train_val = pd.read_csv(\n",
    "            path_dataset.format(target=target, split=\"train\"), \n",
    "            sep=';', \n",
    "            encoding='utf-8-sig'\n",
    "        ).reset_index()[[text_col, 'Polarity']].rename(columns={text_col: 'text', 'Polarity': 'label'})\n",
    "        \n",
    "        train_val.label = train_val.label.apply(lambda x: label_to_int(x))\n",
    "        \n",
    "        # train_val.text = train_val.text.progress_apply(lambda x: x[:13000])\n",
    "\n",
    "        # Check if label is binary\n",
    "        if len(train_val.label.unique()) != 2:\n",
    "            raise Exception(\"There is an error in train_val label transformation: expected to be binary\")\n",
    "        \n",
    "        train, val = train_test_split(train_val, test_size=0.15, random_state=42)\n",
    "        train.reset_index(drop=True, inplace=True)\n",
    "        val.reset_index(drop=True, inplace=True)\n",
    "        \n",
    "        test = pd.read_csv(\n",
    "            path_dataset.format(target=target, split=\"test\"), \n",
    "            sep=';', \n",
    "            encoding='utf-8-sig'\n",
    "        ).reset_index()[[text_col, 'Polarity']].rename(columns={text_col: 'text', 'Polarity': 'label'})\n",
    "        \n",
    "        test.label = test.label.apply(lambda x: label_to_int(x))\n",
    "        input_tokens = 1000\n",
    "        # Tokenize and pad texts\n",
    "        tokenizer = Tokenizer(num_words=input_tokens)\n",
    "        tokenizer.fit_on_texts(train['text'])\n",
    "        \n",
    "        X_train = tokenizer.texts_to_sequences(train['text'])\n",
    "        X_val = tokenizer.texts_to_sequences(val['text'])\n",
    "        X_test = tokenizer.texts_to_sequences(test['text'])\n",
    "        \n",
    "        max_length = max([len(x) for x in X_train])\n",
    "        X_train = pad_sequences(X_train, maxlen=max_length)\n",
    "        X_val = pad_sequences(X_val, maxlen=max_length)\n",
    "        X_test = pad_sequences(X_test, maxlen=max_length)\n",
    "        \n",
    "        y_train = np.array(train['label'])\n",
    "        y_val = np.array(val['label'])\n",
    "        y_test = np.array(test['label'])\n",
    "        \n",
    "        # Build LSTM model\n",
    "        model = Sequential([\n",
    "            Embedding(input_dim=input_tokens, output_dim=128, input_length=max_length),\n",
    "            LSTM(64, return_sequences=True),\n",
    "            LSTM(32),\n",
    "            Dense(1, activation='sigmoid')\n",
    "        ])\n",
    "        \n",
    "        model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "        \n",
    "        # Train the model\n",
    "        model.fit(X_train, y_train, epochs=config['epochs'], batch_size=config['batch_size'], validation_data=(X_val, y_val))\n",
    "        \n",
    "        # Evaluate the model\n",
    "        train_pred = model.predict(X_train)\n",
    "        val_pred = model.predict(X_val)\n",
    "        test_pred = model.predict(X_test)\n",
    "        \n",
    "        # Convert probabilities to binary predictions\n",
    "        train_pred = (train_pred > 0.5).astype(int)\n",
    "        val_pred = (val_pred > 0.5).astype(int)\n",
    "        test_pred = (test_pred > 0.5).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env-stance-pred",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
