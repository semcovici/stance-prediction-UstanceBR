{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8f020349-c880-426d-a878-3089c79c9203",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "from ast import literal_eval\n",
    "from tqdm import tqdm\n",
    "from sklearn.metrics import classification_report\n",
    "tqdm.pandas()\n",
    "import random\n",
    "random.seed(0)\n",
    "from belt_nlp.bert_with_pooling import BertClassifierWithPooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d1c1d926",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data_path = '../data/raw/'\n",
    "processed_data_path = '../data/processed/'\n",
    "reports_path = '../reports/'\n",
    "file_format_users_filtered = processed_data_path + 'r3_{target}_{split}_users_scored_Timeline.csv' \n",
    "file_format_tmt_filtered = processed_data_path + '{split}_r3_{target}_top_mentioned_timelines_scored_Texts.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8aadac76",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_list = [\n",
    "    'ig',\n",
    "    'bo', \n",
    "    'cl', \n",
    "    'co', \n",
    "    'gl', \n",
    "    'lu'\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "def0cbf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_experiments = {\n",
    "    'filtered_Texts5': {\n",
    "        \"text_col\": 'Texts',\n",
    "        \"n_comments\": 5,\n",
    "        \"file_format\": file_format_tmt_filtered\n",
    "    },\n",
    "    'filteredTimeline5': {\n",
    "        \"text_col\": 'Timeline',\n",
    "        \"n_comments\": 5,\n",
    "        \"file_format\": file_format_users_filtered\n",
    "    },\n",
    "    'filtered_Texts10': {\n",
    "        \"text_col\": 'Texts',\n",
    "        \"n_comments\": 10,\n",
    "        \"file_format\": file_format_tmt_filtered\n",
    "    },\n",
    "    'filteredTimeline10': {\n",
    "        \"text_col\": 'Timeline',\n",
    "        \"n_comments\": 10,\n",
    "        \"file_format\": file_format_users_filtered\n",
    "    },\n",
    "    'filtered_Texts15': {\n",
    "        \"text_col\": 'Texts',\n",
    "        \"n_comments\": 15,\n",
    "        \"file_format\": file_format_tmt_filtered\n",
    "    },\n",
    "    'filteredTimeline15': {\n",
    "        \"text_col\": 'Timeline',\n",
    "        \"n_comments\": 15,\n",
    "        \"file_format\": file_format_users_filtered\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "082da124-c5d5-4ed1-8828-fc7f92efbba2",
   "metadata": {},
   "source": [
    "# Example - Model BERT with pooling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bebcd04f-9a46-4562-8afd-25e0f41263ca",
   "metadata": {},
   "source": [
    "In this notebook we will show how to use basic methods `fit` and `predict` for the BERT model with pooling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "214176d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "!export PYTORCH_CUDA_ALLOC_CONF=max_split_size_mb:128\n",
    "!export PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "178145e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "bert_model_name = 'pablocosta/bertabaporu-base-uncased'\n",
    "epochs = 3\n",
    "batch_size = 3\n",
    "\n",
    "MODEL_PARAMS = {\n",
    "    \"batch_size\": batch_size,\n",
    "    \"learning_rate\": 5e-5,\n",
    "    \"epochs\": epochs,\n",
    "    \"chunk_size\": 510,\n",
    "    \"stride\": 510,\n",
    "    \"minimal_chunk_length\": 510,\n",
    "    \"pooling_strategy\": \"mean\",\n",
    "    \"pretrained_model_name_or_path\": bert_model_name\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5ba33cfb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'pablocosta_bertabaporu-base-uncased'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_model_name.replace('/','_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b7094cd2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "####################################  \n",
      "# Running filtered_Texts5\n",
      "#####################################\n",
      "ig\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1758/1758 [00:34<00:00, 51.26it/s]\n",
      "100%|██████████| 1758/1758 [00:00<00:00, 427280.90it/s]\n",
      "100%|██████████| 599/599 [00:12<00:00, 49.48it/s]\n",
      "100%|██████████| 599/599 [00:00<00:00, 352319.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.66      0.61      0.63       339\n",
      "        True       0.54      0.60      0.57       260\n",
      "\n",
      "    accuracy                           0.60       599\n",
      "   macro avg       0.60      0.60      0.60       599\n",
      "weighted avg       0.61      0.60      0.61       599\n",
      "\n",
      "bo\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 556/556 [00:10<00:00, 55.52it/s]\n",
      "100%|██████████| 556/556 [00:00<00:00, 334006.45it/s]\n",
      "100%|██████████| 188/188 [00:03<00:00, 60.09it/s]\n",
      "100%|██████████| 188/188 [00:00<00:00, 260584.65it/s]\n",
      "/home/semcovici/anaconda3/envs/env-stance-pred/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/semcovici/anaconda3/envs/env-stance-pred/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/semcovici/anaconda3/envs/env-stance-pred/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.86      1.00      0.93       162\n",
      "        True       0.00      0.00      0.00        26\n",
      "\n",
      "    accuracy                           0.86       188\n",
      "   macro avg       0.43      0.50      0.46       188\n",
      "weighted avg       0.74      0.86      0.80       188\n",
      "\n",
      "cl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1710/1710 [00:44<00:00, 38.01it/s]\n",
      "100%|██████████| 1710/1710 [00:00<00:00, 342024.79it/s]\n",
      "100%|██████████| 574/574 [00:15<00:00, 36.35it/s]\n",
      "100%|██████████| 574/574 [00:00<00:00, 352855.12it/s]\n",
      "/home/semcovici/anaconda3/envs/env-stance-pred/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/semcovici/anaconda3/envs/env-stance-pred/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/semcovici/anaconda3/envs/env-stance-pred/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.00      0.00      0.00       289\n",
      "        True       0.50      1.00      0.66       285\n",
      "\n",
      "    accuracy                           0.50       574\n",
      "   macro avg       0.25      0.50      0.33       574\n",
      "weighted avg       0.25      0.50      0.33       574\n",
      "\n",
      "co\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2289/2289 [00:57<00:00, 40.04it/s]\n",
      "100%|██████████| 2289/2289 [00:00<00:00, 373033.45it/s]\n",
      "100%|██████████| 774/774 [00:19<00:00, 39.52it/s]\n",
      "100%|██████████| 774/774 [00:00<00:00, 399113.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.67      0.01      0.01       354\n",
      "        True       0.54      1.00      0.70       420\n",
      "\n",
      "    accuracy                           0.54       774\n",
      "   macro avg       0.61      0.50      0.36       774\n",
      "weighted avg       0.60      0.54      0.39       774\n",
      "\n",
      "gl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1210/1210 [00:30<00:00, 39.45it/s]\n",
      "100%|██████████| 1210/1210 [00:00<00:00, 388718.43it/s]\n",
      "100%|██████████| 411/411 [00:10<00:00, 39.09it/s]\n",
      "100%|██████████| 411/411 [00:00<00:00, 276925.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.50      0.45      0.47       167\n",
      "        True       0.65      0.69      0.67       244\n",
      "\n",
      "    accuracy                           0.59       411\n",
      "   macro avg       0.57      0.57      0.57       411\n",
      "weighted avg       0.59      0.59      0.59       411\n",
      "\n",
      "lu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 804/804 [00:15<00:00, 52.65it/s]\n",
      "100%|██████████| 804/804 [00:00<00:00, 330836.89it/s]\n",
      "100%|██████████| 272/272 [00:05<00:00, 54.24it/s]\n",
      "100%|██████████| 272/272 [00:00<00:00, 354191.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.59      0.61      0.60       143\n",
      "        True       0.55      0.53      0.54       129\n",
      "\n",
      "    accuracy                           0.57       272\n",
      "   macro avg       0.57      0.57      0.57       272\n",
      "weighted avg       0.57      0.57      0.57       272\n",
      "\n",
      "####################################  \n",
      "# Running filteredTimeline5\n",
      "#####################################\n",
      "ig\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1796/1796 [01:11<00:00, 25.20it/s]\n",
      "100%|██████████| 1796/1796 [00:00<00:00, 400476.87it/s]\n",
      "100%|██████████| 599/599 [00:24<00:00, 24.32it/s]\n",
      "100%|██████████| 599/599 [00:00<00:00, 426986.42it/s]\n",
      "/home/semcovici/anaconda3/envs/env-stance-pred/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/semcovici/anaconda3/envs/env-stance-pred/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/semcovici/anaconda3/envs/env-stance-pred/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.57      1.00      0.72       339\n",
      "        True       0.00      0.00      0.00       260\n",
      "\n",
      "    accuracy                           0.57       599\n",
      "   macro avg       0.28      0.50      0.36       599\n",
      "weighted avg       0.32      0.57      0.41       599\n",
      "\n",
      "bo\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 563/563 [00:21<00:00, 25.80it/s]\n",
      "100%|██████████| 563/563 [00:00<00:00, 227911.70it/s]\n",
      "100%|██████████| 188/188 [00:07<00:00, 26.25it/s]\n",
      "100%|██████████| 188/188 [00:00<00:00, 278435.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.93      0.85      0.89       162\n",
      "        True       0.40      0.62      0.48        26\n",
      "\n",
      "    accuracy                           0.82       188\n",
      "   macro avg       0.67      0.73      0.69       188\n",
      "weighted avg       0.86      0.82      0.83       188\n",
      "\n",
      "cl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1721/1721 [00:35<00:00, 48.70it/s]\n",
      "100%|██████████| 1721/1721 [00:00<00:00, 441573.21it/s]\n",
      "100%|██████████| 574/574 [00:11<00:00, 48.20it/s]\n",
      "100%|██████████| 574/574 [00:00<00:00, 426942.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.87      0.73      0.79       289\n",
      "        True       0.76      0.89      0.82       285\n",
      "\n",
      "    accuracy                           0.81       574\n",
      "   macro avg       0.81      0.81      0.81       574\n",
      "weighted avg       0.82      0.81      0.81       574\n",
      "\n",
      "co\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2319/2319 [00:47<00:00, 48.32it/s]\n",
      "100%|██████████| 2319/2319 [00:00<00:00, 407481.82it/s]\n",
      "100%|██████████| 774/774 [00:16<00:00, 46.56it/s]\n",
      "100%|██████████| 774/774 [00:00<00:00, 450637.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.83      0.75      0.79       354\n",
      "        True       0.80      0.87      0.84       420\n",
      "\n",
      "    accuracy                           0.81       774\n",
      "   macro avg       0.82      0.81      0.81       774\n",
      "weighted avg       0.82      0.81      0.81       774\n",
      "\n",
      "gl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1231/1231 [00:50<00:00, 24.41it/s]\n",
      "100%|██████████| 1231/1231 [00:00<00:00, 322779.96it/s]\n",
      "100%|██████████| 411/411 [00:17<00:00, 23.29it/s]\n",
      "100%|██████████| 411/411 [00:00<00:00, 376142.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.48      0.35      0.41       167\n",
      "        True       0.63      0.74      0.68       244\n",
      "\n",
      "    accuracy                           0.58       411\n",
      "   macro avg       0.55      0.55      0.54       411\n",
      "weighted avg       0.57      0.58      0.57       411\n",
      "\n",
      "lu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 816/816 [00:31<00:00, 25.72it/s]\n",
      "100%|██████████| 816/816 [00:00<00:00, 387561.10it/s]\n",
      "100%|██████████| 272/272 [00:10<00:00, 25.38it/s]\n",
      "100%|██████████| 272/272 [00:00<00:00, 346868.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.80      0.48      0.60       143\n",
      "        True       0.60      0.87      0.71       129\n",
      "\n",
      "    accuracy                           0.66       272\n",
      "   macro avg       0.70      0.67      0.65       272\n",
      "weighted avg       0.70      0.66      0.65       272\n",
      "\n",
      "####################################  \n",
      "# Running filtered_Texts10\n",
      "#####################################\n",
      "ig\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1758/1758 [00:33<00:00, 52.80it/s]\n",
      "100%|██████████| 1758/1758 [00:00<00:00, 336079.60it/s]\n",
      "100%|██████████| 599/599 [00:11<00:00, 51.66it/s]\n",
      "100%|██████████| 599/599 [00:00<00:00, 238548.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.65      0.73      0.69       339\n",
      "        True       0.58      0.49      0.53       260\n",
      "\n",
      "    accuracy                           0.62       599\n",
      "   macro avg       0.61      0.61      0.61       599\n",
      "weighted avg       0.62      0.62      0.62       599\n",
      "\n",
      "bo\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 556/556 [00:09<00:00, 55.80it/s]\n",
      "100%|██████████| 556/556 [00:00<00:00, 268853.24it/s]\n",
      "100%|██████████| 188/188 [00:03<00:00, 59.55it/s]\n",
      "100%|██████████| 188/188 [00:00<00:00, 229423.67it/s]\n",
      "/home/semcovici/anaconda3/envs/env-stance-pred/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/semcovici/anaconda3/envs/env-stance-pred/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/semcovici/anaconda3/envs/env-stance-pred/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.86      1.00      0.93       162\n",
      "        True       0.00      0.00      0.00        26\n",
      "\n",
      "    accuracy                           0.86       188\n",
      "   macro avg       0.43      0.50      0.46       188\n",
      "weighted avg       0.74      0.86      0.80       188\n",
      "\n",
      "cl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1710/1710 [00:35<00:00, 48.11it/s]\n",
      "100%|██████████| 1710/1710 [00:00<00:00, 316446.50it/s]\n",
      "100%|██████████| 574/574 [00:12<00:00, 45.10it/s]\n",
      "100%|██████████| 574/574 [00:00<00:00, 301922.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.62      0.40      0.49       289\n",
      "        True       0.55      0.75      0.64       285\n",
      "\n",
      "    accuracy                           0.57       574\n",
      "   macro avg       0.59      0.58      0.56       574\n",
      "weighted avg       0.59      0.57      0.56       574\n",
      "\n",
      "co\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2289/2289 [00:51<00:00, 44.17it/s]\n",
      "100%|██████████| 2289/2289 [00:00<00:00, 343411.73it/s]\n",
      "100%|██████████| 774/774 [00:17<00:00, 43.07it/s]\n",
      "100%|██████████| 774/774 [00:00<00:00, 268407.71it/s]\n",
      "/home/semcovici/anaconda3/envs/env-stance-pred/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/semcovici/anaconda3/envs/env-stance-pred/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/semcovici/anaconda3/envs/env-stance-pred/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.00      0.00      0.00       354\n",
      "        True       0.54      1.00      0.70       420\n",
      "\n",
      "    accuracy                           0.54       774\n",
      "   macro avg       0.27      0.50      0.35       774\n",
      "weighted avg       0.29      0.54      0.38       774\n",
      "\n",
      "gl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1210/1210 [00:26<00:00, 46.01it/s]\n",
      "100%|██████████| 1210/1210 [00:00<00:00, 281107.11it/s]\n",
      "100%|██████████| 411/411 [00:09<00:00, 43.93it/s]\n",
      "100%|██████████| 411/411 [00:00<00:00, 295181.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.49      0.35      0.41       167\n",
      "        True       0.63      0.75      0.68       244\n",
      "\n",
      "    accuracy                           0.59       411\n",
      "   macro avg       0.56      0.55      0.55       411\n",
      "weighted avg       0.57      0.59      0.57       411\n",
      "\n",
      "lu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 804/804 [00:15<00:00, 51.17it/s]\n",
      "100%|██████████| 804/804 [00:00<00:00, 295627.28it/s]\n",
      "100%|██████████| 272/272 [00:05<00:00, 49.12it/s]\n",
      "100%|██████████| 272/272 [00:00<00:00, 259107.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.62      0.43      0.51       143\n",
      "        True       0.53      0.71      0.61       129\n",
      "\n",
      "    accuracy                           0.56       272\n",
      "   macro avg       0.58      0.57      0.56       272\n",
      "weighted avg       0.58      0.56      0.55       272\n",
      "\n",
      "####################################  \n",
      "# Running filteredTimeline10\n",
      "#####################################\n",
      "ig\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1796/1796 [01:13<00:00, 24.59it/s]\n",
      "100%|██████████| 1796/1796 [00:00<00:00, 320879.62it/s]\n",
      "100%|██████████| 599/599 [00:25<00:00, 23.93it/s]\n",
      "100%|██████████| 599/599 [00:00<00:00, 281594.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.69      0.79      0.74       339\n",
      "        True       0.67      0.54      0.60       260\n",
      "\n",
      "    accuracy                           0.68       599\n",
      "   macro avg       0.68      0.67      0.67       599\n",
      "weighted avg       0.68      0.68      0.68       599\n",
      "\n",
      "bo\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 563/563 [00:22<00:00, 25.28it/s]\n",
      "100%|██████████| 563/563 [00:00<00:00, 266492.85it/s]\n",
      "100%|██████████| 188/188 [00:07<00:00, 24.02it/s]\n",
      "100%|██████████| 188/188 [00:00<00:00, 157800.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.94      0.99      0.96       162\n",
      "        True       0.88      0.58      0.70        26\n",
      "\n",
      "    accuracy                           0.93       188\n",
      "   macro avg       0.91      0.78      0.83       188\n",
      "weighted avg       0.93      0.93      0.92       188\n",
      "\n",
      "cl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1721/1721 [00:34<00:00, 49.41it/s]\n",
      "100%|██████████| 1721/1721 [00:00<00:00, 338891.89it/s]\n",
      "100%|██████████| 574/574 [00:12<00:00, 46.84it/s]\n",
      "100%|██████████| 574/574 [00:00<00:00, 253825.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.81      0.86      0.83       289\n",
      "        True       0.85      0.79      0.82       285\n",
      "\n",
      "    accuracy                           0.83       574\n",
      "   macro avg       0.83      0.83      0.83       574\n",
      "weighted avg       0.83      0.83      0.83       574\n",
      "\n",
      "co\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2319/2319 [00:47<00:00, 49.21it/s]\n",
      "100%|██████████| 2319/2319 [00:00<00:00, 338398.60it/s]\n",
      "100%|██████████| 774/774 [00:17<00:00, 45.49it/s]\n",
      "100%|██████████| 774/774 [00:00<00:00, 321584.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.99      0.32      0.48       354\n",
      "        True       0.63      1.00      0.78       420\n",
      "\n",
      "    accuracy                           0.69       774\n",
      "   macro avg       0.81      0.66      0.63       774\n",
      "weighted avg       0.80      0.69      0.64       774\n",
      "\n",
      "gl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1231/1231 [00:50<00:00, 24.23it/s]\n",
      "100%|██████████| 1231/1231 [00:00<00:00, 296071.35it/s]\n",
      "100%|██████████| 411/411 [00:17<00:00, 23.05it/s]\n",
      "100%|██████████| 411/411 [00:00<00:00, 273368.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.55      0.50      0.53       167\n",
      "        True       0.68      0.72      0.70       244\n",
      "\n",
      "    accuracy                           0.63       411\n",
      "   macro avg       0.62      0.61      0.61       411\n",
      "weighted avg       0.63      0.63      0.63       411\n",
      "\n",
      "lu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 816/816 [00:31<00:00, 25.82it/s]\n",
      "100%|██████████| 816/816 [00:00<00:00, 267533.19it/s]\n",
      "100%|██████████| 272/272 [00:10<00:00, 24.91it/s]\n",
      "100%|██████████| 272/272 [00:00<00:00, 253072.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.69      0.83      0.75       143\n",
      "        True       0.75      0.58      0.66       129\n",
      "\n",
      "    accuracy                           0.71       272\n",
      "   macro avg       0.72      0.70      0.70       272\n",
      "weighted avg       0.72      0.71      0.70       272\n",
      "\n",
      "####################################  \n",
      "# Running filtered_Texts15\n",
      "#####################################\n",
      "ig\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1758/1758 [00:33<00:00, 52.47it/s]\n",
      "100%|██████████| 1758/1758 [00:00<00:00, 247626.91it/s]\n",
      "100%|██████████| 599/599 [00:11<00:00, 50.85it/s]\n",
      "100%|██████████| 599/599 [00:00<00:00, 252171.85it/s]\n",
      "/home/semcovici/anaconda3/envs/env-stance-pred/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/semcovici/anaconda3/envs/env-stance-pred/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/semcovici/anaconda3/envs/env-stance-pred/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.57      1.00      0.72       339\n",
      "        True       0.00      0.00      0.00       260\n",
      "\n",
      "    accuracy                           0.57       599\n",
      "   macro avg       0.28      0.50      0.36       599\n",
      "weighted avg       0.32      0.57      0.41       599\n",
      "\n",
      "bo\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 556/556 [00:10<00:00, 54.34it/s]\n",
      "100%|██████████| 556/556 [00:00<00:00, 210093.07it/s]\n",
      "100%|██████████| 188/188 [00:03<00:00, 57.69it/s]\n",
      "100%|██████████| 188/188 [00:00<00:00, 176168.26it/s]\n",
      "/home/semcovici/anaconda3/envs/env-stance-pred/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/semcovici/anaconda3/envs/env-stance-pred/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/semcovici/anaconda3/envs/env-stance-pred/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.86      1.00      0.93       162\n",
      "        True       0.00      0.00      0.00        26\n",
      "\n",
      "    accuracy                           0.86       188\n",
      "   macro avg       0.43      0.50      0.46       188\n",
      "weighted avg       0.74      0.86      0.80       188\n",
      "\n",
      "cl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1710/1710 [00:35<00:00, 47.83it/s]\n",
      "100%|██████████| 1710/1710 [00:00<00:00, 244611.71it/s]\n",
      "100%|██████████| 574/574 [00:13<00:00, 44.10it/s]\n",
      "100%|██████████| 574/574 [00:00<00:00, 246572.15it/s]\n",
      "/home/semcovici/anaconda3/envs/env-stance-pred/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/semcovici/anaconda3/envs/env-stance-pred/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/semcovici/anaconda3/envs/env-stance-pred/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.50      1.00      0.67       289\n",
      "        True       0.00      0.00      0.00       285\n",
      "\n",
      "    accuracy                           0.50       574\n",
      "   macro avg       0.25      0.50      0.33       574\n",
      "weighted avg       0.25      0.50      0.34       574\n",
      "\n",
      "co\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2289/2289 [00:52<00:00, 43.54it/s]\n",
      "100%|██████████| 2289/2289 [00:00<00:00, 272007.08it/s]\n",
      "100%|██████████| 774/774 [00:18<00:00, 42.09it/s]\n",
      "100%|██████████| 774/774 [00:00<00:00, 211078.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.61      0.73      0.67       354\n",
      "        True       0.73      0.61      0.66       420\n",
      "\n",
      "    accuracy                           0.67       774\n",
      "   macro avg       0.67      0.67      0.67       774\n",
      "weighted avg       0.68      0.67      0.67       774\n",
      "\n",
      "gl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1210/1210 [00:26<00:00, 45.88it/s]\n",
      "100%|██████████| 1210/1210 [00:00<00:00, 252706.66it/s]\n",
      "100%|██████████| 411/411 [00:09<00:00, 44.33it/s]\n",
      "100%|██████████| 411/411 [00:00<00:00, 212795.82it/s]\n",
      "/home/semcovici/anaconda3/envs/env-stance-pred/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/semcovici/anaconda3/envs/env-stance-pred/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/semcovici/anaconda3/envs/env-stance-pred/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.00      0.00      0.00       167\n",
      "        True       0.59      1.00      0.75       244\n",
      "\n",
      "    accuracy                           0.59       411\n",
      "   macro avg       0.30      0.50      0.37       411\n",
      "weighted avg       0.35      0.59      0.44       411\n",
      "\n",
      "lu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 804/804 [00:15<00:00, 51.30it/s]\n",
      "100%|██████████| 804/804 [00:00<00:00, 228671.62it/s]\n",
      "100%|██████████| 272/272 [00:05<00:00, 49.79it/s]\n",
      "100%|██████████| 272/272 [00:00<00:00, 224223.80it/s]\n",
      "/home/semcovici/anaconda3/envs/env-stance-pred/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/semcovici/anaconda3/envs/env-stance-pred/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/semcovici/anaconda3/envs/env-stance-pred/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.53      1.00      0.69       143\n",
      "        True       0.00      0.00      0.00       129\n",
      "\n",
      "    accuracy                           0.53       272\n",
      "   macro avg       0.26      0.50      0.34       272\n",
      "weighted avg       0.28      0.53      0.36       272\n",
      "\n",
      "####################################  \n",
      "# Running filteredTimeline15\n",
      "#####################################\n",
      "ig\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1796/1796 [01:12<00:00, 24.68it/s]\n",
      "100%|██████████| 1796/1796 [00:00<00:00, 249460.87it/s]\n",
      "100%|██████████| 599/599 [00:25<00:00, 23.82it/s]\n",
      "100%|██████████| 599/599 [00:00<00:00, 253392.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.67      0.59      0.63       339\n",
      "        True       0.54      0.63      0.58       260\n",
      "\n",
      "    accuracy                           0.61       599\n",
      "   macro avg       0.61      0.61      0.61       599\n",
      "weighted avg       0.62      0.61      0.61       599\n",
      "\n",
      "bo\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 563/563 [00:22<00:00, 25.10it/s]\n",
      "100%|██████████| 563/563 [00:00<00:00, 181575.79it/s]\n",
      "100%|██████████| 188/188 [00:07<00:00, 23.71it/s]\n",
      "100%|██████████| 188/188 [00:00<00:00, 167487.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.93      0.98      0.95       162\n",
      "        True       0.82      0.54      0.65        26\n",
      "\n",
      "    accuracy                           0.92       188\n",
      "   macro avg       0.88      0.76      0.80       188\n",
      "weighted avg       0.92      0.92      0.91       188\n",
      "\n",
      "cl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1721/1721 [00:35<00:00, 48.86it/s]\n",
      "100%|██████████| 1721/1721 [00:00<00:00, 254025.80it/s]\n",
      "100%|██████████| 574/574 [00:12<00:00, 46.98it/s]\n",
      "100%|██████████| 574/574 [00:00<00:00, 214938.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.86      0.86      0.86       289\n",
      "        True       0.86      0.85      0.85       285\n",
      "\n",
      "    accuracy                           0.86       574\n",
      "   macro avg       0.86      0.86      0.86       574\n",
      "weighted avg       0.86      0.86      0.86       574\n",
      "\n",
      "co\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2319/2319 [00:47<00:00, 48.85it/s]\n",
      "100%|██████████| 2319/2319 [00:00<00:00, 268260.55it/s]\n",
      "100%|██████████| 774/774 [00:16<00:00, 46.20it/s]\n",
      "100%|██████████| 774/774 [00:00<00:00, 263912.80it/s]\n",
      "/home/semcovici/anaconda3/envs/env-stance-pred/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/semcovici/anaconda3/envs/env-stance-pred/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/semcovici/anaconda3/envs/env-stance-pred/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.00      0.00      0.00       354\n",
      "        True       0.54      1.00      0.70       420\n",
      "\n",
      "    accuracy                           0.54       774\n",
      "   macro avg       0.27      0.50      0.35       774\n",
      "weighted avg       0.29      0.54      0.38       774\n",
      "\n",
      "gl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1231/1231 [01:01<00:00, 20.15it/s]\n",
      "100%|██████████| 1231/1231 [00:00<00:00, 239291.29it/s]\n",
      "100%|██████████| 411/411 [00:18<00:00, 22.54it/s]\n",
      "100%|██████████| 411/411 [00:00<00:00, 228325.69it/s]\n",
      "/home/semcovici/anaconda3/envs/env-stance-pred/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/semcovici/anaconda3/envs/env-stance-pred/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/semcovici/anaconda3/envs/env-stance-pred/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.00      0.00      0.00       167\n",
      "        True       0.59      1.00      0.75       244\n",
      "\n",
      "    accuracy                           0.59       411\n",
      "   macro avg       0.30      0.50      0.37       411\n",
      "weighted avg       0.35      0.59      0.44       411\n",
      "\n",
      "lu\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 816/816 [00:33<00:00, 24.49it/s]\n",
      "100%|██████████| 816/816 [00:00<00:00, 218163.70it/s]\n",
      "100%|██████████| 272/272 [00:11<00:00, 23.31it/s]\n",
      "100%|██████████| 272/272 [00:00<00:00, 208947.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       False       0.74      0.89      0.81       143\n",
      "        True       0.84      0.65      0.73       129\n",
      "\n",
      "    accuracy                           0.78       272\n",
      "   macro avg       0.79      0.77      0.77       272\n",
      "weighted avg       0.79      0.78      0.77       272\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for exp_name, config in dict_experiments.items():\n",
    "    \n",
    "    print(f\"\"\"####################################  \n",
    "# Running {exp_name}\n",
    "#####################################\"\"\")\n",
    "    \n",
    "    \n",
    "    # get configs of experiments\n",
    "    text_col = config['text_col']\n",
    "    file_format = config['file_format']\n",
    "    n_comments = config['n_comments']\n",
    "    file_format = config['file_format']\n",
    "    \n",
    "    \n",
    "    list_responses = []\n",
    "    for target in target_list:\n",
    "        \n",
    "        print(target)\n",
    "        \n",
    "        # read data\n",
    "        train = pd.read_csv(\n",
    "            file_format.format(target = target, split = \"train\"), \n",
    "            sep = ';', \n",
    "            encoding='utf-8-sig'\n",
    "            )\n",
    "\n",
    "        train[f'comments_and_scores_{text_col}'] = train[f'comments_and_scores_{text_col}'].progress_apply(lambda x: literal_eval(x))\n",
    "\n",
    "        train[text_col] = train[f'comments_and_scores_{text_col}'].progress_apply(\n",
    "            lambda x: \" # \".join([comment for score, comment in x[-n_comments:]])\n",
    "            ) \n",
    "        train.Polarity = train.Polarity.map({\n",
    "            \"against\": False,\n",
    "            \"for\": True\n",
    "        })\n",
    "        test = pd.read_csv(\n",
    "            file_format.format(target = target, split = \"test\"), \n",
    "            sep = ';', \n",
    "            encoding='utf-8-sig'\n",
    "            )\n",
    "\n",
    "        test[f'comments_and_scores_{text_col}'] = test[f'comments_and_scores_{text_col}'].progress_apply(lambda x: literal_eval(x))\n",
    "\n",
    "        test[text_col] = test[f'comments_and_scores_{text_col}'].progress_apply(\n",
    "            lambda x: \" # \".join([comment for score, comment in x[-n_comments:]])\n",
    "            ) \n",
    "\n",
    "        test.Polarity = test.Polarity.map({\n",
    "            \"against\": False,\n",
    "            \"for\": True\n",
    "        })\n",
    "        \n",
    "        \n",
    "        X_train = train[text_col].tolist()\n",
    "        X_test = test[text_col].tolist()\n",
    "\n",
    "        y_train = train[\"Polarity\"].tolist()\n",
    "        y_test = test[\"Polarity\"].tolist()        \n",
    "        \n",
    "        torch.cuda.empty_cache()\n",
    "        \n",
    "        model = BertClassifierWithPooling(**MODEL_PARAMS, device=\"cuda:0\")\n",
    "        \n",
    "        model.fit(X_train, y_train, epochs=epochs)\n",
    "        \n",
    "        y_pred = model.predict_classes(X_test)\n",
    "        \n",
    "        del model\n",
    "        \n",
    "        df_responses = pd.DataFrame({\n",
    "            \"y_test\": y_test,\n",
    "            \"y_pred\": y_pred\n",
    "        })\n",
    "        \n",
    "        df_responses['target'] =target\n",
    "        df_responses['exp_name'] = exp_name\n",
    "        df_responses['n_comments'] = n_comments\n",
    "        df_responses['text_col'] = text_col\n",
    "        \n",
    "        print(classification_report(y_test, y_pred))\n",
    "        df_responses.to_csv(f'{reports_path}test_results/belt_{exp_name}_{bert_model_name.replace('/','_')}_test_results_part_{target}.csv')  \n",
    "        \n",
    "        list_responses.append(df_responses)\n",
    "        \n",
    "df_responses_final = pd.concat(list_responses)\n",
    "df_responses_final.to_csv(f'{reports_path}test_results/belt_{exp_name}_{bert_model_name.replace('/','_')}_test_results.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5d9fb544",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_test</th>\n",
       "      <th>y_pred</th>\n",
       "      <th>target</th>\n",
       "      <th>exp_name</th>\n",
       "      <th>n_comments</th>\n",
       "      <th>text_col</th>\n",
       "      <th>hit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>ig</td>\n",
       "      <td>filteredTimeline15</td>\n",
       "      <td>15</td>\n",
       "      <td>Timeline</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>ig</td>\n",
       "      <td>filteredTimeline15</td>\n",
       "      <td>15</td>\n",
       "      <td>Timeline</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>ig</td>\n",
       "      <td>filteredTimeline15</td>\n",
       "      <td>15</td>\n",
       "      <td>Timeline</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>ig</td>\n",
       "      <td>filteredTimeline15</td>\n",
       "      <td>15</td>\n",
       "      <td>Timeline</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>ig</td>\n",
       "      <td>filteredTimeline15</td>\n",
       "      <td>15</td>\n",
       "      <td>Timeline</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>267</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>lu</td>\n",
       "      <td>filteredTimeline15</td>\n",
       "      <td>15</td>\n",
       "      <td>Timeline</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>268</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>lu</td>\n",
       "      <td>filteredTimeline15</td>\n",
       "      <td>15</td>\n",
       "      <td>Timeline</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>269</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>lu</td>\n",
       "      <td>filteredTimeline15</td>\n",
       "      <td>15</td>\n",
       "      <td>Timeline</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>lu</td>\n",
       "      <td>filteredTimeline15</td>\n",
       "      <td>15</td>\n",
       "      <td>Timeline</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>lu</td>\n",
       "      <td>filteredTimeline15</td>\n",
       "      <td>15</td>\n",
       "      <td>Timeline</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2818 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     y_test  y_pred target            exp_name  n_comments  text_col  hit\n",
       "0     False    True     ig  filteredTimeline15          15  Timeline    0\n",
       "1     False   False     ig  filteredTimeline15          15  Timeline    1\n",
       "2     False    True     ig  filteredTimeline15          15  Timeline    0\n",
       "3      True    True     ig  filteredTimeline15          15  Timeline    1\n",
       "4      True    True     ig  filteredTimeline15          15  Timeline    1\n",
       "..      ...     ...    ...                 ...         ...       ...  ...\n",
       "267    True    True     lu  filteredTimeline15          15  Timeline    1\n",
       "268   False   False     lu  filteredTimeline15          15  Timeline    1\n",
       "269    True   False     lu  filteredTimeline15          15  Timeline    0\n",
       "270    True    True     lu  filteredTimeline15          15  Timeline    1\n",
       "271    True    True     lu  filteredTimeline15          15  Timeline    1\n",
       "\n",
       "[2818 rows x 7 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_responses_final['hit'] = df_responses_final.apply(lambda x: 1 if x.y_test == x.y_pred else 0,axis = 1)\n",
    "df_responses_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "da7bfb41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_test</th>\n",
       "      <th>y_pred</th>\n",
       "      <th>target</th>\n",
       "      <th>exp_name</th>\n",
       "      <th>n_comments</th>\n",
       "      <th>text_col</th>\n",
       "      <th>hit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>ig</td>\n",
       "      <td>filteredTimeline15</td>\n",
       "      <td>15</td>\n",
       "      <td>Timeline</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>ig</td>\n",
       "      <td>filteredTimeline15</td>\n",
       "      <td>15</td>\n",
       "      <td>Timeline</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>ig</td>\n",
       "      <td>filteredTimeline15</td>\n",
       "      <td>15</td>\n",
       "      <td>Timeline</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>ig</td>\n",
       "      <td>filteredTimeline15</td>\n",
       "      <td>15</td>\n",
       "      <td>Timeline</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>ig</td>\n",
       "      <td>filteredTimeline15</td>\n",
       "      <td>15</td>\n",
       "      <td>Timeline</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>267</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>lu</td>\n",
       "      <td>filteredTimeline15</td>\n",
       "      <td>15</td>\n",
       "      <td>Timeline</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>268</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>lu</td>\n",
       "      <td>filteredTimeline15</td>\n",
       "      <td>15</td>\n",
       "      <td>Timeline</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>269</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>lu</td>\n",
       "      <td>filteredTimeline15</td>\n",
       "      <td>15</td>\n",
       "      <td>Timeline</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>lu</td>\n",
       "      <td>filteredTimeline15</td>\n",
       "      <td>15</td>\n",
       "      <td>Timeline</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271</th>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>lu</td>\n",
       "      <td>filteredTimeline15</td>\n",
       "      <td>15</td>\n",
       "      <td>Timeline</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2818 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     y_test  y_pred target            exp_name  n_comments  text_col  hit\n",
       "0     False    True     ig  filteredTimeline15          15  Timeline    0\n",
       "1     False   False     ig  filteredTimeline15          15  Timeline    1\n",
       "2     False    True     ig  filteredTimeline15          15  Timeline    0\n",
       "3      True    True     ig  filteredTimeline15          15  Timeline    1\n",
       "4      True    True     ig  filteredTimeline15          15  Timeline    1\n",
       "..      ...     ...    ...                 ...         ...       ...  ...\n",
       "267    True    True     lu  filteredTimeline15          15  Timeline    1\n",
       "268   False   False     lu  filteredTimeline15          15  Timeline    1\n",
       "269    True   False     lu  filteredTimeline15          15  Timeline    0\n",
       "270    True    True     lu  filteredTimeline15          15  Timeline    1\n",
       "271    True    True     lu  filteredTimeline15          15  Timeline    1\n",
       "\n",
       "[2818 rows x 7 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_responses_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c8315e24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_test</th>\n",
       "      <th>y_pred</th>\n",
       "      <th>hit</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n_comments</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.484031</td>\n",
       "      <td>0.669624</td>\n",
       "      <td>0.675302</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              y_test    y_pred       hit\n",
       "n_comments                              \n",
       "15          0.484031  0.669624  0.675302"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_responses_final.groupby('n_comments').mean('hit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f92c86a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8314b024",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
