{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from joblib import Parallel, delayed\n",
    "from joblib_progress import joblib_progress\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import LabelEncoder, MaxAbsScaler\n",
    "import numpy as np\n",
    "from imblearn.over_sampling import RandomOverSampler, SMOTE\n",
    "from imblearn.pipeline import Pipeline as IMBPipeline\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from nltk.corpus import stopwords\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.feature_selection import RFE\n",
    "from tsfresh.feature_extraction import MinimalFCParameters\n",
    "from tsfresh.feature_extraction import extract_features\n",
    "tqdm.pandas()\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore') \n",
    "\n",
    "\n",
    "import sys\n",
    "sys.path.append('../src/')\n",
    "from models.classification_methods import process_classification "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'neuralmind/bert-base-portuguese-cased'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_seed = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data_path = '../data/raw/'\n",
    "processed_data_path = '../data/processed/'\n",
    "results_cr_path = '../reports/classification_reports/'\n",
    "test_results_path = '../reports/test_results/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_list = ['ig','bo', 'cl', 'co', 'gl', 'lu']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_pandas(\n",
    "    path,\n",
    "    file_type = 'csv',\n",
    "    read_data_args = {}\n",
    "):\n",
    "    \n",
    "    match file_type:\n",
    "        case 'csv':\n",
    "            data = pd.read_csv(path, **read_data_args)\n",
    "        case 'parquet':\n",
    "            data =pd.read_parquet(path, **read_data_args)\n",
    "            \n",
    "    return data\n",
    "\n",
    "def create_train_test_tuples(\n",
    "    list_train_paths,\n",
    "    list_test_paths,\n",
    "    target_list,\n",
    "    n_jobs = -1, \n",
    "    file_type = 'csv',\n",
    "    read_data_args = {}\n",
    "):\n",
    "    \n",
    "    if (len(list_train_paths) != len(list_test_paths)) or (len(list_train_paths) != len(target_list)):\n",
    "        \n",
    "        raise Exception('The lists are not the same length')\n",
    "    \n",
    "    len_data_paths = len(list_train_paths)\n",
    "    data_paths = zip(list_train_paths, list_test_paths,target_list)\n",
    "    \n",
    "    func_read_data = lambda a,b,c: (read_pandas(a,file_type = file_type,read_data_args = read_data_args),read_pandas(b,file_type = file_type, read_data_args = read_data_args),c)\n",
    "    \n",
    "    with joblib_progress('Reading data ...', total =len_data_paths):\n",
    "        \n",
    "        parallel  = Parallel(n_jobs=n_jobs)\n",
    "        list_tuples = parallel(delayed(func_read_data)(a,b,c) for a,b,c in data_paths)\n",
    "        \n",
    "    return list_tuples\n",
    "\n",
    "def generate_results( \n",
    "        data_tuples_list,\n",
    "        corpus_name, \n",
    "        X_col,\n",
    "        clf,\n",
    "        reports_path = '../reports/',\n",
    "        estimator_name = None\n",
    "):\n",
    "        \n",
    "        if estimator_name is None:\n",
    "                estimator_name = clf.get('estimator').__class__.__name__\n",
    "                \n",
    "        # get results\n",
    "        results_cr_path = f'{reports_path}classification_reports/'\n",
    "        test_results_path = f'{reports_path}test_results/'\n",
    "\n",
    "        df_cr, df_test_results = process_classification(\n",
    "                **clf,\n",
    "                data_tuples = data_tuples_list,\n",
    "                X_cols = X_col\n",
    "        )\n",
    "        \n",
    "        if 'emb' in X_col[0]:\n",
    "            str_cols = 'emb'\n",
    "        else:\n",
    "            str_cols = '_'.join(X_col)\n",
    "\n",
    "        df_cr.to_csv(results_cr_path + f'{estimator_name}_{corpus_name}_{str_cols}_classification_report.csv')\n",
    "        df_test_results.to_csv(test_results_path + f'{estimator_name}_{corpus_name}_{str_cols}_test_results.csv')\n",
    "        \n",
    "        return df_cr, df_test_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_ment_time_path = raw_data_path + '{}_r3_{}_top_mentioned_timelines.csv'\n",
    "list_train_paths_tmt = [top_ment_time_path.format(\"train\",t) for t in target_list]\n",
    "list_test_paths_tmt = [top_ment_time_path.format(\"test\",t) for t in target_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "users_path = raw_data_path + 'r3_{}_{}_users.csv'\n",
    "list_train_paths_users = [users_path.format(t,\"train\") for t in target_list]\n",
    "list_test_paths_users = [users_path.format(t,\"test\") for t in target_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'neuralmind/bert-base-portuguese-cased'\n",
    "\n",
    "top_ment_time_emb_path = processed_data_path + '{}_r3_{}_top_mentioned_timelines_{}.parquet'\n",
    "list_train_paths_tmt_emb = [top_ment_time_emb_path.format(\"train\",t, model_name.replace(\"/\", \"_\")) for t in target_list]\n",
    "list_test_paths_tmt_emb = [top_ment_time_emb_path.format(\"test\",t, model_name.replace(\"/\", \"_\")) for t in target_list]\n",
    "\n",
    "\n",
    "users_emb_path = processed_data_path + 'r3_{}_{}_users_{}.parquet'\n",
    "list_train_paths_users_emb = [users_emb_path.format(t,\"train\", model_name.replace(\"/\", \"_\")) for t in target_list]\n",
    "list_test_paths_users_emb = [users_emb_path.format(t,\"test\", model_name.replace(\"/\", \"_\")) for t in target_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_to_test = {\n",
    "    'dummy': {\n",
    "        'estimator': DummyClassifier()\n",
    "    },\n",
    "    'tfidf_xgb':{\n",
    "        'preprocessing': TfidfVectorizer(\n",
    "                    stop_words = stopwords.words('portuguese'),\n",
    "                    lowercase = True,\n",
    "                    # ngram_range = (1,3),\n",
    "                    # max_features=50\n",
    "                    \n",
    "                    ),\n",
    "        'scaling': MaxAbsScaler(),\n",
    "        'estimator':  XGBClassifier(\n",
    "                random_state = 42,\n",
    "                verbosity = 3,\n",
    "                device = 'cuda',\n",
    "                tree_method = 'hist'\n",
    "                )\n",
    "    }\n",
    "}\n",
    "\n",
    "clf_to_test_emb = {\n",
    "    'bertimbau_xgb':{\n",
    "        'scaling': MaxAbsScaler(),\n",
    "        'estimator':  XGBClassifier(\n",
    "                random_state = 42,\n",
    "                verbosity = 3,\n",
    "                device = 'cuda',\n",
    "                tree_method = 'hist'\n",
    "                )\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "# X_cols_comb: possible combinations of X_col\n",
    "config_experiments_dict = {\n",
    "    'top_mentioned_timelines':{\n",
    "        'list_train_paths': list_train_paths_tmt,\n",
    "        'list_test_paths' : list_test_paths_tmt,\n",
    "        'file_type': 'csv',\n",
    "        'read_data_args' : {'sep': ';', 'encoding': 'utf-8-sig'},\n",
    "        'X_cols_comb': [['Texts']],\n",
    "        'clf_to_test': clf_to_test\n",
    "    },\n",
    "    'users':{\n",
    "        'list_train_paths': list_train_paths_users,\n",
    "        'list_test_paths' : list_test_paths_users,\n",
    "        'file_type': 'csv',\n",
    "        'read_data_args' : {'sep': ';', 'encoding': 'utf-8-sig'},\n",
    "        'X_cols_comb': [['Timeline'], ['Stance']],\n",
    "        'clf_to_test': clf_to_test\n",
    "    },\n",
    "    'users_emb':{\n",
    "        'list_train_paths': list_train_paths_users_emb,\n",
    "        'list_test_paths' : list_test_paths_users_emb,\n",
    "        'file_type': 'parquet',\n",
    "        'read_data_args' : {},\n",
    "        'X_cols_comb': [\n",
    "            [f'Timeline_emb_{i + 1}' for i in range(768)], \n",
    "            [f'Stance_emb_{i + 1}' for i in range(768)]\n",
    "            ],\n",
    "        'clf_to_test': clf_to_test_emb\n",
    "    },\n",
    "    'top_mentioned_timelines_emb':{\n",
    "        'list_train_paths': list_train_paths_tmt_emb,\n",
    "        'list_test_paths' : list_test_paths_tmt_emb,\n",
    "        'file_type': 'parquet',\n",
    "        'read_data_args' : {},\n",
    "        'X_cols_comb': [\n",
    "            [f'Texts_emb_{i + 1}' for i in range(768)]\n",
    "            ],\n",
    "        'clf_to_test': clf_to_test_emb\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd730620dff94622bf3de5e0f40af52e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##### Start of top_mentioned_timelines - 2024-04-21 19:30:06.682840 #####\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Running combination ['Texts']\n",
      "Training ...\n",
      "[Pipeline] ..... (step 1 of 5) Processing preprocessing, total=   0.0s\n",
      "[Pipeline] .......... (step 2 of 5) Processing sampling, total=   0.0s\n",
      "[Pipeline] ........... (step 3 of 5) Processing scaling, total=   0.0s\n",
      "[Pipeline] ......... (step 4 of 5) Processing selection, total=   0.0s\n",
      "[Pipeline] ......... (step 5 of 5) Processing estimator, total=   0.0s\n",
      "Training ...\n",
      "[Pipeline] ..... (step 1 of 5) Processing preprocessing, total=   0.0s\n",
      "[Pipeline] .......... (step 2 of 5) Processing sampling, total=   0.0s\n",
      "[Pipeline] ........... (step 3 of 5) Processing scaling, total=   0.0s\n",
      "[Pipeline] ......... (step 4 of 5) Processing selection, total=   0.0s\n",
      "[Pipeline] ......... (step 5 of 5) Processing estimator, total=   0.0s\n",
      "Training ...\n",
      "[Pipeline] ..... (step 1 of 5) Processing preprocessing, total=   0.0s\n",
      "[Pipeline] .......... (step 2 of 5) Processing sampling, total=   0.0s\n",
      "[Pipeline] ........... (step 3 of 5) Processing scaling, total=   0.0s\n",
      "[Pipeline] ......... (step 4 of 5) Processing selection, total=   0.0s\n",
      "[Pipeline] ......... (step 5 of 5) Processing estimator, total=   0.0s\n",
      "Training ...\n",
      "[Pipeline] ..... (step 1 of 5) Processing preprocessing, total=   0.0s\n",
      "[Pipeline] .......... (step 2 of 5) Processing sampling, total=   0.0s\n",
      "[Pipeline] ........... (step 3 of 5) Processing scaling, total=   0.0s\n",
      "[Pipeline] ......... (step 4 of 5) Processing selection, total=   0.0s\n",
      "[Pipeline] ......... (step 5 of 5) Processing estimator, total=   0.0s\n",
      "Training ...\n",
      "[Pipeline] ..... (step 1 of 5) Processing preprocessing, total=   0.0s\n",
      "[Pipeline] .......... (step 2 of 5) Processing sampling, total=   0.0s\n",
      "[Pipeline] ........... (step 3 of 5) Processing scaling, total=   0.0s\n",
      "[Pipeline] ......... (step 4 of 5) Processing selection, total=   0.0s\n",
      "[Pipeline] ......... (step 5 of 5) Processing estimator, total=   0.0s\n",
      "Training ...\n",
      "[Pipeline] ..... (step 1 of 5) Processing preprocessing, total=   0.0s\n",
      "[Pipeline] .......... (step 2 of 5) Processing sampling, total=   0.0s\n",
      "[Pipeline] ........... (step 3 of 5) Processing scaling, total=   0.0s\n",
      "[Pipeline] ......... (step 4 of 5) Processing selection, total=   0.0s\n",
      "[Pipeline] ......... (step 5 of 5) Processing estimator, total=   0.0s\n",
      "- Running combination ['Texts']\n",
      "Training ...\n",
      "[Pipeline] ..... (step 1 of 5) Processing preprocessing, total=  26.9s\n",
      "[Pipeline] .......... (step 2 of 5) Processing sampling, total=   0.0s\n",
      "[Pipeline] ........... (step 3 of 5) Processing scaling, total=   0.5s\n",
      "[Pipeline] ......... (step 4 of 5) Processing selection, total=   0.0s\n",
      "[19:30:48] ======== Monitor (0): HostSketchContainer ========\n",
      "[19:30:48] AllReduce: 0.059351s, 1 calls @ 59351us\n",
      "\n",
      "[19:30:48] MakeCuts: 0.132457s, 1 calls @ 132457us\n",
      "\n",
      "[19:30:48] DEBUG: /workspace/src/gbm/gbtree.cc:130: Using tree method: 3\n",
      "[19:30:48] DEBUG: /workspace/src/tree/updater_gpu_hist.cu:744: [GPU Hist]: Configure\n",
      "[19:30:48] ======== Monitor (0):  ========\n",
      "[19:30:48] InitCompressedData: 0.000579s, 1 calls @ 579us\n",
      "\n",
      "[19:30:53] ======== Monitor (0): Learner ========\n",
      "[19:30:53] Configure: 0.015288s, 1 calls @ 15288us\n",
      "\n",
      "[19:30:53] EvalOneIter: 0.000852s, 100 calls @ 852us\n",
      "\n",
      "[19:30:53] GetGradient: 0.00601s, 100 calls @ 6010us\n",
      "\n",
      "[19:30:53] PredictRaw: 0.000157s, 100 calls @ 157us\n",
      "\n",
      "[19:30:53] UpdateOneIter: 4.62215s, 100 calls @ 4622152us\n",
      "\n",
      "[19:30:53] ======== Monitor (0): GBTree ========\n",
      "[19:30:53] BoostNewTrees: 4.59571s, 100 calls @ 4595709us\n",
      "\n",
      "[19:30:53] CommitModel: 5.5e-05s, 100 calls @ 55us\n",
      "\n",
      "[19:30:53] ======== Device 0 Memory Allocations:  ========\n",
      "[19:30:53] Peak memory usage: 694MiB\n",
      "[19:30:53] Number of allocations: 1447\n",
      "[19:30:53] ======== Monitor (0): updater_gpu_hist ========\n",
      "[19:30:53] InitData: 0.000897s, 100 calls @ 897us\n",
      "\n",
      "[19:30:53] InitDataOnce: 0.000878s, 1 calls @ 878us\n",
      "\n",
      "[19:30:53] Update: 4.59171s, 100 calls @ 4591706us\n",
      "\n",
      "[19:30:53] UpdatePredictionCache: 0.003159s, 100 calls @ 3159us\n",
      "\n",
      "[19:30:53] ======== Monitor (0): gradient_based_sampler ========\n",
      "[19:30:53] Sample: 0.02153s, 100 calls @ 21530us\n",
      "\n",
      "[19:30:53] ======== Monitor (0): GPUHistMakerDevice0 ========\n",
      "[19:30:53] AllReduce: 9.8e-05s, 102 calls @ 98us\n",
      "\n",
      "[19:30:53] BuildHist: 0.004396s, 2 calls @ 4396us\n",
      "\n",
      "[19:30:53] EvaluateSplits: 0.16775s, 2 calls @ 167750us\n",
      "\n",
      "[19:30:53] FinalisePosition: 0.009619s, 100 calls @ 9619us\n",
      "\n",
      "[19:30:53] InitRoot: 4.20631s, 100 calls @ 4206313us\n",
      "\n",
      "[19:30:53] Reset: 0.201214s, 100 calls @ 201214us\n",
      "\n",
      "[19:30:53] UpdatePosition: 0.000351s, 2 calls @ 351us\n",
      "\n",
      "[Pipeline] ......... (step 5 of 5) Processing estimator, total=   6.0s\n",
      "[19:31:01] DEBUG: /workspace/src/gbm/gbtree.cc:130: Using tree method: 3\n",
      "[19:31:01] DEBUG: /workspace/src/tree/updater_gpu_hist.cu:744: [GPU Hist]: Configure\n",
      "Training ...\n",
      "[Pipeline] ..... (step 1 of 5) Processing preprocessing, total=   8.3s\n",
      "[Pipeline] .......... (step 2 of 5) Processing sampling, total=   0.0s\n",
      "[Pipeline] ........... (step 3 of 5) Processing scaling, total=   0.1s\n",
      "[Pipeline] ......... (step 4 of 5) Processing selection, total=   0.0s\n",
      "[19:31:18] ======== Monitor (0): HostSketchContainer ========\n",
      "[19:31:18] AllReduce: 0.025638s, 1 calls @ 25638us\n",
      "\n",
      "[19:31:18] MakeCuts: 0.045251s, 1 calls @ 45251us\n",
      "\n",
      "[19:31:18] DEBUG: /workspace/src/gbm/gbtree.cc:130: Using tree method: 3\n",
      "[19:31:18] DEBUG: /workspace/src/tree/updater_gpu_hist.cu:744: [GPU Hist]: Configure\n",
      "[19:31:18] ======== Monitor (0):  ========\n",
      "[19:31:18] InitCompressedData: 0.000193s, 1 calls @ 193us\n",
      "\n",
      "[19:31:18] DEBUG: /workspace/src/tree/gpu_hist/../../common/device_helpers.cuh:291: Skipping empty CUDA kernel.\n",
      "[19:31:20] ======== Monitor (0): Learner ========\n",
      "[19:31:20] Configure: 0.000667s, 1 calls @ 667us\n",
      "\n",
      "[19:31:20] EvalOneIter: 0.000675s, 100 calls @ 675us\n",
      "\n",
      "[19:31:20] GetGradient: 0.003723s, 100 calls @ 3723us\n",
      "\n",
      "[19:31:20] PredictRaw: 0.000117s, 100 calls @ 117us\n",
      "\n",
      "[19:31:20] UpdateOneIter: 1.72806s, 100 calls @ 1728061us\n",
      "\n",
      "[19:31:20] ======== Monitor (0): GBTree ========\n",
      "[19:31:20] BoostNewTrees: 1.72236s, 100 calls @ 1722358us\n",
      "\n",
      "[19:31:20] CommitModel: 5.9e-05s, 100 calls @ 59us\n",
      "\n",
      "[19:31:20] ======== Device 0 Memory Allocations:  ========\n",
      "[19:31:20] Peak memory usage: 694MiB\n",
      "[19:31:20] Number of allocations: 2915\n",
      "[19:31:20] ======== Monitor (0): updater_gpu_hist ========\n",
      "[19:31:20] InitData: 0.000589s, 100 calls @ 589us\n",
      "\n",
      "[19:31:20] InitDataOnce: 0.000576s, 1 calls @ 576us\n",
      "\n",
      "[19:31:20] Update: 1.71967s, 100 calls @ 1719670us\n",
      "\n",
      "[19:31:20] UpdatePredictionCache: 0.002029s, 100 calls @ 2029us\n",
      "\n",
      "[19:31:20] ======== Monitor (0): gradient_based_sampler ========\n",
      "[19:31:20] Sample: 0.005463s, 100 calls @ 5463us\n",
      "\n",
      "[19:31:20] ======== Monitor (0): GPUHistMakerDevice0 ========\n",
      "[19:31:20] AllReduce: 8e-05s, 102 calls @ 80us\n",
      "\n",
      "[19:31:20] BuildHist: 0.001736s, 2 calls @ 1736us\n",
      "\n",
      "[19:31:20] EvaluateSplits: 0.068163s, 2 calls @ 68163us\n",
      "\n",
      "[19:31:20] FinalisePosition: 0.004213s, 100 calls @ 4213us\n",
      "\n",
      "[19:31:20] InitRoot: 1.50195s, 100 calls @ 1501950us\n",
      "\n",
      "[19:31:20] Reset: 0.141746s, 100 calls @ 141746us\n",
      "\n",
      "[19:31:20] UpdatePosition: 0.000187s, 2 calls @ 187us\n",
      "\n",
      "[19:31:20] ======== Monitor (0): Learner ========\n",
      "[19:31:20] Configure: 0.000619s, 1 calls @ 619us\n",
      "\n",
      "[19:31:20] ======== Monitor (0): GBTree ========\n",
      "[19:31:20] ======== Device 0 Memory Allocations:  ========\n",
      "[19:31:20] Peak memory usage: 694MiB\n",
      "[19:31:20] Number of allocations: 2915\n",
      "[19:31:20] ======== Monitor (0): updater_gpu_hist ========\n",
      "[Pipeline] ......... (step 5 of 5) Processing estimator, total=   2.1s\n",
      "[19:31:23] DEBUG: /workspace/src/gbm/gbtree.cc:130: Using tree method: 3\n",
      "[19:31:23] DEBUG: /workspace/src/tree/updater_gpu_hist.cu:744: [GPU Hist]: Configure\n",
      "Training ...\n",
      "[Pipeline] ..... (step 1 of 5) Processing preprocessing, total=  40.9s\n",
      "[Pipeline] .......... (step 2 of 5) Processing sampling, total=   0.0s\n",
      "[Pipeline] ........... (step 3 of 5) Processing scaling, total=   0.6s\n",
      "[Pipeline] ......... (step 4 of 5) Processing selection, total=   0.0s\n",
      "[19:32:08] ======== Monitor (0): HostSketchContainer ========\n",
      "[19:32:08] AllReduce: 0.066367s, 1 calls @ 66367us\n",
      "\n",
      "[19:32:08] MakeCuts: 0.128419s, 1 calls @ 128419us\n",
      "\n",
      "[19:32:08] DEBUG: /workspace/src/gbm/gbtree.cc:130: Using tree method: 3\n",
      "[19:32:08] DEBUG: /workspace/src/tree/updater_gpu_hist.cu:744: [GPU Hist]: Configure\n",
      "[19:32:08] ======== Monitor (0):  ========\n",
      "[19:32:08] InitCompressedData: 0.000707s, 1 calls @ 707us\n",
      "\n",
      "[19:32:08] DEBUG: /workspace/src/tree/gpu_hist/../../common/device_helpers.cuh:291: Skipping empty CUDA kernel.\n",
      "[19:32:09] DEBUG: /workspace/src/tree/gpu_hist/../../common/device_helpers.cuh:291: Skipping empty CUDA kernel.\n",
      "[19:32:09] DEBUG: /workspace/src/tree/gpu_hist/../../common/device_helpers.cuh:291: Skipping empty CUDA kernel.\n",
      "[19:32:09] DEBUG: /workspace/src/tree/gpu_hist/../../common/device_helpers.cuh:291: Skipping empty CUDA kernel.\n",
      "[19:32:14] ======== Monitor (0): Learner ========\n",
      "[19:32:14] Configure: 0.007932s, 1 calls @ 7932us\n",
      "\n",
      "[19:32:14] EvalOneIter: 0.000868s, 100 calls @ 868us\n",
      "\n",
      "[19:32:14] GetGradient: 0.005791s, 100 calls @ 5791us\n",
      "\n",
      "[19:32:14] PredictRaw: 0.000141s, 100 calls @ 141us\n",
      "\n",
      "[19:32:14] UpdateOneIter: 5.1845s, 100 calls @ 5184503us\n",
      "\n",
      "[19:32:14] ======== Monitor (0): GBTree ========\n",
      "[19:32:14] BoostNewTrees: 5.16837s, 100 calls @ 5168373us\n",
      "\n",
      "[19:32:14] CommitModel: 5.6e-05s, 100 calls @ 56us\n",
      "\n",
      "[19:32:14] ======== Device 0 Memory Allocations:  ========\n",
      "[19:32:14] Peak memory usage: 1299MiB\n",
      "[19:32:14] Number of allocations: 4418\n",
      "[19:32:14] ======== Monitor (0): updater_gpu_hist ========\n",
      "[19:32:14] InitData: 0.000649s, 100 calls @ 649us\n",
      "\n",
      "[19:32:14] InitDataOnce: 0.000635s, 1 calls @ 635us\n",
      "\n",
      "[19:32:14] Update: 5.16447s, 100 calls @ 5164471us\n",
      "\n",
      "[19:32:14] UpdatePredictionCache: 0.002785s, 100 calls @ 2785us\n",
      "\n",
      "[19:32:14] ======== Monitor (0): gradient_based_sampler ========\n",
      "[19:32:14] Sample: 0.020564s, 100 calls @ 20564us\n",
      "\n",
      "[19:32:14] ======== Monitor (0): GPUHistMakerDevice0 ========\n",
      "[19:32:14] AllReduce: 0.000106s, 106 calls @ 106us\n",
      "\n",
      "[19:32:14] BuildHist: 0.009318s, 7 calls @ 9318us\n",
      "\n",
      "[19:32:14] EvaluateSplits: 0.395952s, 7 calls @ 395952us\n",
      "\n",
      "[19:32:14] FinalisePosition: 0.007241s, 100 calls @ 7241us\n",
      "\n",
      "[19:32:14] InitRoot: 4.57082s, 100 calls @ 4570817us\n",
      "\n",
      "[19:32:14] Reset: 0.178225s, 100 calls @ 178225us\n",
      "\n",
      "[19:32:14] UpdatePosition: 0.0009s, 7 calls @ 900us\n",
      "\n",
      "[19:32:14] ======== Monitor (0): Learner ========\n",
      "[19:32:14] Configure: 0.000591s, 1 calls @ 591us\n",
      "\n",
      "[19:32:14] ======== Monitor (0): GBTree ========\n",
      "[19:32:14] ======== Device 0 Memory Allocations:  ========\n",
      "[19:32:14] Peak memory usage: 1299MiB\n",
      "[19:32:14] Number of allocations: 4418\n",
      "[19:32:14] ======== Monitor (0): updater_gpu_hist ========\n",
      "[Pipeline] ......... (step 5 of 5) Processing estimator, total=   6.8s\n",
      "[19:32:27] DEBUG: /workspace/src/gbm/gbtree.cc:130: Using tree method: 3\n",
      "[19:32:27] DEBUG: /workspace/src/tree/updater_gpu_hist.cu:744: [GPU Hist]: Configure\n",
      "Training ...\n",
      "[Pipeline] ..... (step 1 of 5) Processing preprocessing, total=  59.2s\n",
      "[Pipeline] .......... (step 2 of 5) Processing sampling, total=   0.0s\n",
      "[Pipeline] ........... (step 3 of 5) Processing scaling, total=   1.2s\n",
      "[Pipeline] ......... (step 4 of 5) Processing selection, total=   0.0s\n",
      "[19:33:42] ======== Monitor (0): HostSketchContainer ========\n",
      "[19:33:42] AllReduce: 0.087188s, 1 calls @ 87188us\n",
      "\n",
      "[19:33:42] MakeCuts: 0.158426s, 1 calls @ 158426us\n",
      "\n",
      "[19:33:42] DEBUG: /workspace/src/gbm/gbtree.cc:130: Using tree method: 3\n",
      "[19:33:42] DEBUG: /workspace/src/tree/updater_gpu_hist.cu:744: [GPU Hist]: Configure\n",
      "[19:33:42] ======== Monitor (0):  ========\n",
      "[19:33:42] InitCompressedData: 0.000919s, 1 calls @ 919us\n",
      "\n",
      "[19:33:43] DEBUG: /workspace/src/tree/gpu_hist/../../common/device_helpers.cuh:291: Skipping empty CUDA kernel.\n",
      "[19:33:43] DEBUG: /workspace/src/tree/gpu_hist/../../common/device_helpers.cuh:291: Skipping empty CUDA kernel.\n",
      "[19:33:43] DEBUG: /workspace/src/tree/gpu_hist/../../common/device_helpers.cuh:291: Skipping empty CUDA kernel.\n",
      "[19:33:43] DEBUG: /workspace/src/tree/gpu_hist/../../common/device_helpers.cuh:291: Skipping empty CUDA kernel.\n",
      "[19:33:49] ======== Monitor (0): Learner ========\n",
      "[19:33:49] Configure: 0.00599s, 1 calls @ 5990us\n",
      "\n",
      "[19:33:49] EvalOneIter: 0.000859s, 100 calls @ 859us\n",
      "\n",
      "[19:33:49] GetGradient: 0.004862s, 100 calls @ 4862us\n",
      "\n",
      "[19:33:49] PredictRaw: 0.000146s, 100 calls @ 146us\n",
      "\n",
      "[19:33:49] UpdateOneIter: 6.90863s, 100 calls @ 6908632us\n",
      "\n",
      "[19:33:49] ======== Monitor (0): GBTree ========\n",
      "[19:33:49] BoostNewTrees: 6.89637s, 100 calls @ 6896367us\n",
      "\n",
      "[19:33:49] CommitModel: 5.9e-05s, 100 calls @ 59us\n",
      "\n",
      "[19:33:49] ======== Device 0 Memory Allocations:  ========\n",
      "[19:33:49] Peak memory usage: 1902MiB\n",
      "[19:33:49] Number of allocations: 5912\n",
      "[19:33:49] ======== Monitor (0): updater_gpu_hist ========\n",
      "[19:33:49] InitData: 0.000884s, 100 calls @ 884us\n",
      "\n",
      "[19:33:49] InitDataOnce: 0.00087s, 1 calls @ 870us\n",
      "\n",
      "[19:33:49] Update: 6.8932s, 100 calls @ 6893197us\n",
      "\n",
      "[19:33:49] UpdatePredictionCache: 0.002346s, 100 calls @ 2346us\n",
      "\n",
      "[19:33:49] ======== Monitor (0): gradient_based_sampler ========\n",
      "[19:33:49] Sample: 0.026724s, 100 calls @ 26724us\n",
      "\n",
      "[19:33:49] ======== Monitor (0): GPUHistMakerDevice0 ========\n",
      "[19:33:49] AllReduce: 0.000108s, 105 calls @ 108us\n",
      "\n",
      "[19:33:49] BuildHist: 0.011826s, 6 calls @ 11826us\n",
      "\n",
      "[19:33:49] EvaluateSplits: 0.471421s, 6 calls @ 471421us\n",
      "\n",
      "[19:33:49] FinalisePosition: 0.006199s, 100 calls @ 6199us\n",
      "\n",
      "[19:33:49] InitRoot: 6.2009s, 100 calls @ 6200905us\n",
      "\n",
      "[19:33:49] Reset: 0.199125s, 100 calls @ 199125us\n",
      "\n",
      "[19:33:49] UpdatePosition: 0.00159s, 6 calls @ 1590us\n",
      "\n",
      "[19:33:49] ======== Monitor (0): Learner ========\n",
      "[19:33:49] Configure: 0.000614s, 1 calls @ 614us\n",
      "\n",
      "[19:33:49] ======== Monitor (0): GBTree ========\n",
      "[19:33:49] ======== Device 0 Memory Allocations:  ========\n",
      "[19:33:49] Peak memory usage: 1902MiB\n",
      "[19:33:49] Number of allocations: 5912\n",
      "[19:33:49] ======== Monitor (0): updater_gpu_hist ========\n",
      "[Pipeline] ......... (step 5 of 5) Processing estimator, total=   9.1s\n",
      "[19:34:08] DEBUG: /workspace/src/gbm/gbtree.cc:130: Using tree method: 3\n",
      "[19:34:08] DEBUG: /workspace/src/tree/updater_gpu_hist.cu:744: [GPU Hist]: Configure\n",
      "Training ...\n",
      "[Pipeline] ..... (step 1 of 5) Processing preprocessing, total=  22.5s\n",
      "[Pipeline] .......... (step 2 of 5) Processing sampling, total=   0.0s\n",
      "[Pipeline] ........... (step 3 of 5) Processing scaling, total=   0.3s\n",
      "[Pipeline] ......... (step 4 of 5) Processing selection, total=   0.0s\n",
      "[19:34:51] ======== Monitor (0): HostSketchContainer ========\n",
      "[19:34:51] AllReduce: 0.035261s, 1 calls @ 35261us\n",
      "\n",
      "[19:34:51] MakeCuts: 0.071401s, 1 calls @ 71401us\n",
      "\n",
      "[19:34:51] DEBUG: /workspace/src/gbm/gbtree.cc:130: Using tree method: 3\n",
      "[19:34:51] DEBUG: /workspace/src/tree/updater_gpu_hist.cu:744: [GPU Hist]: Configure\n",
      "[19:34:51] ======== Monitor (0):  ========\n",
      "[19:34:51] InitCompressedData: 0.000536s, 1 calls @ 536us\n",
      "\n",
      "[19:34:51] DEBUG: /workspace/src/tree/gpu_hist/../../common/device_helpers.cuh:291: Skipping empty CUDA kernel.\n",
      "[19:34:51] DEBUG: /workspace/src/tree/gpu_hist/../../common/device_helpers.cuh:291: Skipping empty CUDA kernel.\n",
      "[19:34:51] DEBUG: /workspace/src/tree/gpu_hist/../../common/device_helpers.cuh:291: Skipping empty CUDA kernel.\n",
      "[19:34:51] DEBUG: /workspace/src/tree/gpu_hist/../../common/device_helpers.cuh:291: Skipping empty CUDA kernel.\n",
      "[19:34:55] ======== Monitor (0): Learner ========\n",
      "[19:34:55] Configure: 0.005944s, 1 calls @ 5944us\n",
      "\n",
      "[19:34:55] EvalOneIter: 0.000823s, 100 calls @ 823us\n",
      "\n",
      "[19:34:55] GetGradient: 0.004587s, 100 calls @ 4587us\n",
      "\n",
      "[19:34:55] PredictRaw: 0.000128s, 100 calls @ 128us\n",
      "\n",
      "[19:34:55] UpdateOneIter: 3.66287s, 100 calls @ 3662874us\n",
      "\n",
      "[19:34:55] ======== Monitor (0): GBTree ========\n",
      "[19:34:55] BoostNewTrees: 3.65079s, 100 calls @ 3650790us\n",
      "\n",
      "[19:34:55] CommitModel: 5.4e-05s, 100 calls @ 54us\n",
      "\n",
      "[19:34:55] ======== Device 0 Memory Allocations:  ========\n",
      "[19:34:55] Peak memory usage: 1902MiB\n",
      "[19:34:55] Number of allocations: 7406\n",
      "[19:34:55] ======== Monitor (0): updater_gpu_hist ========\n",
      "[19:34:55] InitData: 0.000496s, 100 calls @ 496us\n",
      "\n",
      "[19:34:55] InitDataOnce: 0.000482s, 1 calls @ 482us\n",
      "\n",
      "[19:34:55] Update: 3.64784s, 100 calls @ 3647842us\n",
      "\n",
      "[19:34:55] UpdatePredictionCache: 0.002186s, 100 calls @ 2186us\n",
      "\n",
      "[19:34:55] ======== Monitor (0): gradient_based_sampler ========\n",
      "[19:34:55] Sample: 0.013722s, 100 calls @ 13722us\n",
      "\n",
      "[19:34:55] ======== Monitor (0): GPUHistMakerDevice0 ========\n",
      "[19:34:55] AllReduce: 0.000104s, 105 calls @ 104us\n",
      "\n",
      "[19:34:55] BuildHist: 0.007298s, 6 calls @ 7298us\n",
      "\n",
      "[19:34:55] EvaluateSplits: 0.250403s, 6 calls @ 250403us\n",
      "\n",
      "[19:34:55] FinalisePosition: 0.00501s, 100 calls @ 5010us\n",
      "\n",
      "[19:34:55] InitRoot: 3.23379s, 100 calls @ 3233792us\n",
      "\n",
      "[19:34:55] Reset: 0.148621s, 100 calls @ 148621us\n",
      "\n",
      "[19:34:55] UpdatePosition: 0.000956s, 6 calls @ 956us\n",
      "\n",
      "[19:34:55] ======== Monitor (0): Learner ========\n",
      "[19:34:55] Configure: 0.007919s, 1 calls @ 7919us\n",
      "\n",
      "[19:34:55] ======== Monitor (0): GBTree ========\n",
      "[19:34:55] ======== Device 0 Memory Allocations:  ========\n",
      "[19:34:55] Peak memory usage: 1902MiB\n",
      "[19:34:55] Number of allocations: 7406\n",
      "[19:34:55] ======== Monitor (0): updater_gpu_hist ========\n",
      "[Pipeline] ......... (step 5 of 5) Processing estimator, total=   4.5s\n",
      "[19:35:02] DEBUG: /workspace/src/gbm/gbtree.cc:130: Using tree method: 3\n",
      "[19:35:02] DEBUG: /workspace/src/tree/updater_gpu_hist.cu:744: [GPU Hist]: Configure\n",
      "Training ...\n",
      "[Pipeline] ..... (step 1 of 5) Processing preprocessing, total=  16.7s\n",
      "[Pipeline] .......... (step 2 of 5) Processing sampling, total=   0.0s\n",
      "[Pipeline] ........... (step 3 of 5) Processing scaling, total=   0.2s\n",
      "[Pipeline] ......... (step 4 of 5) Processing selection, total=   0.0s\n",
      "[19:35:27] ======== Monitor (0): HostSketchContainer ========\n",
      "[19:35:27] AllReduce: 0.023049s, 1 calls @ 23049us\n",
      "\n",
      "[19:35:27] MakeCuts: 0.052172s, 1 calls @ 52172us\n",
      "\n",
      "[19:35:27] DEBUG: /workspace/src/gbm/gbtree.cc:130: Using tree method: 3\n",
      "[19:35:27] DEBUG: /workspace/src/tree/updater_gpu_hist.cu:744: [GPU Hist]: Configure\n",
      "[19:35:27] ======== Monitor (0):  ========\n",
      "[19:35:27] InitCompressedData: 0.000386s, 1 calls @ 386us\n",
      "\n",
      "[19:35:27] DEBUG: /workspace/src/tree/gpu_hist/../../common/device_helpers.cuh:291: Skipping empty CUDA kernel.\n",
      "[19:35:29] ======== Monitor (0): Learner ========\n",
      "[19:35:29] Configure: 0.006907s, 1 calls @ 6907us\n",
      "\n",
      "[19:35:29] EvalOneIter: 0.000807s, 100 calls @ 807us\n",
      "\n",
      "[19:35:29] GetGradient: 0.003849s, 100 calls @ 3849us\n",
      "\n",
      "[19:35:29] PredictRaw: 0.000131s, 100 calls @ 131us\n",
      "\n",
      "[19:35:29] UpdateOneIter: 2.65043s, 100 calls @ 2650432us\n",
      "\n",
      "[19:35:29] ======== Monitor (0): GBTree ========\n",
      "[19:35:29] BoostNewTrees: 2.63824s, 100 calls @ 2638238us\n",
      "\n",
      "[19:35:29] CommitModel: 6.2e-05s, 100 calls @ 62us\n",
      "\n",
      "[19:35:29] ======== Device 0 Memory Allocations:  ========\n",
      "[19:35:29] Peak memory usage: 1902MiB\n",
      "[19:35:29] Number of allocations: 8875\n",
      "[19:35:29] ======== Monitor (0): updater_gpu_hist ========\n",
      "[19:35:29] InitData: 0.00047s, 100 calls @ 470us\n",
      "\n",
      "[19:35:29] InitDataOnce: 0.000456s, 1 calls @ 456us\n",
      "\n",
      "[19:35:29] Update: 2.63536s, 100 calls @ 2635357us\n",
      "\n",
      "[19:35:29] UpdatePredictionCache: 0.002143s, 100 calls @ 2143us\n",
      "\n",
      "[19:35:29] ======== Monitor (0): gradient_based_sampler ========\n",
      "[19:35:29] Sample: 0.010024s, 100 calls @ 10024us\n",
      "\n",
      "[19:35:29] ======== Monitor (0): GPUHistMakerDevice0 ========\n",
      "[19:35:29] AllReduce: 9.7e-05s, 102 calls @ 97us\n",
      "\n",
      "[19:35:29] BuildHist: 0.00242s, 2 calls @ 2420us\n",
      "\n",
      "[19:35:29] EvaluateSplits: 0.108069s, 2 calls @ 108069us\n",
      "\n",
      "[19:35:29] FinalisePosition: 0.005204s, 100 calls @ 5204us\n",
      "\n",
      "[19:35:29] InitRoot: 2.38367s, 100 calls @ 2383671us\n",
      "\n",
      "[19:35:29] Reset: 0.134083s, 100 calls @ 134083us\n",
      "\n",
      "[19:35:29] UpdatePosition: 0.000195s, 2 calls @ 195us\n",
      "\n",
      "[19:35:29] ======== Monitor (0): Learner ========\n",
      "[19:35:29] Configure: 0.0006s, 1 calls @ 600us\n",
      "\n",
      "[19:35:29] ======== Monitor (0): GBTree ========\n",
      "[19:35:29] ======== Device 0 Memory Allocations:  ========\n",
      "[19:35:29] Peak memory usage: 1902MiB\n",
      "[19:35:29] Number of allocations: 8875\n",
      "[19:35:29] ======== Monitor (0): updater_gpu_hist ========\n",
      "[Pipeline] ......... (step 5 of 5) Processing estimator, total=   3.3s\n",
      "[19:35:34] DEBUG: /workspace/src/gbm/gbtree.cc:130: Using tree method: 3\n",
      "[19:35:34] DEBUG: /workspace/src/tree/updater_gpu_hist.cu:744: [GPU Hist]: Configure\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82db7af486f64da5a241ac57a73ce043",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##### End of top_mentioned_timelines - 2024-04-21 19:35:39.474175 #####\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "##### Start of users - 2024-04-21 19:35:39.474231 #####\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Running combination ['Timeline']\n",
      "Training ...\n",
      "[Pipeline] ..... (step 1 of 5) Processing preprocessing, total=   0.0s\n",
      "[Pipeline] .......... (step 2 of 5) Processing sampling, total=   0.0s\n",
      "[Pipeline] ........... (step 3 of 5) Processing scaling, total=   0.0s\n",
      "[Pipeline] ......... (step 4 of 5) Processing selection, total=   0.0s\n",
      "[Pipeline] ......... (step 5 of 5) Processing estimator, total=   0.0s\n",
      "Training ...\n",
      "[Pipeline] ..... (step 1 of 5) Processing preprocessing, total=   0.0s\n",
      "[Pipeline] .......... (step 2 of 5) Processing sampling, total=   0.0s\n",
      "[Pipeline] ........... (step 3 of 5) Processing scaling, total=   0.0s\n",
      "[Pipeline] ......... (step 4 of 5) Processing selection, total=   0.0s\n",
      "[Pipeline] ......... (step 5 of 5) Processing estimator, total=   0.0s\n",
      "Training ...\n",
      "[Pipeline] ..... (step 1 of 5) Processing preprocessing, total=   0.0s\n",
      "[Pipeline] .......... (step 2 of 5) Processing sampling, total=   0.0s\n",
      "[Pipeline] ........... (step 3 of 5) Processing scaling, total=   0.0s\n",
      "[Pipeline] ......... (step 4 of 5) Processing selection, total=   0.0s\n",
      "[Pipeline] ......... (step 5 of 5) Processing estimator, total=   0.0s\n",
      "Training ...\n",
      "[Pipeline] ..... (step 1 of 5) Processing preprocessing, total=   0.0s\n",
      "[Pipeline] .......... (step 2 of 5) Processing sampling, total=   0.0s\n",
      "[Pipeline] ........... (step 3 of 5) Processing scaling, total=   0.0s\n",
      "[Pipeline] ......... (step 4 of 5) Processing selection, total=   0.0s\n",
      "[Pipeline] ......... (step 5 of 5) Processing estimator, total=   0.0s\n",
      "Training ...\n",
      "[Pipeline] ..... (step 1 of 5) Processing preprocessing, total=   0.0s\n",
      "[Pipeline] .......... (step 2 of 5) Processing sampling, total=   0.0s\n",
      "[Pipeline] ........... (step 3 of 5) Processing scaling, total=   0.0s\n",
      "[Pipeline] ......... (step 4 of 5) Processing selection, total=   0.0s\n",
      "[Pipeline] ......... (step 5 of 5) Processing estimator, total=   0.0s\n",
      "Training ...\n",
      "[Pipeline] ..... (step 1 of 5) Processing preprocessing, total=   0.0s\n",
      "[Pipeline] .......... (step 2 of 5) Processing sampling, total=   0.0s\n",
      "[Pipeline] ........... (step 3 of 5) Processing scaling, total=   0.0s\n",
      "[Pipeline] ......... (step 4 of 5) Processing selection, total=   0.0s\n",
      "[Pipeline] ......... (step 5 of 5) Processing estimator, total=   0.0s\n",
      "- Running combination ['Timeline']\n",
      "Training ...\n",
      "[Pipeline] ..... (step 1 of 5) Processing preprocessing, total=  48.3s\n",
      "[Pipeline] .......... (step 2 of 5) Processing sampling, total=   0.0s\n",
      "[Pipeline] ........... (step 3 of 5) Processing scaling, total=   1.4s\n",
      "[Pipeline] ......... (step 4 of 5) Processing selection, total=   0.0s\n",
      "[19:37:00] ======== Monitor (0): HostSketchContainer ========\n",
      "[19:37:00] AllReduce: 0.160039s, 1 calls @ 160039us\n",
      "\n",
      "[19:37:00] MakeCuts: 0.268216s, 1 calls @ 268216us\n",
      "\n",
      "[19:37:00] DEBUG: /workspace/src/gbm/gbtree.cc:130: Using tree method: 3\n",
      "[19:37:00] DEBUG: /workspace/src/tree/updater_gpu_hist.cu:744: [GPU Hist]: Configure\n",
      "[19:37:00] ======== Monitor (0):  ========\n",
      "[19:37:00] InitCompressedData: 0.000824s, 1 calls @ 824us\n",
      "\n",
      "[19:37:00] DEBUG: /workspace/src/tree/gpu_hist/../../common/device_helpers.cuh:291: Skipping empty CUDA kernel.\n",
      "[19:37:00] DEBUG: /workspace/src/tree/gpu_hist/../../common/device_helpers.cuh:291: Skipping empty CUDA kernel.\n",
      "[19:37:00] DEBUG: /workspace/src/tree/gpu_hist/../../common/device_helpers.cuh:291: Skipping empty CUDA kernel.\n",
      "[19:37:06] ======== Monitor (0): Learner ========\n",
      "[19:37:06] Configure: 0.013188s, 1 calls @ 13188us\n",
      "\n",
      "[19:37:06] EvalOneIter: 0.001792s, 100 calls @ 1792us\n",
      "\n",
      "[19:37:06] GetGradient: 0.006597s, 100 calls @ 6597us\n",
      "\n",
      "[19:37:06] PredictRaw: 0.000161s, 100 calls @ 161us\n",
      "\n",
      "[19:37:06] UpdateOneIter: 6.26042s, 100 calls @ 6260425us\n",
      "\n",
      "[19:37:06] ======== Monitor (0): GBTree ========\n",
      "[19:37:06] BoostNewTrees: 6.23772s, 100 calls @ 6237720us\n",
      "\n",
      "[19:37:06] CommitModel: 6.7e-05s, 100 calls @ 67us\n",
      "\n",
      "[19:37:06] ======== Device 0 Memory Allocations:  ========\n",
      "[19:37:06] Peak memory usage: 2439MiB\n",
      "[19:37:06] Number of allocations: 10369\n",
      "[19:37:06] ======== Monitor (0): updater_gpu_hist ========\n",
      "[19:37:06] InitData: 0.001732s, 100 calls @ 1732us\n",
      "\n",
      "[19:37:06] InitDataOnce: 0.001717s, 1 calls @ 1717us\n",
      "\n",
      "[19:37:06] Update: 6.23368s, 100 calls @ 6233676us\n",
      "\n",
      "[19:37:06] UpdatePredictionCache: 0.003174s, 100 calls @ 3174us\n",
      "\n",
      "[19:37:06] ======== Monitor (0): gradient_based_sampler ========\n",
      "[19:37:06] Sample: 0.025836s, 100 calls @ 25836us\n",
      "\n",
      "[19:37:06] ======== Monitor (0): GPUHistMakerDevice0 ========\n",
      "[19:37:06] AllReduce: 0.000111s, 105 calls @ 111us\n",
      "\n",
      "[19:37:06] BuildHist: 0.015703s, 6 calls @ 15703us\n",
      "\n",
      "[19:37:06] EvaluateSplits: 0.401352s, 6 calls @ 401352us\n",
      "\n",
      "[19:37:06] FinalisePosition: 0.009868s, 100 calls @ 9868us\n",
      "\n",
      "[19:37:06] InitRoot: 5.59716s, 100 calls @ 5597162us\n",
      "\n",
      "[19:37:06] Reset: 0.205584s, 100 calls @ 205584us\n",
      "\n",
      "[19:37:06] UpdatePosition: 0.000806s, 6 calls @ 806us\n",
      "\n",
      "[19:37:06] ======== Monitor (0): Learner ========\n",
      "[19:37:06] Configure: 0.000598s, 1 calls @ 598us\n",
      "\n",
      "[19:37:06] ======== Monitor (0): GBTree ========\n",
      "[19:37:06] ======== Device 0 Memory Allocations:  ========\n",
      "[19:37:06] Peak memory usage: 2439MiB\n",
      "[19:37:06] Number of allocations: 10369\n",
      "[19:37:06] ======== Monitor (0): updater_gpu_hist ========\n",
      "[Pipeline] ......... (step 5 of 5) Processing estimator, total=   8.8s\n",
      "[19:37:20] DEBUG: /workspace/src/gbm/gbtree.cc:130: Using tree method: 3\n",
      "[19:37:20] DEBUG: /workspace/src/tree/updater_gpu_hist.cu:744: [GPU Hist]: Configure\n",
      "Training ...\n",
      "[Pipeline] ..... (step 1 of 5) Processing preprocessing, total=  15.6s\n",
      "[Pipeline] .......... (step 2 of 5) Processing sampling, total=   0.0s\n",
      "[Pipeline] ........... (step 3 of 5) Processing scaling, total=   0.1s\n",
      "[Pipeline] ......... (step 4 of 5) Processing selection, total=   0.0s\n",
      "[19:37:51] ======== Monitor (0): HostSketchContainer ========\n",
      "[19:37:51] AllReduce: 0.020527s, 1 calls @ 20527us\n",
      "\n",
      "[19:37:51] MakeCuts: 0.047928s, 1 calls @ 47928us\n",
      "\n",
      "[19:37:51] DEBUG: /workspace/src/gbm/gbtree.cc:130: Using tree method: 3\n",
      "[19:37:51] DEBUG: /workspace/src/tree/updater_gpu_hist.cu:744: [GPU Hist]: Configure\n",
      "[19:37:51] ======== Monitor (0):  ========\n",
      "[19:37:51] InitCompressedData: 0.000248s, 1 calls @ 248us\n",
      "\n",
      "[19:37:51] DEBUG: /workspace/src/tree/gpu_hist/../../common/device_helpers.cuh:291: Skipping empty CUDA kernel.\n",
      "[19:37:51] DEBUG: /workspace/src/tree/gpu_hist/../../common/device_helpers.cuh:291: Skipping empty CUDA kernel.\n",
      "[19:37:51] DEBUG: /workspace/src/tree/gpu_hist/../../common/device_helpers.cuh:291: Skipping empty CUDA kernel.\n",
      "[19:37:53] ======== Monitor (0): Learner ========\n",
      "[19:37:53] Configure: 0.00478s, 1 calls @ 4780us\n",
      "\n",
      "[19:37:53] EvalOneIter: 0.00079s, 100 calls @ 790us\n",
      "\n",
      "[19:37:53] GetGradient: 0.004571s, 100 calls @ 4571us\n",
      "\n",
      "[19:37:53] PredictRaw: 0.000124s, 100 calls @ 124us\n",
      "\n",
      "[19:37:53] UpdateOneIter: 2.52492s, 100 calls @ 2524918us\n",
      "\n",
      "[19:37:53] ======== Monitor (0): GBTree ========\n",
      "[19:37:53] BoostNewTrees: 2.5139s, 100 calls @ 2513896us\n",
      "\n",
      "[19:37:53] CommitModel: 6.3e-05s, 100 calls @ 63us\n",
      "\n",
      "[19:37:53] ======== Device 0 Memory Allocations:  ========\n",
      "[19:37:53] Peak memory usage: 2439MiB\n",
      "[19:37:53] Number of allocations: 11873\n",
      "[19:37:53] ======== Monitor (0): updater_gpu_hist ========\n",
      "[19:37:53] InitData: 0.000423s, 100 calls @ 423us\n",
      "\n",
      "[19:37:53] InitDataOnce: 0.000408s, 1 calls @ 408us\n",
      "\n",
      "[19:37:53] Update: 2.51081s, 100 calls @ 2510808us\n",
      "\n",
      "[19:37:53] UpdatePredictionCache: 0.002325s, 100 calls @ 2325us\n",
      "\n",
      "[19:37:53] ======== Monitor (0): gradient_based_sampler ========\n",
      "[19:37:53] Sample: 0.009033s, 100 calls @ 9033us\n",
      "\n",
      "[19:37:53] ======== Monitor (0): GPUHistMakerDevice0 ========\n",
      "[19:37:53] AllReduce: 0.000104s, 106 calls @ 104us\n",
      "\n",
      "[19:37:53] BuildHist: 0.006978s, 6 calls @ 6978us\n",
      "\n",
      "[19:37:53] EvaluateSplits: 0.218882s, 6 calls @ 218882us\n",
      "\n",
      "[19:37:53] FinalisePosition: 0.005216s, 100 calls @ 5216us\n",
      "\n",
      "[19:37:53] InitRoot: 2.14655s, 100 calls @ 2146552us\n",
      "\n",
      "[19:37:53] Reset: 0.13088s, 100 calls @ 130880us\n",
      "\n",
      "[19:37:53] UpdatePosition: 0.000683s, 6 calls @ 683us\n",
      "\n",
      "[19:37:53] ======== Monitor (0): Learner ========\n",
      "[19:37:53] Configure: 0.000685s, 1 calls @ 685us\n",
      "\n",
      "[19:37:53] ======== Monitor (0): GBTree ========\n",
      "[19:37:53] ======== Device 0 Memory Allocations:  ========\n",
      "[19:37:53] Peak memory usage: 2439MiB\n",
      "[19:37:53] Number of allocations: 11873\n",
      "[19:37:53] ======== Monitor (0): updater_gpu_hist ========\n",
      "[Pipeline] ......... (step 5 of 5) Processing estimator, total=   3.1s\n",
      "[19:37:58] DEBUG: /workspace/src/gbm/gbtree.cc:130: Using tree method: 3\n",
      "[19:37:58] DEBUG: /workspace/src/tree/updater_gpu_hist.cu:744: [GPU Hist]: Configure\n",
      "Training ...\n",
      "[Pipeline] ..... (step 1 of 5) Processing preprocessing, total=  38.3s\n",
      "[Pipeline] .......... (step 2 of 5) Processing sampling, total=   0.0s\n",
      "[Pipeline] ........... (step 3 of 5) Processing scaling, total=   0.9s\n",
      "[Pipeline] ......... (step 4 of 5) Processing selection, total=   0.0s\n",
      "[19:38:44] ======== Monitor (0): HostSketchContainer ========\n",
      "[19:38:44] AllReduce: 0.072077s, 1 calls @ 72077us\n",
      "\n",
      "[19:38:44] MakeCuts: 0.11968s, 1 calls @ 119680us\n",
      "\n",
      "[19:38:44] DEBUG: /workspace/src/gbm/gbtree.cc:130: Using tree method: 3\n",
      "[19:38:44] DEBUG: /workspace/src/tree/updater_gpu_hist.cu:744: [GPU Hist]: Configure\n",
      "[19:38:44] ======== Monitor (0):  ========\n",
      "[19:38:44] InitCompressedData: 0.000752s, 1 calls @ 752us\n",
      "\n",
      "[19:38:45] DEBUG: /workspace/src/tree/gpu_hist/../../common/device_helpers.cuh:291: Skipping empty CUDA kernel.\n",
      "[19:38:45] DEBUG: /workspace/src/tree/gpu_hist/../../common/device_helpers.cuh:291: Skipping empty CUDA kernel.\n",
      "[19:38:45] DEBUG: /workspace/src/tree/gpu_hist/../../common/device_helpers.cuh:291: Skipping empty CUDA kernel.\n",
      "[19:38:45] DEBUG: /workspace/src/tree/gpu_hist/../../common/device_helpers.cuh:291: Skipping empty CUDA kernel.\n",
      "[19:38:50] ======== Monitor (0): Learner ========\n",
      "[19:38:50] Configure: 0.006075s, 1 calls @ 6075us\n",
      "\n",
      "[19:38:50] EvalOneIter: 0.000929s, 100 calls @ 929us\n",
      "\n",
      "[19:38:50] GetGradient: 0.005822s, 100 calls @ 5822us\n",
      "\n",
      "[19:38:50] PredictRaw: 0.000155s, 100 calls @ 155us\n",
      "\n",
      "[19:38:50] UpdateOneIter: 5.12819s, 100 calls @ 5128195us\n",
      "\n",
      "[19:38:50] ======== Monitor (0): GBTree ========\n",
      "[19:38:50] BoostNewTrees: 5.11355s, 100 calls @ 5113548us\n",
      "\n",
      "[19:38:50] CommitModel: 7.3e-05s, 100 calls @ 73us\n",
      "\n",
      "[19:38:50] ======== Device 0 Memory Allocations:  ========\n",
      "[19:38:50] Peak memory usage: 2608MiB\n",
      "[19:38:50] Number of allocations: 13376\n",
      "[19:38:50] ======== Monitor (0): updater_gpu_hist ========\n",
      "[19:38:50] InitData: 0.000881s, 100 calls @ 881us\n",
      "\n",
      "[19:38:50] InitDataOnce: 0.000866s, 1 calls @ 866us\n",
      "\n",
      "[19:38:50] Update: 5.10844s, 100 calls @ 5108441us\n",
      "\n",
      "[19:38:50] UpdatePredictionCache: 0.004222s, 100 calls @ 4222us\n",
      "\n",
      "[19:38:50] ======== Monitor (0): gradient_based_sampler ========\n",
      "[19:38:50] Sample: 0.023897s, 100 calls @ 23897us\n",
      "\n",
      "[19:38:50] ======== Monitor (0): GPUHistMakerDevice0 ========\n",
      "[19:38:50] AllReduce: 0.000136s, 106 calls @ 136us\n",
      "\n",
      "[19:38:50] BuildHist: 0.017224s, 7 calls @ 17224us\n",
      "\n",
      "[19:38:50] EvaluateSplits: 0.428462s, 7 calls @ 428462us\n",
      "\n",
      "[19:38:50] FinalisePosition: 0.01366s, 100 calls @ 13660us\n",
      "\n",
      "[19:38:50] InitRoot: 4.47158s, 100 calls @ 4471579us\n",
      "\n",
      "[19:38:50] Reset: 0.173576s, 100 calls @ 173576us\n",
      "\n",
      "[19:38:50] UpdatePosition: 0.001365s, 7 calls @ 1365us\n",
      "\n",
      "[19:38:50] ======== Monitor (0): Learner ========\n",
      "[19:38:50] Configure: 0.000697s, 1 calls @ 697us\n",
      "\n",
      "[19:38:50] ======== Monitor (0): GBTree ========\n",
      "[19:38:50] ======== Device 0 Memory Allocations:  ========\n",
      "[19:38:50] Peak memory usage: 2608MiB\n",
      "[19:38:50] Number of allocations: 13376\n",
      "[19:38:50] ======== Monitor (0): updater_gpu_hist ========\n",
      "[Pipeline] ......... (step 5 of 5) Processing estimator, total=   7.9s\n",
      "[19:39:02] DEBUG: /workspace/src/gbm/gbtree.cc:130: Using tree method: 3\n",
      "[19:39:02] DEBUG: /workspace/src/tree/updater_gpu_hist.cu:744: [GPU Hist]: Configure\n",
      "Training ...\n",
      "[Pipeline] ..... (step 1 of 5) Processing preprocessing, total=  43.9s\n",
      "[Pipeline] .......... (step 2 of 5) Processing sampling, total=   0.0s\n",
      "[Pipeline] ........... (step 3 of 5) Processing scaling, total=   1.2s\n",
      "[Pipeline] ......... (step 4 of 5) Processing selection, total=   0.0s\n",
      "[19:40:01] ======== Monitor (0): HostSketchContainer ========\n",
      "[19:40:01] AllReduce: 0.079398s, 1 calls @ 79398us\n",
      "\n",
      "[19:40:01] MakeCuts: 0.159246s, 1 calls @ 159246us\n",
      "\n",
      "[19:40:01] DEBUG: /workspace/src/gbm/gbtree.cc:130: Using tree method: 3\n",
      "[19:40:01] DEBUG: /workspace/src/tree/updater_gpu_hist.cu:744: [GPU Hist]: Configure\n",
      "[19:40:01] ======== Monitor (0):  ========\n",
      "[19:40:01] InitCompressedData: 0.000838s, 1 calls @ 838us\n",
      "\n",
      "[19:40:01] DEBUG: /workspace/src/tree/gpu_hist/../../common/device_helpers.cuh:291: Skipping empty CUDA kernel.\n",
      "[19:40:01] DEBUG: /workspace/src/tree/gpu_hist/../../common/device_helpers.cuh:291: Skipping empty CUDA kernel.\n",
      "[19:40:01] DEBUG: /workspace/src/tree/gpu_hist/../../common/device_helpers.cuh:291: Skipping empty CUDA kernel.\n",
      "[19:40:02] DEBUG: /workspace/src/tree/gpu_hist/../../common/device_helpers.cuh:291: Skipping empty CUDA kernel.\n",
      "[19:40:02] DEBUG: /workspace/src/tree/gpu_hist/../../common/device_helpers.cuh:291: Skipping empty CUDA kernel.\n",
      "[19:40:02] DEBUG: /workspace/src/tree/gpu_hist/../../common/device_helpers.cuh:291: Skipping empty CUDA kernel.\n",
      "[19:40:02] DEBUG: /workspace/src/tree/gpu_hist/../../common/device_helpers.cuh:291: Skipping empty CUDA kernel.\n",
      "[19:40:09] ======== Monitor (0): Learner ========\n",
      "[19:40:09] Configure: 0.005996s, 1 calls @ 5996us\n",
      "\n",
      "[19:40:09] EvalOneIter: 0.00093s, 100 calls @ 930us\n",
      "\n",
      "[19:40:09] GetGradient: 0.006307s, 100 calls @ 6307us\n",
      "\n",
      "[19:40:09] PredictRaw: 0.000156s, 100 calls @ 156us\n",
      "\n",
      "[19:40:09] UpdateOneIter: 7.46935s, 100 calls @ 7469348us\n",
      "\n",
      "[19:40:09] ======== Monitor (0): GBTree ========\n",
      "[19:40:09] BoostNewTrees: 7.45478s, 100 calls @ 7454778us\n",
      "\n",
      "[19:40:09] CommitModel: 6.3e-05s, 100 calls @ 63us\n",
      "\n",
      "[19:40:09] ======== Device 0 Memory Allocations:  ========\n",
      "[19:40:09] Peak memory usage: 5319MiB\n",
      "[19:40:09] Number of allocations: 14880\n",
      "[19:40:09] ======== Monitor (0): updater_gpu_hist ========\n",
      "[19:40:09] InitData: 0.000569s, 100 calls @ 569us\n",
      "\n",
      "[19:40:09] InitDataOnce: 0.000554s, 1 calls @ 554us\n",
      "\n",
      "[19:40:09] Update: 7.4474s, 100 calls @ 7447396us\n",
      "\n",
      "[19:40:09] UpdatePredictionCache: 0.006518s, 100 calls @ 6518us\n",
      "\n",
      "[19:40:09] ======== Monitor (0): gradient_based_sampler ========\n",
      "[19:40:09] Sample: 0.026542s, 100 calls @ 26542us\n",
      "\n",
      "[19:40:09] ======== Monitor (0): GPUHistMakerDevice0 ========\n",
      "[19:40:09] AllReduce: 0.00016s, 106 calls @ 160us\n",
      "\n",
      "[19:40:09] BuildHist: 0.039872s, 7 calls @ 39872us\n",
      "\n",
      "[19:40:09] EvaluateSplits: 0.643838s, 7 calls @ 643838us\n",
      "\n",
      "[19:40:09] FinalisePosition: 0.010746s, 100 calls @ 10746us\n",
      "\n",
      "[19:40:09] InitRoot: 6.55936s, 100 calls @ 6559357us\n",
      "\n",
      "[19:40:09] Reset: 0.189286s, 100 calls @ 189286us\n",
      "\n",
      "[19:40:09] UpdatePosition: 0.001707s, 7 calls @ 1707us\n",
      "\n",
      "[19:40:09] ======== Monitor (0): Learner ========\n",
      "[19:40:09] Configure: 0.001018s, 1 calls @ 1018us\n",
      "\n",
      "[19:40:09] ======== Monitor (0): GBTree ========\n",
      "[19:40:09] ======== Device 0 Memory Allocations:  ========\n",
      "[19:40:09] Peak memory usage: 5319MiB\n",
      "[19:40:09] Number of allocations: 14880\n",
      "[19:40:09] ======== Monitor (0): updater_gpu_hist ========\n",
      "[Pipeline] ......... (step 5 of 5) Processing estimator, total=   9.5s\n",
      "[19:40:23] DEBUG: /workspace/src/gbm/gbtree.cc:130: Using tree method: 3\n",
      "[19:40:23] DEBUG: /workspace/src/tree/updater_gpu_hist.cu:744: [GPU Hist]: Configure\n",
      "Training ...\n",
      "[Pipeline] ..... (step 1 of 5) Processing preprocessing, total=  32.3s\n",
      "[Pipeline] .......... (step 2 of 5) Processing sampling, total=   0.0s\n",
      "[Pipeline] ........... (step 3 of 5) Processing scaling, total=   0.3s\n",
      "[Pipeline] ......... (step 4 of 5) Processing selection, total=   0.0s\n",
      "[19:41:12] ======== Monitor (0): HostSketchContainer ========\n",
      "[19:41:12] AllReduce: 0.044946s, 1 calls @ 44946us\n",
      "\n",
      "[19:41:12] MakeCuts: 0.100795s, 1 calls @ 100795us\n",
      "\n",
      "[19:41:12] DEBUG: /workspace/src/gbm/gbtree.cc:130: Using tree method: 3\n",
      "[19:41:12] DEBUG: /workspace/src/tree/updater_gpu_hist.cu:744: [GPU Hist]: Configure\n",
      "[19:41:12] ======== Monitor (0):  ========\n",
      "[19:41:12] InitCompressedData: 0.00049s, 1 calls @ 490us\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for corpus,config in config_experiments_dict.items():\n",
    "    \n",
    "    print(f'##### Start of {corpus} - {datetime.today()} #####')\n",
    "\n",
    "    data_tuples_list = create_train_test_tuples(\n",
    "        list_train_paths = config.get('list_train_paths'),\n",
    "        list_test_paths = config.get('list_test_paths'),\n",
    "        target_list = target_list,\n",
    "        file_type = config.get('file_type'),\n",
    "        read_data_args= config.get('read_data_args')\n",
    "    )\n",
    "    \n",
    "    for X_col in config.get('X_cols_comb'):\n",
    "        \n",
    "        for clf_name, clf in config.get('clf_to_test').items():\n",
    "            \n",
    "            print(f'- Running combination {X_col}')\n",
    "        \n",
    "            generate_results(       \n",
    "                    data_tuples_list = data_tuples_list,\n",
    "                    corpus_name = corpus, \n",
    "                    X_col =X_col,\n",
    "                    clf = clf,\n",
    "                    reports_path = '../reports/',\n",
    "                    estimator_name = clf_name\n",
    "            )\n",
    "            \n",
    "        print(f'##### End of {corpus} - {datetime.today()} #####\\n\\n\\n\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env-stance-pred",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
