{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.metrics import classification_report\n",
    "from tqdm import tqdm\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../src')\n",
    "\n",
    "from models.classification_methods import get_classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['DummyClassifier_bo_top_mentioned_timelines_Texts_test_results.csv',\n",
       " 'DummyClassifier_bo_users_Stance_test_results.csv',\n",
       " 'DummyClassifier_bo_users_Timeline_test_results.csv',\n",
       " 'DummyClassifier_cl_top_mentioned_timelines_Texts_test_results.csv',\n",
       " 'DummyClassifier_cl_users_Stance_test_results.csv',\n",
       " 'DummyClassifier_cl_users_Timeline_test_results.csv',\n",
       " 'DummyClassifier_co_top_mentioned_timelines_Texts_test_results.csv',\n",
       " 'DummyClassifier_co_users_Stance_test_results.csv',\n",
       " 'DummyClassifier_co_users_Timeline_test_results.csv',\n",
       " 'DummyClassifier_gl_top_mentioned_timelines_Texts_test_results.csv',\n",
       " 'DummyClassifier_gl_users_Stance_test_results.csv',\n",
       " 'DummyClassifier_gl_users_Timeline_test_results.csv',\n",
       " 'DummyClassifier_ig_top_mentioned_timelines_Texts_test_results.csv',\n",
       " 'DummyClassifier_ig_users_Stance_test_results.csv',\n",
       " 'DummyClassifier_ig_users_Timeline_test_results.csv',\n",
       " 'DummyClassifier_lu_top_mentioned_timelines_Texts_test_results.csv',\n",
       " 'DummyClassifier_lu_users_Stance_test_results.csv',\n",
       " 'DummyClassifier_lu_users_Timeline_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_bo_Texts_Timeline_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_cl_Texts_Timeline_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_co_Texts_Timeline_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_gl_Texts_Timeline_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_ig_Texts_Timeline_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_lu_Texts_Timeline_test_results.csv',\n",
       " 'XGBClassifier_TfidfVectorizer_bo_top_mentioned_timelines_Texts_test_results.csv',\n",
       " 'XGBClassifier_TfidfVectorizer_bo_users_Stance_test_results.csv',\n",
       " 'XGBClassifier_TfidfVectorizer_bo_users_Timeline_test_results.csv',\n",
       " 'XGBClassifier_TfidfVectorizer_cl_top_mentioned_timelines_Texts_test_results.csv',\n",
       " 'XGBClassifier_TfidfVectorizer_cl_users_Stance_test_results.csv',\n",
       " 'XGBClassifier_TfidfVectorizer_cl_users_Timeline_test_results.csv',\n",
       " 'XGBClassifier_TfidfVectorizer_co_top_mentioned_timelines_Texts_test_results.csv',\n",
       " 'XGBClassifier_TfidfVectorizer_co_users_Stance_test_results.csv',\n",
       " 'XGBClassifier_TfidfVectorizer_co_users_Timeline_test_results.csv',\n",
       " 'XGBClassifier_TfidfVectorizer_gl_top_mentioned_timelines_Texts_test_results.csv',\n",
       " 'XGBClassifier_TfidfVectorizer_gl_users_Stance_test_results.csv',\n",
       " 'XGBClassifier_TfidfVectorizer_gl_users_Timeline_test_results.csv',\n",
       " 'XGBClassifier_TfidfVectorizer_ig_top_mentioned_timelines_Texts_test_results.csv',\n",
       " 'XGBClassifier_TfidfVectorizer_ig_users_Stance_test_results.csv',\n",
       " 'XGBClassifier_TfidfVectorizer_ig_users_Timeline_test_results.csv',\n",
       " 'XGBClassifier_TfidfVectorizer_lu_top_mentioned_timelines_Texts_test_results.csv',\n",
       " 'XGBClassifier_TfidfVectorizer_lu_users_Stance_test_results.csv',\n",
       " 'XGBClassifier_TfidfVectorizer_lu_users_Timeline_test_results.csv',\n",
       " 'belt_filteredTimeline10_pablocosta_bertabaporu-base-uncased_test_results.csv',\n",
       " 'belt_filteredTimeline10_pablocosta_bertabaporu-base-uncased_test_results_part_bo.csv',\n",
       " 'belt_filteredTimeline10_pablocosta_bertabaporu-base-uncased_test_results_part_cl.csv',\n",
       " 'belt_filteredTimeline10_pablocosta_bertabaporu-base-uncased_test_results_part_co.csv',\n",
       " 'belt_filteredTimeline10_pablocosta_bertabaporu-base-uncased_test_results_part_gl.csv',\n",
       " 'belt_filteredTimeline10_pablocosta_bertabaporu-base-uncased_test_results_part_ig.csv',\n",
       " 'belt_filteredTimeline10_pablocosta_bertabaporu-base-uncased_test_results_part_lu.csv',\n",
       " 'belt_filteredTimeline15_pablocosta_bertabaporu-base-uncased_test_results.csv',\n",
       " 'belt_filteredTimeline15_pablocosta_bertabaporu-base-uncased_test_results_part_bo.csv',\n",
       " 'belt_filteredTimeline15_pablocosta_bertabaporu-base-uncased_test_results_part_cl.csv',\n",
       " 'belt_filteredTimeline15_pablocosta_bertabaporu-base-uncased_test_results_part_co.csv',\n",
       " 'belt_filteredTimeline15_pablocosta_bertabaporu-base-uncased_test_results_part_gl.csv',\n",
       " 'belt_filteredTimeline15_pablocosta_bertabaporu-base-uncased_test_results_part_ig.csv',\n",
       " 'belt_filteredTimeline15_pablocosta_bertabaporu-base-uncased_test_results_part_lu.csv',\n",
       " 'belt_filteredTimeline5_pablocosta_bertabaporu-base-uncased_test_results.csv',\n",
       " 'belt_filteredTimeline5_pablocosta_bertabaporu-base-uncased_test_results_part_bo.csv',\n",
       " 'belt_filteredTimeline5_pablocosta_bertabaporu-base-uncased_test_results_part_cl.csv',\n",
       " 'belt_filteredTimeline5_pablocosta_bertabaporu-base-uncased_test_results_part_co.csv',\n",
       " 'belt_filteredTimeline5_pablocosta_bertabaporu-base-uncased_test_results_part_gl.csv',\n",
       " 'belt_filteredTimeline5_pablocosta_bertabaporu-base-uncased_test_results_part_ig.csv',\n",
       " 'belt_filteredTimeline5_pablocosta_bertabaporu-base-uncased_test_results_part_lu.csv',\n",
       " 'belt_filtered_Texts10_pablocosta_bertabaporu-base-uncased_test_results.csv',\n",
       " 'belt_filtered_Texts10_pablocosta_bertabaporu-base-uncased_test_results_part_bo.csv',\n",
       " 'belt_filtered_Texts10_pablocosta_bertabaporu-base-uncased_test_results_part_cl.csv',\n",
       " 'belt_filtered_Texts10_pablocosta_bertabaporu-base-uncased_test_results_part_co.csv',\n",
       " 'belt_filtered_Texts10_pablocosta_bertabaporu-base-uncased_test_results_part_gl.csv',\n",
       " 'belt_filtered_Texts10_pablocosta_bertabaporu-base-uncased_test_results_part_ig.csv',\n",
       " 'belt_filtered_Texts10_pablocosta_bertabaporu-base-uncased_test_results_part_lu.csv',\n",
       " 'belt_filtered_Texts15_pablocosta_bertabaporu-base-uncased_test_results.csv',\n",
       " 'belt_filtered_Texts15_pablocosta_bertabaporu-base-uncased_test_results_part_bo.csv',\n",
       " 'belt_filtered_Texts15_pablocosta_bertabaporu-base-uncased_test_results_part_cl.csv',\n",
       " 'belt_filtered_Texts15_pablocosta_bertabaporu-base-uncased_test_results_part_co.csv',\n",
       " 'belt_filtered_Texts15_pablocosta_bertabaporu-base-uncased_test_results_part_gl.csv',\n",
       " 'belt_filtered_Texts15_pablocosta_bertabaporu-base-uncased_test_results_part_ig.csv',\n",
       " 'belt_filtered_Texts15_pablocosta_bertabaporu-base-uncased_test_results_part_lu.csv',\n",
       " 'belt_filtered_Texts5_pablocosta_bertabaporu-base-uncased_test_results.csv',\n",
       " 'belt_filtered_Texts5_pablocosta_bertabaporu-base-uncased_test_results_part_bo.csv',\n",
       " 'belt_filtered_Texts5_pablocosta_bertabaporu-base-uncased_test_results_part_cl.csv',\n",
       " 'belt_filtered_Texts5_pablocosta_bertabaporu-base-uncased_test_results_part_co.csv',\n",
       " 'belt_filtered_Texts5_pablocosta_bertabaporu-base-uncased_test_results_part_gl.csv',\n",
       " 'belt_filtered_Texts5_pablocosta_bertabaporu-base-uncased_test_results_part_ig.csv',\n",
       " 'belt_filtered_Texts5_pablocosta_bertabaporu-base-uncased_test_results_part_lu.csv',\n",
       " 'bert_classifier_pablocosta_bertabaporu_base_uncased_bo_Stance_test_results.csv',\n",
       " 'bert_classifier_pablocosta_bertabaporu_base_uncased_bo_Texts_test_results.csv',\n",
       " 'bert_classifier_pablocosta_bertabaporu_base_uncased_bo_Timeline_test_results.csv',\n",
       " 'bert_classifier_pablocosta_bertabaporu_base_uncased_bo_scored_Texts_test_results.csv',\n",
       " 'bert_classifier_pablocosta_bertabaporu_base_uncased_bo_scored_Timeline_test_results.csv',\n",
       " 'bert_classifier_pablocosta_bertabaporu_base_uncased_cl_Stance_test_results.csv',\n",
       " 'bert_classifier_pablocosta_bertabaporu_base_uncased_cl_Texts_test_results.csv',\n",
       " 'bert_classifier_pablocosta_bertabaporu_base_uncased_cl_Timeline_test_results.csv',\n",
       " 'bert_classifier_pablocosta_bertabaporu_base_uncased_cl_scored_Texts_test_results.csv',\n",
       " 'bert_classifier_pablocosta_bertabaporu_base_uncased_cl_scored_Timeline_test_results.csv',\n",
       " 'bert_classifier_pablocosta_bertabaporu_base_uncased_co_Stance_test_results.csv',\n",
       " 'bert_classifier_pablocosta_bertabaporu_base_uncased_co_Texts_test_results.csv',\n",
       " 'bert_classifier_pablocosta_bertabaporu_base_uncased_co_Timeline_test_results.csv',\n",
       " 'bert_classifier_pablocosta_bertabaporu_base_uncased_co_scored_Texts_test_results.csv',\n",
       " 'bert_classifier_pablocosta_bertabaporu_base_uncased_co_scored_Timeline_test_results.csv',\n",
       " 'bert_classifier_pablocosta_bertabaporu_base_uncased_gl_Stance_test_results.csv',\n",
       " 'bert_classifier_pablocosta_bertabaporu_base_uncased_gl_Texts_test_results.csv',\n",
       " 'bert_classifier_pablocosta_bertabaporu_base_uncased_gl_Timeline_test_results.csv',\n",
       " 'bert_classifier_pablocosta_bertabaporu_base_uncased_gl_scored_Texts_test_results.csv',\n",
       " 'bert_classifier_pablocosta_bertabaporu_base_uncased_gl_scored_Timeline_test_results.csv',\n",
       " 'bert_classifier_pablocosta_bertabaporu_base_uncased_ig_Stance_test_results.csv',\n",
       " 'bert_classifier_pablocosta_bertabaporu_base_uncased_ig_Texts_test_results.csv',\n",
       " 'bert_classifier_pablocosta_bertabaporu_base_uncased_ig_Timeline_test_results.csv',\n",
       " 'bert_classifier_pablocosta_bertabaporu_base_uncased_ig_scored_Texts_test_results.csv',\n",
       " 'bert_classifier_pablocosta_bertabaporu_base_uncased_ig_scored_Timeline_test_results.csv',\n",
       " 'bert_classifier_pablocosta_bertabaporu_base_uncased_lu_Stance_test_results.csv',\n",
       " 'bert_classifier_pablocosta_bertabaporu_base_uncased_lu_Texts_test_results.csv',\n",
       " 'bert_classifier_pablocosta_bertabaporu_base_uncased_lu_Timeline_test_results.csv',\n",
       " 'bert_classifier_pablocosta_bertabaporu_base_uncased_lu_scored_Texts_test_results.csv',\n",
       " 'bert_classifier_pablocosta_bertabaporu_base_uncased_lu_scored_Timeline_test_results.csv',\n",
       " 'bertimbau_xgb_bo_top_mentioned_timelines_emb_Texts_test_results.csv',\n",
       " 'bertimbau_xgb_bo_users_emb_Stance_test_results.csv',\n",
       " 'bertimbau_xgb_bo_users_emb_Timeline_test_results.csv',\n",
       " 'bertimbau_xgb_cl_top_mentioned_timelines_emb_Texts_test_results.csv',\n",
       " 'bertimbau_xgb_cl_users_emb_Stance_test_results.csv',\n",
       " 'bertimbau_xgb_cl_users_emb_Timeline_test_results.csv',\n",
       " 'bertimbau_xgb_co_top_mentioned_timelines_emb_Texts_test_results.csv',\n",
       " 'bertimbau_xgb_co_users_emb_Stance_test_results.csv',\n",
       " 'bertimbau_xgb_co_users_emb_Timeline_test_results.csv',\n",
       " 'bertimbau_xgb_gl_top_mentioned_timelines_emb_Texts_test_results.csv',\n",
       " 'bertimbau_xgb_gl_users_emb_Stance_test_results.csv',\n",
       " 'bertimbau_xgb_gl_users_emb_Timeline_test_results.csv',\n",
       " 'bertimbau_xgb_ig_top_mentioned_timelines_emb_Texts_test_results.csv',\n",
       " 'bertimbau_xgb_ig_users_emb_Stance_test_results.csv',\n",
       " 'bertimbau_xgb_ig_users_emb_Timeline_test_results.csv',\n",
       " 'bertimbau_xgb_lu_top_mentioned_timelines_emb_Texts_test_results.csv',\n",
       " 'bertimbau_xgb_lu_users_emb_Stance_test_results.csv',\n",
       " 'bertimbau_xgb_lu_users_emb_Timeline_test_results.csv',\n",
       " 'llama3_bo_Stance_prompt2_Stance_test_results.csv',\n",
       " 'llama3_bo_filteredTimeline10_prompt2_Timeline_test_results.csv',\n",
       " 'llama3_bo_filteredTimeline15_prompt2_Timeline_test_results.csv',\n",
       " 'llama3_bo_filteredTimeline5_prompt2_Timeline_test_results.csv',\n",
       " 'llama3_bo_filtered_Texts10_prompt2_Texts_test_results.csv',\n",
       " 'llama3_bo_filtered_Texts15_prompt2_Texts_test_results.csv',\n",
       " 'llama3_bo_filtered_Texts20_prompt2_Texts_test_results.csv',\n",
       " 'llama3_bo_filtered_Texts5_prompt2_Texts_test_results.csv',\n",
       " 'llama3_cl_Stance_prompt2_Stance_test_results.csv',\n",
       " 'llama3_cl_filteredTimeline10_prompt2_Timeline_test_results.csv',\n",
       " 'llama3_cl_filteredTimeline15_prompt2_Timeline_test_results.csv',\n",
       " 'llama3_cl_filteredTimeline5_prompt2_Timeline_test_results.csv',\n",
       " 'llama3_cl_filtered_Texts10_prompt2_Texts_test_results.csv',\n",
       " 'llama3_cl_filtered_Texts15_prompt2_Texts_test_results.csv',\n",
       " 'llama3_cl_filtered_Texts20_prompt2_Texts_test_results.csv',\n",
       " 'llama3_cl_filtered_Texts5_prompt2_Texts_test_results.csv',\n",
       " 'llama3_co_Stance_prompt2_Stance_test_results.csv',\n",
       " 'llama3_co_filteredTimeline10_prompt2_Timeline_test_results.csv',\n",
       " 'llama3_co_filteredTimeline15_prompt2_Timeline_test_results.csv',\n",
       " 'llama3_co_filteredTimeline5_prompt2_Timeline_test_results.csv',\n",
       " 'llama3_co_filtered_Texts10_prompt2_Texts_test_results.csv',\n",
       " 'llama3_co_filtered_Texts15_prompt2_Texts_test_results.csv',\n",
       " 'llama3_co_filtered_Texts5_prompt2_Texts_test_results.csv',\n",
       " 'llama3_gl_Stance_prompt2_Stance_test_results.csv',\n",
       " 'llama3_gl_filteredTimeline10_prompt2_Timeline_test_results.csv',\n",
       " 'llama3_gl_filteredTimeline15_prompt2_Timeline_test_results.csv',\n",
       " 'llama3_gl_filteredTimeline5_prompt2_Timeline_test_results.csv',\n",
       " 'llama3_gl_filtered_Texts10_prompt2_Texts_test_results.csv',\n",
       " 'llama3_gl_filtered_Texts15_prompt2_Texts_test_results.csv',\n",
       " 'llama3_gl_filtered_Texts5_prompt2_Texts_test_results.csv',\n",
       " 'llama3_ig_Stance_prompt2_Stance_test_results.csv',\n",
       " 'llama3_ig_filteredTimeline10_prompt2_Timeline_test_results.csv',\n",
       " 'llama3_ig_filteredTimeline15_prompt2_Timeline_test_results.csv',\n",
       " 'llama3_ig_filteredTimeline5_prompt2_Timeline_test_results.csv',\n",
       " 'llama3_ig_filtered_Texts10_prompt2_Texts_test_results.csv',\n",
       " 'llama3_ig_filtered_Texts15_prompt2_Texts_test_results.csv',\n",
       " 'llama3_ig_filtered_Texts20_prompt2_Texts_test_results.csv',\n",
       " 'llama3_ig_filtered_Texts5_prompt2_Texts_test_results.csv',\n",
       " 'llama3_lu_Stance_prompt2_Stance_test_results.csv',\n",
       " 'llama3_lu_filteredTimeline10_prompt2_Timeline_test_results.csv',\n",
       " 'llama3_lu_filteredTimeline15_prompt2_Timeline_test_results.csv',\n",
       " 'llama3_lu_filteredTimeline5_prompt2_Timeline_test_results.csv',\n",
       " 'llama3_lu_filtered_Texts10_prompt2_Texts_test_results.csv',\n",
       " 'llama3_lu_filtered_Texts15_prompt2_Texts_test_results.csv',\n",
       " 'llama3_lu_filtered_Texts5_prompt2_Texts_test_results.csv',\n",
       " 'old']"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_results_path = '../reports/test_results/'\n",
    "\n",
    "list_df_t = os.listdir(test_results_path)\n",
    "list_df_t.sort()\n",
    "list_df_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hydrox.', 'Lula', 'Sinovac', 'Church', 'Globo TV', 'Bolsonaro']"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Target list\n",
    "target_list = [\n",
    "    'ig',\n",
    "    'bo', \n",
    "    'cl', \n",
    "    'co', \n",
    "    'gl', \n",
    "    'lu'\n",
    "]\n",
    "\n",
    "dict_cp = {\n",
    "    'cl':'Hydrox.',\n",
    "    'lu':'Lula',\n",
    "    'co':'Sinovac',\n",
    "    'ig':'Church',\n",
    "    'gl':'Globo TV',\n",
    "    'bo':'Bolsonaro',\n",
    "}\n",
    "\n",
    "names = list(dict_cp.values())\n",
    "names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create complete table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (vectorizer,estimator, path_sring) \n",
    "results_tuples_stance = [\n",
    "    # Stance\n",
    "    (\"Stance\", \"-\" ,\"dummy\", \"DummyClassifier_{target}_users_Stance_test_results.csv\"),\n",
    "    (\"Stance\", \"tf-idf\" ,\"xgb\", \"XGBClassifier_TfidfVectorizer_{target}_users_Stance_test_results.csv\"),\n",
    "    (\"Stance\", \"bertabaporu-base\" ,\"xgb\", \"bertimbau_xgb_{target}_users_emb_Stance_test_results.csv\"),\n",
    "    (\"Stance\", \"-\" ,\"bertabaporu-base\", \"bert_classifier_pablocosta_bertabaporu_base_uncased_{target}_Stance_test_results.csv\"),\n",
    "    (\"Stance\", \"-\",  \"llama3:7b zero-shot\", \"llama3_{target}_Stance_prompt2_Stance_test_results.csv\"),\n",
    "    \n",
    "    # Texts\n",
    "    (\"Texts\", \"-\" ,\"dummy\", \"DummyClassifier_{target}_top_mentioned_timelines_Texts_test_results.csv\"),\n",
    "    (\"Texts\", \"tf-idf\" ,\"xgb\", \"XGBClassifier_TfidfVectorizer_{target}_top_mentioned_timelines_Texts_test_results.csv\"),\n",
    "    (\"Texts\", \"bertabaporu-base\" ,\"xgb\", \"bertimbau_xgb_{target}_top_mentioned_timelines_emb_Texts_test_results.csv\"),\n",
    "    (\"Texts\", \"-\" ,\"bertabaporu-base\", \"bert_classifier_pablocosta_bertabaporu_base_uncased_{target}_Texts_test_results.csv\"),\n",
    "    (\"Texts\", \"-\" ,\"bertabaporu-base (R)\", \"bert_classifier_pablocosta_bertabaporu_base_uncased_{target}_scored_Texts_test_results.csv\"),\n",
    "    (\"Texts\", \"-\", \"llama3:7b zero-shot [5] (R)\", \"llama3_{target}_filtered_Texts5_prompt2_Texts_test_results.csv\"),\n",
    "    (\"Texts\", \"-\", \"llama3:7b zero-shot [10] (R)\", \"llama3_{target}_filtered_Texts10_prompt2_Texts_test_results.csv\"),\n",
    "    (\"Texts\", \"-\", \"llama3:7b zero-shot [15] (R)\", \"llama3_{target}_filtered_Texts15_prompt2_Texts_test_results.csv\"),\n",
    "    \n",
    "    # Timeline\n",
    "    (\"Timeline\", \"-\" ,\"dummy\", \"DummyClassifier_{target}_users_Timeline_test_results.csv\"),\n",
    "    (\"Timeline\", \"tf-idf\" ,\"xgb\", \"XGBClassifier_TfidfVectorizer_{target}_users_Timeline_test_results.csv\"),\n",
    "    (\"Timeline\", \"bertabaporu-base\" ,\"xgb\", \"bertimbau_xgb_{target}_users_emb_Timeline_test_results.csv\"),\n",
    "    (\"Timeline\", \"-\" ,\"bertabaporu-base\", \"bert_classifier_pablocosta_bertabaporu_base_uncased_{target}_Timeline_test_results.csv\"),\n",
    "    (\"Timeline\", \"-\" ,\"bertabaporu-base (R)\", \"bert_classifier_pablocosta_bertabaporu_base_uncased_{target}_scored_Timeline_test_results.csv\"),\n",
    "    (\"Timeline\", \"-\", \"llama3:7b zero-shot [5] (R)\", \"llama3_{target}_filteredTimeline5_prompt2_Timeline_test_results.csv\"),\n",
    "    (\"Timeline\", \"-\", \"llama3:7b zero-shot [10] (R)\", \"llama3_{target}_filteredTimeline10_prompt2_Timeline_test_results.csv\"),\n",
    "    (\"Timeline\", \"-\", \"llama3:7b zero-shot [15] (R)\", \"llama3_{target}_filteredTimeline15_prompt2_Timeline_test_results.csv\"),\n",
    "    \n",
    "    (\"Ensemble Texts + Timeline\", \"-\", \"LogisticRegression\", \"Ensemble_LogisticRegression_{target}_Texts_Timeline_test_results.csv\")\n",
    "]\n",
    "\n",
    "list_results = []\n",
    "for text_col, vectorizer, estimator, path_results in results_tuples_stance:\n",
    "    \n",
    "    list_cr = []\n",
    "    \n",
    "    for target in target_list:\n",
    "        \n",
    "        \n",
    "        path = test_results_path + path_results.format(target = target)\n",
    "        df_results = pd.read_csv(path)\n",
    "        df_results_or = df_results.copy()\n",
    "        \n",
    "        # get classification report df\n",
    "        df_classification_report = get_classification_report(df_results.test, df_results.pred, cr_args = {})\n",
    "        \n",
    "        # create multindex\n",
    "        column_indexes = [(metric,dict_cp[target]) for metric in df_classification_report.columns]\n",
    "        multi_index_cols = pd.MultiIndex.from_tuples(column_indexes, names=['metric', 'target'])\n",
    "        rows_indexes = [(text_col, vectorizer, estimator, cl) for cl in df_classification_report.index]\n",
    "        multi_index_rows = pd.MultiIndex.from_tuples(rows_indexes, names=['text_col','vectorizer', 'estimator', 'class'])\n",
    "        df_classification_report.columns = multi_index_cols\n",
    "        df_classification_report.index = multi_index_rows\n",
    "        \n",
    "        # print(text_col, vectorizer, estimator,target)\n",
    "        # print(path)\n",
    "        # display(df_classification_report)\n",
    "        \n",
    "        list_cr.append(df_classification_report)\n",
    "        \n",
    "    df_results = pd.concat(list_cr, axis = 1)\n",
    "    \n",
    "    list_results.append(df_results)\n",
    "    \n",
    "df_results_final = pd.concat(list_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>metric</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>...</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>Church</th>\n",
       "      <th>Church</th>\n",
       "      <th>Church</th>\n",
       "      <th>Church</th>\n",
       "      <th>Bolsonaro</th>\n",
       "      <th>Bolsonaro</th>\n",
       "      <th>Bolsonaro</th>\n",
       "      <th>Bolsonaro</th>\n",
       "      <th>Hydrox.</th>\n",
       "      <th>Hydrox.</th>\n",
       "      <th>...</th>\n",
       "      <th>Sinovac</th>\n",
       "      <th>Sinovac</th>\n",
       "      <th>Globo TV</th>\n",
       "      <th>Globo TV</th>\n",
       "      <th>Globo TV</th>\n",
       "      <th>Globo TV</th>\n",
       "      <th>Lula</th>\n",
       "      <th>Lula</th>\n",
       "      <th>Lula</th>\n",
       "      <th>Lula</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text_col</th>\n",
       "      <th>vectorizer</th>\n",
       "      <th>estimator</th>\n",
       "      <th>class</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">Stance</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">-</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">dummy</th>\n",
       "      <th>against</th>\n",
       "      <td>0.565943</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.722814</td>\n",
       "      <td>339.000000</td>\n",
       "      <td>0.861702</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.925714</td>\n",
       "      <td>162.000000</td>\n",
       "      <td>0.503484</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>354.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>167.000000</td>\n",
       "      <td>0.525735</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.689157</td>\n",
       "      <td>143.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.565943</td>\n",
       "      <td>0.565943</td>\n",
       "      <td>0.565943</td>\n",
       "      <td>0.565943</td>\n",
       "      <td>0.861702</td>\n",
       "      <td>0.861702</td>\n",
       "      <td>0.861702</td>\n",
       "      <td>0.861702</td>\n",
       "      <td>0.503484</td>\n",
       "      <td>0.503484</td>\n",
       "      <td>...</td>\n",
       "      <td>0.542636</td>\n",
       "      <td>0.542636</td>\n",
       "      <td>0.593674</td>\n",
       "      <td>0.593674</td>\n",
       "      <td>0.593674</td>\n",
       "      <td>0.593674</td>\n",
       "      <td>0.525735</td>\n",
       "      <td>0.525735</td>\n",
       "      <td>0.525735</td>\n",
       "      <td>0.525735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.320292</td>\n",
       "      <td>0.565943</td>\n",
       "      <td>0.409072</td>\n",
       "      <td>599.000000</td>\n",
       "      <td>0.742531</td>\n",
       "      <td>0.861702</td>\n",
       "      <td>0.797690</td>\n",
       "      <td>188.000000</td>\n",
       "      <td>0.253496</td>\n",
       "      <td>0.503484</td>\n",
       "      <td>...</td>\n",
       "      <td>0.381754</td>\n",
       "      <td>774.000000</td>\n",
       "      <td>0.352449</td>\n",
       "      <td>0.593674</td>\n",
       "      <td>0.442310</td>\n",
       "      <td>411.000000</td>\n",
       "      <td>0.276398</td>\n",
       "      <td>0.525735</td>\n",
       "      <td>0.362314</td>\n",
       "      <td>272.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.282972</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.361407</td>\n",
       "      <td>599.000000</td>\n",
       "      <td>0.430851</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.462857</td>\n",
       "      <td>188.000000</td>\n",
       "      <td>0.251742</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.351759</td>\n",
       "      <td>774.000000</td>\n",
       "      <td>0.296837</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.372519</td>\n",
       "      <td>411.000000</td>\n",
       "      <td>0.262868</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.344578</td>\n",
       "      <td>272.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>for</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>260.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.703518</td>\n",
       "      <td>420.000000</td>\n",
       "      <td>0.593674</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.745038</td>\n",
       "      <td>244.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>129.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">Ensemble Texts + Timeline</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">-</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">LogisticRegression</th>\n",
       "      <th>against</th>\n",
       "      <td>0.729577</td>\n",
       "      <td>0.764012</td>\n",
       "      <td>0.746398</td>\n",
       "      <td>339.000000</td>\n",
       "      <td>0.908571</td>\n",
       "      <td>0.981481</td>\n",
       "      <td>0.943620</td>\n",
       "      <td>162.000000</td>\n",
       "      <td>0.896907</td>\n",
       "      <td>0.903114</td>\n",
       "      <td>...</td>\n",
       "      <td>0.846626</td>\n",
       "      <td>354.000000</td>\n",
       "      <td>0.582524</td>\n",
       "      <td>0.359281</td>\n",
       "      <td>0.444444</td>\n",
       "      <td>167.000000</td>\n",
       "      <td>0.756944</td>\n",
       "      <td>0.762238</td>\n",
       "      <td>0.759582</td>\n",
       "      <td>143.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.706177</td>\n",
       "      <td>0.706177</td>\n",
       "      <td>0.706177</td>\n",
       "      <td>0.706177</td>\n",
       "      <td>0.898936</td>\n",
       "      <td>0.898936</td>\n",
       "      <td>0.898936</td>\n",
       "      <td>0.898936</td>\n",
       "      <td>0.898955</td>\n",
       "      <td>0.898955</td>\n",
       "      <td>...</td>\n",
       "      <td>0.870801</td>\n",
       "      <td>0.870801</td>\n",
       "      <td>0.635036</td>\n",
       "      <td>0.635036</td>\n",
       "      <td>0.635036</td>\n",
       "      <td>0.635036</td>\n",
       "      <td>0.746324</td>\n",
       "      <td>0.746324</td>\n",
       "      <td>0.746324</td>\n",
       "      <td>0.746324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.704643</td>\n",
       "      <td>0.706177</td>\n",
       "      <td>0.704900</td>\n",
       "      <td>599.000000</td>\n",
       "      <td>0.889301</td>\n",
       "      <td>0.898936</td>\n",
       "      <td>0.884042</td>\n",
       "      <td>188.000000</td>\n",
       "      <td>0.898969</td>\n",
       "      <td>0.898955</td>\n",
       "      <td>...</td>\n",
       "      <td>0.869290</td>\n",
       "      <td>774.000000</td>\n",
       "      <td>0.624125</td>\n",
       "      <td>0.635036</td>\n",
       "      <td>0.612939</td>\n",
       "      <td>411.000000</td>\n",
       "      <td>0.746241</td>\n",
       "      <td>0.746324</td>\n",
       "      <td>0.746272</td>\n",
       "      <td>272.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.700854</td>\n",
       "      <td>0.697391</td>\n",
       "      <td>0.698596</td>\n",
       "      <td>599.000000</td>\n",
       "      <td>0.838901</td>\n",
       "      <td>0.683048</td>\n",
       "      <td>0.728220</td>\n",
       "      <td>188.000000</td>\n",
       "      <td>0.898984</td>\n",
       "      <td>0.898926</td>\n",
       "      <td>...</td>\n",
       "      <td>0.867509</td>\n",
       "      <td>774.000000</td>\n",
       "      <td>0.617561</td>\n",
       "      <td>0.591526</td>\n",
       "      <td>0.586353</td>\n",
       "      <td>411.000000</td>\n",
       "      <td>0.745660</td>\n",
       "      <td>0.745460</td>\n",
       "      <td>0.745550</td>\n",
       "      <td>272.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>for</th>\n",
       "      <td>0.672131</td>\n",
       "      <td>0.630769</td>\n",
       "      <td>0.650794</td>\n",
       "      <td>260.000000</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.384615</td>\n",
       "      <td>0.512821</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>0.901060</td>\n",
       "      <td>0.894737</td>\n",
       "      <td>...</td>\n",
       "      <td>0.888393</td>\n",
       "      <td>420.000000</td>\n",
       "      <td>0.652597</td>\n",
       "      <td>0.823770</td>\n",
       "      <td>0.728261</td>\n",
       "      <td>244.000000</td>\n",
       "      <td>0.734375</td>\n",
       "      <td>0.728682</td>\n",
       "      <td>0.731518</td>\n",
       "      <td>129.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>110 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "metric                                                               precision  \\\n",
       "target                                                                  Church   \n",
       "text_col                  vectorizer estimator          class                    \n",
       "Stance                    -          dummy              against       0.565943   \n",
       "                                                        accuracy      0.565943   \n",
       "                                                        weighted avg  0.320292   \n",
       "                                                        macro avg     0.282972   \n",
       "                                                        for           0.000000   \n",
       "...                                                                        ...   \n",
       "Ensemble Texts + Timeline -          LogisticRegression against       0.729577   \n",
       "                                                        accuracy      0.706177   \n",
       "                                                        weighted avg  0.704643   \n",
       "                                                        macro avg     0.700854   \n",
       "                                                        for           0.672131   \n",
       "\n",
       "metric                                                                  recall  \\\n",
       "target                                                                  Church   \n",
       "text_col                  vectorizer estimator          class                    \n",
       "Stance                    -          dummy              against       1.000000   \n",
       "                                                        accuracy      0.565943   \n",
       "                                                        weighted avg  0.565943   \n",
       "                                                        macro avg     0.500000   \n",
       "                                                        for           0.000000   \n",
       "...                                                                        ...   \n",
       "Ensemble Texts + Timeline -          LogisticRegression against       0.764012   \n",
       "                                                        accuracy      0.706177   \n",
       "                                                        weighted avg  0.706177   \n",
       "                                                        macro avg     0.697391   \n",
       "                                                        for           0.630769   \n",
       "\n",
       "metric                                                                f1-score  \\\n",
       "target                                                                  Church   \n",
       "text_col                  vectorizer estimator          class                    \n",
       "Stance                    -          dummy              against       0.722814   \n",
       "                                                        accuracy      0.565943   \n",
       "                                                        weighted avg  0.409072   \n",
       "                                                        macro avg     0.361407   \n",
       "                                                        for           0.000000   \n",
       "...                                                                        ...   \n",
       "Ensemble Texts + Timeline -          LogisticRegression against       0.746398   \n",
       "                                                        accuracy      0.706177   \n",
       "                                                        weighted avg  0.704900   \n",
       "                                                        macro avg     0.698596   \n",
       "                                                        for           0.650794   \n",
       "\n",
       "metric                                                                   support  \\\n",
       "target                                                                    Church   \n",
       "text_col                  vectorizer estimator          class                      \n",
       "Stance                    -          dummy              against       339.000000   \n",
       "                                                        accuracy        0.565943   \n",
       "                                                        weighted avg  599.000000   \n",
       "                                                        macro avg     599.000000   \n",
       "                                                        for           260.000000   \n",
       "...                                                                          ...   \n",
       "Ensemble Texts + Timeline -          LogisticRegression against       339.000000   \n",
       "                                                        accuracy        0.706177   \n",
       "                                                        weighted avg  599.000000   \n",
       "                                                        macro avg     599.000000   \n",
       "                                                        for           260.000000   \n",
       "\n",
       "metric                                                               precision  \\\n",
       "target                                                               Bolsonaro   \n",
       "text_col                  vectorizer estimator          class                    \n",
       "Stance                    -          dummy              against       0.861702   \n",
       "                                                        accuracy      0.861702   \n",
       "                                                        weighted avg  0.742531   \n",
       "                                                        macro avg     0.430851   \n",
       "                                                        for           0.000000   \n",
       "...                                                                        ...   \n",
       "Ensemble Texts + Timeline -          LogisticRegression against       0.908571   \n",
       "                                                        accuracy      0.898936   \n",
       "                                                        weighted avg  0.889301   \n",
       "                                                        macro avg     0.838901   \n",
       "                                                        for           0.769231   \n",
       "\n",
       "metric                                                                  recall  \\\n",
       "target                                                               Bolsonaro   \n",
       "text_col                  vectorizer estimator          class                    \n",
       "Stance                    -          dummy              against       1.000000   \n",
       "                                                        accuracy      0.861702   \n",
       "                                                        weighted avg  0.861702   \n",
       "                                                        macro avg     0.500000   \n",
       "                                                        for           0.000000   \n",
       "...                                                                        ...   \n",
       "Ensemble Texts + Timeline -          LogisticRegression against       0.981481   \n",
       "                                                        accuracy      0.898936   \n",
       "                                                        weighted avg  0.898936   \n",
       "                                                        macro avg     0.683048   \n",
       "                                                        for           0.384615   \n",
       "\n",
       "metric                                                                f1-score  \\\n",
       "target                                                               Bolsonaro   \n",
       "text_col                  vectorizer estimator          class                    \n",
       "Stance                    -          dummy              against       0.925714   \n",
       "                                                        accuracy      0.861702   \n",
       "                                                        weighted avg  0.797690   \n",
       "                                                        macro avg     0.462857   \n",
       "                                                        for           0.000000   \n",
       "...                                                                        ...   \n",
       "Ensemble Texts + Timeline -          LogisticRegression against       0.943620   \n",
       "                                                        accuracy      0.898936   \n",
       "                                                        weighted avg  0.884042   \n",
       "                                                        macro avg     0.728220   \n",
       "                                                        for           0.512821   \n",
       "\n",
       "metric                                                                   support  \\\n",
       "target                                                                 Bolsonaro   \n",
       "text_col                  vectorizer estimator          class                      \n",
       "Stance                    -          dummy              against       162.000000   \n",
       "                                                        accuracy        0.861702   \n",
       "                                                        weighted avg  188.000000   \n",
       "                                                        macro avg     188.000000   \n",
       "                                                        for            26.000000   \n",
       "...                                                                          ...   \n",
       "Ensemble Texts + Timeline -          LogisticRegression against       162.000000   \n",
       "                                                        accuracy        0.898936   \n",
       "                                                        weighted avg  188.000000   \n",
       "                                                        macro avg     188.000000   \n",
       "                                                        for            26.000000   \n",
       "\n",
       "metric                                                               precision  \\\n",
       "target                                                                 Hydrox.   \n",
       "text_col                  vectorizer estimator          class                    \n",
       "Stance                    -          dummy              against       0.503484   \n",
       "                                                        accuracy      0.503484   \n",
       "                                                        weighted avg  0.253496   \n",
       "                                                        macro avg     0.251742   \n",
       "                                                        for           0.000000   \n",
       "...                                                                        ...   \n",
       "Ensemble Texts + Timeline -          LogisticRegression against       0.896907   \n",
       "                                                        accuracy      0.898955   \n",
       "                                                        weighted avg  0.898969   \n",
       "                                                        macro avg     0.898984   \n",
       "                                                        for           0.901060   \n",
       "\n",
       "metric                                                                  recall  \\\n",
       "target                                                                 Hydrox.   \n",
       "text_col                  vectorizer estimator          class                    \n",
       "Stance                    -          dummy              against       1.000000   \n",
       "                                                        accuracy      0.503484   \n",
       "                                                        weighted avg  0.503484   \n",
       "                                                        macro avg     0.500000   \n",
       "                                                        for           0.000000   \n",
       "...                                                                        ...   \n",
       "Ensemble Texts + Timeline -          LogisticRegression against       0.903114   \n",
       "                                                        accuracy      0.898955   \n",
       "                                                        weighted avg  0.898955   \n",
       "                                                        macro avg     0.898926   \n",
       "                                                        for           0.894737   \n",
       "\n",
       "metric                                                                ...  \\\n",
       "target                                                                ...   \n",
       "text_col                  vectorizer estimator          class         ...   \n",
       "Stance                    -          dummy              against       ...   \n",
       "                                                        accuracy      ...   \n",
       "                                                        weighted avg  ...   \n",
       "                                                        macro avg     ...   \n",
       "                                                        for           ...   \n",
       "...                                                                   ...   \n",
       "Ensemble Texts + Timeline -          LogisticRegression against       ...   \n",
       "                                                        accuracy      ...   \n",
       "                                                        weighted avg  ...   \n",
       "                                                        macro avg     ...   \n",
       "                                                        for           ...   \n",
       "\n",
       "metric                                                                f1-score  \\\n",
       "target                                                                 Sinovac   \n",
       "text_col                  vectorizer estimator          class                    \n",
       "Stance                    -          dummy              against       0.000000   \n",
       "                                                        accuracy      0.542636   \n",
       "                                                        weighted avg  0.381754   \n",
       "                                                        macro avg     0.351759   \n",
       "                                                        for           0.703518   \n",
       "...                                                                        ...   \n",
       "Ensemble Texts + Timeline -          LogisticRegression against       0.846626   \n",
       "                                                        accuracy      0.870801   \n",
       "                                                        weighted avg  0.869290   \n",
       "                                                        macro avg     0.867509   \n",
       "                                                        for           0.888393   \n",
       "\n",
       "metric                                                                   support  \\\n",
       "target                                                                   Sinovac   \n",
       "text_col                  vectorizer estimator          class                      \n",
       "Stance                    -          dummy              against       354.000000   \n",
       "                                                        accuracy        0.542636   \n",
       "                                                        weighted avg  774.000000   \n",
       "                                                        macro avg     774.000000   \n",
       "                                                        for           420.000000   \n",
       "...                                                                          ...   \n",
       "Ensemble Texts + Timeline -          LogisticRegression against       354.000000   \n",
       "                                                        accuracy        0.870801   \n",
       "                                                        weighted avg  774.000000   \n",
       "                                                        macro avg     774.000000   \n",
       "                                                        for           420.000000   \n",
       "\n",
       "metric                                                               precision  \\\n",
       "target                                                                Globo TV   \n",
       "text_col                  vectorizer estimator          class                    \n",
       "Stance                    -          dummy              against       0.000000   \n",
       "                                                        accuracy      0.593674   \n",
       "                                                        weighted avg  0.352449   \n",
       "                                                        macro avg     0.296837   \n",
       "                                                        for           0.593674   \n",
       "...                                                                        ...   \n",
       "Ensemble Texts + Timeline -          LogisticRegression against       0.582524   \n",
       "                                                        accuracy      0.635036   \n",
       "                                                        weighted avg  0.624125   \n",
       "                                                        macro avg     0.617561   \n",
       "                                                        for           0.652597   \n",
       "\n",
       "metric                                                                  recall  \\\n",
       "target                                                                Globo TV   \n",
       "text_col                  vectorizer estimator          class                    \n",
       "Stance                    -          dummy              against       0.000000   \n",
       "                                                        accuracy      0.593674   \n",
       "                                                        weighted avg  0.593674   \n",
       "                                                        macro avg     0.500000   \n",
       "                                                        for           1.000000   \n",
       "...                                                                        ...   \n",
       "Ensemble Texts + Timeline -          LogisticRegression against       0.359281   \n",
       "                                                        accuracy      0.635036   \n",
       "                                                        weighted avg  0.635036   \n",
       "                                                        macro avg     0.591526   \n",
       "                                                        for           0.823770   \n",
       "\n",
       "metric                                                                f1-score  \\\n",
       "target                                                                Globo TV   \n",
       "text_col                  vectorizer estimator          class                    \n",
       "Stance                    -          dummy              against       0.000000   \n",
       "                                                        accuracy      0.593674   \n",
       "                                                        weighted avg  0.442310   \n",
       "                                                        macro avg     0.372519   \n",
       "                                                        for           0.745038   \n",
       "...                                                                        ...   \n",
       "Ensemble Texts + Timeline -          LogisticRegression against       0.444444   \n",
       "                                                        accuracy      0.635036   \n",
       "                                                        weighted avg  0.612939   \n",
       "                                                        macro avg     0.586353   \n",
       "                                                        for           0.728261   \n",
       "\n",
       "metric                                                                   support  \\\n",
       "target                                                                  Globo TV   \n",
       "text_col                  vectorizer estimator          class                      \n",
       "Stance                    -          dummy              against       167.000000   \n",
       "                                                        accuracy        0.593674   \n",
       "                                                        weighted avg  411.000000   \n",
       "                                                        macro avg     411.000000   \n",
       "                                                        for           244.000000   \n",
       "...                                                                          ...   \n",
       "Ensemble Texts + Timeline -          LogisticRegression against       167.000000   \n",
       "                                                        accuracy        0.635036   \n",
       "                                                        weighted avg  411.000000   \n",
       "                                                        macro avg     411.000000   \n",
       "                                                        for           244.000000   \n",
       "\n",
       "metric                                                               precision  \\\n",
       "target                                                                    Lula   \n",
       "text_col                  vectorizer estimator          class                    \n",
       "Stance                    -          dummy              against       0.525735   \n",
       "                                                        accuracy      0.525735   \n",
       "                                                        weighted avg  0.276398   \n",
       "                                                        macro avg     0.262868   \n",
       "                                                        for           0.000000   \n",
       "...                                                                        ...   \n",
       "Ensemble Texts + Timeline -          LogisticRegression against       0.756944   \n",
       "                                                        accuracy      0.746324   \n",
       "                                                        weighted avg  0.746241   \n",
       "                                                        macro avg     0.745660   \n",
       "                                                        for           0.734375   \n",
       "\n",
       "metric                                                                  recall  \\\n",
       "target                                                                    Lula   \n",
       "text_col                  vectorizer estimator          class                    \n",
       "Stance                    -          dummy              against       1.000000   \n",
       "                                                        accuracy      0.525735   \n",
       "                                                        weighted avg  0.525735   \n",
       "                                                        macro avg     0.500000   \n",
       "                                                        for           0.000000   \n",
       "...                                                                        ...   \n",
       "Ensemble Texts + Timeline -          LogisticRegression against       0.762238   \n",
       "                                                        accuracy      0.746324   \n",
       "                                                        weighted avg  0.746324   \n",
       "                                                        macro avg     0.745460   \n",
       "                                                        for           0.728682   \n",
       "\n",
       "metric                                                                f1-score  \\\n",
       "target                                                                    Lula   \n",
       "text_col                  vectorizer estimator          class                    \n",
       "Stance                    -          dummy              against       0.689157   \n",
       "                                                        accuracy      0.525735   \n",
       "                                                        weighted avg  0.362314   \n",
       "                                                        macro avg     0.344578   \n",
       "                                                        for           0.000000   \n",
       "...                                                                        ...   \n",
       "Ensemble Texts + Timeline -          LogisticRegression against       0.759582   \n",
       "                                                        accuracy      0.746324   \n",
       "                                                        weighted avg  0.746272   \n",
       "                                                        macro avg     0.745550   \n",
       "                                                        for           0.731518   \n",
       "\n",
       "metric                                                                   support  \n",
       "target                                                                      Lula  \n",
       "text_col                  vectorizer estimator          class                     \n",
       "Stance                    -          dummy              against       143.000000  \n",
       "                                                        accuracy        0.525735  \n",
       "                                                        weighted avg  272.000000  \n",
       "                                                        macro avg     272.000000  \n",
       "                                                        for           129.000000  \n",
       "...                                                                          ...  \n",
       "Ensemble Texts + Timeline -          LogisticRegression against       143.000000  \n",
       "                                                        accuracy        0.746324  \n",
       "                                                        weighted avg  272.000000  \n",
       "                                                        macro avg     272.000000  \n",
       "                                                        for           129.000000  \n",
       "\n",
       "[110 rows x 24 columns]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results_final.to_excel(\"../reports/table_complete_results.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create table f1 macro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>metric</th>\n",
       "      <th colspan=\"7\" halign=\"left\">f1-score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>Church</th>\n",
       "      <th>Bolsonaro</th>\n",
       "      <th>Hydrox.</th>\n",
       "      <th>Sinovac</th>\n",
       "      <th>Globo TV</th>\n",
       "      <th>Lula</th>\n",
       "      <th>overall</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text_col</th>\n",
       "      <th>vectorizer</th>\n",
       "      <th>estimator</th>\n",
       "      <th>class</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">Stance</th>\n",
       "      <th>-</th>\n",
       "      <th>dummy</th>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.361407</td>\n",
       "      <td>0.462857</td>\n",
       "      <td>0.334878</td>\n",
       "      <td>0.351759</td>\n",
       "      <td>0.372519</td>\n",
       "      <td>0.344578</td>\n",
       "      <td>0.371333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tf-idf</th>\n",
       "      <th>xgb</th>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.702021</td>\n",
       "      <td>0.595312</td>\n",
       "      <td>0.734366</td>\n",
       "      <td>0.752640</td>\n",
       "      <td>0.665243</td>\n",
       "      <td>0.654412</td>\n",
       "      <td>0.683999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bertabaporu-base</th>\n",
       "      <th>xgb</th>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.853801</td>\n",
       "      <td>0.625289</td>\n",
       "      <td>0.830948</td>\n",
       "      <td>0.808036</td>\n",
       "      <td>0.781858</td>\n",
       "      <td>0.766993</td>\n",
       "      <td>0.777821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">-</th>\n",
       "      <th>bertabaporu-base</th>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.866276</td>\n",
       "      <td>0.734945</td>\n",
       "      <td>0.844740</td>\n",
       "      <td>0.823002</td>\n",
       "      <td>0.875418</td>\n",
       "      <td>0.782733</td>\n",
       "      <td>0.821186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>llama3:7b zero-shot</th>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.729458</td>\n",
       "      <td>0.462857</td>\n",
       "      <td>0.638889</td>\n",
       "      <td>0.578779</td>\n",
       "      <td>0.770678</td>\n",
       "      <td>0.699381</td>\n",
       "      <td>0.646674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"8\" valign=\"top\">Texts</th>\n",
       "      <th>-</th>\n",
       "      <th>dummy</th>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.361407</td>\n",
       "      <td>0.462857</td>\n",
       "      <td>0.334878</td>\n",
       "      <td>0.351759</td>\n",
       "      <td>0.372519</td>\n",
       "      <td>0.344578</td>\n",
       "      <td>0.371333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tf-idf</th>\n",
       "      <th>xgb</th>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.596115</td>\n",
       "      <td>0.501220</td>\n",
       "      <td>0.603727</td>\n",
       "      <td>0.670805</td>\n",
       "      <td>0.545620</td>\n",
       "      <td>0.579427</td>\n",
       "      <td>0.582819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bertabaporu-base</th>\n",
       "      <th>xgb</th>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.594754</td>\n",
       "      <td>0.495578</td>\n",
       "      <td>0.609524</td>\n",
       "      <td>0.660542</td>\n",
       "      <td>0.534455</td>\n",
       "      <td>0.569597</td>\n",
       "      <td>0.577408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">-</th>\n",
       "      <th>bertabaporu-base</th>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.586611</td>\n",
       "      <td>0.462857</td>\n",
       "      <td>0.446504</td>\n",
       "      <td>0.608972</td>\n",
       "      <td>0.507381</td>\n",
       "      <td>0.482520</td>\n",
       "      <td>0.515808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bertabaporu-base (R)</th>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.583417</td>\n",
       "      <td>0.462857</td>\n",
       "      <td>0.570531</td>\n",
       "      <td>0.637369</td>\n",
       "      <td>0.586967</td>\n",
       "      <td>0.602167</td>\n",
       "      <td>0.573885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>llama3:7b zero-shot [5] (R)</th>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.499052</td>\n",
       "      <td>0.296142</td>\n",
       "      <td>0.469796</td>\n",
       "      <td>0.470381</td>\n",
       "      <td>0.490101</td>\n",
       "      <td>0.512954</td>\n",
       "      <td>0.456404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>llama3:7b zero-shot [10] (R)</th>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.561274</td>\n",
       "      <td>0.328245</td>\n",
       "      <td>0.440347</td>\n",
       "      <td>0.460580</td>\n",
       "      <td>0.494646</td>\n",
       "      <td>0.478244</td>\n",
       "      <td>0.460556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>llama3:7b zero-shot [15] (R)</th>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.503966</td>\n",
       "      <td>0.285253</td>\n",
       "      <td>0.416946</td>\n",
       "      <td>0.464074</td>\n",
       "      <td>0.475797</td>\n",
       "      <td>0.542401</td>\n",
       "      <td>0.448073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"8\" valign=\"top\">Timeline</th>\n",
       "      <th>-</th>\n",
       "      <th>dummy</th>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.361407</td>\n",
       "      <td>0.462857</td>\n",
       "      <td>0.334878</td>\n",
       "      <td>0.351759</td>\n",
       "      <td>0.372519</td>\n",
       "      <td>0.344578</td>\n",
       "      <td>0.371333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tf-idf</th>\n",
       "      <th>xgb</th>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.699122</td>\n",
       "      <td>0.728220</td>\n",
       "      <td>0.898944</td>\n",
       "      <td>0.863813</td>\n",
       "      <td>0.598358</td>\n",
       "      <td>0.752710</td>\n",
       "      <td>0.756861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bertabaporu-base</th>\n",
       "      <th>xgb</th>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.661773</td>\n",
       "      <td>0.692262</td>\n",
       "      <td>0.776979</td>\n",
       "      <td>0.778471</td>\n",
       "      <td>0.585105</td>\n",
       "      <td>0.645518</td>\n",
       "      <td>0.690018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">-</th>\n",
       "      <th>bertabaporu-base</th>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.652707</td>\n",
       "      <td>0.767310</td>\n",
       "      <td>0.822297</td>\n",
       "      <td>0.819813</td>\n",
       "      <td>0.580105</td>\n",
       "      <td>0.614923</td>\n",
       "      <td>0.709526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bertabaporu-base (R)</th>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.701990</td>\n",
       "      <td>0.822060</td>\n",
       "      <td>0.872170</td>\n",
       "      <td>0.860531</td>\n",
       "      <td>0.597442</td>\n",
       "      <td>0.711676</td>\n",
       "      <td>0.760978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>llama3:7b zero-shot [5] (R)</th>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.605633</td>\n",
       "      <td>0.588752</td>\n",
       "      <td>0.639513</td>\n",
       "      <td>0.528509</td>\n",
       "      <td>0.560086</td>\n",
       "      <td>0.514680</td>\n",
       "      <td>0.572862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>llama3:7b zero-shot [10] (R)</th>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.563199</td>\n",
       "      <td>0.611771</td>\n",
       "      <td>0.609199</td>\n",
       "      <td>0.529703</td>\n",
       "      <td>0.507579</td>\n",
       "      <td>0.516021</td>\n",
       "      <td>0.556245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>llama3:7b zero-shot [15] (R)</th>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.598183</td>\n",
       "      <td>0.586106</td>\n",
       "      <td>0.611868</td>\n",
       "      <td>0.518743</td>\n",
       "      <td>0.515050</td>\n",
       "      <td>0.529726</td>\n",
       "      <td>0.559946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ensemble Texts + Timeline</th>\n",
       "      <th>-</th>\n",
       "      <th>LogisticRegression</th>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.698596</td>\n",
       "      <td>0.728220</td>\n",
       "      <td>0.898944</td>\n",
       "      <td>0.867509</td>\n",
       "      <td>0.586353</td>\n",
       "      <td>0.745550</td>\n",
       "      <td>0.754195</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "metric                                                                             f1-score  \\\n",
       "target                                                                               Church   \n",
       "text_col                  vectorizer       estimator                    class                 \n",
       "Stance                    -                dummy                        macro avg  0.361407   \n",
       "                          tf-idf           xgb                          macro avg  0.702021   \n",
       "                          bertabaporu-base xgb                          macro avg  0.853801   \n",
       "                          -                bertabaporu-base             macro avg  0.866276   \n",
       "                                           llama3:7b zero-shot          macro avg  0.729458   \n",
       "Texts                     -                dummy                        macro avg  0.361407   \n",
       "                          tf-idf           xgb                          macro avg  0.596115   \n",
       "                          bertabaporu-base xgb                          macro avg  0.594754   \n",
       "                          -                bertabaporu-base             macro avg  0.586611   \n",
       "                                           bertabaporu-base (R)         macro avg  0.583417   \n",
       "                                           llama3:7b zero-shot [5] (R)  macro avg  0.499052   \n",
       "                                           llama3:7b zero-shot [10] (R) macro avg  0.561274   \n",
       "                                           llama3:7b zero-shot [15] (R) macro avg  0.503966   \n",
       "Timeline                  -                dummy                        macro avg  0.361407   \n",
       "                          tf-idf           xgb                          macro avg  0.699122   \n",
       "                          bertabaporu-base xgb                          macro avg  0.661773   \n",
       "                          -                bertabaporu-base             macro avg  0.652707   \n",
       "                                           bertabaporu-base (R)         macro avg  0.701990   \n",
       "                                           llama3:7b zero-shot [5] (R)  macro avg  0.605633   \n",
       "                                           llama3:7b zero-shot [10] (R) macro avg  0.563199   \n",
       "                                           llama3:7b zero-shot [15] (R) macro avg  0.598183   \n",
       "Ensemble Texts + Timeline -                LogisticRegression           macro avg  0.698596   \n",
       "\n",
       "metric                                                                                       \\\n",
       "target                                                                            Bolsonaro   \n",
       "text_col                  vectorizer       estimator                    class                 \n",
       "Stance                    -                dummy                        macro avg  0.462857   \n",
       "                          tf-idf           xgb                          macro avg  0.595312   \n",
       "                          bertabaporu-base xgb                          macro avg  0.625289   \n",
       "                          -                bertabaporu-base             macro avg  0.734945   \n",
       "                                           llama3:7b zero-shot          macro avg  0.462857   \n",
       "Texts                     -                dummy                        macro avg  0.462857   \n",
       "                          tf-idf           xgb                          macro avg  0.501220   \n",
       "                          bertabaporu-base xgb                          macro avg  0.495578   \n",
       "                          -                bertabaporu-base             macro avg  0.462857   \n",
       "                                           bertabaporu-base (R)         macro avg  0.462857   \n",
       "                                           llama3:7b zero-shot [5] (R)  macro avg  0.296142   \n",
       "                                           llama3:7b zero-shot [10] (R) macro avg  0.328245   \n",
       "                                           llama3:7b zero-shot [15] (R) macro avg  0.285253   \n",
       "Timeline                  -                dummy                        macro avg  0.462857   \n",
       "                          tf-idf           xgb                          macro avg  0.728220   \n",
       "                          bertabaporu-base xgb                          macro avg  0.692262   \n",
       "                          -                bertabaporu-base             macro avg  0.767310   \n",
       "                                           bertabaporu-base (R)         macro avg  0.822060   \n",
       "                                           llama3:7b zero-shot [5] (R)  macro avg  0.588752   \n",
       "                                           llama3:7b zero-shot [10] (R) macro avg  0.611771   \n",
       "                                           llama3:7b zero-shot [15] (R) macro avg  0.586106   \n",
       "Ensemble Texts + Timeline -                LogisticRegression           macro avg  0.728220   \n",
       "\n",
       "metric                                                                                       \\\n",
       "target                                                                              Hydrox.   \n",
       "text_col                  vectorizer       estimator                    class                 \n",
       "Stance                    -                dummy                        macro avg  0.334878   \n",
       "                          tf-idf           xgb                          macro avg  0.734366   \n",
       "                          bertabaporu-base xgb                          macro avg  0.830948   \n",
       "                          -                bertabaporu-base             macro avg  0.844740   \n",
       "                                           llama3:7b zero-shot          macro avg  0.638889   \n",
       "Texts                     -                dummy                        macro avg  0.334878   \n",
       "                          tf-idf           xgb                          macro avg  0.603727   \n",
       "                          bertabaporu-base xgb                          macro avg  0.609524   \n",
       "                          -                bertabaporu-base             macro avg  0.446504   \n",
       "                                           bertabaporu-base (R)         macro avg  0.570531   \n",
       "                                           llama3:7b zero-shot [5] (R)  macro avg  0.469796   \n",
       "                                           llama3:7b zero-shot [10] (R) macro avg  0.440347   \n",
       "                                           llama3:7b zero-shot [15] (R) macro avg  0.416946   \n",
       "Timeline                  -                dummy                        macro avg  0.334878   \n",
       "                          tf-idf           xgb                          macro avg  0.898944   \n",
       "                          bertabaporu-base xgb                          macro avg  0.776979   \n",
       "                          -                bertabaporu-base             macro avg  0.822297   \n",
       "                                           bertabaporu-base (R)         macro avg  0.872170   \n",
       "                                           llama3:7b zero-shot [5] (R)  macro avg  0.639513   \n",
       "                                           llama3:7b zero-shot [10] (R) macro avg  0.609199   \n",
       "                                           llama3:7b zero-shot [15] (R) macro avg  0.611868   \n",
       "Ensemble Texts + Timeline -                LogisticRegression           macro avg  0.898944   \n",
       "\n",
       "metric                                                                                       \\\n",
       "target                                                                              Sinovac   \n",
       "text_col                  vectorizer       estimator                    class                 \n",
       "Stance                    -                dummy                        macro avg  0.351759   \n",
       "                          tf-idf           xgb                          macro avg  0.752640   \n",
       "                          bertabaporu-base xgb                          macro avg  0.808036   \n",
       "                          -                bertabaporu-base             macro avg  0.823002   \n",
       "                                           llama3:7b zero-shot          macro avg  0.578779   \n",
       "Texts                     -                dummy                        macro avg  0.351759   \n",
       "                          tf-idf           xgb                          macro avg  0.670805   \n",
       "                          bertabaporu-base xgb                          macro avg  0.660542   \n",
       "                          -                bertabaporu-base             macro avg  0.608972   \n",
       "                                           bertabaporu-base (R)         macro avg  0.637369   \n",
       "                                           llama3:7b zero-shot [5] (R)  macro avg  0.470381   \n",
       "                                           llama3:7b zero-shot [10] (R) macro avg  0.460580   \n",
       "                                           llama3:7b zero-shot [15] (R) macro avg  0.464074   \n",
       "Timeline                  -                dummy                        macro avg  0.351759   \n",
       "                          tf-idf           xgb                          macro avg  0.863813   \n",
       "                          bertabaporu-base xgb                          macro avg  0.778471   \n",
       "                          -                bertabaporu-base             macro avg  0.819813   \n",
       "                                           bertabaporu-base (R)         macro avg  0.860531   \n",
       "                                           llama3:7b zero-shot [5] (R)  macro avg  0.528509   \n",
       "                                           llama3:7b zero-shot [10] (R) macro avg  0.529703   \n",
       "                                           llama3:7b zero-shot [15] (R) macro avg  0.518743   \n",
       "Ensemble Texts + Timeline -                LogisticRegression           macro avg  0.867509   \n",
       "\n",
       "metric                                                                                       \\\n",
       "target                                                                             Globo TV   \n",
       "text_col                  vectorizer       estimator                    class                 \n",
       "Stance                    -                dummy                        macro avg  0.372519   \n",
       "                          tf-idf           xgb                          macro avg  0.665243   \n",
       "                          bertabaporu-base xgb                          macro avg  0.781858   \n",
       "                          -                bertabaporu-base             macro avg  0.875418   \n",
       "                                           llama3:7b zero-shot          macro avg  0.770678   \n",
       "Texts                     -                dummy                        macro avg  0.372519   \n",
       "                          tf-idf           xgb                          macro avg  0.545620   \n",
       "                          bertabaporu-base xgb                          macro avg  0.534455   \n",
       "                          -                bertabaporu-base             macro avg  0.507381   \n",
       "                                           bertabaporu-base (R)         macro avg  0.586967   \n",
       "                                           llama3:7b zero-shot [5] (R)  macro avg  0.490101   \n",
       "                                           llama3:7b zero-shot [10] (R) macro avg  0.494646   \n",
       "                                           llama3:7b zero-shot [15] (R) macro avg  0.475797   \n",
       "Timeline                  -                dummy                        macro avg  0.372519   \n",
       "                          tf-idf           xgb                          macro avg  0.598358   \n",
       "                          bertabaporu-base xgb                          macro avg  0.585105   \n",
       "                          -                bertabaporu-base             macro avg  0.580105   \n",
       "                                           bertabaporu-base (R)         macro avg  0.597442   \n",
       "                                           llama3:7b zero-shot [5] (R)  macro avg  0.560086   \n",
       "                                           llama3:7b zero-shot [10] (R) macro avg  0.507579   \n",
       "                                           llama3:7b zero-shot [15] (R) macro avg  0.515050   \n",
       "Ensemble Texts + Timeline -                LogisticRegression           macro avg  0.586353   \n",
       "\n",
       "metric                                                                                       \\\n",
       "target                                                                                 Lula   \n",
       "text_col                  vectorizer       estimator                    class                 \n",
       "Stance                    -                dummy                        macro avg  0.344578   \n",
       "                          tf-idf           xgb                          macro avg  0.654412   \n",
       "                          bertabaporu-base xgb                          macro avg  0.766993   \n",
       "                          -                bertabaporu-base             macro avg  0.782733   \n",
       "                                           llama3:7b zero-shot          macro avg  0.699381   \n",
       "Texts                     -                dummy                        macro avg  0.344578   \n",
       "                          tf-idf           xgb                          macro avg  0.579427   \n",
       "                          bertabaporu-base xgb                          macro avg  0.569597   \n",
       "                          -                bertabaporu-base             macro avg  0.482520   \n",
       "                                           bertabaporu-base (R)         macro avg  0.602167   \n",
       "                                           llama3:7b zero-shot [5] (R)  macro avg  0.512954   \n",
       "                                           llama3:7b zero-shot [10] (R) macro avg  0.478244   \n",
       "                                           llama3:7b zero-shot [15] (R) macro avg  0.542401   \n",
       "Timeline                  -                dummy                        macro avg  0.344578   \n",
       "                          tf-idf           xgb                          macro avg  0.752710   \n",
       "                          bertabaporu-base xgb                          macro avg  0.645518   \n",
       "                          -                bertabaporu-base             macro avg  0.614923   \n",
       "                                           bertabaporu-base (R)         macro avg  0.711676   \n",
       "                                           llama3:7b zero-shot [5] (R)  macro avg  0.514680   \n",
       "                                           llama3:7b zero-shot [10] (R) macro avg  0.516021   \n",
       "                                           llama3:7b zero-shot [15] (R) macro avg  0.529726   \n",
       "Ensemble Texts + Timeline -                LogisticRegression           macro avg  0.745550   \n",
       "\n",
       "metric                                                                                       \n",
       "target                                                                              overall  \n",
       "text_col                  vectorizer       estimator                    class                \n",
       "Stance                    -                dummy                        macro avg  0.371333  \n",
       "                          tf-idf           xgb                          macro avg  0.683999  \n",
       "                          bertabaporu-base xgb                          macro avg  0.777821  \n",
       "                          -                bertabaporu-base             macro avg  0.821186  \n",
       "                                           llama3:7b zero-shot          macro avg  0.646674  \n",
       "Texts                     -                dummy                        macro avg  0.371333  \n",
       "                          tf-idf           xgb                          macro avg  0.582819  \n",
       "                          bertabaporu-base xgb                          macro avg  0.577408  \n",
       "                          -                bertabaporu-base             macro avg  0.515808  \n",
       "                                           bertabaporu-base (R)         macro avg  0.573885  \n",
       "                                           llama3:7b zero-shot [5] (R)  macro avg  0.456404  \n",
       "                                           llama3:7b zero-shot [10] (R) macro avg  0.460556  \n",
       "                                           llama3:7b zero-shot [15] (R) macro avg  0.448073  \n",
       "Timeline                  -                dummy                        macro avg  0.371333  \n",
       "                          tf-idf           xgb                          macro avg  0.756861  \n",
       "                          bertabaporu-base xgb                          macro avg  0.690018  \n",
       "                          -                bertabaporu-base             macro avg  0.709526  \n",
       "                                           bertabaporu-base (R)         macro avg  0.760978  \n",
       "                                           llama3:7b zero-shot [5] (R)  macro avg  0.572862  \n",
       "                                           llama3:7b zero-shot [10] (R) macro avg  0.556245  \n",
       "                                           llama3:7b zero-shot [15] (R) macro avg  0.559946  \n",
       "Ensemble Texts + Timeline -                LogisticRegression           macro avg  0.754195  "
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask_f1 = [True if  \"f1-score\" in col else False for col in df_results_final.columns]\n",
    "mask_macro = [True if  \"macro avg\" in col else False for col in df_results_final.index]\n",
    "\n",
    "f1_macro_df = df_results_final.loc[mask_macro,mask_f1]\n",
    "f1_macro_df[('f1-score','overall')] = f1_macro_df.mean(axis=1)\n",
    "\n",
    "f1_macro_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Table for docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>metric</th>\n",
       "      <th colspan=\"7\" halign=\"left\">f1-score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>Church</th>\n",
       "      <th>Bolsonaro</th>\n",
       "      <th>Hydrox.</th>\n",
       "      <th>Sinovac</th>\n",
       "      <th>Globo TV</th>\n",
       "      <th>Lula</th>\n",
       "      <th>overall</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text_col</th>\n",
       "      <th>vectorizer</th>\n",
       "      <th>estimator</th>\n",
       "      <th>class</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">Stance</th>\n",
       "      <th>-</th>\n",
       "      <th>dummy</th>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.361407</td>\n",
       "      <td>0.462857</td>\n",
       "      <td>0.334878</td>\n",
       "      <td>0.351759</td>\n",
       "      <td>0.372519</td>\n",
       "      <td>0.344578</td>\n",
       "      <td>0.371333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tf-idf</th>\n",
       "      <th>xgb</th>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.702021</td>\n",
       "      <td>0.595312</td>\n",
       "      <td>0.734366</td>\n",
       "      <td>0.752640</td>\n",
       "      <td>0.665243</td>\n",
       "      <td>0.654412</td>\n",
       "      <td>0.683999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bertabaporu-base</th>\n",
       "      <th>xgb</th>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.853801</td>\n",
       "      <td>0.625289</td>\n",
       "      <td>0.830948</td>\n",
       "      <td>0.808036</td>\n",
       "      <td>0.781858</td>\n",
       "      <td>0.766993</td>\n",
       "      <td>0.777821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">-</th>\n",
       "      <th>bertabaporu-base</th>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.866276</td>\n",
       "      <td>0.734945</td>\n",
       "      <td>0.844740</td>\n",
       "      <td>0.823002</td>\n",
       "      <td>0.875418</td>\n",
       "      <td>0.782733</td>\n",
       "      <td>0.821186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>llama3:7b zero-shot</th>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.729458</td>\n",
       "      <td>0.462857</td>\n",
       "      <td>0.638889</td>\n",
       "      <td>0.578779</td>\n",
       "      <td>0.770678</td>\n",
       "      <td>0.699381</td>\n",
       "      <td>0.646674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"8\" valign=\"top\">Texts</th>\n",
       "      <th>-</th>\n",
       "      <th>dummy</th>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.361407</td>\n",
       "      <td>0.462857</td>\n",
       "      <td>0.334878</td>\n",
       "      <td>0.351759</td>\n",
       "      <td>0.372519</td>\n",
       "      <td>0.344578</td>\n",
       "      <td>0.371333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tf-idf</th>\n",
       "      <th>xgb</th>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.596115</td>\n",
       "      <td>0.501220</td>\n",
       "      <td>0.603727</td>\n",
       "      <td>0.670805</td>\n",
       "      <td>0.545620</td>\n",
       "      <td>0.579427</td>\n",
       "      <td>0.582819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bertabaporu-base</th>\n",
       "      <th>xgb</th>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.594754</td>\n",
       "      <td>0.495578</td>\n",
       "      <td>0.609524</td>\n",
       "      <td>0.660542</td>\n",
       "      <td>0.534455</td>\n",
       "      <td>0.569597</td>\n",
       "      <td>0.577408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">-</th>\n",
       "      <th>bertabaporu-base</th>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.586611</td>\n",
       "      <td>0.462857</td>\n",
       "      <td>0.446504</td>\n",
       "      <td>0.608972</td>\n",
       "      <td>0.507381</td>\n",
       "      <td>0.482520</td>\n",
       "      <td>0.515808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bertabaporu-base (R)</th>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.583417</td>\n",
       "      <td>0.462857</td>\n",
       "      <td>0.570531</td>\n",
       "      <td>0.637369</td>\n",
       "      <td>0.586967</td>\n",
       "      <td>0.602167</td>\n",
       "      <td>0.573885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>llama3:7b zero-shot [5] (R)</th>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.499052</td>\n",
       "      <td>0.296142</td>\n",
       "      <td>0.469796</td>\n",
       "      <td>0.470381</td>\n",
       "      <td>0.490101</td>\n",
       "      <td>0.512954</td>\n",
       "      <td>0.456404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>llama3:7b zero-shot [10] (R)</th>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.561274</td>\n",
       "      <td>0.328245</td>\n",
       "      <td>0.440347</td>\n",
       "      <td>0.460580</td>\n",
       "      <td>0.494646</td>\n",
       "      <td>0.478244</td>\n",
       "      <td>0.460556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>llama3:7b zero-shot [15] (R)</th>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.503966</td>\n",
       "      <td>0.285253</td>\n",
       "      <td>0.416946</td>\n",
       "      <td>0.464074</td>\n",
       "      <td>0.475797</td>\n",
       "      <td>0.542401</td>\n",
       "      <td>0.448073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"8\" valign=\"top\">Timeline</th>\n",
       "      <th>-</th>\n",
       "      <th>dummy</th>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.361407</td>\n",
       "      <td>0.462857</td>\n",
       "      <td>0.334878</td>\n",
       "      <td>0.351759</td>\n",
       "      <td>0.372519</td>\n",
       "      <td>0.344578</td>\n",
       "      <td>0.371333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tf-idf</th>\n",
       "      <th>xgb</th>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.699122</td>\n",
       "      <td>0.728220</td>\n",
       "      <td>0.898944</td>\n",
       "      <td>0.863813</td>\n",
       "      <td>0.598358</td>\n",
       "      <td>0.752710</td>\n",
       "      <td>0.756861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bertabaporu-base</th>\n",
       "      <th>xgb</th>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.661773</td>\n",
       "      <td>0.692262</td>\n",
       "      <td>0.776979</td>\n",
       "      <td>0.778471</td>\n",
       "      <td>0.585105</td>\n",
       "      <td>0.645518</td>\n",
       "      <td>0.690018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">-</th>\n",
       "      <th>bertabaporu-base</th>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.652707</td>\n",
       "      <td>0.767310</td>\n",
       "      <td>0.822297</td>\n",
       "      <td>0.819813</td>\n",
       "      <td>0.580105</td>\n",
       "      <td>0.614923</td>\n",
       "      <td>0.709526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bertabaporu-base (R)</th>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.701990</td>\n",
       "      <td>0.822060</td>\n",
       "      <td>0.872170</td>\n",
       "      <td>0.860531</td>\n",
       "      <td>0.597442</td>\n",
       "      <td>0.711676</td>\n",
       "      <td>0.760978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>llama3:7b zero-shot [5] (R)</th>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.605633</td>\n",
       "      <td>0.588752</td>\n",
       "      <td>0.639513</td>\n",
       "      <td>0.528509</td>\n",
       "      <td>0.560086</td>\n",
       "      <td>0.514680</td>\n",
       "      <td>0.572862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>llama3:7b zero-shot [10] (R)</th>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.563199</td>\n",
       "      <td>0.611771</td>\n",
       "      <td>0.609199</td>\n",
       "      <td>0.529703</td>\n",
       "      <td>0.507579</td>\n",
       "      <td>0.516021</td>\n",
       "      <td>0.556245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>llama3:7b zero-shot [15] (R)</th>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.598183</td>\n",
       "      <td>0.586106</td>\n",
       "      <td>0.611868</td>\n",
       "      <td>0.518743</td>\n",
       "      <td>0.515050</td>\n",
       "      <td>0.529726</td>\n",
       "      <td>0.559946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ensemble Texts + Timeline</th>\n",
       "      <th>-</th>\n",
       "      <th>LogisticRegression</th>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.698596</td>\n",
       "      <td>0.728220</td>\n",
       "      <td>0.898944</td>\n",
       "      <td>0.867509</td>\n",
       "      <td>0.586353</td>\n",
       "      <td>0.745550</td>\n",
       "      <td>0.754195</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "metric                                                                             f1-score  \\\n",
       "target                                                                               Church   \n",
       "text_col                  vectorizer       estimator                    class                 \n",
       "Stance                    -                dummy                        macro avg  0.361407   \n",
       "                          tf-idf           xgb                          macro avg  0.702021   \n",
       "                          bertabaporu-base xgb                          macro avg  0.853801   \n",
       "                          -                bertabaporu-base             macro avg  0.866276   \n",
       "                                           llama3:7b zero-shot          macro avg  0.729458   \n",
       "Texts                     -                dummy                        macro avg  0.361407   \n",
       "                          tf-idf           xgb                          macro avg  0.596115   \n",
       "                          bertabaporu-base xgb                          macro avg  0.594754   \n",
       "                          -                bertabaporu-base             macro avg  0.586611   \n",
       "                                           bertabaporu-base (R)         macro avg  0.583417   \n",
       "                                           llama3:7b zero-shot [5] (R)  macro avg  0.499052   \n",
       "                                           llama3:7b zero-shot [10] (R) macro avg  0.561274   \n",
       "                                           llama3:7b zero-shot [15] (R) macro avg  0.503966   \n",
       "Timeline                  -                dummy                        macro avg  0.361407   \n",
       "                          tf-idf           xgb                          macro avg  0.699122   \n",
       "                          bertabaporu-base xgb                          macro avg  0.661773   \n",
       "                          -                bertabaporu-base             macro avg  0.652707   \n",
       "                                           bertabaporu-base (R)         macro avg  0.701990   \n",
       "                                           llama3:7b zero-shot [5] (R)  macro avg  0.605633   \n",
       "                                           llama3:7b zero-shot [10] (R) macro avg  0.563199   \n",
       "                                           llama3:7b zero-shot [15] (R) macro avg  0.598183   \n",
       "Ensemble Texts + Timeline -                LogisticRegression           macro avg  0.698596   \n",
       "\n",
       "metric                                                                                       \\\n",
       "target                                                                            Bolsonaro   \n",
       "text_col                  vectorizer       estimator                    class                 \n",
       "Stance                    -                dummy                        macro avg  0.462857   \n",
       "                          tf-idf           xgb                          macro avg  0.595312   \n",
       "                          bertabaporu-base xgb                          macro avg  0.625289   \n",
       "                          -                bertabaporu-base             macro avg  0.734945   \n",
       "                                           llama3:7b zero-shot          macro avg  0.462857   \n",
       "Texts                     -                dummy                        macro avg  0.462857   \n",
       "                          tf-idf           xgb                          macro avg  0.501220   \n",
       "                          bertabaporu-base xgb                          macro avg  0.495578   \n",
       "                          -                bertabaporu-base             macro avg  0.462857   \n",
       "                                           bertabaporu-base (R)         macro avg  0.462857   \n",
       "                                           llama3:7b zero-shot [5] (R)  macro avg  0.296142   \n",
       "                                           llama3:7b zero-shot [10] (R) macro avg  0.328245   \n",
       "                                           llama3:7b zero-shot [15] (R) macro avg  0.285253   \n",
       "Timeline                  -                dummy                        macro avg  0.462857   \n",
       "                          tf-idf           xgb                          macro avg  0.728220   \n",
       "                          bertabaporu-base xgb                          macro avg  0.692262   \n",
       "                          -                bertabaporu-base             macro avg  0.767310   \n",
       "                                           bertabaporu-base (R)         macro avg  0.822060   \n",
       "                                           llama3:7b zero-shot [5] (R)  macro avg  0.588752   \n",
       "                                           llama3:7b zero-shot [10] (R) macro avg  0.611771   \n",
       "                                           llama3:7b zero-shot [15] (R) macro avg  0.586106   \n",
       "Ensemble Texts + Timeline -                LogisticRegression           macro avg  0.728220   \n",
       "\n",
       "metric                                                                                       \\\n",
       "target                                                                              Hydrox.   \n",
       "text_col                  vectorizer       estimator                    class                 \n",
       "Stance                    -                dummy                        macro avg  0.334878   \n",
       "                          tf-idf           xgb                          macro avg  0.734366   \n",
       "                          bertabaporu-base xgb                          macro avg  0.830948   \n",
       "                          -                bertabaporu-base             macro avg  0.844740   \n",
       "                                           llama3:7b zero-shot          macro avg  0.638889   \n",
       "Texts                     -                dummy                        macro avg  0.334878   \n",
       "                          tf-idf           xgb                          macro avg  0.603727   \n",
       "                          bertabaporu-base xgb                          macro avg  0.609524   \n",
       "                          -                bertabaporu-base             macro avg  0.446504   \n",
       "                                           bertabaporu-base (R)         macro avg  0.570531   \n",
       "                                           llama3:7b zero-shot [5] (R)  macro avg  0.469796   \n",
       "                                           llama3:7b zero-shot [10] (R) macro avg  0.440347   \n",
       "                                           llama3:7b zero-shot [15] (R) macro avg  0.416946   \n",
       "Timeline                  -                dummy                        macro avg  0.334878   \n",
       "                          tf-idf           xgb                          macro avg  0.898944   \n",
       "                          bertabaporu-base xgb                          macro avg  0.776979   \n",
       "                          -                bertabaporu-base             macro avg  0.822297   \n",
       "                                           bertabaporu-base (R)         macro avg  0.872170   \n",
       "                                           llama3:7b zero-shot [5] (R)  macro avg  0.639513   \n",
       "                                           llama3:7b zero-shot [10] (R) macro avg  0.609199   \n",
       "                                           llama3:7b zero-shot [15] (R) macro avg  0.611868   \n",
       "Ensemble Texts + Timeline -                LogisticRegression           macro avg  0.898944   \n",
       "\n",
       "metric                                                                                       \\\n",
       "target                                                                              Sinovac   \n",
       "text_col                  vectorizer       estimator                    class                 \n",
       "Stance                    -                dummy                        macro avg  0.351759   \n",
       "                          tf-idf           xgb                          macro avg  0.752640   \n",
       "                          bertabaporu-base xgb                          macro avg  0.808036   \n",
       "                          -                bertabaporu-base             macro avg  0.823002   \n",
       "                                           llama3:7b zero-shot          macro avg  0.578779   \n",
       "Texts                     -                dummy                        macro avg  0.351759   \n",
       "                          tf-idf           xgb                          macro avg  0.670805   \n",
       "                          bertabaporu-base xgb                          macro avg  0.660542   \n",
       "                          -                bertabaporu-base             macro avg  0.608972   \n",
       "                                           bertabaporu-base (R)         macro avg  0.637369   \n",
       "                                           llama3:7b zero-shot [5] (R)  macro avg  0.470381   \n",
       "                                           llama3:7b zero-shot [10] (R) macro avg  0.460580   \n",
       "                                           llama3:7b zero-shot [15] (R) macro avg  0.464074   \n",
       "Timeline                  -                dummy                        macro avg  0.351759   \n",
       "                          tf-idf           xgb                          macro avg  0.863813   \n",
       "                          bertabaporu-base xgb                          macro avg  0.778471   \n",
       "                          -                bertabaporu-base             macro avg  0.819813   \n",
       "                                           bertabaporu-base (R)         macro avg  0.860531   \n",
       "                                           llama3:7b zero-shot [5] (R)  macro avg  0.528509   \n",
       "                                           llama3:7b zero-shot [10] (R) macro avg  0.529703   \n",
       "                                           llama3:7b zero-shot [15] (R) macro avg  0.518743   \n",
       "Ensemble Texts + Timeline -                LogisticRegression           macro avg  0.867509   \n",
       "\n",
       "metric                                                                                       \\\n",
       "target                                                                             Globo TV   \n",
       "text_col                  vectorizer       estimator                    class                 \n",
       "Stance                    -                dummy                        macro avg  0.372519   \n",
       "                          tf-idf           xgb                          macro avg  0.665243   \n",
       "                          bertabaporu-base xgb                          macro avg  0.781858   \n",
       "                          -                bertabaporu-base             macro avg  0.875418   \n",
       "                                           llama3:7b zero-shot          macro avg  0.770678   \n",
       "Texts                     -                dummy                        macro avg  0.372519   \n",
       "                          tf-idf           xgb                          macro avg  0.545620   \n",
       "                          bertabaporu-base xgb                          macro avg  0.534455   \n",
       "                          -                bertabaporu-base             macro avg  0.507381   \n",
       "                                           bertabaporu-base (R)         macro avg  0.586967   \n",
       "                                           llama3:7b zero-shot [5] (R)  macro avg  0.490101   \n",
       "                                           llama3:7b zero-shot [10] (R) macro avg  0.494646   \n",
       "                                           llama3:7b zero-shot [15] (R) macro avg  0.475797   \n",
       "Timeline                  -                dummy                        macro avg  0.372519   \n",
       "                          tf-idf           xgb                          macro avg  0.598358   \n",
       "                          bertabaporu-base xgb                          macro avg  0.585105   \n",
       "                          -                bertabaporu-base             macro avg  0.580105   \n",
       "                                           bertabaporu-base (R)         macro avg  0.597442   \n",
       "                                           llama3:7b zero-shot [5] (R)  macro avg  0.560086   \n",
       "                                           llama3:7b zero-shot [10] (R) macro avg  0.507579   \n",
       "                                           llama3:7b zero-shot [15] (R) macro avg  0.515050   \n",
       "Ensemble Texts + Timeline -                LogisticRegression           macro avg  0.586353   \n",
       "\n",
       "metric                                                                                       \\\n",
       "target                                                                                 Lula   \n",
       "text_col                  vectorizer       estimator                    class                 \n",
       "Stance                    -                dummy                        macro avg  0.344578   \n",
       "                          tf-idf           xgb                          macro avg  0.654412   \n",
       "                          bertabaporu-base xgb                          macro avg  0.766993   \n",
       "                          -                bertabaporu-base             macro avg  0.782733   \n",
       "                                           llama3:7b zero-shot          macro avg  0.699381   \n",
       "Texts                     -                dummy                        macro avg  0.344578   \n",
       "                          tf-idf           xgb                          macro avg  0.579427   \n",
       "                          bertabaporu-base xgb                          macro avg  0.569597   \n",
       "                          -                bertabaporu-base             macro avg  0.482520   \n",
       "                                           bertabaporu-base (R)         macro avg  0.602167   \n",
       "                                           llama3:7b zero-shot [5] (R)  macro avg  0.512954   \n",
       "                                           llama3:7b zero-shot [10] (R) macro avg  0.478244   \n",
       "                                           llama3:7b zero-shot [15] (R) macro avg  0.542401   \n",
       "Timeline                  -                dummy                        macro avg  0.344578   \n",
       "                          tf-idf           xgb                          macro avg  0.752710   \n",
       "                          bertabaporu-base xgb                          macro avg  0.645518   \n",
       "                          -                bertabaporu-base             macro avg  0.614923   \n",
       "                                           bertabaporu-base (R)         macro avg  0.711676   \n",
       "                                           llama3:7b zero-shot [5] (R)  macro avg  0.514680   \n",
       "                                           llama3:7b zero-shot [10] (R) macro avg  0.516021   \n",
       "                                           llama3:7b zero-shot [15] (R) macro avg  0.529726   \n",
       "Ensemble Texts + Timeline -                LogisticRegression           macro avg  0.745550   \n",
       "\n",
       "metric                                                                                       \n",
       "target                                                                              overall  \n",
       "text_col                  vectorizer       estimator                    class                \n",
       "Stance                    -                dummy                        macro avg  0.371333  \n",
       "                          tf-idf           xgb                          macro avg  0.683999  \n",
       "                          bertabaporu-base xgb                          macro avg  0.777821  \n",
       "                          -                bertabaporu-base             macro avg  0.821186  \n",
       "                                           llama3:7b zero-shot          macro avg  0.646674  \n",
       "Texts                     -                dummy                        macro avg  0.371333  \n",
       "                          tf-idf           xgb                          macro avg  0.582819  \n",
       "                          bertabaporu-base xgb                          macro avg  0.577408  \n",
       "                          -                bertabaporu-base             macro avg  0.515808  \n",
       "                                           bertabaporu-base (R)         macro avg  0.573885  \n",
       "                                           llama3:7b zero-shot [5] (R)  macro avg  0.456404  \n",
       "                                           llama3:7b zero-shot [10] (R) macro avg  0.460556  \n",
       "                                           llama3:7b zero-shot [15] (R) macro avg  0.448073  \n",
       "Timeline                  -                dummy                        macro avg  0.371333  \n",
       "                          tf-idf           xgb                          macro avg  0.756861  \n",
       "                          bertabaporu-base xgb                          macro avg  0.690018  \n",
       "                          -                bertabaporu-base             macro avg  0.709526  \n",
       "                                           bertabaporu-base (R)         macro avg  0.760978  \n",
       "                                           llama3:7b zero-shot [5] (R)  macro avg  0.572862  \n",
       "                                           llama3:7b zero-shot [10] (R) macro avg  0.556245  \n",
       "                                           llama3:7b zero-shot [15] (R) macro avg  0.559946  \n",
       "Ensemble Texts + Timeline -                LogisticRegression           macro avg  0.754195  "
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_report = f1_macro_df.copy()\n",
    "f1_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>metric</th>\n",
       "      <th>text_col</th>\n",
       "      <th>vectorizer</th>\n",
       "      <th>estimator</th>\n",
       "      <th>class</th>\n",
       "      <th colspan=\"7\" halign=\"left\">f1-score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>target</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Church</th>\n",
       "      <th>Bolsonaro</th>\n",
       "      <th>Hydrox.</th>\n",
       "      <th>Sinovac</th>\n",
       "      <th>Globo TV</th>\n",
       "      <th>Lula</th>\n",
       "      <th>overall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Stance</td>\n",
       "      <td>-</td>\n",
       "      <td>dummy</td>\n",
       "      <td>macro avg</td>\n",
       "      <td>0.361407</td>\n",
       "      <td>0.462857</td>\n",
       "      <td>0.334878</td>\n",
       "      <td>0.351759</td>\n",
       "      <td>0.372519</td>\n",
       "      <td>0.344578</td>\n",
       "      <td>0.371333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Stance</td>\n",
       "      <td>tf-idf</td>\n",
       "      <td>xgb</td>\n",
       "      <td>macro avg</td>\n",
       "      <td>0.702021</td>\n",
       "      <td>0.595312</td>\n",
       "      <td>0.734366</td>\n",
       "      <td>0.752640</td>\n",
       "      <td>0.665243</td>\n",
       "      <td>0.654412</td>\n",
       "      <td>0.683999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Stance</td>\n",
       "      <td>bertabaporu-base</td>\n",
       "      <td>xgb</td>\n",
       "      <td>macro avg</td>\n",
       "      <td>0.853801</td>\n",
       "      <td>0.625289</td>\n",
       "      <td>0.830948</td>\n",
       "      <td>0.808036</td>\n",
       "      <td>0.781858</td>\n",
       "      <td>0.766993</td>\n",
       "      <td>0.777821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Stance</td>\n",
       "      <td>-</td>\n",
       "      <td>bertabaporu-base</td>\n",
       "      <td>macro avg</td>\n",
       "      <td>0.866276</td>\n",
       "      <td>0.734945</td>\n",
       "      <td>0.844740</td>\n",
       "      <td>0.823002</td>\n",
       "      <td>0.875418</td>\n",
       "      <td>0.782733</td>\n",
       "      <td>0.821186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Stance</td>\n",
       "      <td>-</td>\n",
       "      <td>llama3:7b zero-shot</td>\n",
       "      <td>macro avg</td>\n",
       "      <td>0.729458</td>\n",
       "      <td>0.462857</td>\n",
       "      <td>0.638889</td>\n",
       "      <td>0.578779</td>\n",
       "      <td>0.770678</td>\n",
       "      <td>0.699381</td>\n",
       "      <td>0.646674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Texts</td>\n",
       "      <td>-</td>\n",
       "      <td>dummy</td>\n",
       "      <td>macro avg</td>\n",
       "      <td>0.361407</td>\n",
       "      <td>0.462857</td>\n",
       "      <td>0.334878</td>\n",
       "      <td>0.351759</td>\n",
       "      <td>0.372519</td>\n",
       "      <td>0.344578</td>\n",
       "      <td>0.371333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Texts</td>\n",
       "      <td>tf-idf</td>\n",
       "      <td>xgb</td>\n",
       "      <td>macro avg</td>\n",
       "      <td>0.596115</td>\n",
       "      <td>0.501220</td>\n",
       "      <td>0.603727</td>\n",
       "      <td>0.670805</td>\n",
       "      <td>0.545620</td>\n",
       "      <td>0.579427</td>\n",
       "      <td>0.582819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Texts</td>\n",
       "      <td>bertabaporu-base</td>\n",
       "      <td>xgb</td>\n",
       "      <td>macro avg</td>\n",
       "      <td>0.594754</td>\n",
       "      <td>0.495578</td>\n",
       "      <td>0.609524</td>\n",
       "      <td>0.660542</td>\n",
       "      <td>0.534455</td>\n",
       "      <td>0.569597</td>\n",
       "      <td>0.577408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Texts</td>\n",
       "      <td>-</td>\n",
       "      <td>bertabaporu-base</td>\n",
       "      <td>macro avg</td>\n",
       "      <td>0.586611</td>\n",
       "      <td>0.462857</td>\n",
       "      <td>0.446504</td>\n",
       "      <td>0.608972</td>\n",
       "      <td>0.507381</td>\n",
       "      <td>0.482520</td>\n",
       "      <td>0.515808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Texts</td>\n",
       "      <td>-</td>\n",
       "      <td>bertabaporu-base (R)</td>\n",
       "      <td>macro avg</td>\n",
       "      <td>0.583417</td>\n",
       "      <td>0.462857</td>\n",
       "      <td>0.570531</td>\n",
       "      <td>0.637369</td>\n",
       "      <td>0.586967</td>\n",
       "      <td>0.602167</td>\n",
       "      <td>0.573885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Texts</td>\n",
       "      <td>-</td>\n",
       "      <td>llama3:7b zero-shot [5] (R)</td>\n",
       "      <td>macro avg</td>\n",
       "      <td>0.499052</td>\n",
       "      <td>0.296142</td>\n",
       "      <td>0.469796</td>\n",
       "      <td>0.470381</td>\n",
       "      <td>0.490101</td>\n",
       "      <td>0.512954</td>\n",
       "      <td>0.456404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Texts</td>\n",
       "      <td>-</td>\n",
       "      <td>llama3:7b zero-shot [10] (R)</td>\n",
       "      <td>macro avg</td>\n",
       "      <td>0.561274</td>\n",
       "      <td>0.328245</td>\n",
       "      <td>0.440347</td>\n",
       "      <td>0.460580</td>\n",
       "      <td>0.494646</td>\n",
       "      <td>0.478244</td>\n",
       "      <td>0.460556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Texts</td>\n",
       "      <td>-</td>\n",
       "      <td>llama3:7b zero-shot [15] (R)</td>\n",
       "      <td>macro avg</td>\n",
       "      <td>0.503966</td>\n",
       "      <td>0.285253</td>\n",
       "      <td>0.416946</td>\n",
       "      <td>0.464074</td>\n",
       "      <td>0.475797</td>\n",
       "      <td>0.542401</td>\n",
       "      <td>0.448073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Timeline</td>\n",
       "      <td>-</td>\n",
       "      <td>dummy</td>\n",
       "      <td>macro avg</td>\n",
       "      <td>0.361407</td>\n",
       "      <td>0.462857</td>\n",
       "      <td>0.334878</td>\n",
       "      <td>0.351759</td>\n",
       "      <td>0.372519</td>\n",
       "      <td>0.344578</td>\n",
       "      <td>0.371333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Timeline</td>\n",
       "      <td>tf-idf</td>\n",
       "      <td>xgb</td>\n",
       "      <td>macro avg</td>\n",
       "      <td>0.699122</td>\n",
       "      <td>0.728220</td>\n",
       "      <td>0.898944</td>\n",
       "      <td>0.863813</td>\n",
       "      <td>0.598358</td>\n",
       "      <td>0.752710</td>\n",
       "      <td>0.756861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Timeline</td>\n",
       "      <td>bertabaporu-base</td>\n",
       "      <td>xgb</td>\n",
       "      <td>macro avg</td>\n",
       "      <td>0.661773</td>\n",
       "      <td>0.692262</td>\n",
       "      <td>0.776979</td>\n",
       "      <td>0.778471</td>\n",
       "      <td>0.585105</td>\n",
       "      <td>0.645518</td>\n",
       "      <td>0.690018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Timeline</td>\n",
       "      <td>-</td>\n",
       "      <td>bertabaporu-base</td>\n",
       "      <td>macro avg</td>\n",
       "      <td>0.652707</td>\n",
       "      <td>0.767310</td>\n",
       "      <td>0.822297</td>\n",
       "      <td>0.819813</td>\n",
       "      <td>0.580105</td>\n",
       "      <td>0.614923</td>\n",
       "      <td>0.709526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Timeline</td>\n",
       "      <td>-</td>\n",
       "      <td>bertabaporu-base (R)</td>\n",
       "      <td>macro avg</td>\n",
       "      <td>0.701990</td>\n",
       "      <td>0.822060</td>\n",
       "      <td>0.872170</td>\n",
       "      <td>0.860531</td>\n",
       "      <td>0.597442</td>\n",
       "      <td>0.711676</td>\n",
       "      <td>0.760978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Timeline</td>\n",
       "      <td>-</td>\n",
       "      <td>llama3:7b zero-shot [5] (R)</td>\n",
       "      <td>macro avg</td>\n",
       "      <td>0.605633</td>\n",
       "      <td>0.588752</td>\n",
       "      <td>0.639513</td>\n",
       "      <td>0.528509</td>\n",
       "      <td>0.560086</td>\n",
       "      <td>0.514680</td>\n",
       "      <td>0.572862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Timeline</td>\n",
       "      <td>-</td>\n",
       "      <td>llama3:7b zero-shot [10] (R)</td>\n",
       "      <td>macro avg</td>\n",
       "      <td>0.563199</td>\n",
       "      <td>0.611771</td>\n",
       "      <td>0.609199</td>\n",
       "      <td>0.529703</td>\n",
       "      <td>0.507579</td>\n",
       "      <td>0.516021</td>\n",
       "      <td>0.556245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Timeline</td>\n",
       "      <td>-</td>\n",
       "      <td>llama3:7b zero-shot [15] (R)</td>\n",
       "      <td>macro avg</td>\n",
       "      <td>0.598183</td>\n",
       "      <td>0.586106</td>\n",
       "      <td>0.611868</td>\n",
       "      <td>0.518743</td>\n",
       "      <td>0.515050</td>\n",
       "      <td>0.529726</td>\n",
       "      <td>0.559946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Ensemble Texts + Timeline</td>\n",
       "      <td>-</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>macro avg</td>\n",
       "      <td>0.698596</td>\n",
       "      <td>0.728220</td>\n",
       "      <td>0.898944</td>\n",
       "      <td>0.867509</td>\n",
       "      <td>0.586353</td>\n",
       "      <td>0.745550</td>\n",
       "      <td>0.754195</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "metric                   text_col        vectorizer  \\\n",
       "target                                                \n",
       "0                          Stance                 -   \n",
       "1                          Stance            tf-idf   \n",
       "2                          Stance  bertabaporu-base   \n",
       "3                          Stance                 -   \n",
       "4                          Stance                 -   \n",
       "5                           Texts                 -   \n",
       "6                           Texts            tf-idf   \n",
       "7                           Texts  bertabaporu-base   \n",
       "8                           Texts                 -   \n",
       "9                           Texts                 -   \n",
       "10                          Texts                 -   \n",
       "11                          Texts                 -   \n",
       "12                          Texts                 -   \n",
       "13                       Timeline                 -   \n",
       "14                       Timeline            tf-idf   \n",
       "15                       Timeline  bertabaporu-base   \n",
       "16                       Timeline                 -   \n",
       "17                       Timeline                 -   \n",
       "18                       Timeline                 -   \n",
       "19                       Timeline                 -   \n",
       "20                       Timeline                 -   \n",
       "21      Ensemble Texts + Timeline                 -   \n",
       "\n",
       "metric                     estimator      class  f1-score                      \\\n",
       "target                                             Church Bolsonaro   Hydrox.   \n",
       "0                              dummy  macro avg  0.361407  0.462857  0.334878   \n",
       "1                                xgb  macro avg  0.702021  0.595312  0.734366   \n",
       "2                                xgb  macro avg  0.853801  0.625289  0.830948   \n",
       "3                   bertabaporu-base  macro avg  0.866276  0.734945  0.844740   \n",
       "4                llama3:7b zero-shot  macro avg  0.729458  0.462857  0.638889   \n",
       "5                              dummy  macro avg  0.361407  0.462857  0.334878   \n",
       "6                                xgb  macro avg  0.596115  0.501220  0.603727   \n",
       "7                                xgb  macro avg  0.594754  0.495578  0.609524   \n",
       "8                   bertabaporu-base  macro avg  0.586611  0.462857  0.446504   \n",
       "9               bertabaporu-base (R)  macro avg  0.583417  0.462857  0.570531   \n",
       "10       llama3:7b zero-shot [5] (R)  macro avg  0.499052  0.296142  0.469796   \n",
       "11      llama3:7b zero-shot [10] (R)  macro avg  0.561274  0.328245  0.440347   \n",
       "12      llama3:7b zero-shot [15] (R)  macro avg  0.503966  0.285253  0.416946   \n",
       "13                             dummy  macro avg  0.361407  0.462857  0.334878   \n",
       "14                               xgb  macro avg  0.699122  0.728220  0.898944   \n",
       "15                               xgb  macro avg  0.661773  0.692262  0.776979   \n",
       "16                  bertabaporu-base  macro avg  0.652707  0.767310  0.822297   \n",
       "17              bertabaporu-base (R)  macro avg  0.701990  0.822060  0.872170   \n",
       "18       llama3:7b zero-shot [5] (R)  macro avg  0.605633  0.588752  0.639513   \n",
       "19      llama3:7b zero-shot [10] (R)  macro avg  0.563199  0.611771  0.609199   \n",
       "20      llama3:7b zero-shot [15] (R)  macro avg  0.598183  0.586106  0.611868   \n",
       "21                LogisticRegression  macro avg  0.698596  0.728220  0.898944   \n",
       "\n",
       "metric                                          \n",
       "target   Sinovac  Globo TV      Lula   overall  \n",
       "0       0.351759  0.372519  0.344578  0.371333  \n",
       "1       0.752640  0.665243  0.654412  0.683999  \n",
       "2       0.808036  0.781858  0.766993  0.777821  \n",
       "3       0.823002  0.875418  0.782733  0.821186  \n",
       "4       0.578779  0.770678  0.699381  0.646674  \n",
       "5       0.351759  0.372519  0.344578  0.371333  \n",
       "6       0.670805  0.545620  0.579427  0.582819  \n",
       "7       0.660542  0.534455  0.569597  0.577408  \n",
       "8       0.608972  0.507381  0.482520  0.515808  \n",
       "9       0.637369  0.586967  0.602167  0.573885  \n",
       "10      0.470381  0.490101  0.512954  0.456404  \n",
       "11      0.460580  0.494646  0.478244  0.460556  \n",
       "12      0.464074  0.475797  0.542401  0.448073  \n",
       "13      0.351759  0.372519  0.344578  0.371333  \n",
       "14      0.863813  0.598358  0.752710  0.756861  \n",
       "15      0.778471  0.585105  0.645518  0.690018  \n",
       "16      0.819813  0.580105  0.614923  0.709526  \n",
       "17      0.860531  0.597442  0.711676  0.760978  \n",
       "18      0.528509  0.560086  0.514680  0.572862  \n",
       "19      0.529703  0.507579  0.516021  0.556245  \n",
       "20      0.518743  0.515050  0.529726  0.559946  \n",
       "21      0.867509  0.586353  0.745550  0.754195  "
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_report.reset_index(drop=False, inplace=True)\n",
    "f1_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultiIndex([(  'text_col',          ''),\n",
       "            ('vectorizer',          ''),\n",
       "            ( 'estimator',          ''),\n",
       "            (     'class',          ''),\n",
       "            (  'f1-score',    'Church'),\n",
       "            (  'f1-score', 'Bolsonaro'),\n",
       "            (  'f1-score',   'Hydrox.'),\n",
       "            (  'f1-score',   'Sinovac'),\n",
       "            (  'f1-score',  'Globo TV'),\n",
       "            (  'f1-score',      'Lula'),\n",
       "            (  'f1-score',   'overall')],\n",
       "           names=['metric', 'target'])"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_report.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['text_col',\n",
       " 'vectorizer',\n",
       " 'estimator',\n",
       " 'class',\n",
       " 'Church',\n",
       " 'Bolsonaro',\n",
       " 'Hydrox.',\n",
       " 'Sinovac',\n",
       " 'Globo TV',\n",
       " 'Lula',\n",
       " 'overall']"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_columns = [col[0] if col[1] == '' else col[1] for col in f1_report.columns]\n",
    "new_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_col</th>\n",
       "      <th>vectorizer</th>\n",
       "      <th>estimator</th>\n",
       "      <th>class</th>\n",
       "      <th>Church</th>\n",
       "      <th>Bolsonaro</th>\n",
       "      <th>Hydrox.</th>\n",
       "      <th>Sinovac</th>\n",
       "      <th>Globo TV</th>\n",
       "      <th>Lula</th>\n",
       "      <th>overall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Stance</td>\n",
       "      <td>-</td>\n",
       "      <td>dummy</td>\n",
       "      <td>macro avg</td>\n",
       "      <td>0.361407</td>\n",
       "      <td>0.462857</td>\n",
       "      <td>0.334878</td>\n",
       "      <td>0.351759</td>\n",
       "      <td>0.372519</td>\n",
       "      <td>0.344578</td>\n",
       "      <td>0.371333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Stance</td>\n",
       "      <td>tf-idf</td>\n",
       "      <td>xgb</td>\n",
       "      <td>macro avg</td>\n",
       "      <td>0.702021</td>\n",
       "      <td>0.595312</td>\n",
       "      <td>0.734366</td>\n",
       "      <td>0.752640</td>\n",
       "      <td>0.665243</td>\n",
       "      <td>0.654412</td>\n",
       "      <td>0.683999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Stance</td>\n",
       "      <td>bertabaporu-base</td>\n",
       "      <td>xgb</td>\n",
       "      <td>macro avg</td>\n",
       "      <td>0.853801</td>\n",
       "      <td>0.625289</td>\n",
       "      <td>0.830948</td>\n",
       "      <td>0.808036</td>\n",
       "      <td>0.781858</td>\n",
       "      <td>0.766993</td>\n",
       "      <td>0.777821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Stance</td>\n",
       "      <td>-</td>\n",
       "      <td>bertabaporu-base</td>\n",
       "      <td>macro avg</td>\n",
       "      <td>0.866276</td>\n",
       "      <td>0.734945</td>\n",
       "      <td>0.844740</td>\n",
       "      <td>0.823002</td>\n",
       "      <td>0.875418</td>\n",
       "      <td>0.782733</td>\n",
       "      <td>0.821186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Stance</td>\n",
       "      <td>-</td>\n",
       "      <td>llama3:7b zero-shot</td>\n",
       "      <td>macro avg</td>\n",
       "      <td>0.729458</td>\n",
       "      <td>0.462857</td>\n",
       "      <td>0.638889</td>\n",
       "      <td>0.578779</td>\n",
       "      <td>0.770678</td>\n",
       "      <td>0.699381</td>\n",
       "      <td>0.646674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Texts</td>\n",
       "      <td>-</td>\n",
       "      <td>dummy</td>\n",
       "      <td>macro avg</td>\n",
       "      <td>0.361407</td>\n",
       "      <td>0.462857</td>\n",
       "      <td>0.334878</td>\n",
       "      <td>0.351759</td>\n",
       "      <td>0.372519</td>\n",
       "      <td>0.344578</td>\n",
       "      <td>0.371333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Texts</td>\n",
       "      <td>tf-idf</td>\n",
       "      <td>xgb</td>\n",
       "      <td>macro avg</td>\n",
       "      <td>0.596115</td>\n",
       "      <td>0.501220</td>\n",
       "      <td>0.603727</td>\n",
       "      <td>0.670805</td>\n",
       "      <td>0.545620</td>\n",
       "      <td>0.579427</td>\n",
       "      <td>0.582819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Texts</td>\n",
       "      <td>bertabaporu-base</td>\n",
       "      <td>xgb</td>\n",
       "      <td>macro avg</td>\n",
       "      <td>0.594754</td>\n",
       "      <td>0.495578</td>\n",
       "      <td>0.609524</td>\n",
       "      <td>0.660542</td>\n",
       "      <td>0.534455</td>\n",
       "      <td>0.569597</td>\n",
       "      <td>0.577408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Texts</td>\n",
       "      <td>-</td>\n",
       "      <td>bertabaporu-base</td>\n",
       "      <td>macro avg</td>\n",
       "      <td>0.586611</td>\n",
       "      <td>0.462857</td>\n",
       "      <td>0.446504</td>\n",
       "      <td>0.608972</td>\n",
       "      <td>0.507381</td>\n",
       "      <td>0.482520</td>\n",
       "      <td>0.515808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Texts</td>\n",
       "      <td>-</td>\n",
       "      <td>bertabaporu-base (R)</td>\n",
       "      <td>macro avg</td>\n",
       "      <td>0.583417</td>\n",
       "      <td>0.462857</td>\n",
       "      <td>0.570531</td>\n",
       "      <td>0.637369</td>\n",
       "      <td>0.586967</td>\n",
       "      <td>0.602167</td>\n",
       "      <td>0.573885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Texts</td>\n",
       "      <td>-</td>\n",
       "      <td>llama3:7b zero-shot [5] (R)</td>\n",
       "      <td>macro avg</td>\n",
       "      <td>0.499052</td>\n",
       "      <td>0.296142</td>\n",
       "      <td>0.469796</td>\n",
       "      <td>0.470381</td>\n",
       "      <td>0.490101</td>\n",
       "      <td>0.512954</td>\n",
       "      <td>0.456404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Texts</td>\n",
       "      <td>-</td>\n",
       "      <td>llama3:7b zero-shot [10] (R)</td>\n",
       "      <td>macro avg</td>\n",
       "      <td>0.561274</td>\n",
       "      <td>0.328245</td>\n",
       "      <td>0.440347</td>\n",
       "      <td>0.460580</td>\n",
       "      <td>0.494646</td>\n",
       "      <td>0.478244</td>\n",
       "      <td>0.460556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Texts</td>\n",
       "      <td>-</td>\n",
       "      <td>llama3:7b zero-shot [15] (R)</td>\n",
       "      <td>macro avg</td>\n",
       "      <td>0.503966</td>\n",
       "      <td>0.285253</td>\n",
       "      <td>0.416946</td>\n",
       "      <td>0.464074</td>\n",
       "      <td>0.475797</td>\n",
       "      <td>0.542401</td>\n",
       "      <td>0.448073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Timeline</td>\n",
       "      <td>-</td>\n",
       "      <td>dummy</td>\n",
       "      <td>macro avg</td>\n",
       "      <td>0.361407</td>\n",
       "      <td>0.462857</td>\n",
       "      <td>0.334878</td>\n",
       "      <td>0.351759</td>\n",
       "      <td>0.372519</td>\n",
       "      <td>0.344578</td>\n",
       "      <td>0.371333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Timeline</td>\n",
       "      <td>tf-idf</td>\n",
       "      <td>xgb</td>\n",
       "      <td>macro avg</td>\n",
       "      <td>0.699122</td>\n",
       "      <td>0.728220</td>\n",
       "      <td>0.898944</td>\n",
       "      <td>0.863813</td>\n",
       "      <td>0.598358</td>\n",
       "      <td>0.752710</td>\n",
       "      <td>0.756861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Timeline</td>\n",
       "      <td>bertabaporu-base</td>\n",
       "      <td>xgb</td>\n",
       "      <td>macro avg</td>\n",
       "      <td>0.661773</td>\n",
       "      <td>0.692262</td>\n",
       "      <td>0.776979</td>\n",
       "      <td>0.778471</td>\n",
       "      <td>0.585105</td>\n",
       "      <td>0.645518</td>\n",
       "      <td>0.690018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Timeline</td>\n",
       "      <td>-</td>\n",
       "      <td>bertabaporu-base</td>\n",
       "      <td>macro avg</td>\n",
       "      <td>0.652707</td>\n",
       "      <td>0.767310</td>\n",
       "      <td>0.822297</td>\n",
       "      <td>0.819813</td>\n",
       "      <td>0.580105</td>\n",
       "      <td>0.614923</td>\n",
       "      <td>0.709526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Timeline</td>\n",
       "      <td>-</td>\n",
       "      <td>bertabaporu-base (R)</td>\n",
       "      <td>macro avg</td>\n",
       "      <td>0.701990</td>\n",
       "      <td>0.822060</td>\n",
       "      <td>0.872170</td>\n",
       "      <td>0.860531</td>\n",
       "      <td>0.597442</td>\n",
       "      <td>0.711676</td>\n",
       "      <td>0.760978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Timeline</td>\n",
       "      <td>-</td>\n",
       "      <td>llama3:7b zero-shot [5] (R)</td>\n",
       "      <td>macro avg</td>\n",
       "      <td>0.605633</td>\n",
       "      <td>0.588752</td>\n",
       "      <td>0.639513</td>\n",
       "      <td>0.528509</td>\n",
       "      <td>0.560086</td>\n",
       "      <td>0.514680</td>\n",
       "      <td>0.572862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Timeline</td>\n",
       "      <td>-</td>\n",
       "      <td>llama3:7b zero-shot [10] (R)</td>\n",
       "      <td>macro avg</td>\n",
       "      <td>0.563199</td>\n",
       "      <td>0.611771</td>\n",
       "      <td>0.609199</td>\n",
       "      <td>0.529703</td>\n",
       "      <td>0.507579</td>\n",
       "      <td>0.516021</td>\n",
       "      <td>0.556245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Timeline</td>\n",
       "      <td>-</td>\n",
       "      <td>llama3:7b zero-shot [15] (R)</td>\n",
       "      <td>macro avg</td>\n",
       "      <td>0.598183</td>\n",
       "      <td>0.586106</td>\n",
       "      <td>0.611868</td>\n",
       "      <td>0.518743</td>\n",
       "      <td>0.515050</td>\n",
       "      <td>0.529726</td>\n",
       "      <td>0.559946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Ensemble Texts + Timeline</td>\n",
       "      <td>-</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>macro avg</td>\n",
       "      <td>0.698596</td>\n",
       "      <td>0.728220</td>\n",
       "      <td>0.898944</td>\n",
       "      <td>0.867509</td>\n",
       "      <td>0.586353</td>\n",
       "      <td>0.745550</td>\n",
       "      <td>0.754195</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     text_col        vectorizer                     estimator  \\\n",
       "0                      Stance                 -                         dummy   \n",
       "1                      Stance            tf-idf                           xgb   \n",
       "2                      Stance  bertabaporu-base                           xgb   \n",
       "3                      Stance                 -              bertabaporu-base   \n",
       "4                      Stance                 -           llama3:7b zero-shot   \n",
       "5                       Texts                 -                         dummy   \n",
       "6                       Texts            tf-idf                           xgb   \n",
       "7                       Texts  bertabaporu-base                           xgb   \n",
       "8                       Texts                 -              bertabaporu-base   \n",
       "9                       Texts                 -          bertabaporu-base (R)   \n",
       "10                      Texts                 -   llama3:7b zero-shot [5] (R)   \n",
       "11                      Texts                 -  llama3:7b zero-shot [10] (R)   \n",
       "12                      Texts                 -  llama3:7b zero-shot [15] (R)   \n",
       "13                   Timeline                 -                         dummy   \n",
       "14                   Timeline            tf-idf                           xgb   \n",
       "15                   Timeline  bertabaporu-base                           xgb   \n",
       "16                   Timeline                 -              bertabaporu-base   \n",
       "17                   Timeline                 -          bertabaporu-base (R)   \n",
       "18                   Timeline                 -   llama3:7b zero-shot [5] (R)   \n",
       "19                   Timeline                 -  llama3:7b zero-shot [10] (R)   \n",
       "20                   Timeline                 -  llama3:7b zero-shot [15] (R)   \n",
       "21  Ensemble Texts + Timeline                 -            LogisticRegression   \n",
       "\n",
       "        class    Church  Bolsonaro   Hydrox.   Sinovac  Globo TV      Lula  \\\n",
       "0   macro avg  0.361407   0.462857  0.334878  0.351759  0.372519  0.344578   \n",
       "1   macro avg  0.702021   0.595312  0.734366  0.752640  0.665243  0.654412   \n",
       "2   macro avg  0.853801   0.625289  0.830948  0.808036  0.781858  0.766993   \n",
       "3   macro avg  0.866276   0.734945  0.844740  0.823002  0.875418  0.782733   \n",
       "4   macro avg  0.729458   0.462857  0.638889  0.578779  0.770678  0.699381   \n",
       "5   macro avg  0.361407   0.462857  0.334878  0.351759  0.372519  0.344578   \n",
       "6   macro avg  0.596115   0.501220  0.603727  0.670805  0.545620  0.579427   \n",
       "7   macro avg  0.594754   0.495578  0.609524  0.660542  0.534455  0.569597   \n",
       "8   macro avg  0.586611   0.462857  0.446504  0.608972  0.507381  0.482520   \n",
       "9   macro avg  0.583417   0.462857  0.570531  0.637369  0.586967  0.602167   \n",
       "10  macro avg  0.499052   0.296142  0.469796  0.470381  0.490101  0.512954   \n",
       "11  macro avg  0.561274   0.328245  0.440347  0.460580  0.494646  0.478244   \n",
       "12  macro avg  0.503966   0.285253  0.416946  0.464074  0.475797  0.542401   \n",
       "13  macro avg  0.361407   0.462857  0.334878  0.351759  0.372519  0.344578   \n",
       "14  macro avg  0.699122   0.728220  0.898944  0.863813  0.598358  0.752710   \n",
       "15  macro avg  0.661773   0.692262  0.776979  0.778471  0.585105  0.645518   \n",
       "16  macro avg  0.652707   0.767310  0.822297  0.819813  0.580105  0.614923   \n",
       "17  macro avg  0.701990   0.822060  0.872170  0.860531  0.597442  0.711676   \n",
       "18  macro avg  0.605633   0.588752  0.639513  0.528509  0.560086  0.514680   \n",
       "19  macro avg  0.563199   0.611771  0.609199  0.529703  0.507579  0.516021   \n",
       "20  macro avg  0.598183   0.586106  0.611868  0.518743  0.515050  0.529726   \n",
       "21  macro avg  0.698596   0.728220  0.898944  0.867509  0.586353  0.745550   \n",
       "\n",
       "     overall  \n",
       "0   0.371333  \n",
       "1   0.683999  \n",
       "2   0.777821  \n",
       "3   0.821186  \n",
       "4   0.646674  \n",
       "5   0.371333  \n",
       "6   0.582819  \n",
       "7   0.577408  \n",
       "8   0.515808  \n",
       "9   0.573885  \n",
       "10  0.456404  \n",
       "11  0.460556  \n",
       "12  0.448073  \n",
       "13  0.371333  \n",
       "14  0.756861  \n",
       "15  0.690018  \n",
       "16  0.709526  \n",
       "17  0.760978  \n",
       "18  0.572862  \n",
       "19  0.556245  \n",
       "20  0.559946  \n",
       "21  0.754195  "
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_report.columns = new_columns\n",
    "f1_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_col</th>\n",
       "      <th>vectorizer</th>\n",
       "      <th>estimator</th>\n",
       "      <th>Church</th>\n",
       "      <th>Bolsonaro</th>\n",
       "      <th>Hydrox.</th>\n",
       "      <th>Sinovac</th>\n",
       "      <th>Globo TV</th>\n",
       "      <th>Lula</th>\n",
       "      <th>overall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Stance</td>\n",
       "      <td>-</td>\n",
       "      <td>dummy</td>\n",
       "      <td>0.361407</td>\n",
       "      <td>0.462857</td>\n",
       "      <td>0.334878</td>\n",
       "      <td>0.351759</td>\n",
       "      <td>0.372519</td>\n",
       "      <td>0.344578</td>\n",
       "      <td>0.371333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Stance</td>\n",
       "      <td>tf-idf</td>\n",
       "      <td>xgb</td>\n",
       "      <td>0.702021</td>\n",
       "      <td>0.595312</td>\n",
       "      <td>0.734366</td>\n",
       "      <td>0.752640</td>\n",
       "      <td>0.665243</td>\n",
       "      <td>0.654412</td>\n",
       "      <td>0.683999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Stance</td>\n",
       "      <td>bertabaporu-base</td>\n",
       "      <td>xgb</td>\n",
       "      <td>0.853801</td>\n",
       "      <td>0.625289</td>\n",
       "      <td>0.830948</td>\n",
       "      <td>0.808036</td>\n",
       "      <td>0.781858</td>\n",
       "      <td>0.766993</td>\n",
       "      <td>0.777821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Stance</td>\n",
       "      <td>-</td>\n",
       "      <td>bertabaporu-base</td>\n",
       "      <td>0.866276</td>\n",
       "      <td>0.734945</td>\n",
       "      <td>0.844740</td>\n",
       "      <td>0.823002</td>\n",
       "      <td>0.875418</td>\n",
       "      <td>0.782733</td>\n",
       "      <td>0.821186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Stance</td>\n",
       "      <td>-</td>\n",
       "      <td>llama3:7b zero-shot</td>\n",
       "      <td>0.729458</td>\n",
       "      <td>0.462857</td>\n",
       "      <td>0.638889</td>\n",
       "      <td>0.578779</td>\n",
       "      <td>0.770678</td>\n",
       "      <td>0.699381</td>\n",
       "      <td>0.646674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Texts</td>\n",
       "      <td>-</td>\n",
       "      <td>dummy</td>\n",
       "      <td>0.361407</td>\n",
       "      <td>0.462857</td>\n",
       "      <td>0.334878</td>\n",
       "      <td>0.351759</td>\n",
       "      <td>0.372519</td>\n",
       "      <td>0.344578</td>\n",
       "      <td>0.371333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Texts</td>\n",
       "      <td>tf-idf</td>\n",
       "      <td>xgb</td>\n",
       "      <td>0.596115</td>\n",
       "      <td>0.501220</td>\n",
       "      <td>0.603727</td>\n",
       "      <td>0.670805</td>\n",
       "      <td>0.545620</td>\n",
       "      <td>0.579427</td>\n",
       "      <td>0.582819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Texts</td>\n",
       "      <td>bertabaporu-base</td>\n",
       "      <td>xgb</td>\n",
       "      <td>0.594754</td>\n",
       "      <td>0.495578</td>\n",
       "      <td>0.609524</td>\n",
       "      <td>0.660542</td>\n",
       "      <td>0.534455</td>\n",
       "      <td>0.569597</td>\n",
       "      <td>0.577408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Texts</td>\n",
       "      <td>-</td>\n",
       "      <td>bertabaporu-base</td>\n",
       "      <td>0.586611</td>\n",
       "      <td>0.462857</td>\n",
       "      <td>0.446504</td>\n",
       "      <td>0.608972</td>\n",
       "      <td>0.507381</td>\n",
       "      <td>0.482520</td>\n",
       "      <td>0.515808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Texts</td>\n",
       "      <td>-</td>\n",
       "      <td>bertabaporu-base (R)</td>\n",
       "      <td>0.583417</td>\n",
       "      <td>0.462857</td>\n",
       "      <td>0.570531</td>\n",
       "      <td>0.637369</td>\n",
       "      <td>0.586967</td>\n",
       "      <td>0.602167</td>\n",
       "      <td>0.573885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Texts</td>\n",
       "      <td>-</td>\n",
       "      <td>llama3:7b zero-shot [5] (R)</td>\n",
       "      <td>0.499052</td>\n",
       "      <td>0.296142</td>\n",
       "      <td>0.469796</td>\n",
       "      <td>0.470381</td>\n",
       "      <td>0.490101</td>\n",
       "      <td>0.512954</td>\n",
       "      <td>0.456404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Texts</td>\n",
       "      <td>-</td>\n",
       "      <td>llama3:7b zero-shot [10] (R)</td>\n",
       "      <td>0.561274</td>\n",
       "      <td>0.328245</td>\n",
       "      <td>0.440347</td>\n",
       "      <td>0.460580</td>\n",
       "      <td>0.494646</td>\n",
       "      <td>0.478244</td>\n",
       "      <td>0.460556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Texts</td>\n",
       "      <td>-</td>\n",
       "      <td>llama3:7b zero-shot [15] (R)</td>\n",
       "      <td>0.503966</td>\n",
       "      <td>0.285253</td>\n",
       "      <td>0.416946</td>\n",
       "      <td>0.464074</td>\n",
       "      <td>0.475797</td>\n",
       "      <td>0.542401</td>\n",
       "      <td>0.448073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Timeline</td>\n",
       "      <td>-</td>\n",
       "      <td>dummy</td>\n",
       "      <td>0.361407</td>\n",
       "      <td>0.462857</td>\n",
       "      <td>0.334878</td>\n",
       "      <td>0.351759</td>\n",
       "      <td>0.372519</td>\n",
       "      <td>0.344578</td>\n",
       "      <td>0.371333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Timeline</td>\n",
       "      <td>tf-idf</td>\n",
       "      <td>xgb</td>\n",
       "      <td>0.699122</td>\n",
       "      <td>0.728220</td>\n",
       "      <td>0.898944</td>\n",
       "      <td>0.863813</td>\n",
       "      <td>0.598358</td>\n",
       "      <td>0.752710</td>\n",
       "      <td>0.756861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Timeline</td>\n",
       "      <td>bertabaporu-base</td>\n",
       "      <td>xgb</td>\n",
       "      <td>0.661773</td>\n",
       "      <td>0.692262</td>\n",
       "      <td>0.776979</td>\n",
       "      <td>0.778471</td>\n",
       "      <td>0.585105</td>\n",
       "      <td>0.645518</td>\n",
       "      <td>0.690018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Timeline</td>\n",
       "      <td>-</td>\n",
       "      <td>bertabaporu-base</td>\n",
       "      <td>0.652707</td>\n",
       "      <td>0.767310</td>\n",
       "      <td>0.822297</td>\n",
       "      <td>0.819813</td>\n",
       "      <td>0.580105</td>\n",
       "      <td>0.614923</td>\n",
       "      <td>0.709526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Timeline</td>\n",
       "      <td>-</td>\n",
       "      <td>bertabaporu-base (R)</td>\n",
       "      <td>0.701990</td>\n",
       "      <td>0.822060</td>\n",
       "      <td>0.872170</td>\n",
       "      <td>0.860531</td>\n",
       "      <td>0.597442</td>\n",
       "      <td>0.711676</td>\n",
       "      <td>0.760978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Timeline</td>\n",
       "      <td>-</td>\n",
       "      <td>llama3:7b zero-shot [5] (R)</td>\n",
       "      <td>0.605633</td>\n",
       "      <td>0.588752</td>\n",
       "      <td>0.639513</td>\n",
       "      <td>0.528509</td>\n",
       "      <td>0.560086</td>\n",
       "      <td>0.514680</td>\n",
       "      <td>0.572862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Timeline</td>\n",
       "      <td>-</td>\n",
       "      <td>llama3:7b zero-shot [10] (R)</td>\n",
       "      <td>0.563199</td>\n",
       "      <td>0.611771</td>\n",
       "      <td>0.609199</td>\n",
       "      <td>0.529703</td>\n",
       "      <td>0.507579</td>\n",
       "      <td>0.516021</td>\n",
       "      <td>0.556245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Timeline</td>\n",
       "      <td>-</td>\n",
       "      <td>llama3:7b zero-shot [15] (R)</td>\n",
       "      <td>0.598183</td>\n",
       "      <td>0.586106</td>\n",
       "      <td>0.611868</td>\n",
       "      <td>0.518743</td>\n",
       "      <td>0.515050</td>\n",
       "      <td>0.529726</td>\n",
       "      <td>0.559946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Ensemble Texts + Timeline</td>\n",
       "      <td>-</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.698596</td>\n",
       "      <td>0.728220</td>\n",
       "      <td>0.898944</td>\n",
       "      <td>0.867509</td>\n",
       "      <td>0.586353</td>\n",
       "      <td>0.745550</td>\n",
       "      <td>0.754195</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     text_col        vectorizer                     estimator  \\\n",
       "0                      Stance                 -                         dummy   \n",
       "1                      Stance            tf-idf                           xgb   \n",
       "2                      Stance  bertabaporu-base                           xgb   \n",
       "3                      Stance                 -              bertabaporu-base   \n",
       "4                      Stance                 -           llama3:7b zero-shot   \n",
       "5                       Texts                 -                         dummy   \n",
       "6                       Texts            tf-idf                           xgb   \n",
       "7                       Texts  bertabaporu-base                           xgb   \n",
       "8                       Texts                 -              bertabaporu-base   \n",
       "9                       Texts                 -          bertabaporu-base (R)   \n",
       "10                      Texts                 -   llama3:7b zero-shot [5] (R)   \n",
       "11                      Texts                 -  llama3:7b zero-shot [10] (R)   \n",
       "12                      Texts                 -  llama3:7b zero-shot [15] (R)   \n",
       "13                   Timeline                 -                         dummy   \n",
       "14                   Timeline            tf-idf                           xgb   \n",
       "15                   Timeline  bertabaporu-base                           xgb   \n",
       "16                   Timeline                 -              bertabaporu-base   \n",
       "17                   Timeline                 -          bertabaporu-base (R)   \n",
       "18                   Timeline                 -   llama3:7b zero-shot [5] (R)   \n",
       "19                   Timeline                 -  llama3:7b zero-shot [10] (R)   \n",
       "20                   Timeline                 -  llama3:7b zero-shot [15] (R)   \n",
       "21  Ensemble Texts + Timeline                 -            LogisticRegression   \n",
       "\n",
       "      Church  Bolsonaro   Hydrox.   Sinovac  Globo TV      Lula   overall  \n",
       "0   0.361407   0.462857  0.334878  0.351759  0.372519  0.344578  0.371333  \n",
       "1   0.702021   0.595312  0.734366  0.752640  0.665243  0.654412  0.683999  \n",
       "2   0.853801   0.625289  0.830948  0.808036  0.781858  0.766993  0.777821  \n",
       "3   0.866276   0.734945  0.844740  0.823002  0.875418  0.782733  0.821186  \n",
       "4   0.729458   0.462857  0.638889  0.578779  0.770678  0.699381  0.646674  \n",
       "5   0.361407   0.462857  0.334878  0.351759  0.372519  0.344578  0.371333  \n",
       "6   0.596115   0.501220  0.603727  0.670805  0.545620  0.579427  0.582819  \n",
       "7   0.594754   0.495578  0.609524  0.660542  0.534455  0.569597  0.577408  \n",
       "8   0.586611   0.462857  0.446504  0.608972  0.507381  0.482520  0.515808  \n",
       "9   0.583417   0.462857  0.570531  0.637369  0.586967  0.602167  0.573885  \n",
       "10  0.499052   0.296142  0.469796  0.470381  0.490101  0.512954  0.456404  \n",
       "11  0.561274   0.328245  0.440347  0.460580  0.494646  0.478244  0.460556  \n",
       "12  0.503966   0.285253  0.416946  0.464074  0.475797  0.542401  0.448073  \n",
       "13  0.361407   0.462857  0.334878  0.351759  0.372519  0.344578  0.371333  \n",
       "14  0.699122   0.728220  0.898944  0.863813  0.598358  0.752710  0.756861  \n",
       "15  0.661773   0.692262  0.776979  0.778471  0.585105  0.645518  0.690018  \n",
       "16  0.652707   0.767310  0.822297  0.819813  0.580105  0.614923  0.709526  \n",
       "17  0.701990   0.822060  0.872170  0.860531  0.597442  0.711676  0.760978  \n",
       "18  0.605633   0.588752  0.639513  0.528509  0.560086  0.514680  0.572862  \n",
       "19  0.563199   0.611771  0.609199  0.529703  0.507579  0.516021  0.556245  \n",
       "20  0.598183   0.586106  0.611868  0.518743  0.515050  0.529726  0.559946  \n",
       "21  0.698596   0.728220  0.898944  0.867509  0.586353  0.745550  0.754195  "
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_report.drop(['class'],axis = 1, inplace=True)\n",
    "f1_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_col</th>\n",
       "      <th>classifier</th>\n",
       "      <th>Church</th>\n",
       "      <th>Bolsonaro</th>\n",
       "      <th>Hydrox.</th>\n",
       "      <th>Sinovac</th>\n",
       "      <th>Globo TV</th>\n",
       "      <th>Lula</th>\n",
       "      <th>overall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Stance</td>\n",
       "      <td>dummy</td>\n",
       "      <td>0.361407</td>\n",
       "      <td>0.462857</td>\n",
       "      <td>0.334878</td>\n",
       "      <td>0.351759</td>\n",
       "      <td>0.372519</td>\n",
       "      <td>0.344578</td>\n",
       "      <td>0.371333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Stance</td>\n",
       "      <td>tf-idf + xgb</td>\n",
       "      <td>0.702021</td>\n",
       "      <td>0.595312</td>\n",
       "      <td>0.734366</td>\n",
       "      <td>0.752640</td>\n",
       "      <td>0.665243</td>\n",
       "      <td>0.654412</td>\n",
       "      <td>0.683999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Stance</td>\n",
       "      <td>bertabaporu-base + xgb</td>\n",
       "      <td>0.853801</td>\n",
       "      <td>0.625289</td>\n",
       "      <td>0.830948</td>\n",
       "      <td>0.808036</td>\n",
       "      <td>0.781858</td>\n",
       "      <td>0.766993</td>\n",
       "      <td>0.777821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Stance</td>\n",
       "      <td>bertabaporu-base</td>\n",
       "      <td>0.866276</td>\n",
       "      <td>0.734945</td>\n",
       "      <td>0.844740</td>\n",
       "      <td>0.823002</td>\n",
       "      <td>0.875418</td>\n",
       "      <td>0.782733</td>\n",
       "      <td>0.821186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Stance</td>\n",
       "      <td>llama3:7b zero-shot</td>\n",
       "      <td>0.729458</td>\n",
       "      <td>0.462857</td>\n",
       "      <td>0.638889</td>\n",
       "      <td>0.578779</td>\n",
       "      <td>0.770678</td>\n",
       "      <td>0.699381</td>\n",
       "      <td>0.646674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Texts</td>\n",
       "      <td>dummy</td>\n",
       "      <td>0.361407</td>\n",
       "      <td>0.462857</td>\n",
       "      <td>0.334878</td>\n",
       "      <td>0.351759</td>\n",
       "      <td>0.372519</td>\n",
       "      <td>0.344578</td>\n",
       "      <td>0.371333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Texts</td>\n",
       "      <td>tf-idf + xgb</td>\n",
       "      <td>0.596115</td>\n",
       "      <td>0.501220</td>\n",
       "      <td>0.603727</td>\n",
       "      <td>0.670805</td>\n",
       "      <td>0.545620</td>\n",
       "      <td>0.579427</td>\n",
       "      <td>0.582819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Texts</td>\n",
       "      <td>bertabaporu-base + xgb</td>\n",
       "      <td>0.594754</td>\n",
       "      <td>0.495578</td>\n",
       "      <td>0.609524</td>\n",
       "      <td>0.660542</td>\n",
       "      <td>0.534455</td>\n",
       "      <td>0.569597</td>\n",
       "      <td>0.577408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Texts</td>\n",
       "      <td>bertabaporu-base</td>\n",
       "      <td>0.586611</td>\n",
       "      <td>0.462857</td>\n",
       "      <td>0.446504</td>\n",
       "      <td>0.608972</td>\n",
       "      <td>0.507381</td>\n",
       "      <td>0.482520</td>\n",
       "      <td>0.515808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Texts</td>\n",
       "      <td>bertabaporu-base (R)</td>\n",
       "      <td>0.583417</td>\n",
       "      <td>0.462857</td>\n",
       "      <td>0.570531</td>\n",
       "      <td>0.637369</td>\n",
       "      <td>0.586967</td>\n",
       "      <td>0.602167</td>\n",
       "      <td>0.573885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Texts</td>\n",
       "      <td>llama3:7b zero-shot [5] (R)</td>\n",
       "      <td>0.499052</td>\n",
       "      <td>0.296142</td>\n",
       "      <td>0.469796</td>\n",
       "      <td>0.470381</td>\n",
       "      <td>0.490101</td>\n",
       "      <td>0.512954</td>\n",
       "      <td>0.456404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Texts</td>\n",
       "      <td>llama3:7b zero-shot [10] (R)</td>\n",
       "      <td>0.561274</td>\n",
       "      <td>0.328245</td>\n",
       "      <td>0.440347</td>\n",
       "      <td>0.460580</td>\n",
       "      <td>0.494646</td>\n",
       "      <td>0.478244</td>\n",
       "      <td>0.460556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Texts</td>\n",
       "      <td>llama3:7b zero-shot [15] (R)</td>\n",
       "      <td>0.503966</td>\n",
       "      <td>0.285253</td>\n",
       "      <td>0.416946</td>\n",
       "      <td>0.464074</td>\n",
       "      <td>0.475797</td>\n",
       "      <td>0.542401</td>\n",
       "      <td>0.448073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Timeline</td>\n",
       "      <td>dummy</td>\n",
       "      <td>0.361407</td>\n",
       "      <td>0.462857</td>\n",
       "      <td>0.334878</td>\n",
       "      <td>0.351759</td>\n",
       "      <td>0.372519</td>\n",
       "      <td>0.344578</td>\n",
       "      <td>0.371333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Timeline</td>\n",
       "      <td>tf-idf + xgb</td>\n",
       "      <td>0.699122</td>\n",
       "      <td>0.728220</td>\n",
       "      <td>0.898944</td>\n",
       "      <td>0.863813</td>\n",
       "      <td>0.598358</td>\n",
       "      <td>0.752710</td>\n",
       "      <td>0.756861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Timeline</td>\n",
       "      <td>bertabaporu-base + xgb</td>\n",
       "      <td>0.661773</td>\n",
       "      <td>0.692262</td>\n",
       "      <td>0.776979</td>\n",
       "      <td>0.778471</td>\n",
       "      <td>0.585105</td>\n",
       "      <td>0.645518</td>\n",
       "      <td>0.690018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Timeline</td>\n",
       "      <td>bertabaporu-base</td>\n",
       "      <td>0.652707</td>\n",
       "      <td>0.767310</td>\n",
       "      <td>0.822297</td>\n",
       "      <td>0.819813</td>\n",
       "      <td>0.580105</td>\n",
       "      <td>0.614923</td>\n",
       "      <td>0.709526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Timeline</td>\n",
       "      <td>bertabaporu-base (R)</td>\n",
       "      <td>0.701990</td>\n",
       "      <td>0.822060</td>\n",
       "      <td>0.872170</td>\n",
       "      <td>0.860531</td>\n",
       "      <td>0.597442</td>\n",
       "      <td>0.711676</td>\n",
       "      <td>0.760978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Timeline</td>\n",
       "      <td>llama3:7b zero-shot [5] (R)</td>\n",
       "      <td>0.605633</td>\n",
       "      <td>0.588752</td>\n",
       "      <td>0.639513</td>\n",
       "      <td>0.528509</td>\n",
       "      <td>0.560086</td>\n",
       "      <td>0.514680</td>\n",
       "      <td>0.572862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Timeline</td>\n",
       "      <td>llama3:7b zero-shot [10] (R)</td>\n",
       "      <td>0.563199</td>\n",
       "      <td>0.611771</td>\n",
       "      <td>0.609199</td>\n",
       "      <td>0.529703</td>\n",
       "      <td>0.507579</td>\n",
       "      <td>0.516021</td>\n",
       "      <td>0.556245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Timeline</td>\n",
       "      <td>llama3:7b zero-shot [15] (R)</td>\n",
       "      <td>0.598183</td>\n",
       "      <td>0.586106</td>\n",
       "      <td>0.611868</td>\n",
       "      <td>0.518743</td>\n",
       "      <td>0.515050</td>\n",
       "      <td>0.529726</td>\n",
       "      <td>0.559946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Ensemble Texts + Timeline</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.698596</td>\n",
       "      <td>0.728220</td>\n",
       "      <td>0.898944</td>\n",
       "      <td>0.867509</td>\n",
       "      <td>0.586353</td>\n",
       "      <td>0.745550</td>\n",
       "      <td>0.754195</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     text_col                    classifier    Church  \\\n",
       "0                      Stance                         dummy  0.361407   \n",
       "1                      Stance                  tf-idf + xgb  0.702021   \n",
       "2                      Stance        bertabaporu-base + xgb  0.853801   \n",
       "3                      Stance              bertabaporu-base  0.866276   \n",
       "4                      Stance           llama3:7b zero-shot  0.729458   \n",
       "5                       Texts                         dummy  0.361407   \n",
       "6                       Texts                  tf-idf + xgb  0.596115   \n",
       "7                       Texts        bertabaporu-base + xgb  0.594754   \n",
       "8                       Texts              bertabaporu-base  0.586611   \n",
       "9                       Texts          bertabaporu-base (R)  0.583417   \n",
       "10                      Texts   llama3:7b zero-shot [5] (R)  0.499052   \n",
       "11                      Texts  llama3:7b zero-shot [10] (R)  0.561274   \n",
       "12                      Texts  llama3:7b zero-shot [15] (R)  0.503966   \n",
       "13                   Timeline                         dummy  0.361407   \n",
       "14                   Timeline                  tf-idf + xgb  0.699122   \n",
       "15                   Timeline        bertabaporu-base + xgb  0.661773   \n",
       "16                   Timeline              bertabaporu-base  0.652707   \n",
       "17                   Timeline          bertabaporu-base (R)  0.701990   \n",
       "18                   Timeline   llama3:7b zero-shot [5] (R)  0.605633   \n",
       "19                   Timeline  llama3:7b zero-shot [10] (R)  0.563199   \n",
       "20                   Timeline  llama3:7b zero-shot [15] (R)  0.598183   \n",
       "21  Ensemble Texts + Timeline            LogisticRegression  0.698596   \n",
       "\n",
       "    Bolsonaro   Hydrox.   Sinovac  Globo TV      Lula   overall  \n",
       "0    0.462857  0.334878  0.351759  0.372519  0.344578  0.371333  \n",
       "1    0.595312  0.734366  0.752640  0.665243  0.654412  0.683999  \n",
       "2    0.625289  0.830948  0.808036  0.781858  0.766993  0.777821  \n",
       "3    0.734945  0.844740  0.823002  0.875418  0.782733  0.821186  \n",
       "4    0.462857  0.638889  0.578779  0.770678  0.699381  0.646674  \n",
       "5    0.462857  0.334878  0.351759  0.372519  0.344578  0.371333  \n",
       "6    0.501220  0.603727  0.670805  0.545620  0.579427  0.582819  \n",
       "7    0.495578  0.609524  0.660542  0.534455  0.569597  0.577408  \n",
       "8    0.462857  0.446504  0.608972  0.507381  0.482520  0.515808  \n",
       "9    0.462857  0.570531  0.637369  0.586967  0.602167  0.573885  \n",
       "10   0.296142  0.469796  0.470381  0.490101  0.512954  0.456404  \n",
       "11   0.328245  0.440347  0.460580  0.494646  0.478244  0.460556  \n",
       "12   0.285253  0.416946  0.464074  0.475797  0.542401  0.448073  \n",
       "13   0.462857  0.334878  0.351759  0.372519  0.344578  0.371333  \n",
       "14   0.728220  0.898944  0.863813  0.598358  0.752710  0.756861  \n",
       "15   0.692262  0.776979  0.778471  0.585105  0.645518  0.690018  \n",
       "16   0.767310  0.822297  0.819813  0.580105  0.614923  0.709526  \n",
       "17   0.822060  0.872170  0.860531  0.597442  0.711676  0.760978  \n",
       "18   0.588752  0.639513  0.528509  0.560086  0.514680  0.572862  \n",
       "19   0.611771  0.609199  0.529703  0.507579  0.516021  0.556245  \n",
       "20   0.586106  0.611868  0.518743  0.515050  0.529726  0.559946  \n",
       "21   0.728220  0.898944  0.867509  0.586353  0.745550  0.754195  "
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_report.insert(\n",
    "    1, \n",
    "    \"classifier\", \n",
    "    f1_report.apply(\n",
    "        lambda x: f\"{x['vectorizer']} + {x['estimator']}\" if x['vectorizer'] != '-' else x['estimator'],\n",
    "        axis = 1\n",
    "        ).to_list()\n",
    "\n",
    ")\n",
    "f1_report.drop(['estimator', 'vectorizer'],axis =1, inplace = True)\n",
    "f1_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input</th>\n",
       "      <th>classifier</th>\n",
       "      <th>Church</th>\n",
       "      <th>Bolsonaro</th>\n",
       "      <th>Hydrox.</th>\n",
       "      <th>Sinovac</th>\n",
       "      <th>Globo TV</th>\n",
       "      <th>Lula</th>\n",
       "      <th>overall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Stance</td>\n",
       "      <td>dummy</td>\n",
       "      <td>0.361407</td>\n",
       "      <td>0.462857</td>\n",
       "      <td>0.334878</td>\n",
       "      <td>0.351759</td>\n",
       "      <td>0.372519</td>\n",
       "      <td>0.344578</td>\n",
       "      <td>0.371333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Stance</td>\n",
       "      <td>tf-idf + xgb</td>\n",
       "      <td>0.702021</td>\n",
       "      <td>0.595312</td>\n",
       "      <td>0.734366</td>\n",
       "      <td>0.752640</td>\n",
       "      <td>0.665243</td>\n",
       "      <td>0.654412</td>\n",
       "      <td>0.683999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Stance</td>\n",
       "      <td>bertabaporu-base + xgb</td>\n",
       "      <td>0.853801</td>\n",
       "      <td>0.625289</td>\n",
       "      <td>0.830948</td>\n",
       "      <td>0.808036</td>\n",
       "      <td>0.781858</td>\n",
       "      <td>0.766993</td>\n",
       "      <td>0.777821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Stance</td>\n",
       "      <td>bertabaporu-base</td>\n",
       "      <td>0.866276</td>\n",
       "      <td>0.734945</td>\n",
       "      <td>0.844740</td>\n",
       "      <td>0.823002</td>\n",
       "      <td>0.875418</td>\n",
       "      <td>0.782733</td>\n",
       "      <td>0.821186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Stance</td>\n",
       "      <td>llama3:7b zero-shot</td>\n",
       "      <td>0.729458</td>\n",
       "      <td>0.462857</td>\n",
       "      <td>0.638889</td>\n",
       "      <td>0.578779</td>\n",
       "      <td>0.770678</td>\n",
       "      <td>0.699381</td>\n",
       "      <td>0.646674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Texts</td>\n",
       "      <td>dummy</td>\n",
       "      <td>0.361407</td>\n",
       "      <td>0.462857</td>\n",
       "      <td>0.334878</td>\n",
       "      <td>0.351759</td>\n",
       "      <td>0.372519</td>\n",
       "      <td>0.344578</td>\n",
       "      <td>0.371333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Texts</td>\n",
       "      <td>tf-idf + xgb</td>\n",
       "      <td>0.596115</td>\n",
       "      <td>0.501220</td>\n",
       "      <td>0.603727</td>\n",
       "      <td>0.670805</td>\n",
       "      <td>0.545620</td>\n",
       "      <td>0.579427</td>\n",
       "      <td>0.582819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Texts</td>\n",
       "      <td>bertabaporu-base + xgb</td>\n",
       "      <td>0.594754</td>\n",
       "      <td>0.495578</td>\n",
       "      <td>0.609524</td>\n",
       "      <td>0.660542</td>\n",
       "      <td>0.534455</td>\n",
       "      <td>0.569597</td>\n",
       "      <td>0.577408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Texts</td>\n",
       "      <td>bertabaporu-base</td>\n",
       "      <td>0.586611</td>\n",
       "      <td>0.462857</td>\n",
       "      <td>0.446504</td>\n",
       "      <td>0.608972</td>\n",
       "      <td>0.507381</td>\n",
       "      <td>0.482520</td>\n",
       "      <td>0.515808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Texts</td>\n",
       "      <td>bertabaporu-base (R)</td>\n",
       "      <td>0.583417</td>\n",
       "      <td>0.462857</td>\n",
       "      <td>0.570531</td>\n",
       "      <td>0.637369</td>\n",
       "      <td>0.586967</td>\n",
       "      <td>0.602167</td>\n",
       "      <td>0.573885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Texts</td>\n",
       "      <td>llama3:7b zero-shot [5] (R)</td>\n",
       "      <td>0.499052</td>\n",
       "      <td>0.296142</td>\n",
       "      <td>0.469796</td>\n",
       "      <td>0.470381</td>\n",
       "      <td>0.490101</td>\n",
       "      <td>0.512954</td>\n",
       "      <td>0.456404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Texts</td>\n",
       "      <td>llama3:7b zero-shot [10] (R)</td>\n",
       "      <td>0.561274</td>\n",
       "      <td>0.328245</td>\n",
       "      <td>0.440347</td>\n",
       "      <td>0.460580</td>\n",
       "      <td>0.494646</td>\n",
       "      <td>0.478244</td>\n",
       "      <td>0.460556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Texts</td>\n",
       "      <td>llama3:7b zero-shot [15] (R)</td>\n",
       "      <td>0.503966</td>\n",
       "      <td>0.285253</td>\n",
       "      <td>0.416946</td>\n",
       "      <td>0.464074</td>\n",
       "      <td>0.475797</td>\n",
       "      <td>0.542401</td>\n",
       "      <td>0.448073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Timeline</td>\n",
       "      <td>dummy</td>\n",
       "      <td>0.361407</td>\n",
       "      <td>0.462857</td>\n",
       "      <td>0.334878</td>\n",
       "      <td>0.351759</td>\n",
       "      <td>0.372519</td>\n",
       "      <td>0.344578</td>\n",
       "      <td>0.371333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Timeline</td>\n",
       "      <td>tf-idf + xgb</td>\n",
       "      <td>0.699122</td>\n",
       "      <td>0.728220</td>\n",
       "      <td>0.898944</td>\n",
       "      <td>0.863813</td>\n",
       "      <td>0.598358</td>\n",
       "      <td>0.752710</td>\n",
       "      <td>0.756861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Timeline</td>\n",
       "      <td>bertabaporu-base + xgb</td>\n",
       "      <td>0.661773</td>\n",
       "      <td>0.692262</td>\n",
       "      <td>0.776979</td>\n",
       "      <td>0.778471</td>\n",
       "      <td>0.585105</td>\n",
       "      <td>0.645518</td>\n",
       "      <td>0.690018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Timeline</td>\n",
       "      <td>bertabaporu-base</td>\n",
       "      <td>0.652707</td>\n",
       "      <td>0.767310</td>\n",
       "      <td>0.822297</td>\n",
       "      <td>0.819813</td>\n",
       "      <td>0.580105</td>\n",
       "      <td>0.614923</td>\n",
       "      <td>0.709526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Timeline</td>\n",
       "      <td>bertabaporu-base (R)</td>\n",
       "      <td>0.701990</td>\n",
       "      <td>0.822060</td>\n",
       "      <td>0.872170</td>\n",
       "      <td>0.860531</td>\n",
       "      <td>0.597442</td>\n",
       "      <td>0.711676</td>\n",
       "      <td>0.760978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Timeline</td>\n",
       "      <td>llama3:7b zero-shot [5] (R)</td>\n",
       "      <td>0.605633</td>\n",
       "      <td>0.588752</td>\n",
       "      <td>0.639513</td>\n",
       "      <td>0.528509</td>\n",
       "      <td>0.560086</td>\n",
       "      <td>0.514680</td>\n",
       "      <td>0.572862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Timeline</td>\n",
       "      <td>llama3:7b zero-shot [10] (R)</td>\n",
       "      <td>0.563199</td>\n",
       "      <td>0.611771</td>\n",
       "      <td>0.609199</td>\n",
       "      <td>0.529703</td>\n",
       "      <td>0.507579</td>\n",
       "      <td>0.516021</td>\n",
       "      <td>0.556245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Timeline</td>\n",
       "      <td>llama3:7b zero-shot [15] (R)</td>\n",
       "      <td>0.598183</td>\n",
       "      <td>0.586106</td>\n",
       "      <td>0.611868</td>\n",
       "      <td>0.518743</td>\n",
       "      <td>0.515050</td>\n",
       "      <td>0.529726</td>\n",
       "      <td>0.559946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Ensemble Texts + Timeline</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.698596</td>\n",
       "      <td>0.728220</td>\n",
       "      <td>0.898944</td>\n",
       "      <td>0.867509</td>\n",
       "      <td>0.586353</td>\n",
       "      <td>0.745550</td>\n",
       "      <td>0.754195</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        input                    classifier    Church  \\\n",
       "0                      Stance                         dummy  0.361407   \n",
       "1                      Stance                  tf-idf + xgb  0.702021   \n",
       "2                      Stance        bertabaporu-base + xgb  0.853801   \n",
       "3                      Stance              bertabaporu-base  0.866276   \n",
       "4                      Stance           llama3:7b zero-shot  0.729458   \n",
       "5                       Texts                         dummy  0.361407   \n",
       "6                       Texts                  tf-idf + xgb  0.596115   \n",
       "7                       Texts        bertabaporu-base + xgb  0.594754   \n",
       "8                       Texts              bertabaporu-base  0.586611   \n",
       "9                       Texts          bertabaporu-base (R)  0.583417   \n",
       "10                      Texts   llama3:7b zero-shot [5] (R)  0.499052   \n",
       "11                      Texts  llama3:7b zero-shot [10] (R)  0.561274   \n",
       "12                      Texts  llama3:7b zero-shot [15] (R)  0.503966   \n",
       "13                   Timeline                         dummy  0.361407   \n",
       "14                   Timeline                  tf-idf + xgb  0.699122   \n",
       "15                   Timeline        bertabaporu-base + xgb  0.661773   \n",
       "16                   Timeline              bertabaporu-base  0.652707   \n",
       "17                   Timeline          bertabaporu-base (R)  0.701990   \n",
       "18                   Timeline   llama3:7b zero-shot [5] (R)  0.605633   \n",
       "19                   Timeline  llama3:7b zero-shot [10] (R)  0.563199   \n",
       "20                   Timeline  llama3:7b zero-shot [15] (R)  0.598183   \n",
       "21  Ensemble Texts + Timeline            LogisticRegression  0.698596   \n",
       "\n",
       "    Bolsonaro   Hydrox.   Sinovac  Globo TV      Lula   overall  \n",
       "0    0.462857  0.334878  0.351759  0.372519  0.344578  0.371333  \n",
       "1    0.595312  0.734366  0.752640  0.665243  0.654412  0.683999  \n",
       "2    0.625289  0.830948  0.808036  0.781858  0.766993  0.777821  \n",
       "3    0.734945  0.844740  0.823002  0.875418  0.782733  0.821186  \n",
       "4    0.462857  0.638889  0.578779  0.770678  0.699381  0.646674  \n",
       "5    0.462857  0.334878  0.351759  0.372519  0.344578  0.371333  \n",
       "6    0.501220  0.603727  0.670805  0.545620  0.579427  0.582819  \n",
       "7    0.495578  0.609524  0.660542  0.534455  0.569597  0.577408  \n",
       "8    0.462857  0.446504  0.608972  0.507381  0.482520  0.515808  \n",
       "9    0.462857  0.570531  0.637369  0.586967  0.602167  0.573885  \n",
       "10   0.296142  0.469796  0.470381  0.490101  0.512954  0.456404  \n",
       "11   0.328245  0.440347  0.460580  0.494646  0.478244  0.460556  \n",
       "12   0.285253  0.416946  0.464074  0.475797  0.542401  0.448073  \n",
       "13   0.462857  0.334878  0.351759  0.372519  0.344578  0.371333  \n",
       "14   0.728220  0.898944  0.863813  0.598358  0.752710  0.756861  \n",
       "15   0.692262  0.776979  0.778471  0.585105  0.645518  0.690018  \n",
       "16   0.767310  0.822297  0.819813  0.580105  0.614923  0.709526  \n",
       "17   0.822060  0.872170  0.860531  0.597442  0.711676  0.760978  \n",
       "18   0.588752  0.639513  0.528509  0.560086  0.514680  0.572862  \n",
       "19   0.611771  0.609199  0.529703  0.507579  0.516021  0.556245  \n",
       "20   0.586106  0.611868  0.518743  0.515050  0.529726  0.559946  \n",
       "21   0.728220  0.898944  0.867509  0.586353  0.745550  0.754195  "
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_report.rename({\"text_col\":\"input\"}, axis = 1, inplace=True)\n",
    "f1_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "#f1_report.set_index(['input'],inplace=True)\n",
    "#f1_report.drop('input', axis = 1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_latex_with_multirow_and_bold(df):\n",
    "    latex_code = ''\n",
    "    latex_code += '\\\\begin{table}[H]'\n",
    "    latex_code += \"\\\\begin{tabular}{ll|rrrrrrr}\\n\\\\toprule\\n\"\n",
    "    latex_code += \"input & classifier & Church & Bolsonaro & Hydrox. & Sinovac & Globo TV & Lula & overall \\\\\\\\ \\n\\\\midrule\\n\"\n",
    "\n",
    "    last_input = None\n",
    "    multirow_count = 0\n",
    "\n",
    "    for input_value in df['input'].unique():\n",
    "        subset = df[df['input'] == input_value]\n",
    "        max_overall_idx = subset['overall'].idxmax()\n",
    "\n",
    "        for i, row in subset.iterrows():\n",
    "            if row['input'] == last_input:\n",
    "                latex_code += \"& \"\n",
    "                multirow_count += 1\n",
    "            else:\n",
    "                if multirow_count > 0:\n",
    "                    latex_code = latex_code.replace(f\"multirow{{{multirow_count}}}\", f\"multirow{{{multirow_count + 1}}}\", 1)\n",
    "                if last_input is not None:\n",
    "                    latex_code += \"\\\\cmidrule(lr){1-9}\\n\"\n",
    "                latex_code += f\"\\\\multirow{{{1}}}{{*}}{{{row['input']}}} & \"\n",
    "                multirow_count = 1\n",
    "\n",
    "            if i == max_overall_idx:\n",
    "                row_data = [f\"\\\\textbf{{{row[col]:.2f}}}\" if col not in ['input', 'classifier'] else f\"\\\\textbf{{{row[col]}}}\" for col in df.columns[1:]]\n",
    "                latex_code += \" & \".join(row_data) + \" \\\\\\\\ \\n\"\n",
    "            else:\n",
    "                latex_code += \" & \".join([f\"{row[col]:.2f}\" if isinstance(row[col], float) else str(row[col]) for col in df.columns[1:]]) + \" \\\\\\\\ \\n\"\n",
    "            \n",
    "            last_input = row['input']\n",
    "\n",
    "    if multirow_count > 0:\n",
    "        latex_code = latex_code.replace(f\"multirow{{{multirow_count}}}\", f\"multirow{{{multirow_count + 1}}}\", 1)\n",
    "\n",
    "    latex_code += \"\\\\cmidrule(lr){1-9}\\n\"\n",
    "    latex_code += \"\\\\bottomrule\\n\\\\end{tabular}\"\n",
    "    latex_code += \"\\caption{F1 macro results}\"\n",
    "    latex_code += '\\label{table:results_f1_macro}\\n'\n",
    "    latex_code += '\\end{table}'\n",
    "\n",
    "    return latex_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_report.input = f1_report.input.map({\n",
    "    \"Stance\": \"S\",\n",
    "    \"Timeline\": 'UT',\n",
    "    \"Texts\": 'UFT',\n",
    "    \"Ensemble Texts + Timeline\": 'E1'\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input</th>\n",
       "      <th>classifier</th>\n",
       "      <th>Church</th>\n",
       "      <th>Bolsonaro</th>\n",
       "      <th>Hydrox.</th>\n",
       "      <th>Sinovac</th>\n",
       "      <th>Globo TV</th>\n",
       "      <th>Lula</th>\n",
       "      <th>overall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>S</td>\n",
       "      <td>dummy</td>\n",
       "      <td>0.361407</td>\n",
       "      <td>0.462857</td>\n",
       "      <td>0.334878</td>\n",
       "      <td>0.351759</td>\n",
       "      <td>0.372519</td>\n",
       "      <td>0.344578</td>\n",
       "      <td>0.371333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>S</td>\n",
       "      <td>tf-idf + xgb</td>\n",
       "      <td>0.702021</td>\n",
       "      <td>0.595312</td>\n",
       "      <td>0.734366</td>\n",
       "      <td>0.752640</td>\n",
       "      <td>0.665243</td>\n",
       "      <td>0.654412</td>\n",
       "      <td>0.683999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>S</td>\n",
       "      <td>bertabaporu-base + xgb</td>\n",
       "      <td>0.853801</td>\n",
       "      <td>0.625289</td>\n",
       "      <td>0.830948</td>\n",
       "      <td>0.808036</td>\n",
       "      <td>0.781858</td>\n",
       "      <td>0.766993</td>\n",
       "      <td>0.777821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>S</td>\n",
       "      <td>bertabaporu-base</td>\n",
       "      <td>0.866276</td>\n",
       "      <td>0.734945</td>\n",
       "      <td>0.844740</td>\n",
       "      <td>0.823002</td>\n",
       "      <td>0.875418</td>\n",
       "      <td>0.782733</td>\n",
       "      <td>0.821186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>S</td>\n",
       "      <td>llama3:7b zero-shot</td>\n",
       "      <td>0.729458</td>\n",
       "      <td>0.462857</td>\n",
       "      <td>0.638889</td>\n",
       "      <td>0.578779</td>\n",
       "      <td>0.770678</td>\n",
       "      <td>0.699381</td>\n",
       "      <td>0.646674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>UFT</td>\n",
       "      <td>dummy</td>\n",
       "      <td>0.361407</td>\n",
       "      <td>0.462857</td>\n",
       "      <td>0.334878</td>\n",
       "      <td>0.351759</td>\n",
       "      <td>0.372519</td>\n",
       "      <td>0.344578</td>\n",
       "      <td>0.371333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>UFT</td>\n",
       "      <td>tf-idf + xgb</td>\n",
       "      <td>0.596115</td>\n",
       "      <td>0.501220</td>\n",
       "      <td>0.603727</td>\n",
       "      <td>0.670805</td>\n",
       "      <td>0.545620</td>\n",
       "      <td>0.579427</td>\n",
       "      <td>0.582819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>UFT</td>\n",
       "      <td>bertabaporu-base + xgb</td>\n",
       "      <td>0.594754</td>\n",
       "      <td>0.495578</td>\n",
       "      <td>0.609524</td>\n",
       "      <td>0.660542</td>\n",
       "      <td>0.534455</td>\n",
       "      <td>0.569597</td>\n",
       "      <td>0.577408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>UFT</td>\n",
       "      <td>bertabaporu-base</td>\n",
       "      <td>0.586611</td>\n",
       "      <td>0.462857</td>\n",
       "      <td>0.446504</td>\n",
       "      <td>0.608972</td>\n",
       "      <td>0.507381</td>\n",
       "      <td>0.482520</td>\n",
       "      <td>0.515808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>UFT</td>\n",
       "      <td>bertabaporu-base (R)</td>\n",
       "      <td>0.583417</td>\n",
       "      <td>0.462857</td>\n",
       "      <td>0.570531</td>\n",
       "      <td>0.637369</td>\n",
       "      <td>0.586967</td>\n",
       "      <td>0.602167</td>\n",
       "      <td>0.573885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>UFT</td>\n",
       "      <td>llama3:7b zero-shot [5] (R)</td>\n",
       "      <td>0.499052</td>\n",
       "      <td>0.296142</td>\n",
       "      <td>0.469796</td>\n",
       "      <td>0.470381</td>\n",
       "      <td>0.490101</td>\n",
       "      <td>0.512954</td>\n",
       "      <td>0.456404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>UFT</td>\n",
       "      <td>llama3:7b zero-shot [10] (R)</td>\n",
       "      <td>0.561274</td>\n",
       "      <td>0.328245</td>\n",
       "      <td>0.440347</td>\n",
       "      <td>0.460580</td>\n",
       "      <td>0.494646</td>\n",
       "      <td>0.478244</td>\n",
       "      <td>0.460556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>UFT</td>\n",
       "      <td>llama3:7b zero-shot [15] (R)</td>\n",
       "      <td>0.503966</td>\n",
       "      <td>0.285253</td>\n",
       "      <td>0.416946</td>\n",
       "      <td>0.464074</td>\n",
       "      <td>0.475797</td>\n",
       "      <td>0.542401</td>\n",
       "      <td>0.448073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>UT</td>\n",
       "      <td>dummy</td>\n",
       "      <td>0.361407</td>\n",
       "      <td>0.462857</td>\n",
       "      <td>0.334878</td>\n",
       "      <td>0.351759</td>\n",
       "      <td>0.372519</td>\n",
       "      <td>0.344578</td>\n",
       "      <td>0.371333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>UT</td>\n",
       "      <td>tf-idf + xgb</td>\n",
       "      <td>0.699122</td>\n",
       "      <td>0.728220</td>\n",
       "      <td>0.898944</td>\n",
       "      <td>0.863813</td>\n",
       "      <td>0.598358</td>\n",
       "      <td>0.752710</td>\n",
       "      <td>0.756861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>UT</td>\n",
       "      <td>bertabaporu-base + xgb</td>\n",
       "      <td>0.661773</td>\n",
       "      <td>0.692262</td>\n",
       "      <td>0.776979</td>\n",
       "      <td>0.778471</td>\n",
       "      <td>0.585105</td>\n",
       "      <td>0.645518</td>\n",
       "      <td>0.690018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>UT</td>\n",
       "      <td>bertabaporu-base</td>\n",
       "      <td>0.652707</td>\n",
       "      <td>0.767310</td>\n",
       "      <td>0.822297</td>\n",
       "      <td>0.819813</td>\n",
       "      <td>0.580105</td>\n",
       "      <td>0.614923</td>\n",
       "      <td>0.709526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>UT</td>\n",
       "      <td>bertabaporu-base (R)</td>\n",
       "      <td>0.701990</td>\n",
       "      <td>0.822060</td>\n",
       "      <td>0.872170</td>\n",
       "      <td>0.860531</td>\n",
       "      <td>0.597442</td>\n",
       "      <td>0.711676</td>\n",
       "      <td>0.760978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>UT</td>\n",
       "      <td>llama3:7b zero-shot [5] (R)</td>\n",
       "      <td>0.605633</td>\n",
       "      <td>0.588752</td>\n",
       "      <td>0.639513</td>\n",
       "      <td>0.528509</td>\n",
       "      <td>0.560086</td>\n",
       "      <td>0.514680</td>\n",
       "      <td>0.572862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>UT</td>\n",
       "      <td>llama3:7b zero-shot [10] (R)</td>\n",
       "      <td>0.563199</td>\n",
       "      <td>0.611771</td>\n",
       "      <td>0.609199</td>\n",
       "      <td>0.529703</td>\n",
       "      <td>0.507579</td>\n",
       "      <td>0.516021</td>\n",
       "      <td>0.556245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>UT</td>\n",
       "      <td>llama3:7b zero-shot [15] (R)</td>\n",
       "      <td>0.598183</td>\n",
       "      <td>0.586106</td>\n",
       "      <td>0.611868</td>\n",
       "      <td>0.518743</td>\n",
       "      <td>0.515050</td>\n",
       "      <td>0.529726</td>\n",
       "      <td>0.559946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>E1</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.698596</td>\n",
       "      <td>0.728220</td>\n",
       "      <td>0.898944</td>\n",
       "      <td>0.867509</td>\n",
       "      <td>0.586353</td>\n",
       "      <td>0.745550</td>\n",
       "      <td>0.754195</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   input                    classifier    Church  Bolsonaro   Hydrox.  \\\n",
       "0      S                         dummy  0.361407   0.462857  0.334878   \n",
       "1      S                  tf-idf + xgb  0.702021   0.595312  0.734366   \n",
       "2      S        bertabaporu-base + xgb  0.853801   0.625289  0.830948   \n",
       "3      S              bertabaporu-base  0.866276   0.734945  0.844740   \n",
       "4      S           llama3:7b zero-shot  0.729458   0.462857  0.638889   \n",
       "5    UFT                         dummy  0.361407   0.462857  0.334878   \n",
       "6    UFT                  tf-idf + xgb  0.596115   0.501220  0.603727   \n",
       "7    UFT        bertabaporu-base + xgb  0.594754   0.495578  0.609524   \n",
       "8    UFT              bertabaporu-base  0.586611   0.462857  0.446504   \n",
       "9    UFT          bertabaporu-base (R)  0.583417   0.462857  0.570531   \n",
       "10   UFT   llama3:7b zero-shot [5] (R)  0.499052   0.296142  0.469796   \n",
       "11   UFT  llama3:7b zero-shot [10] (R)  0.561274   0.328245  0.440347   \n",
       "12   UFT  llama3:7b zero-shot [15] (R)  0.503966   0.285253  0.416946   \n",
       "13    UT                         dummy  0.361407   0.462857  0.334878   \n",
       "14    UT                  tf-idf + xgb  0.699122   0.728220  0.898944   \n",
       "15    UT        bertabaporu-base + xgb  0.661773   0.692262  0.776979   \n",
       "16    UT              bertabaporu-base  0.652707   0.767310  0.822297   \n",
       "17    UT          bertabaporu-base (R)  0.701990   0.822060  0.872170   \n",
       "18    UT   llama3:7b zero-shot [5] (R)  0.605633   0.588752  0.639513   \n",
       "19    UT  llama3:7b zero-shot [10] (R)  0.563199   0.611771  0.609199   \n",
       "20    UT  llama3:7b zero-shot [15] (R)  0.598183   0.586106  0.611868   \n",
       "21    E1            LogisticRegression  0.698596   0.728220  0.898944   \n",
       "\n",
       "     Sinovac  Globo TV      Lula   overall  \n",
       "0   0.351759  0.372519  0.344578  0.371333  \n",
       "1   0.752640  0.665243  0.654412  0.683999  \n",
       "2   0.808036  0.781858  0.766993  0.777821  \n",
       "3   0.823002  0.875418  0.782733  0.821186  \n",
       "4   0.578779  0.770678  0.699381  0.646674  \n",
       "5   0.351759  0.372519  0.344578  0.371333  \n",
       "6   0.670805  0.545620  0.579427  0.582819  \n",
       "7   0.660542  0.534455  0.569597  0.577408  \n",
       "8   0.608972  0.507381  0.482520  0.515808  \n",
       "9   0.637369  0.586967  0.602167  0.573885  \n",
       "10  0.470381  0.490101  0.512954  0.456404  \n",
       "11  0.460580  0.494646  0.478244  0.460556  \n",
       "12  0.464074  0.475797  0.542401  0.448073  \n",
       "13  0.351759  0.372519  0.344578  0.371333  \n",
       "14  0.863813  0.598358  0.752710  0.756861  \n",
       "15  0.778471  0.585105  0.645518  0.690018  \n",
       "16  0.819813  0.580105  0.614923  0.709526  \n",
       "17  0.860531  0.597442  0.711676  0.760978  \n",
       "18  0.528509  0.560086  0.514680  0.572862  \n",
       "19  0.529703  0.507579  0.516021  0.556245  \n",
       "20  0.518743  0.515050  0.529726  0.559946  \n",
       "21  0.867509  0.586353  0.745550  0.754195  "
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "str_latex = generate_latex_with_multirow_and_bold(f1_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{table}[H]\\begin{tabular}{ll|rrrrrrr}\n",
      "\\toprule\n",
      "input & classifier & Church & Bolsonaro & Hydrox. & Sinovac & Globo TV & Lula & overall \\\\ \n",
      "\\midrule\n",
      "\\multirow{2}{*}{S} & dummy & 0.36 & 0.46 & 0.33 & 0.35 & 0.37 & 0.34 & 0.37 \\\\ \n",
      "& tf-idf + xgb & 0.70 & 0.60 & 0.73 & 0.75 & 0.67 & 0.65 & 0.68 \\\\ \n",
      "& bertabaporu-base + xgb & 0.85 & 0.63 & 0.83 & 0.81 & 0.78 & 0.77 & 0.78 \\\\ \n",
      "& \\textbf{bertabaporu-base} & \\textbf{0.87} & \\textbf{0.73} & \\textbf{0.84} & \\textbf{0.82} & \\textbf{0.88} & \\textbf{0.78} & \\textbf{0.82} \\\\ \n",
      "& llama3:7b zero-shot & 0.73 & 0.46 & 0.64 & 0.58 & 0.77 & 0.70 & 0.65 \\\\ \n",
      "\\cmidrule(lr){1-9}\n",
      "\\multirow{1}{*}{UFT} & dummy & 0.36 & 0.46 & 0.33 & 0.35 & 0.37 & 0.34 & 0.37 \\\\ \n",
      "& \\textbf{tf-idf + xgb} & \\textbf{0.60} & \\textbf{0.50} & \\textbf{0.60} & \\textbf{0.67} & \\textbf{0.55} & \\textbf{0.58} & \\textbf{0.58} \\\\ \n",
      "& bertabaporu-base + xgb & 0.59 & 0.50 & 0.61 & 0.66 & 0.53 & 0.57 & 0.58 \\\\ \n",
      "& bertabaporu-base & 0.59 & 0.46 & 0.45 & 0.61 & 0.51 & 0.48 & 0.52 \\\\ \n",
      "& bertabaporu-base (R) & 0.58 & 0.46 & 0.57 & 0.64 & 0.59 & 0.60 & 0.57 \\\\ \n",
      "& llama3:7b zero-shot [5] (R) & 0.50 & 0.30 & 0.47 & 0.47 & 0.49 & 0.51 & 0.46 \\\\ \n",
      "& llama3:7b zero-shot [10] (R) & 0.56 & 0.33 & 0.44 & 0.46 & 0.49 & 0.48 & 0.46 \\\\ \n",
      "& llama3:7b zero-shot [15] (R) & 0.50 & 0.29 & 0.42 & 0.46 & 0.48 & 0.54 & 0.45 \\\\ \n",
      "\\cmidrule(lr){1-9}\n",
      "\\multirow{1}{*}{UT} & dummy & 0.36 & 0.46 & 0.33 & 0.35 & 0.37 & 0.34 & 0.37 \\\\ \n",
      "& tf-idf + xgb & 0.70 & 0.73 & 0.90 & 0.86 & 0.60 & 0.75 & 0.76 \\\\ \n",
      "& bertabaporu-base + xgb & 0.66 & 0.69 & 0.78 & 0.78 & 0.59 & 0.65 & 0.69 \\\\ \n",
      "& bertabaporu-base & 0.65 & 0.77 & 0.82 & 0.82 & 0.58 & 0.61 & 0.71 \\\\ \n",
      "& \\textbf{bertabaporu-base (R)} & \\textbf{0.70} & \\textbf{0.82} & \\textbf{0.87} & \\textbf{0.86} & \\textbf{0.60} & \\textbf{0.71} & \\textbf{0.76} \\\\ \n",
      "& llama3:7b zero-shot [5] (R) & 0.61 & 0.59 & 0.64 & 0.53 & 0.56 & 0.51 & 0.57 \\\\ \n",
      "& llama3:7b zero-shot [10] (R) & 0.56 & 0.61 & 0.61 & 0.53 & 0.51 & 0.52 & 0.56 \\\\ \n",
      "& llama3:7b zero-shot [15] (R) & 0.60 & 0.59 & 0.61 & 0.52 & 0.52 & 0.53 & 0.56 \\\\ \n",
      "\\cmidrule(lr){1-9}\n",
      "\\multirow{1}{*}{E1} & \\textbf{LogisticRegression} & \\textbf{0.70} & \\textbf{0.73} & \\textbf{0.90} & \\textbf{0.87} & \\textbf{0.59} & \\textbf{0.75} & \\textbf{0.75} \\\\ \n",
      "\\cmidrule(lr){1-9}\n",
      "\\bottomrule\n",
      "\\end{tabular}\\caption{F1 macro results}\\label{table:results_f1_macro}\n",
      "\\end{table}\n"
     ]
    }
   ],
   "source": [
    "print(str_latex)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env-stance-pred",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
