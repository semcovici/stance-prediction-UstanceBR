{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.metrics import classification_report\n",
    "from tqdm import tqdm\n",
    "import itertools\n",
    "import warnings\n",
    "import sys\n",
    "sys.path.append('../src')\n",
    "import itertools\n",
    "\n",
    "from models.classification_methods import get_classification_report\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_latex_with_multirow_and_bold(df):\n",
    "    latex_code = ''\n",
    "    latex_code += '\\\\begin{table}[H]'\n",
    "    latex_code += '\\\\scriptsize'\n",
    "    latex_code += '\\\\centering'\n",
    "    latex_code += \"\\\\begin{tabular}{ll|rrrrrrr}\\n\\\\toprule\\n\"\n",
    "    latex_code += \"input & classifier & Church & Bolsonaro & Hydrox. & Sinovac & Globo TV & Lula & overall \\\\\\\\ \\n\\\\midrule\\n\"\n",
    "\n",
    "    last_input = None\n",
    "    multirow_count = 0\n",
    "\n",
    "    for input_value in df['input'].unique():\n",
    "        subset = df[df['input'] == input_value]\n",
    "        max_overall_idx = subset['overall'].idxmax()\n",
    "\n",
    "        for i, row in subset.iterrows():\n",
    "            if row['input'] == last_input:\n",
    "                latex_code += \"& \"\n",
    "                multirow_count += 1\n",
    "            else:\n",
    "                if multirow_count > 0:\n",
    "                    latex_code = latex_code.replace(f\"multirow{{{multirow_count}}}\", f\"multirow{{{multirow_count + 1}}}\", 1)\n",
    "                if last_input is not None:\n",
    "                    latex_code += \"\\\\cmidrule(lr){1-9}\\n\"\n",
    "                latex_code += f\"\\\\multirow{{{1}}}{{*}}{{{row['input']}}} & \"\n",
    "                multirow_count = 1\n",
    "\n",
    "            if i == max_overall_idx:\n",
    "                row_data = [f\"\\\\textbf{{{row[col]:.2f}}}\" if col not in ['input', 'classifier'] else f\"\\\\textbf{{{row[col]}}}\" for col in df.columns[1:]]\n",
    "                latex_code += \" & \".join(row_data) + \" \\\\\\\\ \\n\"\n",
    "            else:\n",
    "                latex_code += \" & \".join([f\"{row[col]:.2f}\" if isinstance(row[col], float) else str(row[col]) for col in df.columns[1:]]) + \" \\\\\\\\ \\n\"\n",
    "            \n",
    "            last_input = row['input']\n",
    "\n",
    "    if multirow_count > 0:\n",
    "        latex_code = latex_code.replace(f\"multirow{{{multirow_count}}}\", f\"multirow{{{multirow_count + 1}}}\", 1)\n",
    "\n",
    "    latex_code += \"\\\\cmidrule(lr){1-9}\\n\"\n",
    "    latex_code += \"\\\\bottomrule\\n\\\\end{tabular}\"\n",
    "    latex_code += \"\\caption{F1 macro results}\"\n",
    "    latex_code += '\\label{table:results_f1_macro}\\n'\n",
    "    latex_code += '\\end{table}'\n",
    "\n",
    "    return latex_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['DummyClassifier_bo_concat_Texts_Timeline_concat_Texts_Timeline_test_results.csv',\n",
       " 'DummyClassifier_bo_top_mentioned_timelines_Texts_test_results.csv',\n",
       " 'DummyClassifier_bo_users_Stance_test_results.csv',\n",
       " 'DummyClassifier_bo_users_Timeline_test_results.csv',\n",
       " 'DummyClassifier_cl_concat_Texts_Timeline_concat_Texts_Timeline_test_results.csv',\n",
       " 'DummyClassifier_cl_top_mentioned_timelines_Texts_test_results.csv',\n",
       " 'DummyClassifier_cl_users_Stance_test_results.csv',\n",
       " 'DummyClassifier_cl_users_Timeline_test_results.csv',\n",
       " 'DummyClassifier_co_concat_Texts_Timeline_concat_Texts_Timeline_test_results.csv',\n",
       " 'DummyClassifier_co_top_mentioned_timelines_Texts_test_results.csv',\n",
       " 'DummyClassifier_co_users_Stance_test_results.csv',\n",
       " 'DummyClassifier_co_users_Timeline_test_results.csv',\n",
       " 'DummyClassifier_gl_concat_Texts_Timeline_concat_Texts_Timeline_test_results.csv',\n",
       " 'DummyClassifier_gl_top_mentioned_timelines_Texts_test_results.csv',\n",
       " 'DummyClassifier_gl_users_Stance_test_results.csv',\n",
       " 'DummyClassifier_gl_users_Timeline_test_results.csv',\n",
       " 'DummyClassifier_ig_concat_Texts_Timeline_concat_Texts_Timeline_test_results.csv',\n",
       " 'DummyClassifier_ig_top_mentioned_timelines_Texts_test_results.csv',\n",
       " 'DummyClassifier_ig_users_Stance_test_results.csv',\n",
       " 'DummyClassifier_ig_users_Timeline_test_results.csv',\n",
       " 'DummyClassifier_lu_concat_Texts_Timeline_concat_Texts_Timeline_test_results.csv',\n",
       " 'DummyClassifier_lu_top_mentioned_timelines_Texts_test_results.csv',\n",
       " 'DummyClassifier_lu_users_Stance_test_results.csv',\n",
       " 'DummyClassifier_lu_users_Timeline_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_bo_BoF_BoFr_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_bo_BoM_BoF_BoFr_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_bo_BoM_BoF_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_bo_BoM_BoFr_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_bo_Stance_BoF_BoFr_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_bo_Stance_BoF_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_bo_Stance_BoFr_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_bo_Stance_BoM_BoF_BoFr_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_bo_Stance_BoM_BoF_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_bo_Stance_BoM_BoFr_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_bo_Stance_BoM_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_bo_Stance_Texts_BoF_BoFr_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_bo_Stance_Texts_BoF_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_bo_Stance_Texts_BoFr_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_bo_Stance_Texts_BoM_BoF_BoFr_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_bo_Stance_Texts_BoM_BoF_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_bo_Stance_Texts_BoM_BoFr_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_bo_Stance_Texts_BoM_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_bo_Stance_Texts_Timeline_BoF_BoFr_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_bo_Stance_Texts_Timeline_BoF_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_bo_Stance_Texts_Timeline_BoFr_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_bo_Stance_Texts_Timeline_BoM_BoF_BoFr_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_bo_Stance_Texts_Timeline_BoM_BoF_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_bo_Stance_Texts_Timeline_BoM_BoFr_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_bo_Stance_Texts_Timeline_BoM_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_bo_Stance_Texts_Timeline_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_bo_Stance_Texts_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_bo_Stance_Timeline_BoF_BoFr_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_bo_Stance_Timeline_BoF_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_bo_Stance_Timeline_BoFr_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_bo_Stance_Timeline_BoM_BoF_BoFr_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_bo_Stance_Timeline_BoM_BoF_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_bo_Stance_Timeline_BoM_BoFr_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_bo_Stance_Timeline_BoM_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_bo_Stance_Timeline_Texts_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_bo_Stance_Timeline_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_bo_Texts_BoF_BoFr_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_bo_Texts_BoF_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_bo_Texts_BoFr_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_bo_Texts_BoM_BoF_BoFr_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_bo_Texts_BoM_BoF_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_bo_Texts_BoM_BoFr_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_bo_Texts_BoM_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_bo_Texts_Stance_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_bo_Texts_Texts_BoF_BoFr_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_bo_Texts_Texts_BoF_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_bo_Texts_Texts_BoFr_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_bo_Texts_Texts_BoM_BoF_BoFr_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_bo_Texts_Texts_BoM_BoF_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_bo_Texts_Texts_BoM_BoFr_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_bo_Texts_Texts_BoM_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_bo_Texts_Texts_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_bo_Texts_Timeline_BoF_BoFr_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_bo_Texts_Timeline_BoF_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_bo_Texts_Timeline_BoFr_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_bo_Texts_Timeline_BoM_BoF_BoFr_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_bo_Texts_Timeline_BoM_BoF_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_bo_Texts_Timeline_BoM_BoFr_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_bo_Texts_Timeline_BoM_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_bo_Texts_Timeline_Texts_BoF_BoFr_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_bo_Texts_Timeline_Texts_BoF_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_bo_Texts_Timeline_Texts_BoFr_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_bo_Texts_Timeline_Texts_BoM_BoF_BoFr_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_bo_Texts_Timeline_Texts_BoM_BoF_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_bo_Texts_Timeline_Texts_BoM_BoFr_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_bo_Texts_Timeline_Texts_BoM_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_bo_Texts_Timeline_Texts_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_bo_Texts_Timeline_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_bo_Timeline_BoF_BoFr_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_bo_Timeline_BoF_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_bo_Timeline_BoFr_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_bo_Timeline_BoM_BoF_BoFr_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_bo_Timeline_BoM_BoF_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_bo_Timeline_BoM_BoFr_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_bo_Timeline_BoM_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_bo_Timeline_Texts_BoF_BoFr_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_bo_Timeline_Texts_BoF_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_bo_Timeline_Texts_BoFr_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_bo_Timeline_Texts_BoM_BoF_BoFr_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_bo_Timeline_Texts_BoM_BoF_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_bo_Timeline_Texts_BoM_BoFr_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_bo_Timeline_Texts_BoM_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_bo_Timeline_Texts_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_cl_BoF_BoFr_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_cl_BoM_BoF_BoFr_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_cl_BoM_BoF_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_cl_BoM_BoFr_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_cl_Stance_BoF_BoFr_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_cl_Stance_BoF_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_cl_Stance_BoFr_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_cl_Stance_BoM_BoF_BoFr_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_cl_Stance_BoM_BoF_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_cl_Stance_BoM_BoFr_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_cl_Stance_BoM_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_cl_Stance_Texts_BoF_BoFr_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_cl_Stance_Texts_BoF_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_cl_Stance_Texts_BoFr_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_cl_Stance_Texts_BoM_BoF_BoFr_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_cl_Stance_Texts_BoM_BoF_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_cl_Stance_Texts_BoM_BoFr_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_cl_Stance_Texts_BoM_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_cl_Stance_Texts_Timeline_BoF_BoFr_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_cl_Stance_Texts_Timeline_BoF_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_cl_Stance_Texts_Timeline_BoFr_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_cl_Stance_Texts_Timeline_BoM_BoF_BoFr_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_cl_Stance_Texts_Timeline_BoM_BoF_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_cl_Stance_Texts_Timeline_BoM_BoFr_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_cl_Stance_Texts_Timeline_BoM_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_cl_Stance_Texts_Timeline_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_cl_Stance_Texts_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_cl_Stance_Timeline_BoF_BoFr_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_cl_Stance_Timeline_BoF_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_cl_Stance_Timeline_BoFr_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_cl_Stance_Timeline_BoM_BoF_BoFr_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_cl_Stance_Timeline_BoM_BoF_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_cl_Stance_Timeline_BoM_BoFr_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_cl_Stance_Timeline_BoM_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_cl_Stance_Timeline_Texts_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_cl_Stance_Timeline_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_cl_Texts_BoF_BoFr_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_cl_Texts_BoF_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_cl_Texts_BoFr_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_cl_Texts_BoM_BoF_BoFr_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_cl_Texts_BoM_BoF_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_cl_Texts_BoM_BoFr_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_cl_Texts_BoM_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_cl_Texts_Stance_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_cl_Texts_Texts_BoF_BoFr_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_cl_Texts_Texts_BoF_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_cl_Texts_Texts_BoFr_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_cl_Texts_Texts_BoM_BoF_BoFr_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_cl_Texts_Texts_BoM_BoF_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_cl_Texts_Texts_BoM_BoFr_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_cl_Texts_Texts_BoM_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_cl_Texts_Texts_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_cl_Texts_Timeline_BoF_BoFr_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_cl_Texts_Timeline_BoF_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_cl_Texts_Timeline_BoFr_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_cl_Texts_Timeline_BoM_BoF_BoFr_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_cl_Texts_Timeline_BoM_BoF_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_cl_Texts_Timeline_BoM_BoFr_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_cl_Texts_Timeline_BoM_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_cl_Texts_Timeline_Texts_BoF_BoFr_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_cl_Texts_Timeline_Texts_BoF_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_cl_Texts_Timeline_Texts_BoFr_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_cl_Texts_Timeline_Texts_BoM_BoF_BoFr_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_cl_Texts_Timeline_Texts_BoM_BoF_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_cl_Texts_Timeline_Texts_BoM_BoFr_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_cl_Texts_Timeline_Texts_BoM_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_cl_Texts_Timeline_Texts_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_cl_Texts_Timeline_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_cl_Timeline_BoF_BoFr_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_cl_Timeline_BoF_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_cl_Timeline_BoFr_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_cl_Timeline_BoM_BoF_BoFr_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_cl_Timeline_BoM_BoF_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_cl_Timeline_BoM_BoFr_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_cl_Timeline_BoM_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_cl_Timeline_Texts_BoF_BoFr_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_cl_Timeline_Texts_BoF_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_cl_Timeline_Texts_BoFr_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_cl_Timeline_Texts_BoM_BoF_BoFr_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_cl_Timeline_Texts_BoM_BoF_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_cl_Timeline_Texts_BoM_BoFr_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_cl_Timeline_Texts_BoM_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_cl_Timeline_Texts_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_co_BoF_BoFr_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_co_BoM_BoF_BoFr_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_co_BoM_BoF_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_co_BoM_BoFr_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_co_Stance_BoF_BoFr_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_co_Stance_BoF_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_co_Stance_BoFr_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_co_Stance_BoM_BoF_BoFr_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_co_Stance_BoM_BoF_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_co_Stance_BoM_BoFr_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_co_Stance_BoM_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_co_Stance_Texts_BoF_BoFr_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_co_Stance_Texts_BoF_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_co_Stance_Texts_BoFr_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_co_Stance_Texts_BoM_BoF_BoFr_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_co_Stance_Texts_BoM_BoF_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_co_Stance_Texts_BoM_BoFr_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_co_Stance_Texts_BoM_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_co_Stance_Texts_Timeline_BoF_BoFr_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_co_Stance_Texts_Timeline_BoF_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_co_Stance_Texts_Timeline_BoFr_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_co_Stance_Texts_Timeline_BoM_BoF_BoFr_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_co_Stance_Texts_Timeline_BoM_BoF_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_co_Stance_Texts_Timeline_BoM_BoFr_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_co_Stance_Texts_Timeline_BoM_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_co_Stance_Texts_Timeline_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_co_Stance_Texts_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_co_Stance_Timeline_BoF_BoFr_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_co_Stance_Timeline_BoF_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_co_Stance_Timeline_BoFr_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_co_Stance_Timeline_BoM_BoF_BoFr_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_co_Stance_Timeline_BoM_BoF_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_co_Stance_Timeline_BoM_BoFr_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_co_Stance_Timeline_BoM_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_co_Stance_Timeline_Texts_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_co_Stance_Timeline_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_co_Texts_BoF_BoFr_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_co_Texts_BoF_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_co_Texts_BoFr_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_co_Texts_BoM_BoF_BoFr_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_co_Texts_BoM_BoF_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_co_Texts_BoM_BoFr_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_co_Texts_BoM_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_co_Texts_Stance_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_co_Texts_Texts_BoF_BoFr_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_co_Texts_Texts_BoF_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_co_Texts_Texts_BoFr_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_co_Texts_Texts_BoM_BoF_BoFr_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_co_Texts_Texts_BoM_BoF_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_co_Texts_Texts_BoM_BoFr_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_co_Texts_Texts_BoM_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_co_Texts_Texts_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_co_Texts_Timeline_BoF_BoFr_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_co_Texts_Timeline_BoF_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_co_Texts_Timeline_BoFr_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_co_Texts_Timeline_BoM_BoF_BoFr_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_co_Texts_Timeline_BoM_BoF_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_co_Texts_Timeline_BoM_BoFr_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_co_Texts_Timeline_BoM_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_co_Texts_Timeline_Texts_BoF_BoFr_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_co_Texts_Timeline_Texts_BoF_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_co_Texts_Timeline_Texts_BoFr_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_co_Texts_Timeline_Texts_BoM_BoF_BoFr_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_co_Texts_Timeline_Texts_BoM_BoF_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_co_Texts_Timeline_Texts_BoM_BoFr_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_co_Texts_Timeline_Texts_BoM_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_co_Texts_Timeline_Texts_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_co_Texts_Timeline_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_co_Timeline_BoF_BoFr_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_co_Timeline_BoF_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_co_Timeline_BoFr_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_co_Timeline_BoM_BoF_BoFr_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_co_Timeline_BoM_BoF_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_co_Timeline_BoM_BoFr_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_co_Timeline_BoM_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_co_Timeline_Texts_BoF_BoFr_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_co_Timeline_Texts_BoF_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_co_Timeline_Texts_BoFr_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_co_Timeline_Texts_BoM_BoF_BoFr_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_co_Timeline_Texts_BoM_BoF_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_co_Timeline_Texts_BoM_BoFr_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_co_Timeline_Texts_BoM_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_co_Timeline_Texts_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_gl_BoF_BoFr_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_gl_BoM_BoF_BoFr_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_gl_BoM_BoF_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_gl_BoM_BoFr_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_gl_Stance_BoF_BoFr_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_gl_Stance_BoF_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_gl_Stance_BoFr_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_gl_Stance_BoM_BoF_BoFr_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_gl_Stance_BoM_BoF_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_gl_Stance_BoM_BoFr_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_gl_Stance_BoM_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_gl_Stance_Texts_BoF_BoFr_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_gl_Stance_Texts_BoF_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_gl_Stance_Texts_BoFr_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_gl_Stance_Texts_BoM_BoF_BoFr_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_gl_Stance_Texts_BoM_BoF_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_gl_Stance_Texts_BoM_BoFr_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_gl_Stance_Texts_BoM_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_gl_Stance_Texts_Timeline_BoF_BoFr_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_gl_Stance_Texts_Timeline_BoF_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_gl_Stance_Texts_Timeline_BoFr_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_gl_Stance_Texts_Timeline_BoM_BoF_BoFr_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_gl_Stance_Texts_Timeline_BoM_BoF_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_gl_Stance_Texts_Timeline_BoM_BoFr_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_gl_Stance_Texts_Timeline_BoM_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_gl_Stance_Texts_Timeline_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_gl_Stance_Texts_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_gl_Stance_Timeline_BoF_BoFr_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_gl_Stance_Timeline_BoF_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_gl_Stance_Timeline_BoFr_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_gl_Stance_Timeline_BoM_BoF_BoFr_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_gl_Stance_Timeline_BoM_BoF_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_gl_Stance_Timeline_BoM_BoFr_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_gl_Stance_Timeline_BoM_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_gl_Stance_Timeline_Texts_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_gl_Stance_Timeline_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_gl_Texts_BoF_BoFr_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_gl_Texts_BoF_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_gl_Texts_BoFr_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_gl_Texts_BoM_BoF_BoFr_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_gl_Texts_BoM_BoF_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_gl_Texts_BoM_BoFr_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_gl_Texts_BoM_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_gl_Texts_Stance_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_gl_Texts_Texts_BoF_BoFr_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_gl_Texts_Texts_BoF_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_gl_Texts_Texts_BoFr_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_gl_Texts_Texts_BoM_BoF_BoFr_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_gl_Texts_Texts_BoM_BoF_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_gl_Texts_Texts_BoM_BoFr_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_gl_Texts_Texts_BoM_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_gl_Texts_Texts_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_gl_Texts_Timeline_BoF_BoFr_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_gl_Texts_Timeline_BoF_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_gl_Texts_Timeline_BoFr_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_gl_Texts_Timeline_BoM_BoF_BoFr_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_gl_Texts_Timeline_BoM_BoF_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_gl_Texts_Timeline_BoM_BoFr_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_gl_Texts_Timeline_BoM_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_gl_Texts_Timeline_Texts_BoF_BoFr_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_gl_Texts_Timeline_Texts_BoF_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_gl_Texts_Timeline_Texts_BoFr_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_gl_Texts_Timeline_Texts_BoM_BoF_BoFr_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_gl_Texts_Timeline_Texts_BoM_BoF_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_gl_Texts_Timeline_Texts_BoM_BoFr_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_gl_Texts_Timeline_Texts_BoM_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_gl_Texts_Timeline_Texts_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_gl_Texts_Timeline_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_gl_Timeline_BoF_BoFr_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_gl_Timeline_BoF_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_gl_Timeline_BoFr_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_gl_Timeline_BoM_BoF_BoFr_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_gl_Timeline_BoM_BoF_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_gl_Timeline_BoM_BoFr_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_gl_Timeline_BoM_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_gl_Timeline_Texts_BoF_BoFr_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_gl_Timeline_Texts_BoF_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_gl_Timeline_Texts_BoFr_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_gl_Timeline_Texts_BoM_BoF_BoFr_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_gl_Timeline_Texts_BoM_BoF_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_gl_Timeline_Texts_BoM_BoFr_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_gl_Timeline_Texts_BoM_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_gl_Timeline_Texts_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_ig_BoF_BoFr_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_ig_BoM_BoF_BoFr_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_ig_BoM_BoF_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_ig_BoM_BoFr_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_ig_Stance_BoF_BoFr_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_ig_Stance_BoF_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_ig_Stance_BoFr_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_ig_Stance_BoM_BoF_BoFr_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_ig_Stance_BoM_BoF_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_ig_Stance_BoM_BoFr_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_ig_Stance_BoM_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_ig_Stance_Texts_BoF_BoFr_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_ig_Stance_Texts_BoF_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_ig_Stance_Texts_BoFr_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_ig_Stance_Texts_BoM_BoF_BoFr_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_ig_Stance_Texts_BoM_BoF_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_ig_Stance_Texts_BoM_BoFr_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_ig_Stance_Texts_BoM_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_ig_Stance_Texts_Timeline_BoF_BoFr_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_ig_Stance_Texts_Timeline_BoF_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_ig_Stance_Texts_Timeline_BoFr_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_ig_Stance_Texts_Timeline_BoM_BoF_BoFr_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_ig_Stance_Texts_Timeline_BoM_BoF_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_ig_Stance_Texts_Timeline_BoM_BoFr_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_ig_Stance_Texts_Timeline_BoM_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_ig_Stance_Texts_Timeline_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_ig_Stance_Texts_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_ig_Stance_Timeline_BoF_BoFr_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_ig_Stance_Timeline_BoF_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_ig_Stance_Timeline_BoFr_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_ig_Stance_Timeline_BoM_BoF_BoFr_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_ig_Stance_Timeline_BoM_BoF_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_ig_Stance_Timeline_BoM_BoFr_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_ig_Stance_Timeline_BoM_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_ig_Stance_Timeline_Texts_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_ig_Stance_Timeline_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_ig_Texts_BoF_BoFr_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_ig_Texts_BoF_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_ig_Texts_BoFr_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_ig_Texts_BoM_BoF_BoFr_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_ig_Texts_BoM_BoF_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_ig_Texts_BoM_BoFr_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_ig_Texts_BoM_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_ig_Texts_Stance_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_ig_Texts_Texts_BoF_BoFr_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_ig_Texts_Texts_BoF_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_ig_Texts_Texts_BoFr_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_ig_Texts_Texts_BoM_BoF_BoFr_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_ig_Texts_Texts_BoM_BoF_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_ig_Texts_Texts_BoM_BoFr_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_ig_Texts_Texts_BoM_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_ig_Texts_Texts_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_ig_Texts_Timeline_BoF_BoFr_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_ig_Texts_Timeline_BoF_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_ig_Texts_Timeline_BoFr_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_ig_Texts_Timeline_BoM_BoF_BoFr_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_ig_Texts_Timeline_BoM_BoF_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_ig_Texts_Timeline_BoM_BoFr_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_ig_Texts_Timeline_BoM_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_ig_Texts_Timeline_Texts_BoF_BoFr_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_ig_Texts_Timeline_Texts_BoF_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_ig_Texts_Timeline_Texts_BoFr_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_ig_Texts_Timeline_Texts_BoM_BoF_BoFr_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_ig_Texts_Timeline_Texts_BoM_BoF_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_ig_Texts_Timeline_Texts_BoM_BoFr_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_ig_Texts_Timeline_Texts_BoM_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_ig_Texts_Timeline_Texts_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_ig_Texts_Timeline_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_ig_Timeline_BoF_BoFr_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_ig_Timeline_BoF_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_ig_Timeline_BoFr_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_ig_Timeline_BoM_BoF_BoFr_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_ig_Timeline_BoM_BoF_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_ig_Timeline_BoM_BoFr_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_ig_Timeline_BoM_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_ig_Timeline_Texts_BoF_BoFr_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_ig_Timeline_Texts_BoF_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_ig_Timeline_Texts_BoFr_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_ig_Timeline_Texts_BoM_BoF_BoFr_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_ig_Timeline_Texts_BoM_BoF_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_ig_Timeline_Texts_BoM_BoFr_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_ig_Timeline_Texts_BoM_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_ig_Timeline_Texts_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_lu_BoF_BoFr_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_lu_BoM_BoF_BoFr_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_lu_BoM_BoF_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_lu_BoM_BoFr_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_lu_Stance_BoF_BoFr_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_lu_Stance_BoF_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_lu_Stance_BoFr_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_lu_Stance_BoM_BoF_BoFr_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_lu_Stance_BoM_BoF_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_lu_Stance_BoM_BoFr_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_lu_Stance_BoM_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_lu_Stance_Texts_BoF_BoFr_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_lu_Stance_Texts_BoF_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_lu_Stance_Texts_BoFr_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_lu_Stance_Texts_BoM_BoF_BoFr_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_lu_Stance_Texts_BoM_BoF_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_lu_Stance_Texts_BoM_BoFr_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_lu_Stance_Texts_BoM_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_lu_Stance_Texts_Timeline_BoF_BoFr_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_lu_Stance_Texts_Timeline_BoF_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_lu_Stance_Texts_Timeline_BoFr_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_lu_Stance_Texts_Timeline_BoM_BoF_BoFr_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_lu_Stance_Texts_Timeline_BoM_BoF_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_lu_Stance_Texts_Timeline_BoM_BoFr_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_lu_Stance_Texts_Timeline_BoM_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_lu_Stance_Texts_Timeline_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_lu_Stance_Texts_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_lu_Stance_Timeline_BoF_BoFr_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_lu_Stance_Timeline_BoF_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_lu_Stance_Timeline_BoFr_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_lu_Stance_Timeline_BoM_BoF_BoFr_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_lu_Stance_Timeline_BoM_BoF_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_lu_Stance_Timeline_BoM_BoFr_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_lu_Stance_Timeline_BoM_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_lu_Stance_Timeline_Texts_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_lu_Stance_Timeline_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_lu_Texts_BoF_BoFr_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_lu_Texts_BoF_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_lu_Texts_BoFr_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_lu_Texts_BoM_BoF_BoFr_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_lu_Texts_BoM_BoF_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_lu_Texts_BoM_BoFr_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_lu_Texts_BoM_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_lu_Texts_Stance_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_lu_Texts_Texts_BoF_BoFr_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_lu_Texts_Texts_BoF_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_lu_Texts_Texts_BoFr_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_lu_Texts_Texts_BoM_BoF_BoFr_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_lu_Texts_Texts_BoM_BoF_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_lu_Texts_Texts_BoM_BoFr_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_lu_Texts_Texts_BoM_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_lu_Texts_Texts_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_lu_Texts_Timeline_BoF_BoFr_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_lu_Texts_Timeline_BoF_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_lu_Texts_Timeline_BoFr_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_lu_Texts_Timeline_BoM_BoF_BoFr_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_lu_Texts_Timeline_BoM_BoF_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_lu_Texts_Timeline_BoM_BoFr_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_lu_Texts_Timeline_BoM_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_lu_Texts_Timeline_Texts_BoF_BoFr_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_lu_Texts_Timeline_Texts_BoF_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_lu_Texts_Timeline_Texts_BoFr_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_lu_Texts_Timeline_Texts_BoM_BoF_BoFr_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_lu_Texts_Timeline_Texts_BoM_BoF_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_lu_Texts_Timeline_Texts_BoM_BoFr_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_lu_Texts_Timeline_Texts_BoM_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_lu_Texts_Timeline_Texts_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_lu_Texts_Timeline_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_lu_Timeline_BoF_BoFr_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_lu_Timeline_BoF_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_lu_Timeline_BoFr_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_lu_Timeline_BoM_BoF_BoFr_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_lu_Timeline_BoM_BoF_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_lu_Timeline_BoM_BoFr_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_lu_Timeline_BoM_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_lu_Timeline_Texts_BoF_BoFr_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_lu_Timeline_Texts_BoF_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_lu_Timeline_Texts_BoFr_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_lu_Timeline_Texts_BoM_BoF_BoFr_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_lu_Timeline_Texts_BoM_BoF_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_lu_Timeline_Texts_BoM_BoFr_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_lu_Timeline_Texts_BoM_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_lu_Timeline_Texts_test_results.csv',\n",
       " 'LSTM_lu_Stance_test_results.csv',\n",
       " 'TfidfVectorizer_SelectKBest_LogisticRegression_bo_BagOfFollowers_test_results.csv',\n",
       " 'TfidfVectorizer_SelectKBest_LogisticRegression_bo_BagOfFriends_test_results.csv',\n",
       " 'TfidfVectorizer_SelectKBest_LogisticRegression_bo_BagOfMentions_test_results.csv',\n",
       " 'TfidfVectorizer_SelectKBest_LogisticRegression_cl_BagOfFollowers_test_results.csv',\n",
       " 'TfidfVectorizer_SelectKBest_LogisticRegression_cl_BagOfFriends_test_results.csv',\n",
       " 'TfidfVectorizer_SelectKBest_LogisticRegression_cl_BagOfMentions_test_results.csv',\n",
       " 'TfidfVectorizer_SelectKBest_LogisticRegression_co_BagOfFollowers_test_results.csv',\n",
       " 'TfidfVectorizer_SelectKBest_LogisticRegression_co_BagOfFriends_test_results.csv',\n",
       " 'TfidfVectorizer_SelectKBest_LogisticRegression_co_BagOfMentions_test_results.csv',\n",
       " 'TfidfVectorizer_SelectKBest_LogisticRegression_gl_BagOfFollowers_test_results.csv',\n",
       " 'TfidfVectorizer_SelectKBest_LogisticRegression_gl_BagOfFriends_test_results.csv',\n",
       " 'TfidfVectorizer_SelectKBest_LogisticRegression_gl_BagOfMentions_test_results.csv',\n",
       " 'TfidfVectorizer_SelectKBest_LogisticRegression_ig_BagOfFollowers_test_results.csv',\n",
       " 'TfidfVectorizer_SelectKBest_LogisticRegression_ig_BagOfFriends_test_results.csv',\n",
       " 'TfidfVectorizer_SelectKBest_LogisticRegression_ig_BagOfMentions_test_results.csv',\n",
       " 'TfidfVectorizer_SelectKBest_LogisticRegression_lu_BagOfFollowers_test_results.csv',\n",
       " 'TfidfVectorizer_SelectKBest_LogisticRegression_lu_BagOfFriends_test_results.csv',\n",
       " 'TfidfVectorizer_SelectKBest_LogisticRegression_lu_BagOfMentions_test_results.csv',\n",
       " 'XGBClassifier_TfidfVectorizer_bo_concat_Texts_Timeline_concat_Texts_Timeline_test_results.csv',\n",
       " 'XGBClassifier_TfidfVectorizer_bo_top_mentioned_timelines_Texts_test_results.csv',\n",
       " 'XGBClassifier_TfidfVectorizer_bo_users_Stance_test_results.csv',\n",
       " 'XGBClassifier_TfidfVectorizer_bo_users_Timeline_test_results.csv',\n",
       " 'XGBClassifier_TfidfVectorizer_cl_concat_Texts_Timeline_concat_Texts_Timeline_test_results.csv',\n",
       " 'XGBClassifier_TfidfVectorizer_cl_top_mentioned_timelines_Texts_test_results.csv',\n",
       " 'XGBClassifier_TfidfVectorizer_cl_users_Stance_test_results.csv',\n",
       " 'XGBClassifier_TfidfVectorizer_cl_users_Timeline_test_results.csv',\n",
       " 'XGBClassifier_TfidfVectorizer_co_concat_Texts_Timeline_concat_Texts_Timeline_test_results.csv',\n",
       " 'XGBClassifier_TfidfVectorizer_co_top_mentioned_timelines_Texts_test_results.csv',\n",
       " 'XGBClassifier_TfidfVectorizer_co_users_Stance_test_results.csv',\n",
       " 'XGBClassifier_TfidfVectorizer_co_users_Timeline_test_results.csv',\n",
       " 'XGBClassifier_TfidfVectorizer_gl_concat_Texts_Timeline_concat_Texts_Timeline_test_results.csv',\n",
       " 'XGBClassifier_TfidfVectorizer_gl_top_mentioned_timelines_Texts_test_results.csv',\n",
       " 'XGBClassifier_TfidfVectorizer_gl_users_Stance_test_results.csv',\n",
       " 'XGBClassifier_TfidfVectorizer_gl_users_Timeline_test_results.csv',\n",
       " 'XGBClassifier_TfidfVectorizer_ig_concat_Texts_Timeline_concat_Texts_Timeline_test_results.csv',\n",
       " 'XGBClassifier_TfidfVectorizer_ig_top_mentioned_timelines_Texts_test_results.csv',\n",
       " 'XGBClassifier_TfidfVectorizer_ig_users_Stance_test_results.csv',\n",
       " 'XGBClassifier_TfidfVectorizer_ig_users_Timeline_test_results.csv',\n",
       " 'XGBClassifier_TfidfVectorizer_lu_concat_Texts_Timeline_concat_Texts_Timeline_test_results.csv',\n",
       " 'XGBClassifier_TfidfVectorizer_lu_top_mentioned_timelines_Texts_test_results.csv',\n",
       " 'XGBClassifier_TfidfVectorizer_lu_users_Stance_test_results.csv',\n",
       " 'XGBClassifier_TfidfVectorizer_lu_users_Timeline_test_results.csv',\n",
       " 'belt_filteredTimeline10_pablocosta_bertabaporu-base-uncased_test_results.csv',\n",
       " 'belt_filteredTimeline10_pablocosta_bertabaporu-base-uncased_test_results_part_bo.csv',\n",
       " 'belt_filteredTimeline10_pablocosta_bertabaporu-base-uncased_test_results_part_cl.csv',\n",
       " 'belt_filteredTimeline10_pablocosta_bertabaporu-base-uncased_test_results_part_co.csv',\n",
       " 'belt_filteredTimeline10_pablocosta_bertabaporu-base-uncased_test_results_part_gl.csv',\n",
       " 'belt_filteredTimeline10_pablocosta_bertabaporu-base-uncased_test_results_part_ig.csv',\n",
       " 'belt_filteredTimeline10_pablocosta_bertabaporu-base-uncased_test_results_part_lu.csv',\n",
       " 'belt_filteredTimeline15_pablocosta_bertabaporu-base-uncased_test_results.csv',\n",
       " 'belt_filteredTimeline15_pablocosta_bertabaporu-base-uncased_test_results_part_bo.csv',\n",
       " 'belt_filteredTimeline15_pablocosta_bertabaporu-base-uncased_test_results_part_cl.csv',\n",
       " 'belt_filteredTimeline15_pablocosta_bertabaporu-base-uncased_test_results_part_co.csv',\n",
       " 'belt_filteredTimeline15_pablocosta_bertabaporu-base-uncased_test_results_part_gl.csv',\n",
       " 'belt_filteredTimeline15_pablocosta_bertabaporu-base-uncased_test_results_part_ig.csv',\n",
       " 'belt_filteredTimeline15_pablocosta_bertabaporu-base-uncased_test_results_part_lu.csv',\n",
       " 'belt_filteredTimeline5_pablocosta_bertabaporu-base-uncased_test_results.csv',\n",
       " 'belt_filteredTimeline5_pablocosta_bertabaporu-base-uncased_test_results_part_bo.csv',\n",
       " 'belt_filteredTimeline5_pablocosta_bertabaporu-base-uncased_test_results_part_cl.csv',\n",
       " 'belt_filteredTimeline5_pablocosta_bertabaporu-base-uncased_test_results_part_co.csv',\n",
       " 'belt_filteredTimeline5_pablocosta_bertabaporu-base-uncased_test_results_part_gl.csv',\n",
       " 'belt_filteredTimeline5_pablocosta_bertabaporu-base-uncased_test_results_part_ig.csv',\n",
       " 'belt_filteredTimeline5_pablocosta_bertabaporu-base-uncased_test_results_part_lu.csv',\n",
       " 'belt_filtered_Texts10_pablocosta_bertabaporu-base-uncased_test_results.csv',\n",
       " 'belt_filtered_Texts10_pablocosta_bertabaporu-base-uncased_test_results_part_bo.csv',\n",
       " 'belt_filtered_Texts10_pablocosta_bertabaporu-base-uncased_test_results_part_cl.csv',\n",
       " 'belt_filtered_Texts10_pablocosta_bertabaporu-base-uncased_test_results_part_co.csv',\n",
       " 'belt_filtered_Texts10_pablocosta_bertabaporu-base-uncased_test_results_part_gl.csv',\n",
       " 'belt_filtered_Texts10_pablocosta_bertabaporu-base-uncased_test_results_part_ig.csv',\n",
       " 'belt_filtered_Texts10_pablocosta_bertabaporu-base-uncased_test_results_part_lu.csv',\n",
       " 'belt_filtered_Texts15_pablocosta_bertabaporu-base-uncased_test_results.csv',\n",
       " 'belt_filtered_Texts15_pablocosta_bertabaporu-base-uncased_test_results_part_bo.csv',\n",
       " 'belt_filtered_Texts15_pablocosta_bertabaporu-base-uncased_test_results_part_cl.csv',\n",
       " 'belt_filtered_Texts15_pablocosta_bertabaporu-base-uncased_test_results_part_co.csv',\n",
       " 'belt_filtered_Texts15_pablocosta_bertabaporu-base-uncased_test_results_part_gl.csv',\n",
       " 'belt_filtered_Texts15_pablocosta_bertabaporu-base-uncased_test_results_part_ig.csv',\n",
       " 'belt_filtered_Texts15_pablocosta_bertabaporu-base-uncased_test_results_part_lu.csv',\n",
       " 'belt_filtered_Texts5_pablocosta_bertabaporu-base-uncased_test_results.csv',\n",
       " 'belt_filtered_Texts5_pablocosta_bertabaporu-base-uncased_test_results_part_bo.csv',\n",
       " 'belt_filtered_Texts5_pablocosta_bertabaporu-base-uncased_test_results_part_cl.csv',\n",
       " 'belt_filtered_Texts5_pablocosta_bertabaporu-base-uncased_test_results_part_co.csv',\n",
       " 'belt_filtered_Texts5_pablocosta_bertabaporu-base-uncased_test_results_part_gl.csv',\n",
       " 'belt_filtered_Texts5_pablocosta_bertabaporu-base-uncased_test_results_part_ig.csv',\n",
       " 'belt_filtered_Texts5_pablocosta_bertabaporu-base-uncased_test_results_part_lu.csv',\n",
       " 'bert_classifier_pablocosta_bertabaporu_base_uncased_bo_Stance_test_results.csv',\n",
       " 'bert_classifier_pablocosta_bertabaporu_base_uncased_bo_Texts_test_results.csv',\n",
       " 'bert_classifier_pablocosta_bertabaporu_base_uncased_bo_Timeline_test_results.csv',\n",
       " 'bert_classifier_pablocosta_bertabaporu_base_uncased_bo_scored_Texts_test_results.csv',\n",
       " 'bert_classifier_pablocosta_bertabaporu_base_uncased_bo_scored_Timeline_test_results.csv',\n",
       " 'bert_classifier_pablocosta_bertabaporu_base_uncased_cl_Stance_test_results.csv',\n",
       " 'bert_classifier_pablocosta_bertabaporu_base_uncased_cl_Texts_test_results.csv',\n",
       " 'bert_classifier_pablocosta_bertabaporu_base_uncased_cl_Timeline_test_results.csv',\n",
       " 'bert_classifier_pablocosta_bertabaporu_base_uncased_cl_scored_Texts_test_results.csv',\n",
       " 'bert_classifier_pablocosta_bertabaporu_base_uncased_cl_scored_Timeline_test_results.csv',\n",
       " 'bert_classifier_pablocosta_bertabaporu_base_uncased_co_Stance_test_results.csv',\n",
       " 'bert_classifier_pablocosta_bertabaporu_base_uncased_co_Texts_test_results.csv',\n",
       " 'bert_classifier_pablocosta_bertabaporu_base_uncased_co_Timeline_test_results.csv',\n",
       " 'bert_classifier_pablocosta_bertabaporu_base_uncased_co_scored_Texts_test_results.csv',\n",
       " 'bert_classifier_pablocosta_bertabaporu_base_uncased_co_scored_Timeline_test_results.csv',\n",
       " 'bert_classifier_pablocosta_bertabaporu_base_uncased_gl_Stance_test_results.csv',\n",
       " 'bert_classifier_pablocosta_bertabaporu_base_uncased_gl_Texts_test_results.csv',\n",
       " 'bert_classifier_pablocosta_bertabaporu_base_uncased_gl_Timeline_test_results.csv',\n",
       " 'bert_classifier_pablocosta_bertabaporu_base_uncased_gl_scored_Texts_test_results.csv',\n",
       " 'bert_classifier_pablocosta_bertabaporu_base_uncased_gl_scored_Timeline_test_results.csv',\n",
       " 'bert_classifier_pablocosta_bertabaporu_base_uncased_ig_Stance_test_results.csv',\n",
       " 'bert_classifier_pablocosta_bertabaporu_base_uncased_ig_Texts_test_results.csv',\n",
       " 'bert_classifier_pablocosta_bertabaporu_base_uncased_ig_Timeline_test_results.csv',\n",
       " 'bert_classifier_pablocosta_bertabaporu_base_uncased_ig_scored_Texts_test_results.csv',\n",
       " 'bert_classifier_pablocosta_bertabaporu_base_uncased_ig_scored_Timeline_test_results.csv',\n",
       " 'bert_classifier_pablocosta_bertabaporu_base_uncased_lu_Stance_test_results.csv',\n",
       " 'bert_classifier_pablocosta_bertabaporu_base_uncased_lu_Texts_test_results.csv',\n",
       " 'bert_classifier_pablocosta_bertabaporu_base_uncased_lu_Timeline_test_results.csv',\n",
       " 'bert_classifier_pablocosta_bertabaporu_base_uncased_lu_scored_Texts_test_results.csv',\n",
       " 'bert_classifier_pablocosta_bertabaporu_base_uncased_lu_scored_Timeline_test_results.csv',\n",
       " 'bertimbau_xgb_bo_top_mentioned_timelines_emb_Texts_test_results.csv',\n",
       " 'bertimbau_xgb_bo_users_emb_Stance_test_results.csv',\n",
       " 'bertimbau_xgb_bo_users_emb_Timeline_test_results.csv',\n",
       " 'bertimbau_xgb_cl_top_mentioned_timelines_emb_Texts_test_results.csv',\n",
       " 'bertimbau_xgb_cl_users_emb_Stance_test_results.csv',\n",
       " 'bertimbau_xgb_cl_users_emb_Timeline_test_results.csv',\n",
       " 'bertimbau_xgb_co_top_mentioned_timelines_emb_Texts_test_results.csv',\n",
       " 'bertimbau_xgb_co_users_emb_Stance_test_results.csv',\n",
       " 'bertimbau_xgb_co_users_emb_Timeline_test_results.csv',\n",
       " 'bertimbau_xgb_gl_top_mentioned_timelines_emb_Texts_test_results.csv',\n",
       " 'bertimbau_xgb_gl_users_emb_Stance_test_results.csv',\n",
       " 'bertimbau_xgb_gl_users_emb_Timeline_test_results.csv',\n",
       " 'bertimbau_xgb_ig_top_mentioned_timelines_emb_Texts_test_results.csv',\n",
       " 'bertimbau_xgb_ig_users_emb_Stance_test_results.csv',\n",
       " 'bertimbau_xgb_ig_users_emb_Timeline_test_results.csv',\n",
       " 'bertimbau_xgb_lu_top_mentioned_timelines_emb_Texts_test_results.csv',\n",
       " 'bertimbau_xgb_lu_users_emb_Stance_test_results.csv',\n",
       " 'bertimbau_xgb_lu_users_emb_Timeline_test_results.csv',\n",
       " 'llama3_bo_Stance_prompt2_Stance_test_results.csv',\n",
       " 'llama3_bo_filteredTimeline10_prompt2_Timeline_test_results.csv',\n",
       " 'llama3_bo_filteredTimeline15_prompt2_Timeline_test_results.csv',\n",
       " 'llama3_bo_filteredTimeline5_prompt2_Timeline_test_results.csv',\n",
       " 'llama3_bo_filtered_Texts10_prompt2_Texts_test_results.csv',\n",
       " 'llama3_bo_filtered_Texts15_prompt2_Texts_test_results.csv',\n",
       " 'llama3_bo_filtered_Texts20_prompt2_Texts_test_results.csv',\n",
       " 'llama3_bo_filtered_Texts5_prompt2_Texts_test_results.csv',\n",
       " 'llama3_cl_Stance_prompt2_Stance_test_results.csv',\n",
       " 'llama3_cl_filteredTimeline10_prompt2_Timeline_test_results.csv',\n",
       " 'llama3_cl_filteredTimeline15_prompt2_Timeline_test_results.csv',\n",
       " 'llama3_cl_filteredTimeline5_prompt2_Timeline_test_results.csv',\n",
       " 'llama3_cl_filtered_Texts10_prompt2_Texts_test_results.csv',\n",
       " 'llama3_cl_filtered_Texts15_prompt2_Texts_test_results.csv',\n",
       " 'llama3_cl_filtered_Texts20_prompt2_Texts_test_results.csv',\n",
       " 'llama3_cl_filtered_Texts5_prompt2_Texts_test_results.csv',\n",
       " 'llama3_co_Stance_prompt2_Stance_test_results.csv',\n",
       " 'llama3_co_filteredTimeline10_prompt2_Timeline_test_results.csv',\n",
       " 'llama3_co_filteredTimeline15_prompt2_Timeline_test_results.csv',\n",
       " 'llama3_co_filteredTimeline5_prompt2_Timeline_test_results.csv',\n",
       " 'llama3_co_filtered_Texts10_prompt2_Texts_test_results.csv',\n",
       " 'llama3_co_filtered_Texts15_prompt2_Texts_test_results.csv',\n",
       " 'llama3_co_filtered_Texts5_prompt2_Texts_test_results.csv',\n",
       " 'llama3_gl_Stance_prompt2_Stance_test_results.csv',\n",
       " 'llama3_gl_filteredTimeline10_prompt2_Timeline_test_results.csv',\n",
       " 'llama3_gl_filteredTimeline15_prompt2_Timeline_test_results.csv',\n",
       " 'llama3_gl_filteredTimeline5_prompt2_Timeline_test_results.csv',\n",
       " 'llama3_gl_filtered_Texts10_prompt2_Texts_test_results.csv',\n",
       " 'llama3_gl_filtered_Texts15_prompt2_Texts_test_results.csv',\n",
       " 'llama3_gl_filtered_Texts5_prompt2_Texts_test_results.csv',\n",
       " 'llama3_ig_Stance_prompt2_Stance_test_results.csv',\n",
       " 'llama3_ig_filteredTimeline10_prompt2_Timeline_test_results.csv',\n",
       " 'llama3_ig_filteredTimeline15_prompt2_Timeline_test_results.csv',\n",
       " 'llama3_ig_filteredTimeline5_prompt2_Timeline_test_results.csv',\n",
       " 'llama3_ig_filtered_Texts10_prompt2_Texts_test_results.csv',\n",
       " 'llama3_ig_filtered_Texts15_prompt2_Texts_test_results.csv',\n",
       " 'llama3_ig_filtered_Texts20_prompt2_Texts_test_results.csv',\n",
       " 'llama3_ig_filtered_Texts5_prompt2_Texts_test_results.csv',\n",
       " 'llama3_lu_Stance_prompt2_Stance_test_results.csv',\n",
       " 'llama3_lu_filteredTimeline10_prompt2_Timeline_test_results.csv',\n",
       " 'llama3_lu_filteredTimeline15_prompt2_Timeline_test_results.csv',\n",
       " 'llama3_lu_filteredTimeline5_prompt2_Timeline_test_results.csv',\n",
       " 'llama3_lu_filtered_Texts10_prompt2_Texts_test_results.csv',\n",
       " 'llama3_lu_filtered_Texts15_prompt2_Texts_test_results.csv',\n",
       " 'llama3_lu_filtered_Texts5_prompt2_Texts_test_results.csv',\n",
       " 'old']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_results_path = '../reports/test_results/'\n",
    "\n",
    "list_df_t = os.listdir(test_results_path)\n",
    "list_df_t.sort()\n",
    "list_df_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hydrox.', 'Lula', 'Sinovac', 'Church', 'Globo TV', 'Bolsonaro']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Target list\n",
    "target_list = [\n",
    "    'ig',\n",
    "    'bo', \n",
    "    'cl', \n",
    "    'co', \n",
    "    'gl', \n",
    "    'lu'\n",
    "]\n",
    "\n",
    "dict_cp = {\n",
    "    'cl':'Hydrox.',\n",
    "    'lu':'Lula',\n",
    "    'co':'Sinovac',\n",
    "    'ig':'Church',\n",
    "    'gl':'Globo TV',\n",
    "    'bo':'Bolsonaro',\n",
    "}\n",
    "\n",
    "names = list(dict_cp.values())\n",
    "names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create complete table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get all the combinations of Stacking:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_list = [\n",
    "    'Stance','Texts', 'Timeline', 'Texts',\n",
    "    'BoM', 'BoF', 'BoFr'\n",
    "]\n",
    "\n",
    "# Remove duplicados mantendo a ordem\n",
    "unique_my_list = []\n",
    "seen = set()\n",
    "for item in my_list:\n",
    "    if item not in seen:\n",
    "        unique_my_list.append(item)\n",
    "        seen.add(item)\n",
    "\n",
    "all_combinations = []\n",
    "for r in range(2, len(unique_my_list) + 1):\n",
    "    all_combinations.extend(itertools.combinations(unique_my_list, r))\n",
    "\n",
    "\n",
    "\n",
    "tuples_stacking_exps = []\n",
    "clf_name = 'LogisticRegression'\n",
    "preprocess_name = '-'\n",
    "for comb in all_combinations:\n",
    "    \n",
    "    str_cols = \"_\".join(comb)\n",
    "    \n",
    "    exp_name = 'Stacking ' + \" + \".join(comb)\n",
    "    \n",
    "    \n",
    "    filename = 'Ensemble_LogisticRegression_{target}_' + str_cols + '_test_results.csv'\n",
    "    tuples_stacking_exps.append((exp_name, preprocess_name, clf_name, filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Stacking Stance + Texts',\n",
       "  '-',\n",
       "  'LogisticRegression',\n",
       "  'Ensemble_LogisticRegression_{target}_Stance_Texts_test_results.csv'),\n",
       " ('Stacking Stance + Timeline',\n",
       "  '-',\n",
       "  'LogisticRegression',\n",
       "  'Ensemble_LogisticRegression_{target}_Stance_Timeline_test_results.csv'),\n",
       " ('Stacking Stance + BoM',\n",
       "  '-',\n",
       "  'LogisticRegression',\n",
       "  'Ensemble_LogisticRegression_{target}_Stance_BoM_test_results.csv'),\n",
       " ('Stacking Stance + BoF',\n",
       "  '-',\n",
       "  'LogisticRegression',\n",
       "  'Ensemble_LogisticRegression_{target}_Stance_BoF_test_results.csv'),\n",
       " ('Stacking Stance + BoFr',\n",
       "  '-',\n",
       "  'LogisticRegression',\n",
       "  'Ensemble_LogisticRegression_{target}_Stance_BoFr_test_results.csv'),\n",
       " ('Stacking Texts + Timeline',\n",
       "  '-',\n",
       "  'LogisticRegression',\n",
       "  'Ensemble_LogisticRegression_{target}_Texts_Timeline_test_results.csv'),\n",
       " ('Stacking Texts + BoM',\n",
       "  '-',\n",
       "  'LogisticRegression',\n",
       "  'Ensemble_LogisticRegression_{target}_Texts_BoM_test_results.csv'),\n",
       " ('Stacking Texts + BoF',\n",
       "  '-',\n",
       "  'LogisticRegression',\n",
       "  'Ensemble_LogisticRegression_{target}_Texts_BoF_test_results.csv'),\n",
       " ('Stacking Texts + BoFr',\n",
       "  '-',\n",
       "  'LogisticRegression',\n",
       "  'Ensemble_LogisticRegression_{target}_Texts_BoFr_test_results.csv'),\n",
       " ('Stacking Timeline + BoM',\n",
       "  '-',\n",
       "  'LogisticRegression',\n",
       "  'Ensemble_LogisticRegression_{target}_Timeline_BoM_test_results.csv'),\n",
       " ('Stacking Timeline + BoF',\n",
       "  '-',\n",
       "  'LogisticRegression',\n",
       "  'Ensemble_LogisticRegression_{target}_Timeline_BoF_test_results.csv'),\n",
       " ('Stacking Timeline + BoFr',\n",
       "  '-',\n",
       "  'LogisticRegression',\n",
       "  'Ensemble_LogisticRegression_{target}_Timeline_BoFr_test_results.csv'),\n",
       " ('Stacking BoM + BoF',\n",
       "  '-',\n",
       "  'LogisticRegression',\n",
       "  'Ensemble_LogisticRegression_{target}_BoM_BoF_test_results.csv'),\n",
       " ('Stacking BoM + BoFr',\n",
       "  '-',\n",
       "  'LogisticRegression',\n",
       "  'Ensemble_LogisticRegression_{target}_BoM_BoFr_test_results.csv'),\n",
       " ('Stacking BoF + BoFr',\n",
       "  '-',\n",
       "  'LogisticRegression',\n",
       "  'Ensemble_LogisticRegression_{target}_BoF_BoFr_test_results.csv'),\n",
       " ('Stacking Stance + Texts + Timeline',\n",
       "  '-',\n",
       "  'LogisticRegression',\n",
       "  'Ensemble_LogisticRegression_{target}_Stance_Texts_Timeline_test_results.csv'),\n",
       " ('Stacking Stance + Texts + BoM',\n",
       "  '-',\n",
       "  'LogisticRegression',\n",
       "  'Ensemble_LogisticRegression_{target}_Stance_Texts_BoM_test_results.csv'),\n",
       " ('Stacking Stance + Texts + BoF',\n",
       "  '-',\n",
       "  'LogisticRegression',\n",
       "  'Ensemble_LogisticRegression_{target}_Stance_Texts_BoF_test_results.csv'),\n",
       " ('Stacking Stance + Texts + BoFr',\n",
       "  '-',\n",
       "  'LogisticRegression',\n",
       "  'Ensemble_LogisticRegression_{target}_Stance_Texts_BoFr_test_results.csv'),\n",
       " ('Stacking Stance + Timeline + BoM',\n",
       "  '-',\n",
       "  'LogisticRegression',\n",
       "  'Ensemble_LogisticRegression_{target}_Stance_Timeline_BoM_test_results.csv'),\n",
       " ('Stacking Stance + Timeline + BoF',\n",
       "  '-',\n",
       "  'LogisticRegression',\n",
       "  'Ensemble_LogisticRegression_{target}_Stance_Timeline_BoF_test_results.csv'),\n",
       " ('Stacking Stance + Timeline + BoFr',\n",
       "  '-',\n",
       "  'LogisticRegression',\n",
       "  'Ensemble_LogisticRegression_{target}_Stance_Timeline_BoFr_test_results.csv'),\n",
       " ('Stacking Stance + BoM + BoF',\n",
       "  '-',\n",
       "  'LogisticRegression',\n",
       "  'Ensemble_LogisticRegression_{target}_Stance_BoM_BoF_test_results.csv'),\n",
       " ('Stacking Stance + BoM + BoFr',\n",
       "  '-',\n",
       "  'LogisticRegression',\n",
       "  'Ensemble_LogisticRegression_{target}_Stance_BoM_BoFr_test_results.csv'),\n",
       " ('Stacking Stance + BoF + BoFr',\n",
       "  '-',\n",
       "  'LogisticRegression',\n",
       "  'Ensemble_LogisticRegression_{target}_Stance_BoF_BoFr_test_results.csv'),\n",
       " ('Stacking Texts + Timeline + BoM',\n",
       "  '-',\n",
       "  'LogisticRegression',\n",
       "  'Ensemble_LogisticRegression_{target}_Texts_Timeline_BoM_test_results.csv'),\n",
       " ('Stacking Texts + Timeline + BoF',\n",
       "  '-',\n",
       "  'LogisticRegression',\n",
       "  'Ensemble_LogisticRegression_{target}_Texts_Timeline_BoF_test_results.csv'),\n",
       " ('Stacking Texts + Timeline + BoFr',\n",
       "  '-',\n",
       "  'LogisticRegression',\n",
       "  'Ensemble_LogisticRegression_{target}_Texts_Timeline_BoFr_test_results.csv'),\n",
       " ('Stacking Texts + BoM + BoF',\n",
       "  '-',\n",
       "  'LogisticRegression',\n",
       "  'Ensemble_LogisticRegression_{target}_Texts_BoM_BoF_test_results.csv'),\n",
       " ('Stacking Texts + BoM + BoFr',\n",
       "  '-',\n",
       "  'LogisticRegression',\n",
       "  'Ensemble_LogisticRegression_{target}_Texts_BoM_BoFr_test_results.csv'),\n",
       " ('Stacking Texts + BoF + BoFr',\n",
       "  '-',\n",
       "  'LogisticRegression',\n",
       "  'Ensemble_LogisticRegression_{target}_Texts_BoF_BoFr_test_results.csv'),\n",
       " ('Stacking Timeline + BoM + BoF',\n",
       "  '-',\n",
       "  'LogisticRegression',\n",
       "  'Ensemble_LogisticRegression_{target}_Timeline_BoM_BoF_test_results.csv'),\n",
       " ('Stacking Timeline + BoM + BoFr',\n",
       "  '-',\n",
       "  'LogisticRegression',\n",
       "  'Ensemble_LogisticRegression_{target}_Timeline_BoM_BoFr_test_results.csv'),\n",
       " ('Stacking Timeline + BoF + BoFr',\n",
       "  '-',\n",
       "  'LogisticRegression',\n",
       "  'Ensemble_LogisticRegression_{target}_Timeline_BoF_BoFr_test_results.csv'),\n",
       " ('Stacking BoM + BoF + BoFr',\n",
       "  '-',\n",
       "  'LogisticRegression',\n",
       "  'Ensemble_LogisticRegression_{target}_BoM_BoF_BoFr_test_results.csv'),\n",
       " ('Stacking Stance + Texts + Timeline + BoM',\n",
       "  '-',\n",
       "  'LogisticRegression',\n",
       "  'Ensemble_LogisticRegression_{target}_Stance_Texts_Timeline_BoM_test_results.csv'),\n",
       " ('Stacking Stance + Texts + Timeline + BoF',\n",
       "  '-',\n",
       "  'LogisticRegression',\n",
       "  'Ensemble_LogisticRegression_{target}_Stance_Texts_Timeline_BoF_test_results.csv'),\n",
       " ('Stacking Stance + Texts + Timeline + BoFr',\n",
       "  '-',\n",
       "  'LogisticRegression',\n",
       "  'Ensemble_LogisticRegression_{target}_Stance_Texts_Timeline_BoFr_test_results.csv'),\n",
       " ('Stacking Stance + Texts + BoM + BoF',\n",
       "  '-',\n",
       "  'LogisticRegression',\n",
       "  'Ensemble_LogisticRegression_{target}_Stance_Texts_BoM_BoF_test_results.csv'),\n",
       " ('Stacking Stance + Texts + BoM + BoFr',\n",
       "  '-',\n",
       "  'LogisticRegression',\n",
       "  'Ensemble_LogisticRegression_{target}_Stance_Texts_BoM_BoFr_test_results.csv'),\n",
       " ('Stacking Stance + Texts + BoF + BoFr',\n",
       "  '-',\n",
       "  'LogisticRegression',\n",
       "  'Ensemble_LogisticRegression_{target}_Stance_Texts_BoF_BoFr_test_results.csv'),\n",
       " ('Stacking Stance + Timeline + BoM + BoF',\n",
       "  '-',\n",
       "  'LogisticRegression',\n",
       "  'Ensemble_LogisticRegression_{target}_Stance_Timeline_BoM_BoF_test_results.csv'),\n",
       " ('Stacking Stance + Timeline + BoM + BoFr',\n",
       "  '-',\n",
       "  'LogisticRegression',\n",
       "  'Ensemble_LogisticRegression_{target}_Stance_Timeline_BoM_BoFr_test_results.csv'),\n",
       " ('Stacking Stance + Timeline + BoF + BoFr',\n",
       "  '-',\n",
       "  'LogisticRegression',\n",
       "  'Ensemble_LogisticRegression_{target}_Stance_Timeline_BoF_BoFr_test_results.csv'),\n",
       " ('Stacking Stance + BoM + BoF + BoFr',\n",
       "  '-',\n",
       "  'LogisticRegression',\n",
       "  'Ensemble_LogisticRegression_{target}_Stance_BoM_BoF_BoFr_test_results.csv'),\n",
       " ('Stacking Texts + Timeline + BoM + BoF',\n",
       "  '-',\n",
       "  'LogisticRegression',\n",
       "  'Ensemble_LogisticRegression_{target}_Texts_Timeline_BoM_BoF_test_results.csv'),\n",
       " ('Stacking Texts + Timeline + BoM + BoFr',\n",
       "  '-',\n",
       "  'LogisticRegression',\n",
       "  'Ensemble_LogisticRegression_{target}_Texts_Timeline_BoM_BoFr_test_results.csv'),\n",
       " ('Stacking Texts + Timeline + BoF + BoFr',\n",
       "  '-',\n",
       "  'LogisticRegression',\n",
       "  'Ensemble_LogisticRegression_{target}_Texts_Timeline_BoF_BoFr_test_results.csv'),\n",
       " ('Stacking Texts + BoM + BoF + BoFr',\n",
       "  '-',\n",
       "  'LogisticRegression',\n",
       "  'Ensemble_LogisticRegression_{target}_Texts_BoM_BoF_BoFr_test_results.csv'),\n",
       " ('Stacking Timeline + BoM + BoF + BoFr',\n",
       "  '-',\n",
       "  'LogisticRegression',\n",
       "  'Ensemble_LogisticRegression_{target}_Timeline_BoM_BoF_BoFr_test_results.csv'),\n",
       " ('Stacking Stance + Texts + Timeline + BoM + BoF',\n",
       "  '-',\n",
       "  'LogisticRegression',\n",
       "  'Ensemble_LogisticRegression_{target}_Stance_Texts_Timeline_BoM_BoF_test_results.csv'),\n",
       " ('Stacking Stance + Texts + Timeline + BoM + BoFr',\n",
       "  '-',\n",
       "  'LogisticRegression',\n",
       "  'Ensemble_LogisticRegression_{target}_Stance_Texts_Timeline_BoM_BoFr_test_results.csv'),\n",
       " ('Stacking Stance + Texts + Timeline + BoF + BoFr',\n",
       "  '-',\n",
       "  'LogisticRegression',\n",
       "  'Ensemble_LogisticRegression_{target}_Stance_Texts_Timeline_BoF_BoFr_test_results.csv'),\n",
       " ('Stacking Stance + Texts + BoM + BoF + BoFr',\n",
       "  '-',\n",
       "  'LogisticRegression',\n",
       "  'Ensemble_LogisticRegression_{target}_Stance_Texts_BoM_BoF_BoFr_test_results.csv'),\n",
       " ('Stacking Stance + Timeline + BoM + BoF + BoFr',\n",
       "  '-',\n",
       "  'LogisticRegression',\n",
       "  'Ensemble_LogisticRegression_{target}_Stance_Timeline_BoM_BoF_BoFr_test_results.csv'),\n",
       " ('Stacking Texts + Timeline + BoM + BoF + BoFr',\n",
       "  '-',\n",
       "  'LogisticRegression',\n",
       "  'Ensemble_LogisticRegression_{target}_Texts_Timeline_BoM_BoF_BoFr_test_results.csv'),\n",
       " ('Stacking Stance + Texts + Timeline + BoM + BoF + BoFr',\n",
       "  '-',\n",
       "  'LogisticRegression',\n",
       "  'Ensemble_LogisticRegression_{target}_Stance_Texts_Timeline_BoM_BoF_BoFr_test_results.csv')]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tuples_stacking_exps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "PATH_BEST_BoM = \"\"\n",
    "PATH_BEST_BoF = \"\"\n",
    "\n",
    "# (vectorizer,estimator, path_sring) \n",
    "results_tuples_stance = [\n",
    "    # Stance\n",
    "    (\"Stance\", \"-\" ,\"dummy\", \"DummyClassifier_{target}_users_Stance_test_results.csv\"),\n",
    "    (\"Stance\", \"tf-idf\" ,\"xgb\", \"XGBClassifier_TfidfVectorizer_{target}_users_Stance_test_results.csv\"),\n",
    "    (\"Stance\", \"bertabaporu-base\" ,\"xgb\", \"bertimbau_xgb_{target}_users_emb_Stance_test_results.csv\"),\n",
    "    (\"Stance\", \"-\" ,\"bertabaporu-base\", \"bert_classifier_pablocosta_bertabaporu_base_uncased_{target}_Stance_test_results.csv\"),\n",
    "    (\"Stance\", \"-\",  \"llama3:7b zero-shot\", \"llama3_{target}_Stance_prompt2_Stance_test_results.csv\"),\n",
    "    \n",
    "    # Texts\n",
    "    (\"Texts\", \"-\" ,\"dummy\", \"DummyClassifier_{target}_top_mentioned_timelines_Texts_test_results.csv\"),\n",
    "    (\"Texts\", \"tf-idf\" ,\"xgb\", \"XGBClassifier_TfidfVectorizer_{target}_top_mentioned_timelines_Texts_test_results.csv\"),\n",
    "    (\"Texts\", \"bertabaporu-base\" ,\"xgb\", \"bertimbau_xgb_{target}_top_mentioned_timelines_emb_Texts_test_results.csv\"),\n",
    "    (\"Texts\", \"-\" ,\"bertabaporu-base\", \"bert_classifier_pablocosta_bertabaporu_base_uncased_{target}_Texts_test_results.csv\"),\n",
    "    (\"Texts\", \"-\" ,\"bertabaporu-base (R)\", \"bert_classifier_pablocosta_bertabaporu_base_uncased_{target}_scored_Texts_test_results.csv\"),\n",
    "    (\"Texts\", \"-\", \"llama3:7b zero-shot [5] (R)\", \"llama3_{target}_filtered_Texts5_prompt2_Texts_test_results.csv\"),\n",
    "    (\"Texts\", \"-\", \"llama3:7b zero-shot [10] (R)\", \"llama3_{target}_filtered_Texts10_prompt2_Texts_test_results.csv\"),\n",
    "    (\"Texts\", \"-\", \"llama3:7b zero-shot [15] (R)\", \"llama3_{target}_filtered_Texts15_prompt2_Texts_test_results.csv\"),\n",
    "    \n",
    "    # Timeline\n",
    "    (\"Timeline\", \"-\" ,\"dummy\", \"DummyClassifier_{target}_users_Timeline_test_results.csv\"),\n",
    "    (\"Timeline\", \"tf-idf\" ,\"xgb\", \"XGBClassifier_TfidfVectorizer_{target}_users_Timeline_test_results.csv\"),\n",
    "    (\"Timeline\", \"bertabaporu-base\" ,\"xgb\", \"bertimbau_xgb_{target}_users_emb_Timeline_test_results.csv\"),\n",
    "    (\"Timeline\", \"-\" ,\"bertabaporu-base\", \"bert_classifier_pablocosta_bertabaporu_base_uncased_{target}_Timeline_test_results.csv\"),\n",
    "    (\"Timeline\", \"-\" ,\"bertabaporu-base (R)\", \"bert_classifier_pablocosta_bertabaporu_base_uncased_{target}_scored_Timeline_test_results.csv\"),\n",
    "    (\"Timeline\", \"-\", \"llama3:7b zero-shot [5] (R)\", \"llama3_{target}_filteredTimeline5_prompt2_Timeline_test_results.csv\"),\n",
    "    (\"Timeline\", \"-\", \"llama3:7b zero-shot [10] (R)\", \"llama3_{target}_filteredTimeline10_prompt2_Timeline_test_results.csv\"),\n",
    "    (\"Timeline\", \"-\", \"llama3:7b zero-shot [15] (R)\", \"llama3_{target}_filteredTimeline15_prompt2_Timeline_test_results.csv\"),\n",
    "    \n",
    "    # Bag of xxx\n",
    "    ('Bag of Friends', 'tf-idf', 'LogisticRegression', \"TfidfVectorizer_SelectKBest_LogisticRegression_{target}_BagOfFriends_test_results.csv\"),\n",
    "    ('Bag of Followers', 'tf-idf', 'LogisticRegression', \"TfidfVectorizer_SelectKBest_LogisticRegression_{target}_BagOfFollowers_test_results.csv\"),\n",
    "    ('Bag of Mentions', 'tf-idf', 'LogisticRegression', \"TfidfVectorizer_SelectKBest_LogisticRegression_{target}_BagOfMentions_test_results.csv\"),\n",
    "    \n",
    "    # Ensembles\n",
    "    # (\"Ensemble Texts + Timeline\", \"-\", \"LogisticRegression\", \"Ensemble_LogisticRegression_{target}_Texts_Timeline_test_results.csv\"),\n",
    "    # (\"Ensemble Texts + Stance\", \"-\", \"LogisticRegression\", \"Ensemble_LogisticRegression_{target}_Texts_Stance_test_results.csv\"),\n",
    "    # (\"Ensemble Stance + Timeline\", \"-\", \"LogisticRegression\", \"Ensemble_LogisticRegression_{target}_Stance_Timeline_test_results.csv\"),\n",
    "    # (\"Ensemble Stance + Timeline + Texts\", \"-\", \"LogisticRegression\", \"Ensemble_LogisticRegression_{target}_Stance_Timeline_Texts_test_results.csv\"),\n",
    "    (\"concat_Texts_Timeline\", \"tf-idf\", \"xgb\", \"XGBClassifier_TfidfVectorizer_{target}_concat_Texts_Timeline_concat_Texts_Timeline_test_results.csv\")\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_tuples_stance = results_tuples_stance + tuples_stacking_exps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Stance',\n",
       "  '-',\n",
       "  'dummy',\n",
       "  'DummyClassifier_{target}_users_Stance_test_results.csv'),\n",
       " ('Stance',\n",
       "  'tf-idf',\n",
       "  'xgb',\n",
       "  'XGBClassifier_TfidfVectorizer_{target}_users_Stance_test_results.csv'),\n",
       " ('Stance',\n",
       "  'bertabaporu-base',\n",
       "  'xgb',\n",
       "  'bertimbau_xgb_{target}_users_emb_Stance_test_results.csv'),\n",
       " ('Stance',\n",
       "  '-',\n",
       "  'bertabaporu-base',\n",
       "  'bert_classifier_pablocosta_bertabaporu_base_uncased_{target}_Stance_test_results.csv'),\n",
       " ('Stance',\n",
       "  '-',\n",
       "  'llama3:7b zero-shot',\n",
       "  'llama3_{target}_Stance_prompt2_Stance_test_results.csv'),\n",
       " ('Texts',\n",
       "  '-',\n",
       "  'dummy',\n",
       "  'DummyClassifier_{target}_top_mentioned_timelines_Texts_test_results.csv'),\n",
       " ('Texts',\n",
       "  'tf-idf',\n",
       "  'xgb',\n",
       "  'XGBClassifier_TfidfVectorizer_{target}_top_mentioned_timelines_Texts_test_results.csv'),\n",
       " ('Texts',\n",
       "  'bertabaporu-base',\n",
       "  'xgb',\n",
       "  'bertimbau_xgb_{target}_top_mentioned_timelines_emb_Texts_test_results.csv'),\n",
       " ('Texts',\n",
       "  '-',\n",
       "  'bertabaporu-base',\n",
       "  'bert_classifier_pablocosta_bertabaporu_base_uncased_{target}_Texts_test_results.csv'),\n",
       " ('Texts',\n",
       "  '-',\n",
       "  'bertabaporu-base (R)',\n",
       "  'bert_classifier_pablocosta_bertabaporu_base_uncased_{target}_scored_Texts_test_results.csv'),\n",
       " ('Texts',\n",
       "  '-',\n",
       "  'llama3:7b zero-shot [5] (R)',\n",
       "  'llama3_{target}_filtered_Texts5_prompt2_Texts_test_results.csv'),\n",
       " ('Texts',\n",
       "  '-',\n",
       "  'llama3:7b zero-shot [10] (R)',\n",
       "  'llama3_{target}_filtered_Texts10_prompt2_Texts_test_results.csv'),\n",
       " ('Texts',\n",
       "  '-',\n",
       "  'llama3:7b zero-shot [15] (R)',\n",
       "  'llama3_{target}_filtered_Texts15_prompt2_Texts_test_results.csv'),\n",
       " ('Timeline',\n",
       "  '-',\n",
       "  'dummy',\n",
       "  'DummyClassifier_{target}_users_Timeline_test_results.csv'),\n",
       " ('Timeline',\n",
       "  'tf-idf',\n",
       "  'xgb',\n",
       "  'XGBClassifier_TfidfVectorizer_{target}_users_Timeline_test_results.csv'),\n",
       " ('Timeline',\n",
       "  'bertabaporu-base',\n",
       "  'xgb',\n",
       "  'bertimbau_xgb_{target}_users_emb_Timeline_test_results.csv'),\n",
       " ('Timeline',\n",
       "  '-',\n",
       "  'bertabaporu-base',\n",
       "  'bert_classifier_pablocosta_bertabaporu_base_uncased_{target}_Timeline_test_results.csv'),\n",
       " ('Timeline',\n",
       "  '-',\n",
       "  'bertabaporu-base (R)',\n",
       "  'bert_classifier_pablocosta_bertabaporu_base_uncased_{target}_scored_Timeline_test_results.csv'),\n",
       " ('Timeline',\n",
       "  '-',\n",
       "  'llama3:7b zero-shot [5] (R)',\n",
       "  'llama3_{target}_filteredTimeline5_prompt2_Timeline_test_results.csv'),\n",
       " ('Timeline',\n",
       "  '-',\n",
       "  'llama3:7b zero-shot [10] (R)',\n",
       "  'llama3_{target}_filteredTimeline10_prompt2_Timeline_test_results.csv'),\n",
       " ('Timeline',\n",
       "  '-',\n",
       "  'llama3:7b zero-shot [15] (R)',\n",
       "  'llama3_{target}_filteredTimeline15_prompt2_Timeline_test_results.csv'),\n",
       " ('Bag of Friends',\n",
       "  'tf-idf',\n",
       "  'LogisticRegression',\n",
       "  'TfidfVectorizer_SelectKBest_LogisticRegression_{target}_BagOfFriends_test_results.csv'),\n",
       " ('Bag of Followers',\n",
       "  'tf-idf',\n",
       "  'LogisticRegression',\n",
       "  'TfidfVectorizer_SelectKBest_LogisticRegression_{target}_BagOfFollowers_test_results.csv'),\n",
       " ('Bag of Mentions',\n",
       "  'tf-idf',\n",
       "  'LogisticRegression',\n",
       "  'TfidfVectorizer_SelectKBest_LogisticRegression_{target}_BagOfMentions_test_results.csv'),\n",
       " ('concat_Texts_Timeline',\n",
       "  'tf-idf',\n",
       "  'xgb',\n",
       "  'XGBClassifier_TfidfVectorizer_{target}_concat_Texts_Timeline_concat_Texts_Timeline_test_results.csv'),\n",
       " ('Stacking Stance + Texts',\n",
       "  '-',\n",
       "  'LogisticRegression',\n",
       "  'Ensemble_LogisticRegression_{target}_Stance_Texts_test_results.csv'),\n",
       " ('Stacking Stance + Timeline',\n",
       "  '-',\n",
       "  'LogisticRegression',\n",
       "  'Ensemble_LogisticRegression_{target}_Stance_Timeline_test_results.csv'),\n",
       " ('Stacking Stance + BoM',\n",
       "  '-',\n",
       "  'LogisticRegression',\n",
       "  'Ensemble_LogisticRegression_{target}_Stance_BoM_test_results.csv'),\n",
       " ('Stacking Stance + BoF',\n",
       "  '-',\n",
       "  'LogisticRegression',\n",
       "  'Ensemble_LogisticRegression_{target}_Stance_BoF_test_results.csv'),\n",
       " ('Stacking Stance + BoFr',\n",
       "  '-',\n",
       "  'LogisticRegression',\n",
       "  'Ensemble_LogisticRegression_{target}_Stance_BoFr_test_results.csv'),\n",
       " ('Stacking Texts + Timeline',\n",
       "  '-',\n",
       "  'LogisticRegression',\n",
       "  'Ensemble_LogisticRegression_{target}_Texts_Timeline_test_results.csv'),\n",
       " ('Stacking Texts + BoM',\n",
       "  '-',\n",
       "  'LogisticRegression',\n",
       "  'Ensemble_LogisticRegression_{target}_Texts_BoM_test_results.csv'),\n",
       " ('Stacking Texts + BoF',\n",
       "  '-',\n",
       "  'LogisticRegression',\n",
       "  'Ensemble_LogisticRegression_{target}_Texts_BoF_test_results.csv'),\n",
       " ('Stacking Texts + BoFr',\n",
       "  '-',\n",
       "  'LogisticRegression',\n",
       "  'Ensemble_LogisticRegression_{target}_Texts_BoFr_test_results.csv'),\n",
       " ('Stacking Timeline + BoM',\n",
       "  '-',\n",
       "  'LogisticRegression',\n",
       "  'Ensemble_LogisticRegression_{target}_Timeline_BoM_test_results.csv'),\n",
       " ('Stacking Timeline + BoF',\n",
       "  '-',\n",
       "  'LogisticRegression',\n",
       "  'Ensemble_LogisticRegression_{target}_Timeline_BoF_test_results.csv'),\n",
       " ('Stacking Timeline + BoFr',\n",
       "  '-',\n",
       "  'LogisticRegression',\n",
       "  'Ensemble_LogisticRegression_{target}_Timeline_BoFr_test_results.csv'),\n",
       " ('Stacking BoM + BoF',\n",
       "  '-',\n",
       "  'LogisticRegression',\n",
       "  'Ensemble_LogisticRegression_{target}_BoM_BoF_test_results.csv'),\n",
       " ('Stacking BoM + BoFr',\n",
       "  '-',\n",
       "  'LogisticRegression',\n",
       "  'Ensemble_LogisticRegression_{target}_BoM_BoFr_test_results.csv'),\n",
       " ('Stacking BoF + BoFr',\n",
       "  '-',\n",
       "  'LogisticRegression',\n",
       "  'Ensemble_LogisticRegression_{target}_BoF_BoFr_test_results.csv'),\n",
       " ('Stacking Stance + Texts + Timeline',\n",
       "  '-',\n",
       "  'LogisticRegression',\n",
       "  'Ensemble_LogisticRegression_{target}_Stance_Texts_Timeline_test_results.csv'),\n",
       " ('Stacking Stance + Texts + BoM',\n",
       "  '-',\n",
       "  'LogisticRegression',\n",
       "  'Ensemble_LogisticRegression_{target}_Stance_Texts_BoM_test_results.csv'),\n",
       " ('Stacking Stance + Texts + BoF',\n",
       "  '-',\n",
       "  'LogisticRegression',\n",
       "  'Ensemble_LogisticRegression_{target}_Stance_Texts_BoF_test_results.csv'),\n",
       " ('Stacking Stance + Texts + BoFr',\n",
       "  '-',\n",
       "  'LogisticRegression',\n",
       "  'Ensemble_LogisticRegression_{target}_Stance_Texts_BoFr_test_results.csv'),\n",
       " ('Stacking Stance + Timeline + BoM',\n",
       "  '-',\n",
       "  'LogisticRegression',\n",
       "  'Ensemble_LogisticRegression_{target}_Stance_Timeline_BoM_test_results.csv'),\n",
       " ('Stacking Stance + Timeline + BoF',\n",
       "  '-',\n",
       "  'LogisticRegression',\n",
       "  'Ensemble_LogisticRegression_{target}_Stance_Timeline_BoF_test_results.csv'),\n",
       " ('Stacking Stance + Timeline + BoFr',\n",
       "  '-',\n",
       "  'LogisticRegression',\n",
       "  'Ensemble_LogisticRegression_{target}_Stance_Timeline_BoFr_test_results.csv'),\n",
       " ('Stacking Stance + BoM + BoF',\n",
       "  '-',\n",
       "  'LogisticRegression',\n",
       "  'Ensemble_LogisticRegression_{target}_Stance_BoM_BoF_test_results.csv'),\n",
       " ('Stacking Stance + BoM + BoFr',\n",
       "  '-',\n",
       "  'LogisticRegression',\n",
       "  'Ensemble_LogisticRegression_{target}_Stance_BoM_BoFr_test_results.csv'),\n",
       " ('Stacking Stance + BoF + BoFr',\n",
       "  '-',\n",
       "  'LogisticRegression',\n",
       "  'Ensemble_LogisticRegression_{target}_Stance_BoF_BoFr_test_results.csv'),\n",
       " ('Stacking Texts + Timeline + BoM',\n",
       "  '-',\n",
       "  'LogisticRegression',\n",
       "  'Ensemble_LogisticRegression_{target}_Texts_Timeline_BoM_test_results.csv'),\n",
       " ('Stacking Texts + Timeline + BoF',\n",
       "  '-',\n",
       "  'LogisticRegression',\n",
       "  'Ensemble_LogisticRegression_{target}_Texts_Timeline_BoF_test_results.csv'),\n",
       " ('Stacking Texts + Timeline + BoFr',\n",
       "  '-',\n",
       "  'LogisticRegression',\n",
       "  'Ensemble_LogisticRegression_{target}_Texts_Timeline_BoFr_test_results.csv'),\n",
       " ('Stacking Texts + BoM + BoF',\n",
       "  '-',\n",
       "  'LogisticRegression',\n",
       "  'Ensemble_LogisticRegression_{target}_Texts_BoM_BoF_test_results.csv'),\n",
       " ('Stacking Texts + BoM + BoFr',\n",
       "  '-',\n",
       "  'LogisticRegression',\n",
       "  'Ensemble_LogisticRegression_{target}_Texts_BoM_BoFr_test_results.csv'),\n",
       " ('Stacking Texts + BoF + BoFr',\n",
       "  '-',\n",
       "  'LogisticRegression',\n",
       "  'Ensemble_LogisticRegression_{target}_Texts_BoF_BoFr_test_results.csv'),\n",
       " ('Stacking Timeline + BoM + BoF',\n",
       "  '-',\n",
       "  'LogisticRegression',\n",
       "  'Ensemble_LogisticRegression_{target}_Timeline_BoM_BoF_test_results.csv'),\n",
       " ('Stacking Timeline + BoM + BoFr',\n",
       "  '-',\n",
       "  'LogisticRegression',\n",
       "  'Ensemble_LogisticRegression_{target}_Timeline_BoM_BoFr_test_results.csv'),\n",
       " ('Stacking Timeline + BoF + BoFr',\n",
       "  '-',\n",
       "  'LogisticRegression',\n",
       "  'Ensemble_LogisticRegression_{target}_Timeline_BoF_BoFr_test_results.csv'),\n",
       " ('Stacking BoM + BoF + BoFr',\n",
       "  '-',\n",
       "  'LogisticRegression',\n",
       "  'Ensemble_LogisticRegression_{target}_BoM_BoF_BoFr_test_results.csv'),\n",
       " ('Stacking Stance + Texts + Timeline + BoM',\n",
       "  '-',\n",
       "  'LogisticRegression',\n",
       "  'Ensemble_LogisticRegression_{target}_Stance_Texts_Timeline_BoM_test_results.csv'),\n",
       " ('Stacking Stance + Texts + Timeline + BoF',\n",
       "  '-',\n",
       "  'LogisticRegression',\n",
       "  'Ensemble_LogisticRegression_{target}_Stance_Texts_Timeline_BoF_test_results.csv'),\n",
       " ('Stacking Stance + Texts + Timeline + BoFr',\n",
       "  '-',\n",
       "  'LogisticRegression',\n",
       "  'Ensemble_LogisticRegression_{target}_Stance_Texts_Timeline_BoFr_test_results.csv'),\n",
       " ('Stacking Stance + Texts + BoM + BoF',\n",
       "  '-',\n",
       "  'LogisticRegression',\n",
       "  'Ensemble_LogisticRegression_{target}_Stance_Texts_BoM_BoF_test_results.csv'),\n",
       " ('Stacking Stance + Texts + BoM + BoFr',\n",
       "  '-',\n",
       "  'LogisticRegression',\n",
       "  'Ensemble_LogisticRegression_{target}_Stance_Texts_BoM_BoFr_test_results.csv'),\n",
       " ('Stacking Stance + Texts + BoF + BoFr',\n",
       "  '-',\n",
       "  'LogisticRegression',\n",
       "  'Ensemble_LogisticRegression_{target}_Stance_Texts_BoF_BoFr_test_results.csv'),\n",
       " ('Stacking Stance + Timeline + BoM + BoF',\n",
       "  '-',\n",
       "  'LogisticRegression',\n",
       "  'Ensemble_LogisticRegression_{target}_Stance_Timeline_BoM_BoF_test_results.csv'),\n",
       " ('Stacking Stance + Timeline + BoM + BoFr',\n",
       "  '-',\n",
       "  'LogisticRegression',\n",
       "  'Ensemble_LogisticRegression_{target}_Stance_Timeline_BoM_BoFr_test_results.csv'),\n",
       " ('Stacking Stance + Timeline + BoF + BoFr',\n",
       "  '-',\n",
       "  'LogisticRegression',\n",
       "  'Ensemble_LogisticRegression_{target}_Stance_Timeline_BoF_BoFr_test_results.csv'),\n",
       " ('Stacking Stance + BoM + BoF + BoFr',\n",
       "  '-',\n",
       "  'LogisticRegression',\n",
       "  'Ensemble_LogisticRegression_{target}_Stance_BoM_BoF_BoFr_test_results.csv'),\n",
       " ('Stacking Texts + Timeline + BoM + BoF',\n",
       "  '-',\n",
       "  'LogisticRegression',\n",
       "  'Ensemble_LogisticRegression_{target}_Texts_Timeline_BoM_BoF_test_results.csv'),\n",
       " ('Stacking Texts + Timeline + BoM + BoFr',\n",
       "  '-',\n",
       "  'LogisticRegression',\n",
       "  'Ensemble_LogisticRegression_{target}_Texts_Timeline_BoM_BoFr_test_results.csv'),\n",
       " ('Stacking Texts + Timeline + BoF + BoFr',\n",
       "  '-',\n",
       "  'LogisticRegression',\n",
       "  'Ensemble_LogisticRegression_{target}_Texts_Timeline_BoF_BoFr_test_results.csv'),\n",
       " ('Stacking Texts + BoM + BoF + BoFr',\n",
       "  '-',\n",
       "  'LogisticRegression',\n",
       "  'Ensemble_LogisticRegression_{target}_Texts_BoM_BoF_BoFr_test_results.csv'),\n",
       " ('Stacking Timeline + BoM + BoF + BoFr',\n",
       "  '-',\n",
       "  'LogisticRegression',\n",
       "  'Ensemble_LogisticRegression_{target}_Timeline_BoM_BoF_BoFr_test_results.csv'),\n",
       " ('Stacking Stance + Texts + Timeline + BoM + BoF',\n",
       "  '-',\n",
       "  'LogisticRegression',\n",
       "  'Ensemble_LogisticRegression_{target}_Stance_Texts_Timeline_BoM_BoF_test_results.csv'),\n",
       " ('Stacking Stance + Texts + Timeline + BoM + BoFr',\n",
       "  '-',\n",
       "  'LogisticRegression',\n",
       "  'Ensemble_LogisticRegression_{target}_Stance_Texts_Timeline_BoM_BoFr_test_results.csv'),\n",
       " ('Stacking Stance + Texts + Timeline + BoF + BoFr',\n",
       "  '-',\n",
       "  'LogisticRegression',\n",
       "  'Ensemble_LogisticRegression_{target}_Stance_Texts_Timeline_BoF_BoFr_test_results.csv'),\n",
       " ('Stacking Stance + Texts + BoM + BoF + BoFr',\n",
       "  '-',\n",
       "  'LogisticRegression',\n",
       "  'Ensemble_LogisticRegression_{target}_Stance_Texts_BoM_BoF_BoFr_test_results.csv'),\n",
       " ('Stacking Stance + Timeline + BoM + BoF + BoFr',\n",
       "  '-',\n",
       "  'LogisticRegression',\n",
       "  'Ensemble_LogisticRegression_{target}_Stance_Timeline_BoM_BoF_BoFr_test_results.csv'),\n",
       " ('Stacking Texts + Timeline + BoM + BoF + BoFr',\n",
       "  '-',\n",
       "  'LogisticRegression',\n",
       "  'Ensemble_LogisticRegression_{target}_Texts_Timeline_BoM_BoF_BoFr_test_results.csv'),\n",
       " ('Stacking Stance + Texts + Timeline + BoM + BoF + BoFr',\n",
       "  '-',\n",
       "  'LogisticRegression',\n",
       "  'Ensemble_LogisticRegression_{target}_Stance_Texts_Timeline_BoM_BoF_BoFr_test_results.csv')]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_tuples_stance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "list_results = []\n",
    "for text_col, vectorizer, estimator, path_results in results_tuples_stance:\n",
    "    \n",
    "    list_cr = []\n",
    "    \n",
    "    for target in target_list:\n",
    "        \n",
    "        \n",
    "        path = test_results_path + path_results.format(target = target)\n",
    "        df_results = pd.read_csv(path)\n",
    "        df_results_or = df_results.copy()\n",
    "        \n",
    "        # get classification report df\n",
    "        df_classification_report = get_classification_report(df_results.test, df_results.pred, cr_args = {})\n",
    "        \n",
    "        # create multindex\n",
    "        column_indexes = [(metric,dict_cp[target]) for metric in df_classification_report.columns]\n",
    "        multi_index_cols = pd.MultiIndex.from_tuples(column_indexes, names=['metric', 'target'])\n",
    "        rows_indexes = [(text_col, vectorizer, estimator, cl) for cl in df_classification_report.index]\n",
    "        multi_index_rows = pd.MultiIndex.from_tuples(rows_indexes, names=['text_col','vectorizer', 'estimator', 'class'])\n",
    "        df_classification_report.columns = multi_index_cols\n",
    "        df_classification_report.index = multi_index_rows\n",
    "        \n",
    "        # print(text_col, vectorizer, estimator,target)\n",
    "        # print(path)\n",
    "        # display(df_classification_report)\n",
    "        \n",
    "        list_cr.append(df_classification_report)\n",
    "        \n",
    "    df_results = pd.concat(list_cr, axis = 1)\n",
    "    \n",
    "    list_results.append(df_results)\n",
    "    \n",
    "df_results_final = pd.concat(list_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>metric</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>...</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>Church</th>\n",
       "      <th>Church</th>\n",
       "      <th>Church</th>\n",
       "      <th>Church</th>\n",
       "      <th>Bolsonaro</th>\n",
       "      <th>Bolsonaro</th>\n",
       "      <th>Bolsonaro</th>\n",
       "      <th>Bolsonaro</th>\n",
       "      <th>Hydrox.</th>\n",
       "      <th>Hydrox.</th>\n",
       "      <th>...</th>\n",
       "      <th>Sinovac</th>\n",
       "      <th>Sinovac</th>\n",
       "      <th>Globo TV</th>\n",
       "      <th>Globo TV</th>\n",
       "      <th>Globo TV</th>\n",
       "      <th>Globo TV</th>\n",
       "      <th>Lula</th>\n",
       "      <th>Lula</th>\n",
       "      <th>Lula</th>\n",
       "      <th>Lula</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text_col</th>\n",
       "      <th>vectorizer</th>\n",
       "      <th>estimator</th>\n",
       "      <th>class</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">Stance</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">-</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">dummy</th>\n",
       "      <th>against</th>\n",
       "      <td>0.565943</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.722814</td>\n",
       "      <td>339.000000</td>\n",
       "      <td>0.861702</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.925714</td>\n",
       "      <td>162.000000</td>\n",
       "      <td>0.503484</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>354.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>167.000000</td>\n",
       "      <td>0.525735</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.689157</td>\n",
       "      <td>143.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.565943</td>\n",
       "      <td>0.565943</td>\n",
       "      <td>0.565943</td>\n",
       "      <td>0.565943</td>\n",
       "      <td>0.861702</td>\n",
       "      <td>0.861702</td>\n",
       "      <td>0.861702</td>\n",
       "      <td>0.861702</td>\n",
       "      <td>0.503484</td>\n",
       "      <td>0.503484</td>\n",
       "      <td>...</td>\n",
       "      <td>0.542636</td>\n",
       "      <td>0.542636</td>\n",
       "      <td>0.593674</td>\n",
       "      <td>0.593674</td>\n",
       "      <td>0.593674</td>\n",
       "      <td>0.593674</td>\n",
       "      <td>0.525735</td>\n",
       "      <td>0.525735</td>\n",
       "      <td>0.525735</td>\n",
       "      <td>0.525735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.320292</td>\n",
       "      <td>0.565943</td>\n",
       "      <td>0.409072</td>\n",
       "      <td>599.000000</td>\n",
       "      <td>0.742531</td>\n",
       "      <td>0.861702</td>\n",
       "      <td>0.797690</td>\n",
       "      <td>188.000000</td>\n",
       "      <td>0.253496</td>\n",
       "      <td>0.503484</td>\n",
       "      <td>...</td>\n",
       "      <td>0.381754</td>\n",
       "      <td>774.000000</td>\n",
       "      <td>0.352449</td>\n",
       "      <td>0.593674</td>\n",
       "      <td>0.442310</td>\n",
       "      <td>411.000000</td>\n",
       "      <td>0.276398</td>\n",
       "      <td>0.525735</td>\n",
       "      <td>0.362314</td>\n",
       "      <td>272.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.282972</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.361407</td>\n",
       "      <td>599.000000</td>\n",
       "      <td>0.430851</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.462857</td>\n",
       "      <td>188.000000</td>\n",
       "      <td>0.251742</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.351759</td>\n",
       "      <td>774.000000</td>\n",
       "      <td>0.296837</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.372519</td>\n",
       "      <td>411.000000</td>\n",
       "      <td>0.262868</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.344578</td>\n",
       "      <td>272.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>for</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>260.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.703518</td>\n",
       "      <td>420.000000</td>\n",
       "      <td>0.593674</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.745038</td>\n",
       "      <td>244.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>129.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">Stacking Stance + Texts + Timeline + BoM + BoF + BoFr</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">-</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">LogisticRegression</th>\n",
       "      <th>against</th>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.787611</td>\n",
       "      <td>0.768345</td>\n",
       "      <td>339.000000</td>\n",
       "      <td>0.913793</td>\n",
       "      <td>0.981481</td>\n",
       "      <td>0.946429</td>\n",
       "      <td>162.000000</td>\n",
       "      <td>0.889680</td>\n",
       "      <td>0.865052</td>\n",
       "      <td>...</td>\n",
       "      <td>0.828528</td>\n",
       "      <td>354.000000</td>\n",
       "      <td>0.647619</td>\n",
       "      <td>0.407186</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>167.000000</td>\n",
       "      <td>0.767606</td>\n",
       "      <td>0.762238</td>\n",
       "      <td>0.764912</td>\n",
       "      <td>143.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.731219</td>\n",
       "      <td>0.731219</td>\n",
       "      <td>0.731219</td>\n",
       "      <td>0.731219</td>\n",
       "      <td>0.904255</td>\n",
       "      <td>0.904255</td>\n",
       "      <td>0.904255</td>\n",
       "      <td>0.904255</td>\n",
       "      <td>0.878049</td>\n",
       "      <td>0.878049</td>\n",
       "      <td>...</td>\n",
       "      <td>0.854005</td>\n",
       "      <td>0.854005</td>\n",
       "      <td>0.669100</td>\n",
       "      <td>0.669100</td>\n",
       "      <td>0.669100</td>\n",
       "      <td>0.669100</td>\n",
       "      <td>0.753676</td>\n",
       "      <td>0.753676</td>\n",
       "      <td>0.753676</td>\n",
       "      <td>0.753676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.729905</td>\n",
       "      <td>0.731219</td>\n",
       "      <td>0.729964</td>\n",
       "      <td>599.000000</td>\n",
       "      <td>0.896080</td>\n",
       "      <td>0.904255</td>\n",
       "      <td>0.891603</td>\n",
       "      <td>188.000000</td>\n",
       "      <td>0.878366</td>\n",
       "      <td>0.878049</td>\n",
       "      <td>...</td>\n",
       "      <td>0.852601</td>\n",
       "      <td>774.000000</td>\n",
       "      <td>0.664747</td>\n",
       "      <td>0.669100</td>\n",
       "      <td>0.650038</td>\n",
       "      <td>411.000000</td>\n",
       "      <td>0.753784</td>\n",
       "      <td>0.753676</td>\n",
       "      <td>0.753720</td>\n",
       "      <td>272.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.726852</td>\n",
       "      <td>0.722651</td>\n",
       "      <td>0.724133</td>\n",
       "      <td>599.000000</td>\n",
       "      <td>0.849754</td>\n",
       "      <td>0.702279</td>\n",
       "      <td>0.748214</td>\n",
       "      <td>188.000000</td>\n",
       "      <td>0.878287</td>\n",
       "      <td>0.878140</td>\n",
       "      <td>...</td>\n",
       "      <td>0.850709</td>\n",
       "      <td>774.000000</td>\n",
       "      <td>0.662045</td>\n",
       "      <td>0.627773</td>\n",
       "      <td>0.626364</td>\n",
       "      <td>411.000000</td>\n",
       "      <td>0.753034</td>\n",
       "      <td>0.753212</td>\n",
       "      <td>0.753113</td>\n",
       "      <td>272.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>for</th>\n",
       "      <td>0.703704</td>\n",
       "      <td>0.657692</td>\n",
       "      <td>0.679920</td>\n",
       "      <td>260.000000</td>\n",
       "      <td>0.785714</td>\n",
       "      <td>0.423077</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>0.866894</td>\n",
       "      <td>0.891228</td>\n",
       "      <td>...</td>\n",
       "      <td>0.872891</td>\n",
       "      <td>420.000000</td>\n",
       "      <td>0.676471</td>\n",
       "      <td>0.848361</td>\n",
       "      <td>0.752727</td>\n",
       "      <td>244.000000</td>\n",
       "      <td>0.738462</td>\n",
       "      <td>0.744186</td>\n",
       "      <td>0.741313</td>\n",
       "      <td>129.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>410 rows  24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "metric                                                                                        precision  \\\n",
       "target                                                                                           Church   \n",
       "text_col                                           vectorizer estimator          class                    \n",
       "Stance                                             -          dummy              against       0.565943   \n",
       "                                                                                 accuracy      0.565943   \n",
       "                                                                                 weighted avg  0.320292   \n",
       "                                                                                 macro avg     0.282972   \n",
       "                                                                                 for           0.000000   \n",
       "...                                                                                                 ...   \n",
       "Stacking Stance + Texts + Timeline + BoM + BoF ... -          LogisticRegression against       0.750000   \n",
       "                                                                                 accuracy      0.731219   \n",
       "                                                                                 weighted avg  0.729905   \n",
       "                                                                                 macro avg     0.726852   \n",
       "                                                                                 for           0.703704   \n",
       "\n",
       "metric                                                                                           recall  \\\n",
       "target                                                                                           Church   \n",
       "text_col                                           vectorizer estimator          class                    \n",
       "Stance                                             -          dummy              against       1.000000   \n",
       "                                                                                 accuracy      0.565943   \n",
       "                                                                                 weighted avg  0.565943   \n",
       "                                                                                 macro avg     0.500000   \n",
       "                                                                                 for           0.000000   \n",
       "...                                                                                                 ...   \n",
       "Stacking Stance + Texts + Timeline + BoM + BoF ... -          LogisticRegression against       0.787611   \n",
       "                                                                                 accuracy      0.731219   \n",
       "                                                                                 weighted avg  0.731219   \n",
       "                                                                                 macro avg     0.722651   \n",
       "                                                                                 for           0.657692   \n",
       "\n",
       "metric                                                                                         f1-score  \\\n",
       "target                                                                                           Church   \n",
       "text_col                                           vectorizer estimator          class                    \n",
       "Stance                                             -          dummy              against       0.722814   \n",
       "                                                                                 accuracy      0.565943   \n",
       "                                                                                 weighted avg  0.409072   \n",
       "                                                                                 macro avg     0.361407   \n",
       "                                                                                 for           0.000000   \n",
       "...                                                                                                 ...   \n",
       "Stacking Stance + Texts + Timeline + BoM + BoF ... -          LogisticRegression against       0.768345   \n",
       "                                                                                 accuracy      0.731219   \n",
       "                                                                                 weighted avg  0.729964   \n",
       "                                                                                 macro avg     0.724133   \n",
       "                                                                                 for           0.679920   \n",
       "\n",
       "metric                                                                                            support  \\\n",
       "target                                                                                             Church   \n",
       "text_col                                           vectorizer estimator          class                      \n",
       "Stance                                             -          dummy              against       339.000000   \n",
       "                                                                                 accuracy        0.565943   \n",
       "                                                                                 weighted avg  599.000000   \n",
       "                                                                                 macro avg     599.000000   \n",
       "                                                                                 for           260.000000   \n",
       "...                                                                                                   ...   \n",
       "Stacking Stance + Texts + Timeline + BoM + BoF ... -          LogisticRegression against       339.000000   \n",
       "                                                                                 accuracy        0.731219   \n",
       "                                                                                 weighted avg  599.000000   \n",
       "                                                                                 macro avg     599.000000   \n",
       "                                                                                 for           260.000000   \n",
       "\n",
       "metric                                                                                        precision  \\\n",
       "target                                                                                        Bolsonaro   \n",
       "text_col                                           vectorizer estimator          class                    \n",
       "Stance                                             -          dummy              against       0.861702   \n",
       "                                                                                 accuracy      0.861702   \n",
       "                                                                                 weighted avg  0.742531   \n",
       "                                                                                 macro avg     0.430851   \n",
       "                                                                                 for           0.000000   \n",
       "...                                                                                                 ...   \n",
       "Stacking Stance + Texts + Timeline + BoM + BoF ... -          LogisticRegression against       0.913793   \n",
       "                                                                                 accuracy      0.904255   \n",
       "                                                                                 weighted avg  0.896080   \n",
       "                                                                                 macro avg     0.849754   \n",
       "                                                                                 for           0.785714   \n",
       "\n",
       "metric                                                                                           recall  \\\n",
       "target                                                                                        Bolsonaro   \n",
       "text_col                                           vectorizer estimator          class                    \n",
       "Stance                                             -          dummy              against       1.000000   \n",
       "                                                                                 accuracy      0.861702   \n",
       "                                                                                 weighted avg  0.861702   \n",
       "                                                                                 macro avg     0.500000   \n",
       "                                                                                 for           0.000000   \n",
       "...                                                                                                 ...   \n",
       "Stacking Stance + Texts + Timeline + BoM + BoF ... -          LogisticRegression against       0.981481   \n",
       "                                                                                 accuracy      0.904255   \n",
       "                                                                                 weighted avg  0.904255   \n",
       "                                                                                 macro avg     0.702279   \n",
       "                                                                                 for           0.423077   \n",
       "\n",
       "metric                                                                                         f1-score  \\\n",
       "target                                                                                        Bolsonaro   \n",
       "text_col                                           vectorizer estimator          class                    \n",
       "Stance                                             -          dummy              against       0.925714   \n",
       "                                                                                 accuracy      0.861702   \n",
       "                                                                                 weighted avg  0.797690   \n",
       "                                                                                 macro avg     0.462857   \n",
       "                                                                                 for           0.000000   \n",
       "...                                                                                                 ...   \n",
       "Stacking Stance + Texts + Timeline + BoM + BoF ... -          LogisticRegression against       0.946429   \n",
       "                                                                                 accuracy      0.904255   \n",
       "                                                                                 weighted avg  0.891603   \n",
       "                                                                                 macro avg     0.748214   \n",
       "                                                                                 for           0.550000   \n",
       "\n",
       "metric                                                                                            support  \\\n",
       "target                                                                                          Bolsonaro   \n",
       "text_col                                           vectorizer estimator          class                      \n",
       "Stance                                             -          dummy              against       162.000000   \n",
       "                                                                                 accuracy        0.861702   \n",
       "                                                                                 weighted avg  188.000000   \n",
       "                                                                                 macro avg     188.000000   \n",
       "                                                                                 for            26.000000   \n",
       "...                                                                                                   ...   \n",
       "Stacking Stance + Texts + Timeline + BoM + BoF ... -          LogisticRegression against       162.000000   \n",
       "                                                                                 accuracy        0.904255   \n",
       "                                                                                 weighted avg  188.000000   \n",
       "                                                                                 macro avg     188.000000   \n",
       "                                                                                 for            26.000000   \n",
       "\n",
       "metric                                                                                        precision  \\\n",
       "target                                                                                          Hydrox.   \n",
       "text_col                                           vectorizer estimator          class                    \n",
       "Stance                                             -          dummy              against       0.503484   \n",
       "                                                                                 accuracy      0.503484   \n",
       "                                                                                 weighted avg  0.253496   \n",
       "                                                                                 macro avg     0.251742   \n",
       "                                                                                 for           0.000000   \n",
       "...                                                                                                 ...   \n",
       "Stacking Stance + Texts + Timeline + BoM + BoF ... -          LogisticRegression against       0.889680   \n",
       "                                                                                 accuracy      0.878049   \n",
       "                                                                                 weighted avg  0.878366   \n",
       "                                                                                 macro avg     0.878287   \n",
       "                                                                                 for           0.866894   \n",
       "\n",
       "metric                                                                                           recall  \\\n",
       "target                                                                                          Hydrox.   \n",
       "text_col                                           vectorizer estimator          class                    \n",
       "Stance                                             -          dummy              against       1.000000   \n",
       "                                                                                 accuracy      0.503484   \n",
       "                                                                                 weighted avg  0.503484   \n",
       "                                                                                 macro avg     0.500000   \n",
       "                                                                                 for           0.000000   \n",
       "...                                                                                                 ...   \n",
       "Stacking Stance + Texts + Timeline + BoM + BoF ... -          LogisticRegression against       0.865052   \n",
       "                                                                                 accuracy      0.878049   \n",
       "                                                                                 weighted avg  0.878049   \n",
       "                                                                                 macro avg     0.878140   \n",
       "                                                                                 for           0.891228   \n",
       "\n",
       "metric                                                                                         ...  \\\n",
       "target                                                                                         ...   \n",
       "text_col                                           vectorizer estimator          class         ...   \n",
       "Stance                                             -          dummy              against       ...   \n",
       "                                                                                 accuracy      ...   \n",
       "                                                                                 weighted avg  ...   \n",
       "                                                                                 macro avg     ...   \n",
       "                                                                                 for           ...   \n",
       "...                                                                                            ...   \n",
       "Stacking Stance + Texts + Timeline + BoM + BoF ... -          LogisticRegression against       ...   \n",
       "                                                                                 accuracy      ...   \n",
       "                                                                                 weighted avg  ...   \n",
       "                                                                                 macro avg     ...   \n",
       "                                                                                 for           ...   \n",
       "\n",
       "metric                                                                                         f1-score  \\\n",
       "target                                                                                          Sinovac   \n",
       "text_col                                           vectorizer estimator          class                    \n",
       "Stance                                             -          dummy              against       0.000000   \n",
       "                                                                                 accuracy      0.542636   \n",
       "                                                                                 weighted avg  0.381754   \n",
       "                                                                                 macro avg     0.351759   \n",
       "                                                                                 for           0.703518   \n",
       "...                                                                                                 ...   \n",
       "Stacking Stance + Texts + Timeline + BoM + BoF ... -          LogisticRegression against       0.828528   \n",
       "                                                                                 accuracy      0.854005   \n",
       "                                                                                 weighted avg  0.852601   \n",
       "                                                                                 macro avg     0.850709   \n",
       "                                                                                 for           0.872891   \n",
       "\n",
       "metric                                                                                            support  \\\n",
       "target                                                                                            Sinovac   \n",
       "text_col                                           vectorizer estimator          class                      \n",
       "Stance                                             -          dummy              against       354.000000   \n",
       "                                                                                 accuracy        0.542636   \n",
       "                                                                                 weighted avg  774.000000   \n",
       "                                                                                 macro avg     774.000000   \n",
       "                                                                                 for           420.000000   \n",
       "...                                                                                                   ...   \n",
       "Stacking Stance + Texts + Timeline + BoM + BoF ... -          LogisticRegression against       354.000000   \n",
       "                                                                                 accuracy        0.854005   \n",
       "                                                                                 weighted avg  774.000000   \n",
       "                                                                                 macro avg     774.000000   \n",
       "                                                                                 for           420.000000   \n",
       "\n",
       "metric                                                                                        precision  \\\n",
       "target                                                                                         Globo TV   \n",
       "text_col                                           vectorizer estimator          class                    \n",
       "Stance                                             -          dummy              against       0.000000   \n",
       "                                                                                 accuracy      0.593674   \n",
       "                                                                                 weighted avg  0.352449   \n",
       "                                                                                 macro avg     0.296837   \n",
       "                                                                                 for           0.593674   \n",
       "...                                                                                                 ...   \n",
       "Stacking Stance + Texts + Timeline + BoM + BoF ... -          LogisticRegression against       0.647619   \n",
       "                                                                                 accuracy      0.669100   \n",
       "                                                                                 weighted avg  0.664747   \n",
       "                                                                                 macro avg     0.662045   \n",
       "                                                                                 for           0.676471   \n",
       "\n",
       "metric                                                                                           recall  \\\n",
       "target                                                                                         Globo TV   \n",
       "text_col                                           vectorizer estimator          class                    \n",
       "Stance                                             -          dummy              against       0.000000   \n",
       "                                                                                 accuracy      0.593674   \n",
       "                                                                                 weighted avg  0.593674   \n",
       "                                                                                 macro avg     0.500000   \n",
       "                                                                                 for           1.000000   \n",
       "...                                                                                                 ...   \n",
       "Stacking Stance + Texts + Timeline + BoM + BoF ... -          LogisticRegression against       0.407186   \n",
       "                                                                                 accuracy      0.669100   \n",
       "                                                                                 weighted avg  0.669100   \n",
       "                                                                                 macro avg     0.627773   \n",
       "                                                                                 for           0.848361   \n",
       "\n",
       "metric                                                                                         f1-score  \\\n",
       "target                                                                                         Globo TV   \n",
       "text_col                                           vectorizer estimator          class                    \n",
       "Stance                                             -          dummy              against       0.000000   \n",
       "                                                                                 accuracy      0.593674   \n",
       "                                                                                 weighted avg  0.442310   \n",
       "                                                                                 macro avg     0.372519   \n",
       "                                                                                 for           0.745038   \n",
       "...                                                                                                 ...   \n",
       "Stacking Stance + Texts + Timeline + BoM + BoF ... -          LogisticRegression against       0.500000   \n",
       "                                                                                 accuracy      0.669100   \n",
       "                                                                                 weighted avg  0.650038   \n",
       "                                                                                 macro avg     0.626364   \n",
       "                                                                                 for           0.752727   \n",
       "\n",
       "metric                                                                                            support  \\\n",
       "target                                                                                           Globo TV   \n",
       "text_col                                           vectorizer estimator          class                      \n",
       "Stance                                             -          dummy              against       167.000000   \n",
       "                                                                                 accuracy        0.593674   \n",
       "                                                                                 weighted avg  411.000000   \n",
       "                                                                                 macro avg     411.000000   \n",
       "                                                                                 for           244.000000   \n",
       "...                                                                                                   ...   \n",
       "Stacking Stance + Texts + Timeline + BoM + BoF ... -          LogisticRegression against       167.000000   \n",
       "                                                                                 accuracy        0.669100   \n",
       "                                                                                 weighted avg  411.000000   \n",
       "                                                                                 macro avg     411.000000   \n",
       "                                                                                 for           244.000000   \n",
       "\n",
       "metric                                                                                        precision  \\\n",
       "target                                                                                             Lula   \n",
       "text_col                                           vectorizer estimator          class                    \n",
       "Stance                                             -          dummy              against       0.525735   \n",
       "                                                                                 accuracy      0.525735   \n",
       "                                                                                 weighted avg  0.276398   \n",
       "                                                                                 macro avg     0.262868   \n",
       "                                                                                 for           0.000000   \n",
       "...                                                                                                 ...   \n",
       "Stacking Stance + Texts + Timeline + BoM + BoF ... -          LogisticRegression against       0.767606   \n",
       "                                                                                 accuracy      0.753676   \n",
       "                                                                                 weighted avg  0.753784   \n",
       "                                                                                 macro avg     0.753034   \n",
       "                                                                                 for           0.738462   \n",
       "\n",
       "metric                                                                                           recall  \\\n",
       "target                                                                                             Lula   \n",
       "text_col                                           vectorizer estimator          class                    \n",
       "Stance                                             -          dummy              against       1.000000   \n",
       "                                                                                 accuracy      0.525735   \n",
       "                                                                                 weighted avg  0.525735   \n",
       "                                                                                 macro avg     0.500000   \n",
       "                                                                                 for           0.000000   \n",
       "...                                                                                                 ...   \n",
       "Stacking Stance + Texts + Timeline + BoM + BoF ... -          LogisticRegression against       0.762238   \n",
       "                                                                                 accuracy      0.753676   \n",
       "                                                                                 weighted avg  0.753676   \n",
       "                                                                                 macro avg     0.753212   \n",
       "                                                                                 for           0.744186   \n",
       "\n",
       "metric                                                                                         f1-score  \\\n",
       "target                                                                                             Lula   \n",
       "text_col                                           vectorizer estimator          class                    \n",
       "Stance                                             -          dummy              against       0.689157   \n",
       "                                                                                 accuracy      0.525735   \n",
       "                                                                                 weighted avg  0.362314   \n",
       "                                                                                 macro avg     0.344578   \n",
       "                                                                                 for           0.000000   \n",
       "...                                                                                                 ...   \n",
       "Stacking Stance + Texts + Timeline + BoM + BoF ... -          LogisticRegression against       0.764912   \n",
       "                                                                                 accuracy      0.753676   \n",
       "                                                                                 weighted avg  0.753720   \n",
       "                                                                                 macro avg     0.753113   \n",
       "                                                                                 for           0.741313   \n",
       "\n",
       "metric                                                                                            support  \n",
       "target                                                                                               Lula  \n",
       "text_col                                           vectorizer estimator          class                     \n",
       "Stance                                             -          dummy              against       143.000000  \n",
       "                                                                                 accuracy        0.525735  \n",
       "                                                                                 weighted avg  272.000000  \n",
       "                                                                                 macro avg     272.000000  \n",
       "                                                                                 for           129.000000  \n",
       "...                                                                                                   ...  \n",
       "Stacking Stance + Texts + Timeline + BoM + BoF ... -          LogisticRegression against       143.000000  \n",
       "                                                                                 accuracy        0.753676  \n",
       "                                                                                 weighted avg  272.000000  \n",
       "                                                                                 macro avg     272.000000  \n",
       "                                                                                 for           129.000000  \n",
       "\n",
       "[410 rows x 24 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results_final.to_excel(\"../reports/table_complete_results.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create table f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>metric</th>\n",
       "      <th colspan=\"7\" halign=\"left\">f1-score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>Church</th>\n",
       "      <th>Bolsonaro</th>\n",
       "      <th>Hydrox.</th>\n",
       "      <th>Sinovac</th>\n",
       "      <th>Globo TV</th>\n",
       "      <th>Lula</th>\n",
       "      <th>overall</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text_col</th>\n",
       "      <th>vectorizer</th>\n",
       "      <th>estimator</th>\n",
       "      <th>class</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">Stance</th>\n",
       "      <th>-</th>\n",
       "      <th>dummy</th>\n",
       "      <th>for</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.703518</td>\n",
       "      <td>0.745038</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.241426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tf-idf</th>\n",
       "      <th>xgb</th>\n",
       "      <th>for</th>\n",
       "      <td>0.654762</td>\n",
       "      <td>0.270270</td>\n",
       "      <td>0.719557</td>\n",
       "      <td>0.785877</td>\n",
       "      <td>0.758095</td>\n",
       "      <td>0.654412</td>\n",
       "      <td>0.640496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bertabaporu-base</th>\n",
       "      <th>xgb</th>\n",
       "      <th>for</th>\n",
       "      <td>0.824268</td>\n",
       "      <td>0.324324</td>\n",
       "      <td>0.827709</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.825911</td>\n",
       "      <td>0.749004</td>\n",
       "      <td>0.730758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">-</th>\n",
       "      <th>bertabaporu-base</th>\n",
       "      <th>for</th>\n",
       "      <td>0.844622</td>\n",
       "      <td>0.541667</td>\n",
       "      <td>0.854758</td>\n",
       "      <td>0.859076</td>\n",
       "      <td>0.882353</td>\n",
       "      <td>0.778210</td>\n",
       "      <td>0.793447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>llama3:7b zero-shot</th>\n",
       "      <th>for</th>\n",
       "      <td>0.734426</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>0.652101</td>\n",
       "      <td>0.625581</td>\n",
       "      <td>0.834286</td>\n",
       "      <td>0.743590</td>\n",
       "      <td>0.645950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Stacking Stance + Texts + Timeline + BoF + BoFr</th>\n",
       "      <th>-</th>\n",
       "      <th>LogisticRegression</th>\n",
       "      <th>for</th>\n",
       "      <td>0.677228</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>0.877375</td>\n",
       "      <td>0.872891</td>\n",
       "      <td>0.753199</td>\n",
       "      <td>0.736434</td>\n",
       "      <td>0.744521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Stacking Stance + Texts + BoM + BoF + BoFr</th>\n",
       "      <th>-</th>\n",
       "      <th>LogisticRegression</th>\n",
       "      <th>for</th>\n",
       "      <td>0.814953</td>\n",
       "      <td>0.604651</td>\n",
       "      <td>0.885764</td>\n",
       "      <td>0.879545</td>\n",
       "      <td>0.896000</td>\n",
       "      <td>0.796935</td>\n",
       "      <td>0.812975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Stacking Stance + Timeline + BoM + BoF + BoFr</th>\n",
       "      <th>-</th>\n",
       "      <th>LogisticRegression</th>\n",
       "      <th>for</th>\n",
       "      <td>0.734694</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>0.880416</td>\n",
       "      <td>0.868095</td>\n",
       "      <td>0.853333</td>\n",
       "      <td>0.789062</td>\n",
       "      <td>0.779267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Stacking Texts + Timeline + BoM + BoF + BoFr</th>\n",
       "      <th>-</th>\n",
       "      <th>LogisticRegression</th>\n",
       "      <th>for</th>\n",
       "      <td>0.650699</td>\n",
       "      <td>0.512821</td>\n",
       "      <td>0.880829</td>\n",
       "      <td>0.879910</td>\n",
       "      <td>0.723636</td>\n",
       "      <td>0.736434</td>\n",
       "      <td>0.730721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Stacking Stance + Texts + Timeline + BoM + BoF + BoFr</th>\n",
       "      <th>-</th>\n",
       "      <th>LogisticRegression</th>\n",
       "      <th>for</th>\n",
       "      <td>0.679920</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>0.878893</td>\n",
       "      <td>0.872891</td>\n",
       "      <td>0.752727</td>\n",
       "      <td>0.741313</td>\n",
       "      <td>0.745957</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>82 rows  7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "metric                                                                                         f1-score  \\\n",
       "target                                                                                           Church   \n",
       "text_col                                           vectorizer       estimator           class             \n",
       "Stance                                             -                dummy               for    0.000000   \n",
       "                                                   tf-idf           xgb                 for    0.654762   \n",
       "                                                   bertabaporu-base xgb                 for    0.824268   \n",
       "                                                   -                bertabaporu-base    for    0.844622   \n",
       "                                                                    llama3:7b zero-shot for    0.734426   \n",
       "...                                                                                                 ...   \n",
       "Stacking Stance + Texts + Timeline + BoF + BoFr    -                LogisticRegression  for    0.677228   \n",
       "Stacking Stance + Texts + BoM + BoF + BoFr         -                LogisticRegression  for    0.814953   \n",
       "Stacking Stance + Timeline + BoM + BoF + BoFr      -                LogisticRegression  for    0.734694   \n",
       "Stacking Texts + Timeline + BoM + BoF + BoFr       -                LogisticRegression  for    0.650699   \n",
       "Stacking Stance + Texts + Timeline + BoM + BoF ... -                LogisticRegression  for    0.679920   \n",
       "\n",
       "metric                                                                                                   \\\n",
       "target                                                                                        Bolsonaro   \n",
       "text_col                                           vectorizer       estimator           class             \n",
       "Stance                                             -                dummy               for    0.000000   \n",
       "                                                   tf-idf           xgb                 for    0.270270   \n",
       "                                                   bertabaporu-base xgb                 for    0.324324   \n",
       "                                                   -                bertabaporu-base    for    0.541667   \n",
       "                                                                    llama3:7b zero-shot for    0.285714   \n",
       "...                                                                                                 ...   \n",
       "Stacking Stance + Texts + Timeline + BoF + BoFr    -                LogisticRegression  for    0.550000   \n",
       "Stacking Stance + Texts + BoM + BoF + BoFr         -                LogisticRegression  for    0.604651   \n",
       "Stacking Stance + Timeline + BoM + BoF + BoFr      -                LogisticRegression  for    0.550000   \n",
       "Stacking Texts + Timeline + BoM + BoF + BoFr       -                LogisticRegression  for    0.512821   \n",
       "Stacking Stance + Texts + Timeline + BoM + BoF ... -                LogisticRegression  for    0.550000   \n",
       "\n",
       "metric                                                                                                   \\\n",
       "target                                                                                          Hydrox.   \n",
       "text_col                                           vectorizer       estimator           class             \n",
       "Stance                                             -                dummy               for    0.000000   \n",
       "                                                   tf-idf           xgb                 for    0.719557   \n",
       "                                                   bertabaporu-base xgb                 for    0.827709   \n",
       "                                                   -                bertabaporu-base    for    0.854758   \n",
       "                                                                    llama3:7b zero-shot for    0.652101   \n",
       "...                                                                                                 ...   \n",
       "Stacking Stance + Texts + Timeline + BoF + BoFr    -                LogisticRegression  for    0.877375   \n",
       "Stacking Stance + Texts + BoM + BoF + BoFr         -                LogisticRegression  for    0.885764   \n",
       "Stacking Stance + Timeline + BoM + BoF + BoFr      -                LogisticRegression  for    0.880416   \n",
       "Stacking Texts + Timeline + BoM + BoF + BoFr       -                LogisticRegression  for    0.880829   \n",
       "Stacking Stance + Texts + Timeline + BoM + BoF ... -                LogisticRegression  for    0.878893   \n",
       "\n",
       "metric                                                                                                   \\\n",
       "target                                                                                          Sinovac   \n",
       "text_col                                           vectorizer       estimator           class             \n",
       "Stance                                             -                dummy               for    0.703518   \n",
       "                                                   tf-idf           xgb                 for    0.785877   \n",
       "                                                   bertabaporu-base xgb                 for    0.833333   \n",
       "                                                   -                bertabaporu-base    for    0.859076   \n",
       "                                                                    llama3:7b zero-shot for    0.625581   \n",
       "...                                                                                                 ...   \n",
       "Stacking Stance + Texts + Timeline + BoF + BoFr    -                LogisticRegression  for    0.872891   \n",
       "Stacking Stance + Texts + BoM + BoF + BoFr         -                LogisticRegression  for    0.879545   \n",
       "Stacking Stance + Timeline + BoM + BoF + BoFr      -                LogisticRegression  for    0.868095   \n",
       "Stacking Texts + Timeline + BoM + BoF + BoFr       -                LogisticRegression  for    0.879910   \n",
       "Stacking Stance + Texts + Timeline + BoM + BoF ... -                LogisticRegression  for    0.872891   \n",
       "\n",
       "metric                                                                                                   \\\n",
       "target                                                                                         Globo TV   \n",
       "text_col                                           vectorizer       estimator           class             \n",
       "Stance                                             -                dummy               for    0.745038   \n",
       "                                                   tf-idf           xgb                 for    0.758095   \n",
       "                                                   bertabaporu-base xgb                 for    0.825911   \n",
       "                                                   -                bertabaporu-base    for    0.882353   \n",
       "                                                                    llama3:7b zero-shot for    0.834286   \n",
       "...                                                                                                 ...   \n",
       "Stacking Stance + Texts + Timeline + BoF + BoFr    -                LogisticRegression  for    0.753199   \n",
       "Stacking Stance + Texts + BoM + BoF + BoFr         -                LogisticRegression  for    0.896000   \n",
       "Stacking Stance + Timeline + BoM + BoF + BoFr      -                LogisticRegression  for    0.853333   \n",
       "Stacking Texts + Timeline + BoM + BoF + BoFr       -                LogisticRegression  for    0.723636   \n",
       "Stacking Stance + Texts + Timeline + BoM + BoF ... -                LogisticRegression  for    0.752727   \n",
       "\n",
       "metric                                                                                                   \\\n",
       "target                                                                                             Lula   \n",
       "text_col                                           vectorizer       estimator           class             \n",
       "Stance                                             -                dummy               for    0.000000   \n",
       "                                                   tf-idf           xgb                 for    0.654412   \n",
       "                                                   bertabaporu-base xgb                 for    0.749004   \n",
       "                                                   -                bertabaporu-base    for    0.778210   \n",
       "                                                                    llama3:7b zero-shot for    0.743590   \n",
       "...                                                                                                 ...   \n",
       "Stacking Stance + Texts + Timeline + BoF + BoFr    -                LogisticRegression  for    0.736434   \n",
       "Stacking Stance + Texts + BoM + BoF + BoFr         -                LogisticRegression  for    0.796935   \n",
       "Stacking Stance + Timeline + BoM + BoF + BoFr      -                LogisticRegression  for    0.789062   \n",
       "Stacking Texts + Timeline + BoM + BoF + BoFr       -                LogisticRegression  for    0.736434   \n",
       "Stacking Stance + Texts + Timeline + BoM + BoF ... -                LogisticRegression  for    0.741313   \n",
       "\n",
       "metric                                                                                                   \n",
       "target                                                                                          overall  \n",
       "text_col                                           vectorizer       estimator           class            \n",
       "Stance                                             -                dummy               for    0.241426  \n",
       "                                                   tf-idf           xgb                 for    0.640496  \n",
       "                                                   bertabaporu-base xgb                 for    0.730758  \n",
       "                                                   -                bertabaporu-base    for    0.793447  \n",
       "                                                                    llama3:7b zero-shot for    0.645950  \n",
       "...                                                                                                 ...  \n",
       "Stacking Stance + Texts + Timeline + BoF + BoFr    -                LogisticRegression  for    0.744521  \n",
       "Stacking Stance + Texts + BoM + BoF + BoFr         -                LogisticRegression  for    0.812975  \n",
       "Stacking Stance + Timeline + BoM + BoF + BoFr      -                LogisticRegression  for    0.779267  \n",
       "Stacking Texts + Timeline + BoM + BoF + BoFr       -                LogisticRegression  for    0.730721  \n",
       "Stacking Stance + Texts + Timeline + BoM + BoF ... -                LogisticRegression  for    0.745957  \n",
       "\n",
       "[82 rows x 7 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask_f1 = [True if  \"f1-score\" in col else False for col in df_results_final.columns]\n",
    "mask_macro = [True if  \"for\" in col else False for col in df_results_final.index]\n",
    "\n",
    "f1_df = df_results_final.loc[mask_macro,mask_f1]\n",
    "f1_df[('f1-score','overall')] = f1_df.mean(axis=1)\n",
    "\n",
    "f1_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>metric</th>\n",
       "      <th colspan=\"7\" halign=\"left\">f1-score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>Church</th>\n",
       "      <th>Bolsonaro</th>\n",
       "      <th>Hydrox.</th>\n",
       "      <th>Sinovac</th>\n",
       "      <th>Globo TV</th>\n",
       "      <th>Lula</th>\n",
       "      <th>overall</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text_col</th>\n",
       "      <th>vectorizer</th>\n",
       "      <th>estimator</th>\n",
       "      <th>class</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Stance</th>\n",
       "      <th>-</th>\n",
       "      <th>dummy</th>\n",
       "      <th>for</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.703518</td>\n",
       "      <td>0.745038</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.241426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Timeline</th>\n",
       "      <th>-</th>\n",
       "      <th>dummy</th>\n",
       "      <th>for</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.703518</td>\n",
       "      <td>0.745038</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.241426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">Texts</th>\n",
       "      <th rowspan=\"3\" valign=\"top\">-</th>\n",
       "      <th>dummy</th>\n",
       "      <th>for</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.703518</td>\n",
       "      <td>0.745038</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.241426</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bertabaporu-base</th>\n",
       "      <th>for</th>\n",
       "      <td>0.458937</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.218935</td>\n",
       "      <td>0.560472</td>\n",
       "      <td>0.730318</td>\n",
       "      <td>0.309392</td>\n",
       "      <td>0.379676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bertabaporu-base (R)</th>\n",
       "      <th>for</th>\n",
       "      <td>0.458234</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.536862</td>\n",
       "      <td>0.619565</td>\n",
       "      <td>0.704545</td>\n",
       "      <td>0.619718</td>\n",
       "      <td>0.489821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Stacking Stance + Texts + BoM + BoFr</th>\n",
       "      <th>-</th>\n",
       "      <th>LogisticRegression</th>\n",
       "      <th>for</th>\n",
       "      <td>0.838095</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>0.877622</td>\n",
       "      <td>0.871445</td>\n",
       "      <td>0.897384</td>\n",
       "      <td>0.767442</td>\n",
       "      <td>0.815808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Stacking Stance + Texts + BoM</th>\n",
       "      <th>-</th>\n",
       "      <th>LogisticRegression</th>\n",
       "      <th>for</th>\n",
       "      <td>0.838095</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>0.877622</td>\n",
       "      <td>0.871445</td>\n",
       "      <td>0.897384</td>\n",
       "      <td>0.767442</td>\n",
       "      <td>0.815808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Stacking Stance + Texts + BoF + BoFr</th>\n",
       "      <th>-</th>\n",
       "      <th>LogisticRegression</th>\n",
       "      <th>for</th>\n",
       "      <td>0.798521</td>\n",
       "      <td>0.697674</td>\n",
       "      <td>0.879433</td>\n",
       "      <td>0.874720</td>\n",
       "      <td>0.896000</td>\n",
       "      <td>0.779923</td>\n",
       "      <td>0.821045</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Stacking Stance + BoF + BoFr</th>\n",
       "      <th>-</th>\n",
       "      <th>LogisticRegression</th>\n",
       "      <th>for</th>\n",
       "      <td>0.844794</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.891986</td>\n",
       "      <td>0.884211</td>\n",
       "      <td>0.887500</td>\n",
       "      <td>0.837736</td>\n",
       "      <td>0.835482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Stacking Stance + BoF</th>\n",
       "      <th>-</th>\n",
       "      <th>LogisticRegression</th>\n",
       "      <th>for</th>\n",
       "      <td>0.830409</td>\n",
       "      <td>0.711111</td>\n",
       "      <td>0.884283</td>\n",
       "      <td>0.869565</td>\n",
       "      <td>0.887967</td>\n",
       "      <td>0.842912</td>\n",
       "      <td>0.837708</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>82 rows  7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "metric                                                                      f1-score  \\\n",
       "target                                                                        Church   \n",
       "text_col                             vectorizer estimator            class             \n",
       "Stance                               -          dummy                for    0.000000   \n",
       "Timeline                             -          dummy                for    0.000000   \n",
       "Texts                                -          dummy                for    0.000000   \n",
       "                                                bertabaporu-base     for    0.458937   \n",
       "                                                bertabaporu-base (R) for    0.458234   \n",
       "...                                                                              ...   \n",
       "Stacking Stance + Texts + BoM + BoFr -          LogisticRegression   for    0.838095   \n",
       "Stacking Stance + Texts + BoM        -          LogisticRegression   for    0.838095   \n",
       "Stacking Stance + Texts + BoF + BoFr -          LogisticRegression   for    0.798521   \n",
       "Stacking Stance + BoF + BoFr         -          LogisticRegression   for    0.844794   \n",
       "Stacking Stance + BoF                -          LogisticRegression   for    0.830409   \n",
       "\n",
       "metric                                                                                \\\n",
       "target                                                                     Bolsonaro   \n",
       "text_col                             vectorizer estimator            class             \n",
       "Stance                               -          dummy                for    0.000000   \n",
       "Timeline                             -          dummy                for    0.000000   \n",
       "Texts                                -          dummy                for    0.000000   \n",
       "                                                bertabaporu-base     for    0.000000   \n",
       "                                                bertabaporu-base (R) for    0.000000   \n",
       "...                                                                              ...   \n",
       "Stacking Stance + Texts + BoM + BoFr -          LogisticRegression   for    0.642857   \n",
       "Stacking Stance + Texts + BoM        -          LogisticRegression   for    0.642857   \n",
       "Stacking Stance + Texts + BoF + BoFr -          LogisticRegression   for    0.697674   \n",
       "Stacking Stance + BoF + BoFr         -          LogisticRegression   for    0.666667   \n",
       "Stacking Stance + BoF                -          LogisticRegression   for    0.711111   \n",
       "\n",
       "metric                                                                                \\\n",
       "target                                                                       Hydrox.   \n",
       "text_col                             vectorizer estimator            class             \n",
       "Stance                               -          dummy                for    0.000000   \n",
       "Timeline                             -          dummy                for    0.000000   \n",
       "Texts                                -          dummy                for    0.000000   \n",
       "                                                bertabaporu-base     for    0.218935   \n",
       "                                                bertabaporu-base (R) for    0.536862   \n",
       "...                                                                              ...   \n",
       "Stacking Stance + Texts + BoM + BoFr -          LogisticRegression   for    0.877622   \n",
       "Stacking Stance + Texts + BoM        -          LogisticRegression   for    0.877622   \n",
       "Stacking Stance + Texts + BoF + BoFr -          LogisticRegression   for    0.879433   \n",
       "Stacking Stance + BoF + BoFr         -          LogisticRegression   for    0.891986   \n",
       "Stacking Stance + BoF                -          LogisticRegression   for    0.884283   \n",
       "\n",
       "metric                                                                                \\\n",
       "target                                                                       Sinovac   \n",
       "text_col                             vectorizer estimator            class             \n",
       "Stance                               -          dummy                for    0.703518   \n",
       "Timeline                             -          dummy                for    0.703518   \n",
       "Texts                                -          dummy                for    0.703518   \n",
       "                                                bertabaporu-base     for    0.560472   \n",
       "                                                bertabaporu-base (R) for    0.619565   \n",
       "...                                                                              ...   \n",
       "Stacking Stance + Texts + BoM + BoFr -          LogisticRegression   for    0.871445   \n",
       "Stacking Stance + Texts + BoM        -          LogisticRegression   for    0.871445   \n",
       "Stacking Stance + Texts + BoF + BoFr -          LogisticRegression   for    0.874720   \n",
       "Stacking Stance + BoF + BoFr         -          LogisticRegression   for    0.884211   \n",
       "Stacking Stance + BoF                -          LogisticRegression   for    0.869565   \n",
       "\n",
       "metric                                                                                \\\n",
       "target                                                                      Globo TV   \n",
       "text_col                             vectorizer estimator            class             \n",
       "Stance                               -          dummy                for    0.745038   \n",
       "Timeline                             -          dummy                for    0.745038   \n",
       "Texts                                -          dummy                for    0.745038   \n",
       "                                                bertabaporu-base     for    0.730318   \n",
       "                                                bertabaporu-base (R) for    0.704545   \n",
       "...                                                                              ...   \n",
       "Stacking Stance + Texts + BoM + BoFr -          LogisticRegression   for    0.897384   \n",
       "Stacking Stance + Texts + BoM        -          LogisticRegression   for    0.897384   \n",
       "Stacking Stance + Texts + BoF + BoFr -          LogisticRegression   for    0.896000   \n",
       "Stacking Stance + BoF + BoFr         -          LogisticRegression   for    0.887500   \n",
       "Stacking Stance + BoF                -          LogisticRegression   for    0.887967   \n",
       "\n",
       "metric                                                                                \\\n",
       "target                                                                          Lula   \n",
       "text_col                             vectorizer estimator            class             \n",
       "Stance                               -          dummy                for    0.000000   \n",
       "Timeline                             -          dummy                for    0.000000   \n",
       "Texts                                -          dummy                for    0.000000   \n",
       "                                                bertabaporu-base     for    0.309392   \n",
       "                                                bertabaporu-base (R) for    0.619718   \n",
       "...                                                                              ...   \n",
       "Stacking Stance + Texts + BoM + BoFr -          LogisticRegression   for    0.767442   \n",
       "Stacking Stance + Texts + BoM        -          LogisticRegression   for    0.767442   \n",
       "Stacking Stance + Texts + BoF + BoFr -          LogisticRegression   for    0.779923   \n",
       "Stacking Stance + BoF + BoFr         -          LogisticRegression   for    0.837736   \n",
       "Stacking Stance + BoF                -          LogisticRegression   for    0.842912   \n",
       "\n",
       "metric                                                                                \n",
       "target                                                                       overall  \n",
       "text_col                             vectorizer estimator            class            \n",
       "Stance                               -          dummy                for    0.241426  \n",
       "Timeline                             -          dummy                for    0.241426  \n",
       "Texts                                -          dummy                for    0.241426  \n",
       "                                                bertabaporu-base     for    0.379676  \n",
       "                                                bertabaporu-base (R) for    0.489821  \n",
       "...                                                                              ...  \n",
       "Stacking Stance + Texts + BoM + BoFr -          LogisticRegression   for    0.815808  \n",
       "Stacking Stance + Texts + BoM        -          LogisticRegression   for    0.815808  \n",
       "Stacking Stance + Texts + BoF + BoFr -          LogisticRegression   for    0.821045  \n",
       "Stacking Stance + BoF + BoFr         -          LogisticRegression   for    0.835482  \n",
       "Stacking Stance + BoF                -          LogisticRegression   for    0.837708  \n",
       "\n",
       "[82 rows x 7 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_df.sort_values([('f1-score','overall')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create table f1 macro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>metric</th>\n",
       "      <th colspan=\"7\" halign=\"left\">f1-score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>Church</th>\n",
       "      <th>Bolsonaro</th>\n",
       "      <th>Hydrox.</th>\n",
       "      <th>Sinovac</th>\n",
       "      <th>Globo TV</th>\n",
       "      <th>Lula</th>\n",
       "      <th>overall</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text_col</th>\n",
       "      <th>vectorizer</th>\n",
       "      <th>estimator</th>\n",
       "      <th>class</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">Stance</th>\n",
       "      <th>-</th>\n",
       "      <th>dummy</th>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.361407</td>\n",
       "      <td>0.462857</td>\n",
       "      <td>0.334878</td>\n",
       "      <td>0.351759</td>\n",
       "      <td>0.372519</td>\n",
       "      <td>0.344578</td>\n",
       "      <td>0.371333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tf-idf</th>\n",
       "      <th>xgb</th>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.702021</td>\n",
       "      <td>0.595312</td>\n",
       "      <td>0.734366</td>\n",
       "      <td>0.752640</td>\n",
       "      <td>0.665243</td>\n",
       "      <td>0.654412</td>\n",
       "      <td>0.683999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bertabaporu-base</th>\n",
       "      <th>xgb</th>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.853801</td>\n",
       "      <td>0.625289</td>\n",
       "      <td>0.830948</td>\n",
       "      <td>0.808036</td>\n",
       "      <td>0.781858</td>\n",
       "      <td>0.766993</td>\n",
       "      <td>0.777821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">-</th>\n",
       "      <th>bertabaporu-base</th>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.866276</td>\n",
       "      <td>0.737297</td>\n",
       "      <td>0.848144</td>\n",
       "      <td>0.834984</td>\n",
       "      <td>0.860252</td>\n",
       "      <td>0.789802</td>\n",
       "      <td>0.822792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>llama3:7b zero-shot</th>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.729458</td>\n",
       "      <td>0.462857</td>\n",
       "      <td>0.638889</td>\n",
       "      <td>0.578779</td>\n",
       "      <td>0.770678</td>\n",
       "      <td>0.699381</td>\n",
       "      <td>0.646674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Stacking Stance + Texts + Timeline + BoF + BoFr</th>\n",
       "      <th>-</th>\n",
       "      <th>LogisticRegression</th>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.721009</td>\n",
       "      <td>0.748214</td>\n",
       "      <td>0.876297</td>\n",
       "      <td>0.850709</td>\n",
       "      <td>0.631145</td>\n",
       "      <td>0.749336</td>\n",
       "      <td>0.762785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Stacking Stance + Texts + BoM + BoF + BoFr</th>\n",
       "      <th>-</th>\n",
       "      <th>LogisticRegression</th>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.832816</td>\n",
       "      <td>0.776800</td>\n",
       "      <td>0.886751</td>\n",
       "      <td>0.860431</td>\n",
       "      <td>0.867255</td>\n",
       "      <td>0.804828</td>\n",
       "      <td>0.838147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Stacking Stance + Timeline + BoM + BoF + BoFr</th>\n",
       "      <th>-</th>\n",
       "      <th>LogisticRegression</th>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.775539</td>\n",
       "      <td>0.748214</td>\n",
       "      <td>0.879788</td>\n",
       "      <td>0.845545</td>\n",
       "      <td>0.797037</td>\n",
       "      <td>0.800781</td>\n",
       "      <td>0.807817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Stacking Texts + Timeline + BoM + BoF + BoFr</th>\n",
       "      <th>-</th>\n",
       "      <th>LogisticRegression</th>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.699811</td>\n",
       "      <td>0.728220</td>\n",
       "      <td>0.879782</td>\n",
       "      <td>0.858524</td>\n",
       "      <td>0.582406</td>\n",
       "      <td>0.749336</td>\n",
       "      <td>0.749680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Stacking Stance + Texts + Timeline + BoM + BoF + BoFr</th>\n",
       "      <th>-</th>\n",
       "      <th>LogisticRegression</th>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.724133</td>\n",
       "      <td>0.748214</td>\n",
       "      <td>0.878043</td>\n",
       "      <td>0.850709</td>\n",
       "      <td>0.626364</td>\n",
       "      <td>0.753113</td>\n",
       "      <td>0.763429</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>82 rows  7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "metric                                                                                             f1-score  \\\n",
       "target                                                                                               Church   \n",
       "text_col                                           vectorizer       estimator           class                 \n",
       "Stance                                             -                dummy               macro avg  0.361407   \n",
       "                                                   tf-idf           xgb                 macro avg  0.702021   \n",
       "                                                   bertabaporu-base xgb                 macro avg  0.853801   \n",
       "                                                   -                bertabaporu-base    macro avg  0.866276   \n",
       "                                                                    llama3:7b zero-shot macro avg  0.729458   \n",
       "...                                                                                                     ...   \n",
       "Stacking Stance + Texts + Timeline + BoF + BoFr    -                LogisticRegression  macro avg  0.721009   \n",
       "Stacking Stance + Texts + BoM + BoF + BoFr         -                LogisticRegression  macro avg  0.832816   \n",
       "Stacking Stance + Timeline + BoM + BoF + BoFr      -                LogisticRegression  macro avg  0.775539   \n",
       "Stacking Texts + Timeline + BoM + BoF + BoFr       -                LogisticRegression  macro avg  0.699811   \n",
       "Stacking Stance + Texts + Timeline + BoM + BoF ... -                LogisticRegression  macro avg  0.724133   \n",
       "\n",
       "metric                                                                                                       \\\n",
       "target                                                                                            Bolsonaro   \n",
       "text_col                                           vectorizer       estimator           class                 \n",
       "Stance                                             -                dummy               macro avg  0.462857   \n",
       "                                                   tf-idf           xgb                 macro avg  0.595312   \n",
       "                                                   bertabaporu-base xgb                 macro avg  0.625289   \n",
       "                                                   -                bertabaporu-base    macro avg  0.737297   \n",
       "                                                                    llama3:7b zero-shot macro avg  0.462857   \n",
       "...                                                                                                     ...   \n",
       "Stacking Stance + Texts + Timeline + BoF + BoFr    -                LogisticRegression  macro avg  0.748214   \n",
       "Stacking Stance + Texts + BoM + BoF + BoFr         -                LogisticRegression  macro avg  0.776800   \n",
       "Stacking Stance + Timeline + BoM + BoF + BoFr      -                LogisticRegression  macro avg  0.748214   \n",
       "Stacking Texts + Timeline + BoM + BoF + BoFr       -                LogisticRegression  macro avg  0.728220   \n",
       "Stacking Stance + Texts + Timeline + BoM + BoF ... -                LogisticRegression  macro avg  0.748214   \n",
       "\n",
       "metric                                                                                                       \\\n",
       "target                                                                                              Hydrox.   \n",
       "text_col                                           vectorizer       estimator           class                 \n",
       "Stance                                             -                dummy               macro avg  0.334878   \n",
       "                                                   tf-idf           xgb                 macro avg  0.734366   \n",
       "                                                   bertabaporu-base xgb                 macro avg  0.830948   \n",
       "                                                   -                bertabaporu-base    macro avg  0.848144   \n",
       "                                                                    llama3:7b zero-shot macro avg  0.638889   \n",
       "...                                                                                                     ...   \n",
       "Stacking Stance + Texts + Timeline + BoF + BoFr    -                LogisticRegression  macro avg  0.876297   \n",
       "Stacking Stance + Texts + BoM + BoF + BoFr         -                LogisticRegression  macro avg  0.886751   \n",
       "Stacking Stance + Timeline + BoM + BoF + BoFr      -                LogisticRegression  macro avg  0.879788   \n",
       "Stacking Texts + Timeline + BoM + BoF + BoFr       -                LogisticRegression  macro avg  0.879782   \n",
       "Stacking Stance + Texts + Timeline + BoM + BoF ... -                LogisticRegression  macro avg  0.878043   \n",
       "\n",
       "metric                                                                                                       \\\n",
       "target                                                                                              Sinovac   \n",
       "text_col                                           vectorizer       estimator           class                 \n",
       "Stance                                             -                dummy               macro avg  0.351759   \n",
       "                                                   tf-idf           xgb                 macro avg  0.752640   \n",
       "                                                   bertabaporu-base xgb                 macro avg  0.808036   \n",
       "                                                   -                bertabaporu-base    macro avg  0.834984   \n",
       "                                                                    llama3:7b zero-shot macro avg  0.578779   \n",
       "...                                                                                                     ...   \n",
       "Stacking Stance + Texts + Timeline + BoF + BoFr    -                LogisticRegression  macro avg  0.850709   \n",
       "Stacking Stance + Texts + BoM + BoF + BoFr         -                LogisticRegression  macro avg  0.860431   \n",
       "Stacking Stance + Timeline + BoM + BoF + BoFr      -                LogisticRegression  macro avg  0.845545   \n",
       "Stacking Texts + Timeline + BoM + BoF + BoFr       -                LogisticRegression  macro avg  0.858524   \n",
       "Stacking Stance + Texts + Timeline + BoM + BoF ... -                LogisticRegression  macro avg  0.850709   \n",
       "\n",
       "metric                                                                                                       \\\n",
       "target                                                                                             Globo TV   \n",
       "text_col                                           vectorizer       estimator           class                 \n",
       "Stance                                             -                dummy               macro avg  0.372519   \n",
       "                                                   tf-idf           xgb                 macro avg  0.665243   \n",
       "                                                   bertabaporu-base xgb                 macro avg  0.781858   \n",
       "                                                   -                bertabaporu-base    macro avg  0.860252   \n",
       "                                                                    llama3:7b zero-shot macro avg  0.770678   \n",
       "...                                                                                                     ...   \n",
       "Stacking Stance + Texts + Timeline + BoF + BoFr    -                LogisticRegression  macro avg  0.631145   \n",
       "Stacking Stance + Texts + BoM + BoF + BoFr         -                LogisticRegression  macro avg  0.867255   \n",
       "Stacking Stance + Timeline + BoM + BoF + BoFr      -                LogisticRegression  macro avg  0.797037   \n",
       "Stacking Texts + Timeline + BoM + BoF + BoFr       -                LogisticRegression  macro avg  0.582406   \n",
       "Stacking Stance + Texts + Timeline + BoM + BoF ... -                LogisticRegression  macro avg  0.626364   \n",
       "\n",
       "metric                                                                                                       \\\n",
       "target                                                                                                 Lula   \n",
       "text_col                                           vectorizer       estimator           class                 \n",
       "Stance                                             -                dummy               macro avg  0.344578   \n",
       "                                                   tf-idf           xgb                 macro avg  0.654412   \n",
       "                                                   bertabaporu-base xgb                 macro avg  0.766993   \n",
       "                                                   -                bertabaporu-base    macro avg  0.789802   \n",
       "                                                                    llama3:7b zero-shot macro avg  0.699381   \n",
       "...                                                                                                     ...   \n",
       "Stacking Stance + Texts + Timeline + BoF + BoFr    -                LogisticRegression  macro avg  0.749336   \n",
       "Stacking Stance + Texts + BoM + BoF + BoFr         -                LogisticRegression  macro avg  0.804828   \n",
       "Stacking Stance + Timeline + BoM + BoF + BoFr      -                LogisticRegression  macro avg  0.800781   \n",
       "Stacking Texts + Timeline + BoM + BoF + BoFr       -                LogisticRegression  macro avg  0.749336   \n",
       "Stacking Stance + Texts + Timeline + BoM + BoF ... -                LogisticRegression  macro avg  0.753113   \n",
       "\n",
       "metric                                                                                                       \n",
       "target                                                                                              overall  \n",
       "text_col                                           vectorizer       estimator           class                \n",
       "Stance                                             -                dummy               macro avg  0.371333  \n",
       "                                                   tf-idf           xgb                 macro avg  0.683999  \n",
       "                                                   bertabaporu-base xgb                 macro avg  0.777821  \n",
       "                                                   -                bertabaporu-base    macro avg  0.822792  \n",
       "                                                                    llama3:7b zero-shot macro avg  0.646674  \n",
       "...                                                                                                     ...  \n",
       "Stacking Stance + Texts + Timeline + BoF + BoFr    -                LogisticRegression  macro avg  0.762785  \n",
       "Stacking Stance + Texts + BoM + BoF + BoFr         -                LogisticRegression  macro avg  0.838147  \n",
       "Stacking Stance + Timeline + BoM + BoF + BoFr      -                LogisticRegression  macro avg  0.807817  \n",
       "Stacking Texts + Timeline + BoM + BoF + BoFr       -                LogisticRegression  macro avg  0.749680  \n",
       "Stacking Stance + Texts + Timeline + BoM + BoF ... -                LogisticRegression  macro avg  0.763429  \n",
       "\n",
       "[82 rows x 7 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask_f1 = [True if  \"f1-score\" in col else False for col in df_results_final.columns]\n",
    "mask_macro = [True if  \"macro avg\" in col else False for col in df_results_final.index]\n",
    "\n",
    "f1_macro_df = df_results_final.loc[mask_macro,mask_f1]\n",
    "f1_macro_df[('f1-score','overall')] = f1_macro_df.mean(axis=1)\n",
    "\n",
    "f1_macro_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Table for docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>metric</th>\n",
       "      <th colspan=\"7\" halign=\"left\">f1-score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>Church</th>\n",
       "      <th>Bolsonaro</th>\n",
       "      <th>Hydrox.</th>\n",
       "      <th>Sinovac</th>\n",
       "      <th>Globo TV</th>\n",
       "      <th>Lula</th>\n",
       "      <th>overall</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text_col</th>\n",
       "      <th>vectorizer</th>\n",
       "      <th>estimator</th>\n",
       "      <th>class</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">Stance</th>\n",
       "      <th>-</th>\n",
       "      <th>dummy</th>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.361407</td>\n",
       "      <td>0.462857</td>\n",
       "      <td>0.334878</td>\n",
       "      <td>0.351759</td>\n",
       "      <td>0.372519</td>\n",
       "      <td>0.344578</td>\n",
       "      <td>0.371333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tf-idf</th>\n",
       "      <th>xgb</th>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.702021</td>\n",
       "      <td>0.595312</td>\n",
       "      <td>0.734366</td>\n",
       "      <td>0.752640</td>\n",
       "      <td>0.665243</td>\n",
       "      <td>0.654412</td>\n",
       "      <td>0.683999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bertabaporu-base</th>\n",
       "      <th>xgb</th>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.853801</td>\n",
       "      <td>0.625289</td>\n",
       "      <td>0.830948</td>\n",
       "      <td>0.808036</td>\n",
       "      <td>0.781858</td>\n",
       "      <td>0.766993</td>\n",
       "      <td>0.777821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">-</th>\n",
       "      <th>bertabaporu-base</th>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.866276</td>\n",
       "      <td>0.737297</td>\n",
       "      <td>0.848144</td>\n",
       "      <td>0.834984</td>\n",
       "      <td>0.860252</td>\n",
       "      <td>0.789802</td>\n",
       "      <td>0.822792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>llama3:7b zero-shot</th>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.729458</td>\n",
       "      <td>0.462857</td>\n",
       "      <td>0.638889</td>\n",
       "      <td>0.578779</td>\n",
       "      <td>0.770678</td>\n",
       "      <td>0.699381</td>\n",
       "      <td>0.646674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Stacking Stance + Texts + Timeline + BoF + BoFr</th>\n",
       "      <th>-</th>\n",
       "      <th>LogisticRegression</th>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.721009</td>\n",
       "      <td>0.748214</td>\n",
       "      <td>0.876297</td>\n",
       "      <td>0.850709</td>\n",
       "      <td>0.631145</td>\n",
       "      <td>0.749336</td>\n",
       "      <td>0.762785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Stacking Stance + Texts + BoM + BoF + BoFr</th>\n",
       "      <th>-</th>\n",
       "      <th>LogisticRegression</th>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.832816</td>\n",
       "      <td>0.776800</td>\n",
       "      <td>0.886751</td>\n",
       "      <td>0.860431</td>\n",
       "      <td>0.867255</td>\n",
       "      <td>0.804828</td>\n",
       "      <td>0.838147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Stacking Stance + Timeline + BoM + BoF + BoFr</th>\n",
       "      <th>-</th>\n",
       "      <th>LogisticRegression</th>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.775539</td>\n",
       "      <td>0.748214</td>\n",
       "      <td>0.879788</td>\n",
       "      <td>0.845545</td>\n",
       "      <td>0.797037</td>\n",
       "      <td>0.800781</td>\n",
       "      <td>0.807817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Stacking Texts + Timeline + BoM + BoF + BoFr</th>\n",
       "      <th>-</th>\n",
       "      <th>LogisticRegression</th>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.699811</td>\n",
       "      <td>0.728220</td>\n",
       "      <td>0.879782</td>\n",
       "      <td>0.858524</td>\n",
       "      <td>0.582406</td>\n",
       "      <td>0.749336</td>\n",
       "      <td>0.749680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Stacking Stance + Texts + Timeline + BoM + BoF + BoFr</th>\n",
       "      <th>-</th>\n",
       "      <th>LogisticRegression</th>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.724133</td>\n",
       "      <td>0.748214</td>\n",
       "      <td>0.878043</td>\n",
       "      <td>0.850709</td>\n",
       "      <td>0.626364</td>\n",
       "      <td>0.753113</td>\n",
       "      <td>0.763429</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>82 rows  7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "metric                                                                                             f1-score  \\\n",
       "target                                                                                               Church   \n",
       "text_col                                           vectorizer       estimator           class                 \n",
       "Stance                                             -                dummy               macro avg  0.361407   \n",
       "                                                   tf-idf           xgb                 macro avg  0.702021   \n",
       "                                                   bertabaporu-base xgb                 macro avg  0.853801   \n",
       "                                                   -                bertabaporu-base    macro avg  0.866276   \n",
       "                                                                    llama3:7b zero-shot macro avg  0.729458   \n",
       "...                                                                                                     ...   \n",
       "Stacking Stance + Texts + Timeline + BoF + BoFr    -                LogisticRegression  macro avg  0.721009   \n",
       "Stacking Stance + Texts + BoM + BoF + BoFr         -                LogisticRegression  macro avg  0.832816   \n",
       "Stacking Stance + Timeline + BoM + BoF + BoFr      -                LogisticRegression  macro avg  0.775539   \n",
       "Stacking Texts + Timeline + BoM + BoF + BoFr       -                LogisticRegression  macro avg  0.699811   \n",
       "Stacking Stance + Texts + Timeline + BoM + BoF ... -                LogisticRegression  macro avg  0.724133   \n",
       "\n",
       "metric                                                                                                       \\\n",
       "target                                                                                            Bolsonaro   \n",
       "text_col                                           vectorizer       estimator           class                 \n",
       "Stance                                             -                dummy               macro avg  0.462857   \n",
       "                                                   tf-idf           xgb                 macro avg  0.595312   \n",
       "                                                   bertabaporu-base xgb                 macro avg  0.625289   \n",
       "                                                   -                bertabaporu-base    macro avg  0.737297   \n",
       "                                                                    llama3:7b zero-shot macro avg  0.462857   \n",
       "...                                                                                                     ...   \n",
       "Stacking Stance + Texts + Timeline + BoF + BoFr    -                LogisticRegression  macro avg  0.748214   \n",
       "Stacking Stance + Texts + BoM + BoF + BoFr         -                LogisticRegression  macro avg  0.776800   \n",
       "Stacking Stance + Timeline + BoM + BoF + BoFr      -                LogisticRegression  macro avg  0.748214   \n",
       "Stacking Texts + Timeline + BoM + BoF + BoFr       -                LogisticRegression  macro avg  0.728220   \n",
       "Stacking Stance + Texts + Timeline + BoM + BoF ... -                LogisticRegression  macro avg  0.748214   \n",
       "\n",
       "metric                                                                                                       \\\n",
       "target                                                                                              Hydrox.   \n",
       "text_col                                           vectorizer       estimator           class                 \n",
       "Stance                                             -                dummy               macro avg  0.334878   \n",
       "                                                   tf-idf           xgb                 macro avg  0.734366   \n",
       "                                                   bertabaporu-base xgb                 macro avg  0.830948   \n",
       "                                                   -                bertabaporu-base    macro avg  0.848144   \n",
       "                                                                    llama3:7b zero-shot macro avg  0.638889   \n",
       "...                                                                                                     ...   \n",
       "Stacking Stance + Texts + Timeline + BoF + BoFr    -                LogisticRegression  macro avg  0.876297   \n",
       "Stacking Stance + Texts + BoM + BoF + BoFr         -                LogisticRegression  macro avg  0.886751   \n",
       "Stacking Stance + Timeline + BoM + BoF + BoFr      -                LogisticRegression  macro avg  0.879788   \n",
       "Stacking Texts + Timeline + BoM + BoF + BoFr       -                LogisticRegression  macro avg  0.879782   \n",
       "Stacking Stance + Texts + Timeline + BoM + BoF ... -                LogisticRegression  macro avg  0.878043   \n",
       "\n",
       "metric                                                                                                       \\\n",
       "target                                                                                              Sinovac   \n",
       "text_col                                           vectorizer       estimator           class                 \n",
       "Stance                                             -                dummy               macro avg  0.351759   \n",
       "                                                   tf-idf           xgb                 macro avg  0.752640   \n",
       "                                                   bertabaporu-base xgb                 macro avg  0.808036   \n",
       "                                                   -                bertabaporu-base    macro avg  0.834984   \n",
       "                                                                    llama3:7b zero-shot macro avg  0.578779   \n",
       "...                                                                                                     ...   \n",
       "Stacking Stance + Texts + Timeline + BoF + BoFr    -                LogisticRegression  macro avg  0.850709   \n",
       "Stacking Stance + Texts + BoM + BoF + BoFr         -                LogisticRegression  macro avg  0.860431   \n",
       "Stacking Stance + Timeline + BoM + BoF + BoFr      -                LogisticRegression  macro avg  0.845545   \n",
       "Stacking Texts + Timeline + BoM + BoF + BoFr       -                LogisticRegression  macro avg  0.858524   \n",
       "Stacking Stance + Texts + Timeline + BoM + BoF ... -                LogisticRegression  macro avg  0.850709   \n",
       "\n",
       "metric                                                                                                       \\\n",
       "target                                                                                             Globo TV   \n",
       "text_col                                           vectorizer       estimator           class                 \n",
       "Stance                                             -                dummy               macro avg  0.372519   \n",
       "                                                   tf-idf           xgb                 macro avg  0.665243   \n",
       "                                                   bertabaporu-base xgb                 macro avg  0.781858   \n",
       "                                                   -                bertabaporu-base    macro avg  0.860252   \n",
       "                                                                    llama3:7b zero-shot macro avg  0.770678   \n",
       "...                                                                                                     ...   \n",
       "Stacking Stance + Texts + Timeline + BoF + BoFr    -                LogisticRegression  macro avg  0.631145   \n",
       "Stacking Stance + Texts + BoM + BoF + BoFr         -                LogisticRegression  macro avg  0.867255   \n",
       "Stacking Stance + Timeline + BoM + BoF + BoFr      -                LogisticRegression  macro avg  0.797037   \n",
       "Stacking Texts + Timeline + BoM + BoF + BoFr       -                LogisticRegression  macro avg  0.582406   \n",
       "Stacking Stance + Texts + Timeline + BoM + BoF ... -                LogisticRegression  macro avg  0.626364   \n",
       "\n",
       "metric                                                                                                       \\\n",
       "target                                                                                                 Lula   \n",
       "text_col                                           vectorizer       estimator           class                 \n",
       "Stance                                             -                dummy               macro avg  0.344578   \n",
       "                                                   tf-idf           xgb                 macro avg  0.654412   \n",
       "                                                   bertabaporu-base xgb                 macro avg  0.766993   \n",
       "                                                   -                bertabaporu-base    macro avg  0.789802   \n",
       "                                                                    llama3:7b zero-shot macro avg  0.699381   \n",
       "...                                                                                                     ...   \n",
       "Stacking Stance + Texts + Timeline + BoF + BoFr    -                LogisticRegression  macro avg  0.749336   \n",
       "Stacking Stance + Texts + BoM + BoF + BoFr         -                LogisticRegression  macro avg  0.804828   \n",
       "Stacking Stance + Timeline + BoM + BoF + BoFr      -                LogisticRegression  macro avg  0.800781   \n",
       "Stacking Texts + Timeline + BoM + BoF + BoFr       -                LogisticRegression  macro avg  0.749336   \n",
       "Stacking Stance + Texts + Timeline + BoM + BoF ... -                LogisticRegression  macro avg  0.753113   \n",
       "\n",
       "metric                                                                                                       \n",
       "target                                                                                              overall  \n",
       "text_col                                           vectorizer       estimator           class                \n",
       "Stance                                             -                dummy               macro avg  0.371333  \n",
       "                                                   tf-idf           xgb                 macro avg  0.683999  \n",
       "                                                   bertabaporu-base xgb                 macro avg  0.777821  \n",
       "                                                   -                bertabaporu-base    macro avg  0.822792  \n",
       "                                                                    llama3:7b zero-shot macro avg  0.646674  \n",
       "...                                                                                                     ...  \n",
       "Stacking Stance + Texts + Timeline + BoF + BoFr    -                LogisticRegression  macro avg  0.762785  \n",
       "Stacking Stance + Texts + BoM + BoF + BoFr         -                LogisticRegression  macro avg  0.838147  \n",
       "Stacking Stance + Timeline + BoM + BoF + BoFr      -                LogisticRegression  macro avg  0.807817  \n",
       "Stacking Texts + Timeline + BoM + BoF + BoFr       -                LogisticRegression  macro avg  0.749680  \n",
       "Stacking Stance + Texts + Timeline + BoM + BoF ... -                LogisticRegression  macro avg  0.763429  \n",
       "\n",
       "[82 rows x 7 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_report = f1_macro_df.copy()\n",
    "f1_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>metric</th>\n",
       "      <th>text_col</th>\n",
       "      <th>vectorizer</th>\n",
       "      <th>estimator</th>\n",
       "      <th>class</th>\n",
       "      <th colspan=\"7\" halign=\"left\">f1-score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>target</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Church</th>\n",
       "      <th>Bolsonaro</th>\n",
       "      <th>Hydrox.</th>\n",
       "      <th>Sinovac</th>\n",
       "      <th>Globo TV</th>\n",
       "      <th>Lula</th>\n",
       "      <th>overall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Stance</td>\n",
       "      <td>-</td>\n",
       "      <td>dummy</td>\n",
       "      <td>macro avg</td>\n",
       "      <td>0.361407</td>\n",
       "      <td>0.462857</td>\n",
       "      <td>0.334878</td>\n",
       "      <td>0.351759</td>\n",
       "      <td>0.372519</td>\n",
       "      <td>0.344578</td>\n",
       "      <td>0.371333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Stance</td>\n",
       "      <td>tf-idf</td>\n",
       "      <td>xgb</td>\n",
       "      <td>macro avg</td>\n",
       "      <td>0.702021</td>\n",
       "      <td>0.595312</td>\n",
       "      <td>0.734366</td>\n",
       "      <td>0.752640</td>\n",
       "      <td>0.665243</td>\n",
       "      <td>0.654412</td>\n",
       "      <td>0.683999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Stance</td>\n",
       "      <td>bertabaporu-base</td>\n",
       "      <td>xgb</td>\n",
       "      <td>macro avg</td>\n",
       "      <td>0.853801</td>\n",
       "      <td>0.625289</td>\n",
       "      <td>0.830948</td>\n",
       "      <td>0.808036</td>\n",
       "      <td>0.781858</td>\n",
       "      <td>0.766993</td>\n",
       "      <td>0.777821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Stance</td>\n",
       "      <td>-</td>\n",
       "      <td>bertabaporu-base</td>\n",
       "      <td>macro avg</td>\n",
       "      <td>0.866276</td>\n",
       "      <td>0.737297</td>\n",
       "      <td>0.848144</td>\n",
       "      <td>0.834984</td>\n",
       "      <td>0.860252</td>\n",
       "      <td>0.789802</td>\n",
       "      <td>0.822792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Stance</td>\n",
       "      <td>-</td>\n",
       "      <td>llama3:7b zero-shot</td>\n",
       "      <td>macro avg</td>\n",
       "      <td>0.729458</td>\n",
       "      <td>0.462857</td>\n",
       "      <td>0.638889</td>\n",
       "      <td>0.578779</td>\n",
       "      <td>0.770678</td>\n",
       "      <td>0.699381</td>\n",
       "      <td>0.646674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>Stacking Stance + Texts + Timeline + BoF + BoFr</td>\n",
       "      <td>-</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>macro avg</td>\n",
       "      <td>0.721009</td>\n",
       "      <td>0.748214</td>\n",
       "      <td>0.876297</td>\n",
       "      <td>0.850709</td>\n",
       "      <td>0.631145</td>\n",
       "      <td>0.749336</td>\n",
       "      <td>0.762785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>Stacking Stance + Texts + BoM + BoF + BoFr</td>\n",
       "      <td>-</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>macro avg</td>\n",
       "      <td>0.832816</td>\n",
       "      <td>0.776800</td>\n",
       "      <td>0.886751</td>\n",
       "      <td>0.860431</td>\n",
       "      <td>0.867255</td>\n",
       "      <td>0.804828</td>\n",
       "      <td>0.838147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>Stacking Stance + Timeline + BoM + BoF + BoFr</td>\n",
       "      <td>-</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>macro avg</td>\n",
       "      <td>0.775539</td>\n",
       "      <td>0.748214</td>\n",
       "      <td>0.879788</td>\n",
       "      <td>0.845545</td>\n",
       "      <td>0.797037</td>\n",
       "      <td>0.800781</td>\n",
       "      <td>0.807817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>Stacking Texts + Timeline + BoM + BoF + BoFr</td>\n",
       "      <td>-</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>macro avg</td>\n",
       "      <td>0.699811</td>\n",
       "      <td>0.728220</td>\n",
       "      <td>0.879782</td>\n",
       "      <td>0.858524</td>\n",
       "      <td>0.582406</td>\n",
       "      <td>0.749336</td>\n",
       "      <td>0.749680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>Stacking Stance + Texts + Timeline + BoM + BoF...</td>\n",
       "      <td>-</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>macro avg</td>\n",
       "      <td>0.724133</td>\n",
       "      <td>0.748214</td>\n",
       "      <td>0.878043</td>\n",
       "      <td>0.850709</td>\n",
       "      <td>0.626364</td>\n",
       "      <td>0.753113</td>\n",
       "      <td>0.763429</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>82 rows  11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "metric                                           text_col        vectorizer  \\\n",
       "target                                                                        \n",
       "0                                                  Stance                 -   \n",
       "1                                                  Stance            tf-idf   \n",
       "2                                                  Stance  bertabaporu-base   \n",
       "3                                                  Stance                 -   \n",
       "4                                                  Stance                 -   \n",
       "..                                                    ...               ...   \n",
       "77        Stacking Stance + Texts + Timeline + BoF + BoFr                 -   \n",
       "78             Stacking Stance + Texts + BoM + BoF + BoFr                 -   \n",
       "79          Stacking Stance + Timeline + BoM + BoF + BoFr                 -   \n",
       "80           Stacking Texts + Timeline + BoM + BoF + BoFr                 -   \n",
       "81      Stacking Stance + Texts + Timeline + BoM + BoF...                 -   \n",
       "\n",
       "metric            estimator      class  f1-score                      \\\n",
       "target                                    Church Bolsonaro   Hydrox.   \n",
       "0                     dummy  macro avg  0.361407  0.462857  0.334878   \n",
       "1                       xgb  macro avg  0.702021  0.595312  0.734366   \n",
       "2                       xgb  macro avg  0.853801  0.625289  0.830948   \n",
       "3          bertabaporu-base  macro avg  0.866276  0.737297  0.848144   \n",
       "4       llama3:7b zero-shot  macro avg  0.729458  0.462857  0.638889   \n",
       "..                      ...        ...       ...       ...       ...   \n",
       "77       LogisticRegression  macro avg  0.721009  0.748214  0.876297   \n",
       "78       LogisticRegression  macro avg  0.832816  0.776800  0.886751   \n",
       "79       LogisticRegression  macro avg  0.775539  0.748214  0.879788   \n",
       "80       LogisticRegression  macro avg  0.699811  0.728220  0.879782   \n",
       "81       LogisticRegression  macro avg  0.724133  0.748214  0.878043   \n",
       "\n",
       "metric                                          \n",
       "target   Sinovac  Globo TV      Lula   overall  \n",
       "0       0.351759  0.372519  0.344578  0.371333  \n",
       "1       0.752640  0.665243  0.654412  0.683999  \n",
       "2       0.808036  0.781858  0.766993  0.777821  \n",
       "3       0.834984  0.860252  0.789802  0.822792  \n",
       "4       0.578779  0.770678  0.699381  0.646674  \n",
       "..           ...       ...       ...       ...  \n",
       "77      0.850709  0.631145  0.749336  0.762785  \n",
       "78      0.860431  0.867255  0.804828  0.838147  \n",
       "79      0.845545  0.797037  0.800781  0.807817  \n",
       "80      0.858524  0.582406  0.749336  0.749680  \n",
       "81      0.850709  0.626364  0.753113  0.763429  \n",
       "\n",
       "[82 rows x 11 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_report.reset_index(drop=False, inplace=True)\n",
    "f1_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultiIndex([(  'text_col',          ''),\n",
       "            ('vectorizer',          ''),\n",
       "            ( 'estimator',          ''),\n",
       "            (     'class',          ''),\n",
       "            (  'f1-score',    'Church'),\n",
       "            (  'f1-score', 'Bolsonaro'),\n",
       "            (  'f1-score',   'Hydrox.'),\n",
       "            (  'f1-score',   'Sinovac'),\n",
       "            (  'f1-score',  'Globo TV'),\n",
       "            (  'f1-score',      'Lula'),\n",
       "            (  'f1-score',   'overall')],\n",
       "           names=['metric', 'target'])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_report.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['text_col',\n",
       " 'vectorizer',\n",
       " 'estimator',\n",
       " 'class',\n",
       " 'Church',\n",
       " 'Bolsonaro',\n",
       " 'Hydrox.',\n",
       " 'Sinovac',\n",
       " 'Globo TV',\n",
       " 'Lula',\n",
       " 'overall']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_columns = [col[0] if col[1] == '' else col[1] for col in f1_report.columns]\n",
    "new_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_col</th>\n",
       "      <th>vectorizer</th>\n",
       "      <th>estimator</th>\n",
       "      <th>class</th>\n",
       "      <th>Church</th>\n",
       "      <th>Bolsonaro</th>\n",
       "      <th>Hydrox.</th>\n",
       "      <th>Sinovac</th>\n",
       "      <th>Globo TV</th>\n",
       "      <th>Lula</th>\n",
       "      <th>overall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Stance</td>\n",
       "      <td>-</td>\n",
       "      <td>dummy</td>\n",
       "      <td>macro avg</td>\n",
       "      <td>0.361407</td>\n",
       "      <td>0.462857</td>\n",
       "      <td>0.334878</td>\n",
       "      <td>0.351759</td>\n",
       "      <td>0.372519</td>\n",
       "      <td>0.344578</td>\n",
       "      <td>0.371333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Stance</td>\n",
       "      <td>tf-idf</td>\n",
       "      <td>xgb</td>\n",
       "      <td>macro avg</td>\n",
       "      <td>0.702021</td>\n",
       "      <td>0.595312</td>\n",
       "      <td>0.734366</td>\n",
       "      <td>0.752640</td>\n",
       "      <td>0.665243</td>\n",
       "      <td>0.654412</td>\n",
       "      <td>0.683999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Stance</td>\n",
       "      <td>bertabaporu-base</td>\n",
       "      <td>xgb</td>\n",
       "      <td>macro avg</td>\n",
       "      <td>0.853801</td>\n",
       "      <td>0.625289</td>\n",
       "      <td>0.830948</td>\n",
       "      <td>0.808036</td>\n",
       "      <td>0.781858</td>\n",
       "      <td>0.766993</td>\n",
       "      <td>0.777821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Stance</td>\n",
       "      <td>-</td>\n",
       "      <td>bertabaporu-base</td>\n",
       "      <td>macro avg</td>\n",
       "      <td>0.866276</td>\n",
       "      <td>0.737297</td>\n",
       "      <td>0.848144</td>\n",
       "      <td>0.834984</td>\n",
       "      <td>0.860252</td>\n",
       "      <td>0.789802</td>\n",
       "      <td>0.822792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Stance</td>\n",
       "      <td>-</td>\n",
       "      <td>llama3:7b zero-shot</td>\n",
       "      <td>macro avg</td>\n",
       "      <td>0.729458</td>\n",
       "      <td>0.462857</td>\n",
       "      <td>0.638889</td>\n",
       "      <td>0.578779</td>\n",
       "      <td>0.770678</td>\n",
       "      <td>0.699381</td>\n",
       "      <td>0.646674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>Stacking Stance + Texts + Timeline + BoF + BoFr</td>\n",
       "      <td>-</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>macro avg</td>\n",
       "      <td>0.721009</td>\n",
       "      <td>0.748214</td>\n",
       "      <td>0.876297</td>\n",
       "      <td>0.850709</td>\n",
       "      <td>0.631145</td>\n",
       "      <td>0.749336</td>\n",
       "      <td>0.762785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>Stacking Stance + Texts + BoM + BoF + BoFr</td>\n",
       "      <td>-</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>macro avg</td>\n",
       "      <td>0.832816</td>\n",
       "      <td>0.776800</td>\n",
       "      <td>0.886751</td>\n",
       "      <td>0.860431</td>\n",
       "      <td>0.867255</td>\n",
       "      <td>0.804828</td>\n",
       "      <td>0.838147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>Stacking Stance + Timeline + BoM + BoF + BoFr</td>\n",
       "      <td>-</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>macro avg</td>\n",
       "      <td>0.775539</td>\n",
       "      <td>0.748214</td>\n",
       "      <td>0.879788</td>\n",
       "      <td>0.845545</td>\n",
       "      <td>0.797037</td>\n",
       "      <td>0.800781</td>\n",
       "      <td>0.807817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>Stacking Texts + Timeline + BoM + BoF + BoFr</td>\n",
       "      <td>-</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>macro avg</td>\n",
       "      <td>0.699811</td>\n",
       "      <td>0.728220</td>\n",
       "      <td>0.879782</td>\n",
       "      <td>0.858524</td>\n",
       "      <td>0.582406</td>\n",
       "      <td>0.749336</td>\n",
       "      <td>0.749680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>Stacking Stance + Texts + Timeline + BoM + BoF...</td>\n",
       "      <td>-</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>macro avg</td>\n",
       "      <td>0.724133</td>\n",
       "      <td>0.748214</td>\n",
       "      <td>0.878043</td>\n",
       "      <td>0.850709</td>\n",
       "      <td>0.626364</td>\n",
       "      <td>0.753113</td>\n",
       "      <td>0.763429</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>82 rows  11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             text_col        vectorizer  \\\n",
       "0                                              Stance                 -   \n",
       "1                                              Stance            tf-idf   \n",
       "2                                              Stance  bertabaporu-base   \n",
       "3                                              Stance                 -   \n",
       "4                                              Stance                 -   \n",
       "..                                                ...               ...   \n",
       "77    Stacking Stance + Texts + Timeline + BoF + BoFr                 -   \n",
       "78         Stacking Stance + Texts + BoM + BoF + BoFr                 -   \n",
       "79      Stacking Stance + Timeline + BoM + BoF + BoFr                 -   \n",
       "80       Stacking Texts + Timeline + BoM + BoF + BoFr                 -   \n",
       "81  Stacking Stance + Texts + Timeline + BoM + BoF...                 -   \n",
       "\n",
       "              estimator      class    Church  Bolsonaro   Hydrox.   Sinovac  \\\n",
       "0                 dummy  macro avg  0.361407   0.462857  0.334878  0.351759   \n",
       "1                   xgb  macro avg  0.702021   0.595312  0.734366  0.752640   \n",
       "2                   xgb  macro avg  0.853801   0.625289  0.830948  0.808036   \n",
       "3      bertabaporu-base  macro avg  0.866276   0.737297  0.848144  0.834984   \n",
       "4   llama3:7b zero-shot  macro avg  0.729458   0.462857  0.638889  0.578779   \n",
       "..                  ...        ...       ...        ...       ...       ...   \n",
       "77   LogisticRegression  macro avg  0.721009   0.748214  0.876297  0.850709   \n",
       "78   LogisticRegression  macro avg  0.832816   0.776800  0.886751  0.860431   \n",
       "79   LogisticRegression  macro avg  0.775539   0.748214  0.879788  0.845545   \n",
       "80   LogisticRegression  macro avg  0.699811   0.728220  0.879782  0.858524   \n",
       "81   LogisticRegression  macro avg  0.724133   0.748214  0.878043  0.850709   \n",
       "\n",
       "    Globo TV      Lula   overall  \n",
       "0   0.372519  0.344578  0.371333  \n",
       "1   0.665243  0.654412  0.683999  \n",
       "2   0.781858  0.766993  0.777821  \n",
       "3   0.860252  0.789802  0.822792  \n",
       "4   0.770678  0.699381  0.646674  \n",
       "..       ...       ...       ...  \n",
       "77  0.631145  0.749336  0.762785  \n",
       "78  0.867255  0.804828  0.838147  \n",
       "79  0.797037  0.800781  0.807817  \n",
       "80  0.582406  0.749336  0.749680  \n",
       "81  0.626364  0.753113  0.763429  \n",
       "\n",
       "[82 rows x 11 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_report.columns = new_columns\n",
    "f1_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_col</th>\n",
       "      <th>vectorizer</th>\n",
       "      <th>estimator</th>\n",
       "      <th>Church</th>\n",
       "      <th>Bolsonaro</th>\n",
       "      <th>Hydrox.</th>\n",
       "      <th>Sinovac</th>\n",
       "      <th>Globo TV</th>\n",
       "      <th>Lula</th>\n",
       "      <th>overall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Stance</td>\n",
       "      <td>-</td>\n",
       "      <td>dummy</td>\n",
       "      <td>0.361407</td>\n",
       "      <td>0.462857</td>\n",
       "      <td>0.334878</td>\n",
       "      <td>0.351759</td>\n",
       "      <td>0.372519</td>\n",
       "      <td>0.344578</td>\n",
       "      <td>0.371333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Stance</td>\n",
       "      <td>tf-idf</td>\n",
       "      <td>xgb</td>\n",
       "      <td>0.702021</td>\n",
       "      <td>0.595312</td>\n",
       "      <td>0.734366</td>\n",
       "      <td>0.752640</td>\n",
       "      <td>0.665243</td>\n",
       "      <td>0.654412</td>\n",
       "      <td>0.683999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Stance</td>\n",
       "      <td>bertabaporu-base</td>\n",
       "      <td>xgb</td>\n",
       "      <td>0.853801</td>\n",
       "      <td>0.625289</td>\n",
       "      <td>0.830948</td>\n",
       "      <td>0.808036</td>\n",
       "      <td>0.781858</td>\n",
       "      <td>0.766993</td>\n",
       "      <td>0.777821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Stance</td>\n",
       "      <td>-</td>\n",
       "      <td>bertabaporu-base</td>\n",
       "      <td>0.866276</td>\n",
       "      <td>0.737297</td>\n",
       "      <td>0.848144</td>\n",
       "      <td>0.834984</td>\n",
       "      <td>0.860252</td>\n",
       "      <td>0.789802</td>\n",
       "      <td>0.822792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Stance</td>\n",
       "      <td>-</td>\n",
       "      <td>llama3:7b zero-shot</td>\n",
       "      <td>0.729458</td>\n",
       "      <td>0.462857</td>\n",
       "      <td>0.638889</td>\n",
       "      <td>0.578779</td>\n",
       "      <td>0.770678</td>\n",
       "      <td>0.699381</td>\n",
       "      <td>0.646674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>Stacking Stance + Texts + Timeline + BoF + BoFr</td>\n",
       "      <td>-</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.721009</td>\n",
       "      <td>0.748214</td>\n",
       "      <td>0.876297</td>\n",
       "      <td>0.850709</td>\n",
       "      <td>0.631145</td>\n",
       "      <td>0.749336</td>\n",
       "      <td>0.762785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>Stacking Stance + Texts + BoM + BoF + BoFr</td>\n",
       "      <td>-</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.832816</td>\n",
       "      <td>0.776800</td>\n",
       "      <td>0.886751</td>\n",
       "      <td>0.860431</td>\n",
       "      <td>0.867255</td>\n",
       "      <td>0.804828</td>\n",
       "      <td>0.838147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>Stacking Stance + Timeline + BoM + BoF + BoFr</td>\n",
       "      <td>-</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.775539</td>\n",
       "      <td>0.748214</td>\n",
       "      <td>0.879788</td>\n",
       "      <td>0.845545</td>\n",
       "      <td>0.797037</td>\n",
       "      <td>0.800781</td>\n",
       "      <td>0.807817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>Stacking Texts + Timeline + BoM + BoF + BoFr</td>\n",
       "      <td>-</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.699811</td>\n",
       "      <td>0.728220</td>\n",
       "      <td>0.879782</td>\n",
       "      <td>0.858524</td>\n",
       "      <td>0.582406</td>\n",
       "      <td>0.749336</td>\n",
       "      <td>0.749680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>Stacking Stance + Texts + Timeline + BoM + BoF...</td>\n",
       "      <td>-</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.724133</td>\n",
       "      <td>0.748214</td>\n",
       "      <td>0.878043</td>\n",
       "      <td>0.850709</td>\n",
       "      <td>0.626364</td>\n",
       "      <td>0.753113</td>\n",
       "      <td>0.763429</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>82 rows  10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             text_col        vectorizer  \\\n",
       "0                                              Stance                 -   \n",
       "1                                              Stance            tf-idf   \n",
       "2                                              Stance  bertabaporu-base   \n",
       "3                                              Stance                 -   \n",
       "4                                              Stance                 -   \n",
       "..                                                ...               ...   \n",
       "77    Stacking Stance + Texts + Timeline + BoF + BoFr                 -   \n",
       "78         Stacking Stance + Texts + BoM + BoF + BoFr                 -   \n",
       "79      Stacking Stance + Timeline + BoM + BoF + BoFr                 -   \n",
       "80       Stacking Texts + Timeline + BoM + BoF + BoFr                 -   \n",
       "81  Stacking Stance + Texts + Timeline + BoM + BoF...                 -   \n",
       "\n",
       "              estimator    Church  Bolsonaro   Hydrox.   Sinovac  Globo TV  \\\n",
       "0                 dummy  0.361407   0.462857  0.334878  0.351759  0.372519   \n",
       "1                   xgb  0.702021   0.595312  0.734366  0.752640  0.665243   \n",
       "2                   xgb  0.853801   0.625289  0.830948  0.808036  0.781858   \n",
       "3      bertabaporu-base  0.866276   0.737297  0.848144  0.834984  0.860252   \n",
       "4   llama3:7b zero-shot  0.729458   0.462857  0.638889  0.578779  0.770678   \n",
       "..                  ...       ...        ...       ...       ...       ...   \n",
       "77   LogisticRegression  0.721009   0.748214  0.876297  0.850709  0.631145   \n",
       "78   LogisticRegression  0.832816   0.776800  0.886751  0.860431  0.867255   \n",
       "79   LogisticRegression  0.775539   0.748214  0.879788  0.845545  0.797037   \n",
       "80   LogisticRegression  0.699811   0.728220  0.879782  0.858524  0.582406   \n",
       "81   LogisticRegression  0.724133   0.748214  0.878043  0.850709  0.626364   \n",
       "\n",
       "        Lula   overall  \n",
       "0   0.344578  0.371333  \n",
       "1   0.654412  0.683999  \n",
       "2   0.766993  0.777821  \n",
       "3   0.789802  0.822792  \n",
       "4   0.699381  0.646674  \n",
       "..       ...       ...  \n",
       "77  0.749336  0.762785  \n",
       "78  0.804828  0.838147  \n",
       "79  0.800781  0.807817  \n",
       "80  0.749336  0.749680  \n",
       "81  0.753113  0.763429  \n",
       "\n",
       "[82 rows x 10 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_report.drop(['class'],axis = 1, inplace=True)\n",
    "f1_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_col</th>\n",
       "      <th>classifier</th>\n",
       "      <th>Church</th>\n",
       "      <th>Bolsonaro</th>\n",
       "      <th>Hydrox.</th>\n",
       "      <th>Sinovac</th>\n",
       "      <th>Globo TV</th>\n",
       "      <th>Lula</th>\n",
       "      <th>overall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Stance</td>\n",
       "      <td>dummy</td>\n",
       "      <td>0.361407</td>\n",
       "      <td>0.462857</td>\n",
       "      <td>0.334878</td>\n",
       "      <td>0.351759</td>\n",
       "      <td>0.372519</td>\n",
       "      <td>0.344578</td>\n",
       "      <td>0.371333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Stance</td>\n",
       "      <td>tf-idf + xgb</td>\n",
       "      <td>0.702021</td>\n",
       "      <td>0.595312</td>\n",
       "      <td>0.734366</td>\n",
       "      <td>0.752640</td>\n",
       "      <td>0.665243</td>\n",
       "      <td>0.654412</td>\n",
       "      <td>0.683999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Stance</td>\n",
       "      <td>bertabaporu-base + xgb</td>\n",
       "      <td>0.853801</td>\n",
       "      <td>0.625289</td>\n",
       "      <td>0.830948</td>\n",
       "      <td>0.808036</td>\n",
       "      <td>0.781858</td>\n",
       "      <td>0.766993</td>\n",
       "      <td>0.777821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Stance</td>\n",
       "      <td>bertabaporu-base</td>\n",
       "      <td>0.866276</td>\n",
       "      <td>0.737297</td>\n",
       "      <td>0.848144</td>\n",
       "      <td>0.834984</td>\n",
       "      <td>0.860252</td>\n",
       "      <td>0.789802</td>\n",
       "      <td>0.822792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Stance</td>\n",
       "      <td>llama3:7b zero-shot</td>\n",
       "      <td>0.729458</td>\n",
       "      <td>0.462857</td>\n",
       "      <td>0.638889</td>\n",
       "      <td>0.578779</td>\n",
       "      <td>0.770678</td>\n",
       "      <td>0.699381</td>\n",
       "      <td>0.646674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>Stacking Stance + Texts + Timeline + BoF + BoFr</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.721009</td>\n",
       "      <td>0.748214</td>\n",
       "      <td>0.876297</td>\n",
       "      <td>0.850709</td>\n",
       "      <td>0.631145</td>\n",
       "      <td>0.749336</td>\n",
       "      <td>0.762785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>Stacking Stance + Texts + BoM + BoF + BoFr</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.832816</td>\n",
       "      <td>0.776800</td>\n",
       "      <td>0.886751</td>\n",
       "      <td>0.860431</td>\n",
       "      <td>0.867255</td>\n",
       "      <td>0.804828</td>\n",
       "      <td>0.838147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>Stacking Stance + Timeline + BoM + BoF + BoFr</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.775539</td>\n",
       "      <td>0.748214</td>\n",
       "      <td>0.879788</td>\n",
       "      <td>0.845545</td>\n",
       "      <td>0.797037</td>\n",
       "      <td>0.800781</td>\n",
       "      <td>0.807817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>Stacking Texts + Timeline + BoM + BoF + BoFr</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.699811</td>\n",
       "      <td>0.728220</td>\n",
       "      <td>0.879782</td>\n",
       "      <td>0.858524</td>\n",
       "      <td>0.582406</td>\n",
       "      <td>0.749336</td>\n",
       "      <td>0.749680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>Stacking Stance + Texts + Timeline + BoM + BoF...</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.724133</td>\n",
       "      <td>0.748214</td>\n",
       "      <td>0.878043</td>\n",
       "      <td>0.850709</td>\n",
       "      <td>0.626364</td>\n",
       "      <td>0.753113</td>\n",
       "      <td>0.763429</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>82 rows  9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             text_col              classifier  \\\n",
       "0                                              Stance                   dummy   \n",
       "1                                              Stance            tf-idf + xgb   \n",
       "2                                              Stance  bertabaporu-base + xgb   \n",
       "3                                              Stance        bertabaporu-base   \n",
       "4                                              Stance     llama3:7b zero-shot   \n",
       "..                                                ...                     ...   \n",
       "77    Stacking Stance + Texts + Timeline + BoF + BoFr      LogisticRegression   \n",
       "78         Stacking Stance + Texts + BoM + BoF + BoFr      LogisticRegression   \n",
       "79      Stacking Stance + Timeline + BoM + BoF + BoFr      LogisticRegression   \n",
       "80       Stacking Texts + Timeline + BoM + BoF + BoFr      LogisticRegression   \n",
       "81  Stacking Stance + Texts + Timeline + BoM + BoF...      LogisticRegression   \n",
       "\n",
       "      Church  Bolsonaro   Hydrox.   Sinovac  Globo TV      Lula   overall  \n",
       "0   0.361407   0.462857  0.334878  0.351759  0.372519  0.344578  0.371333  \n",
       "1   0.702021   0.595312  0.734366  0.752640  0.665243  0.654412  0.683999  \n",
       "2   0.853801   0.625289  0.830948  0.808036  0.781858  0.766993  0.777821  \n",
       "3   0.866276   0.737297  0.848144  0.834984  0.860252  0.789802  0.822792  \n",
       "4   0.729458   0.462857  0.638889  0.578779  0.770678  0.699381  0.646674  \n",
       "..       ...        ...       ...       ...       ...       ...       ...  \n",
       "77  0.721009   0.748214  0.876297  0.850709  0.631145  0.749336  0.762785  \n",
       "78  0.832816   0.776800  0.886751  0.860431  0.867255  0.804828  0.838147  \n",
       "79  0.775539   0.748214  0.879788  0.845545  0.797037  0.800781  0.807817  \n",
       "80  0.699811   0.728220  0.879782  0.858524  0.582406  0.749336  0.749680  \n",
       "81  0.724133   0.748214  0.878043  0.850709  0.626364  0.753113  0.763429  \n",
       "\n",
       "[82 rows x 9 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_report.insert(\n",
    "    1, \n",
    "    \"classifier\", \n",
    "    f1_report.apply(\n",
    "        lambda x: f\"{x['vectorizer']} + {x['estimator']}\" if x['vectorizer'] != '-' else x['estimator'],\n",
    "        axis = 1\n",
    "        ).to_list()\n",
    "\n",
    ")\n",
    "f1_report.drop(['estimator', 'vectorizer'],axis =1, inplace = True)\n",
    "f1_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input</th>\n",
       "      <th>classifier</th>\n",
       "      <th>Church</th>\n",
       "      <th>Bolsonaro</th>\n",
       "      <th>Hydrox.</th>\n",
       "      <th>Sinovac</th>\n",
       "      <th>Globo TV</th>\n",
       "      <th>Lula</th>\n",
       "      <th>overall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Stance</td>\n",
       "      <td>dummy</td>\n",
       "      <td>0.361407</td>\n",
       "      <td>0.462857</td>\n",
       "      <td>0.334878</td>\n",
       "      <td>0.351759</td>\n",
       "      <td>0.372519</td>\n",
       "      <td>0.344578</td>\n",
       "      <td>0.371333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Stance</td>\n",
       "      <td>tf-idf + xgb</td>\n",
       "      <td>0.702021</td>\n",
       "      <td>0.595312</td>\n",
       "      <td>0.734366</td>\n",
       "      <td>0.752640</td>\n",
       "      <td>0.665243</td>\n",
       "      <td>0.654412</td>\n",
       "      <td>0.683999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Stance</td>\n",
       "      <td>bertabaporu-base + xgb</td>\n",
       "      <td>0.853801</td>\n",
       "      <td>0.625289</td>\n",
       "      <td>0.830948</td>\n",
       "      <td>0.808036</td>\n",
       "      <td>0.781858</td>\n",
       "      <td>0.766993</td>\n",
       "      <td>0.777821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Stance</td>\n",
       "      <td>bertabaporu-base</td>\n",
       "      <td>0.866276</td>\n",
       "      <td>0.737297</td>\n",
       "      <td>0.848144</td>\n",
       "      <td>0.834984</td>\n",
       "      <td>0.860252</td>\n",
       "      <td>0.789802</td>\n",
       "      <td>0.822792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Stance</td>\n",
       "      <td>llama3:7b zero-shot</td>\n",
       "      <td>0.729458</td>\n",
       "      <td>0.462857</td>\n",
       "      <td>0.638889</td>\n",
       "      <td>0.578779</td>\n",
       "      <td>0.770678</td>\n",
       "      <td>0.699381</td>\n",
       "      <td>0.646674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>Stacking Stance + Texts + Timeline + BoF + BoFr</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.721009</td>\n",
       "      <td>0.748214</td>\n",
       "      <td>0.876297</td>\n",
       "      <td>0.850709</td>\n",
       "      <td>0.631145</td>\n",
       "      <td>0.749336</td>\n",
       "      <td>0.762785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>Stacking Stance + Texts + BoM + BoF + BoFr</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.832816</td>\n",
       "      <td>0.776800</td>\n",
       "      <td>0.886751</td>\n",
       "      <td>0.860431</td>\n",
       "      <td>0.867255</td>\n",
       "      <td>0.804828</td>\n",
       "      <td>0.838147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>Stacking Stance + Timeline + BoM + BoF + BoFr</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.775539</td>\n",
       "      <td>0.748214</td>\n",
       "      <td>0.879788</td>\n",
       "      <td>0.845545</td>\n",
       "      <td>0.797037</td>\n",
       "      <td>0.800781</td>\n",
       "      <td>0.807817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>Stacking Texts + Timeline + BoM + BoF + BoFr</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.699811</td>\n",
       "      <td>0.728220</td>\n",
       "      <td>0.879782</td>\n",
       "      <td>0.858524</td>\n",
       "      <td>0.582406</td>\n",
       "      <td>0.749336</td>\n",
       "      <td>0.749680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>Stacking Stance + Texts + Timeline + BoM + BoF...</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.724133</td>\n",
       "      <td>0.748214</td>\n",
       "      <td>0.878043</td>\n",
       "      <td>0.850709</td>\n",
       "      <td>0.626364</td>\n",
       "      <td>0.753113</td>\n",
       "      <td>0.763429</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>82 rows  9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                input              classifier  \\\n",
       "0                                              Stance                   dummy   \n",
       "1                                              Stance            tf-idf + xgb   \n",
       "2                                              Stance  bertabaporu-base + xgb   \n",
       "3                                              Stance        bertabaporu-base   \n",
       "4                                              Stance     llama3:7b zero-shot   \n",
       "..                                                ...                     ...   \n",
       "77    Stacking Stance + Texts + Timeline + BoF + BoFr      LogisticRegression   \n",
       "78         Stacking Stance + Texts + BoM + BoF + BoFr      LogisticRegression   \n",
       "79      Stacking Stance + Timeline + BoM + BoF + BoFr      LogisticRegression   \n",
       "80       Stacking Texts + Timeline + BoM + BoF + BoFr      LogisticRegression   \n",
       "81  Stacking Stance + Texts + Timeline + BoM + BoF...      LogisticRegression   \n",
       "\n",
       "      Church  Bolsonaro   Hydrox.   Sinovac  Globo TV      Lula   overall  \n",
       "0   0.361407   0.462857  0.334878  0.351759  0.372519  0.344578  0.371333  \n",
       "1   0.702021   0.595312  0.734366  0.752640  0.665243  0.654412  0.683999  \n",
       "2   0.853801   0.625289  0.830948  0.808036  0.781858  0.766993  0.777821  \n",
       "3   0.866276   0.737297  0.848144  0.834984  0.860252  0.789802  0.822792  \n",
       "4   0.729458   0.462857  0.638889  0.578779  0.770678  0.699381  0.646674  \n",
       "..       ...        ...       ...       ...       ...       ...       ...  \n",
       "77  0.721009   0.748214  0.876297  0.850709  0.631145  0.749336  0.762785  \n",
       "78  0.832816   0.776800  0.886751  0.860431  0.867255  0.804828  0.838147  \n",
       "79  0.775539   0.748214  0.879788  0.845545  0.797037  0.800781  0.807817  \n",
       "80  0.699811   0.728220  0.879782  0.858524  0.582406  0.749336  0.749680  \n",
       "81  0.724133   0.748214  0.878043  0.850709  0.626364  0.753113  0.763429  \n",
       "\n",
       "[82 rows x 9 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_report.rename({\"text_col\":\"input\"}, axis = 1, inplace=True)\n",
    "f1_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#f1_report.set_index(['input'],inplace=True)\n",
    "#f1_report.drop('input', axis = 1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "input\n",
       "Texts                                                    8\n",
       "Timeline                                                 8\n",
       "Stance                                                   5\n",
       "Stacking Texts + Timeline + BoM + BoF + BoFr             1\n",
       "Stacking Stance + Timeline + BoM + BoF + BoFr            1\n",
       "                                                        ..\n",
       "Stacking Stance + Timeline + BoM                         1\n",
       "Stacking Stance + Timeline + BoF                         1\n",
       "Stacking Stance + Timeline + BoFr                        1\n",
       "Stacking Stance + BoM + BoF                              1\n",
       "Stacking Stance + Texts + Timeline + BoM + BoF + BoFr    1\n",
       "Name: count, Length: 64, dtype: int64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_report.input.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input</th>\n",
       "      <th>classifier</th>\n",
       "      <th>Church</th>\n",
       "      <th>Bolsonaro</th>\n",
       "      <th>Hydrox.</th>\n",
       "      <th>Sinovac</th>\n",
       "      <th>Globo TV</th>\n",
       "      <th>Lula</th>\n",
       "      <th>overall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Stance</td>\n",
       "      <td>dummy</td>\n",
       "      <td>0.361407</td>\n",
       "      <td>0.462857</td>\n",
       "      <td>0.334878</td>\n",
       "      <td>0.351759</td>\n",
       "      <td>0.372519</td>\n",
       "      <td>0.344578</td>\n",
       "      <td>0.371333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Stance</td>\n",
       "      <td>tf-idf + xgb</td>\n",
       "      <td>0.702021</td>\n",
       "      <td>0.595312</td>\n",
       "      <td>0.734366</td>\n",
       "      <td>0.752640</td>\n",
       "      <td>0.665243</td>\n",
       "      <td>0.654412</td>\n",
       "      <td>0.683999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Stance</td>\n",
       "      <td>bertabaporu-base + xgb</td>\n",
       "      <td>0.853801</td>\n",
       "      <td>0.625289</td>\n",
       "      <td>0.830948</td>\n",
       "      <td>0.808036</td>\n",
       "      <td>0.781858</td>\n",
       "      <td>0.766993</td>\n",
       "      <td>0.777821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Stance</td>\n",
       "      <td>bertabaporu-base</td>\n",
       "      <td>0.866276</td>\n",
       "      <td>0.737297</td>\n",
       "      <td>0.848144</td>\n",
       "      <td>0.834984</td>\n",
       "      <td>0.860252</td>\n",
       "      <td>0.789802</td>\n",
       "      <td>0.822792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Stance</td>\n",
       "      <td>llama3:7b zero-shot</td>\n",
       "      <td>0.729458</td>\n",
       "      <td>0.462857</td>\n",
       "      <td>0.638889</td>\n",
       "      <td>0.578779</td>\n",
       "      <td>0.770678</td>\n",
       "      <td>0.699381</td>\n",
       "      <td>0.646674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>Stacking Stance + Texts + Timeline + BoF + BoFr</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.721009</td>\n",
       "      <td>0.748214</td>\n",
       "      <td>0.876297</td>\n",
       "      <td>0.850709</td>\n",
       "      <td>0.631145</td>\n",
       "      <td>0.749336</td>\n",
       "      <td>0.762785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>Stacking Stance + Texts + BoM + BoF + BoFr</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.832816</td>\n",
       "      <td>0.776800</td>\n",
       "      <td>0.886751</td>\n",
       "      <td>0.860431</td>\n",
       "      <td>0.867255</td>\n",
       "      <td>0.804828</td>\n",
       "      <td>0.838147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>Stacking Stance + Timeline + BoM + BoF + BoFr</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.775539</td>\n",
       "      <td>0.748214</td>\n",
       "      <td>0.879788</td>\n",
       "      <td>0.845545</td>\n",
       "      <td>0.797037</td>\n",
       "      <td>0.800781</td>\n",
       "      <td>0.807817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>Stacking Texts + Timeline + BoM + BoF + BoFr</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.699811</td>\n",
       "      <td>0.728220</td>\n",
       "      <td>0.879782</td>\n",
       "      <td>0.858524</td>\n",
       "      <td>0.582406</td>\n",
       "      <td>0.749336</td>\n",
       "      <td>0.749680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>Stacking Stance + Texts + Timeline + BoM + BoF...</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.724133</td>\n",
       "      <td>0.748214</td>\n",
       "      <td>0.878043</td>\n",
       "      <td>0.850709</td>\n",
       "      <td>0.626364</td>\n",
       "      <td>0.753113</td>\n",
       "      <td>0.763429</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>82 rows  9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                input              classifier  \\\n",
       "0                                              Stance                   dummy   \n",
       "1                                              Stance            tf-idf + xgb   \n",
       "2                                              Stance  bertabaporu-base + xgb   \n",
       "3                                              Stance        bertabaporu-base   \n",
       "4                                              Stance     llama3:7b zero-shot   \n",
       "..                                                ...                     ...   \n",
       "77    Stacking Stance + Texts + Timeline + BoF + BoFr      LogisticRegression   \n",
       "78         Stacking Stance + Texts + BoM + BoF + BoFr      LogisticRegression   \n",
       "79      Stacking Stance + Timeline + BoM + BoF + BoFr      LogisticRegression   \n",
       "80       Stacking Texts + Timeline + BoM + BoF + BoFr      LogisticRegression   \n",
       "81  Stacking Stance + Texts + Timeline + BoM + BoF...      LogisticRegression   \n",
       "\n",
       "      Church  Bolsonaro   Hydrox.   Sinovac  Globo TV      Lula   overall  \n",
       "0   0.361407   0.462857  0.334878  0.351759  0.372519  0.344578  0.371333  \n",
       "1   0.702021   0.595312  0.734366  0.752640  0.665243  0.654412  0.683999  \n",
       "2   0.853801   0.625289  0.830948  0.808036  0.781858  0.766993  0.777821  \n",
       "3   0.866276   0.737297  0.848144  0.834984  0.860252  0.789802  0.822792  \n",
       "4   0.729458   0.462857  0.638889  0.578779  0.770678  0.699381  0.646674  \n",
       "..       ...        ...       ...       ...       ...       ...       ...  \n",
       "77  0.721009   0.748214  0.876297  0.850709  0.631145  0.749336  0.762785  \n",
       "78  0.832816   0.776800  0.886751  0.860431  0.867255  0.804828  0.838147  \n",
       "79  0.775539   0.748214  0.879788  0.845545  0.797037  0.800781  0.807817  \n",
       "80  0.699811   0.728220  0.879782  0.858524  0.582406  0.749336  0.749680  \n",
       "81  0.724133   0.748214  0.878043  0.850709  0.626364  0.753113  0.763429  \n",
       "\n",
       "[82 rows x 9 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "str_latex = generate_latex_with_multirow_and_bold(f1_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{table}[H]\\scriptsize\\centering\\begin{tabular}{ll|rrrrrrr}\n",
      "\\toprule\n",
      "input & classifier & Church & Bolsonaro & Hydrox. & Sinovac & Globo TV & Lula & overall \\\\ \n",
      "\\midrule\n",
      "\\multirow{2}{*}{Stance} & dummy & 0.36 & 0.46 & 0.33 & 0.35 & 0.37 & 0.34 & 0.37 \\\\ \n",
      "& tf-idf + xgb & 0.70 & 0.60 & 0.73 & 0.75 & 0.67 & 0.65 & 0.68 \\\\ \n",
      "& bertabaporu-base + xgb & 0.85 & 0.63 & 0.83 & 0.81 & 0.78 & 0.77 & 0.78 \\\\ \n",
      "& \\textbf{bertabaporu-base} & \\textbf{0.87} & \\textbf{0.74} & \\textbf{0.85} & \\textbf{0.83} & \\textbf{0.86} & \\textbf{0.79} & \\textbf{0.82} \\\\ \n",
      "& llama3:7b zero-shot & 0.73 & 0.46 & 0.64 & 0.58 & 0.77 & 0.70 & 0.65 \\\\ \n",
      "\\cmidrule(lr){1-9}\n",
      "\\multirow{2}{*}{Texts} & dummy & 0.36 & 0.46 & 0.33 & 0.35 & 0.37 & 0.34 & 0.37 \\\\ \n",
      "& \\textbf{tf-idf + xgb} & \\textbf{0.60} & \\textbf{0.50} & \\textbf{0.60} & \\textbf{0.67} & \\textbf{0.55} & \\textbf{0.58} & \\textbf{0.58} \\\\ \n",
      "& bertabaporu-base + xgb & 0.59 & 0.50 & 0.61 & 0.66 & 0.53 & 0.57 & 0.58 \\\\ \n",
      "& bertabaporu-base & 0.59 & 0.46 & 0.45 & 0.61 & 0.51 & 0.48 & 0.52 \\\\ \n",
      "& bertabaporu-base (R) & 0.58 & 0.46 & 0.57 & 0.64 & 0.59 & 0.60 & 0.57 \\\\ \n",
      "& llama3:7b zero-shot [5] (R) & 0.50 & 0.30 & 0.47 & 0.47 & 0.49 & 0.51 & 0.46 \\\\ \n",
      "& llama3:7b zero-shot [10] (R) & 0.56 & 0.33 & 0.44 & 0.46 & 0.49 & 0.48 & 0.46 \\\\ \n",
      "& llama3:7b zero-shot [15] (R) & 0.50 & 0.29 & 0.42 & 0.46 & 0.48 & 0.54 & 0.45 \\\\ \n",
      "\\cmidrule(lr){1-9}\n",
      "\\multirow{2}{*}{Timeline} & dummy & 0.36 & 0.46 & 0.33 & 0.35 & 0.37 & 0.34 & 0.37 \\\\ \n",
      "& \\textbf{tf-idf + xgb} & \\textbf{0.70} & \\textbf{0.73} & \\textbf{0.90} & \\textbf{0.86} & \\textbf{0.60} & \\textbf{0.75} & \\textbf{0.76} \\\\ \n",
      "& bertabaporu-base + xgb & 0.66 & 0.69 & 0.78 & 0.78 & 0.59 & 0.65 & 0.69 \\\\ \n",
      "& bertabaporu-base & 0.65 & 0.77 & 0.81 & 0.80 & 0.58 & 0.63 & 0.71 \\\\ \n",
      "& bertabaporu-base (R) & 0.70 & 0.79 & 0.88 & 0.86 & 0.51 & 0.71 & 0.74 \\\\ \n",
      "& llama3:7b zero-shot [5] (R) & 0.61 & 0.59 & 0.64 & 0.53 & 0.56 & 0.51 & 0.57 \\\\ \n",
      "& llama3:7b zero-shot [10] (R) & 0.56 & 0.61 & 0.61 & 0.53 & 0.51 & 0.52 & 0.56 \\\\ \n",
      "& llama3:7b zero-shot [15] (R) & 0.60 & 0.59 & 0.61 & 0.52 & 0.52 & 0.53 & 0.56 \\\\ \n",
      "\\cmidrule(lr){1-9}\n",
      "\\multirow{2}{*}{Bag of Friends} & \\textbf{tf-idf + LogisticRegression} & \\textbf{0.64} & \\textbf{0.75} & \\textbf{0.84} & \\textbf{0.83} & \\textbf{0.59} & \\textbf{0.73} & \\textbf{0.73} \\\\ \n",
      "\\cmidrule(lr){1-9}\n",
      "\\multirow{2}{*}{Bag of Followers} & \\textbf{tf-idf + LogisticRegression} & \\textbf{0.61} & \\textbf{0.70} & \\textbf{0.82} & \\textbf{0.76} & \\textbf{0.57} & \\textbf{0.70} & \\textbf{0.69} \\\\ \n",
      "\\cmidrule(lr){1-9}\n",
      "\\multirow{2}{*}{Bag of Mentions} & \\textbf{tf-idf + LogisticRegression} & \\textbf{0.64} & \\textbf{0.73} & \\textbf{0.86} & \\textbf{0.84} & \\textbf{0.59} & \\textbf{0.71} & \\textbf{0.73} \\\\ \n",
      "\\cmidrule(lr){1-9}\n",
      "\\multirow{2}{*}{concat_Texts_Timeline} & \\textbf{tf-idf + xgb} & \\textbf{0.70} & \\textbf{0.73} & \\textbf{0.83} & \\textbf{0.83} & \\textbf{0.58} & \\textbf{0.68} & \\textbf{0.72} \\\\ \n",
      "\\cmidrule(lr){1-9}\n",
      "\\multirow{2}{*}{Stacking Stance + Texts} & \\textbf{LogisticRegression} & \\textbf{0.82} & \\textbf{0.80} & \\textbf{0.81} & \\textbf{0.81} & \\textbf{0.87} & \\textbf{0.75} & \\textbf{0.81} \\\\ \n",
      "\\cmidrule(lr){1-9}\n",
      "\\multirow{2}{*}{Stacking Stance + Timeline} & \\textbf{LogisticRegression} & \\textbf{0.78} & \\textbf{0.77} & \\textbf{0.91} & \\textbf{0.88} & \\textbf{0.80} & \\textbf{0.80} & \\textbf{0.82} \\\\ \n",
      "\\cmidrule(lr){1-9}\n",
      "\\multirow{2}{*}{Stacking Stance + BoM} & \\textbf{LogisticRegression} & \\textbf{0.84} & \\textbf{0.74} & \\textbf{0.89} & \\textbf{0.86} & \\textbf{0.87} & \\textbf{0.79} & \\textbf{0.83} \\\\ \n",
      "\\cmidrule(lr){1-9}\n",
      "\\multirow{2}{*}{Stacking Stance + BoF} & \\textbf{LogisticRegression} & \\textbf{0.85} & \\textbf{0.84} & \\textbf{0.88} & \\textbf{0.86} & \\textbf{0.86} & \\textbf{0.85} & \\textbf{0.86} \\\\ \n",
      "\\cmidrule(lr){1-9}\n",
      "\\multirow{2}{*}{Stacking Stance + BoFr} & \\textbf{LogisticRegression} & \\textbf{0.87} & \\textbf{0.75} & \\textbf{0.85} & \\textbf{0.83} & \\textbf{0.86} & \\textbf{0.79} & \\textbf{0.83} \\\\ \n",
      "\\cmidrule(lr){1-9}\n",
      "\\multirow{2}{*}{Stacking Texts + Timeline} & \\textbf{LogisticRegression} & \\textbf{0.70} & \\textbf{0.73} & \\textbf{0.90} & \\textbf{0.87} & \\textbf{0.59} & \\textbf{0.75} & \\textbf{0.75} \\\\ \n",
      "\\cmidrule(lr){1-9}\n",
      "\\multirow{2}{*}{Stacking Texts + BoM} & \\textbf{LogisticRegression} & \\textbf{0.64} & \\textbf{0.75} & \\textbf{0.83} & \\textbf{0.80} & \\textbf{0.59} & \\textbf{0.69} & \\textbf{0.72} \\\\ \n",
      "\\cmidrule(lr){1-9}\n",
      "\\multirow{2}{*}{Stacking Texts + BoF} & \\textbf{LogisticRegression} & \\textbf{0.65} & \\textbf{0.81} & \\textbf{0.76} & \\textbf{0.77} & \\textbf{0.54} & \\textbf{0.69} & \\textbf{0.71} \\\\ \n",
      "\\cmidrule(lr){1-9}\n",
      "\\multirow{2}{*}{Stacking Texts + BoFr} & \\textbf{LogisticRegression} & \\textbf{0.60} & \\textbf{0.53} & \\textbf{0.60} & \\textbf{0.67} & \\textbf{0.58} & \\textbf{0.58} & \\textbf{0.59} \\\\ \n",
      "\\cmidrule(lr){1-9}\n",
      "\\multirow{2}{*}{Stacking Timeline + BoM} & \\textbf{LogisticRegression} & \\textbf{0.65} & \\textbf{0.78} & \\textbf{0.90} & \\textbf{0.87} & \\textbf{0.57} & \\textbf{0.66} & \\textbf{0.74} \\\\ \n",
      "\\cmidrule(lr){1-9}\n",
      "\\multirow{2}{*}{Stacking Timeline + BoF} & \\textbf{LogisticRegression} & \\textbf{0.68} & \\textbf{0.77} & \\textbf{0.85} & \\textbf{0.87} & \\textbf{0.57} & \\textbf{0.68} & \\textbf{0.74} \\\\ \n",
      "\\cmidrule(lr){1-9}\n",
      "\\multirow{2}{*}{Stacking Timeline + BoFr} & \\textbf{LogisticRegression} & \\textbf{0.70} & \\textbf{0.73} & \\textbf{0.90} & \\textbf{0.87} & \\textbf{0.60} & \\textbf{0.75} & \\textbf{0.76} \\\\ \n",
      "\\cmidrule(lr){1-9}\n",
      "\\multirow{2}{*}{Stacking BoM + BoF} & \\textbf{LogisticRegression} & \\textbf{0.69} & \\textbf{0.71} & \\textbf{0.87} & \\textbf{0.84} & \\textbf{0.59} & \\textbf{0.72} & \\textbf{0.74} \\\\ \n",
      "\\cmidrule(lr){1-9}\n",
      "\\multirow{2}{*}{Stacking BoM + BoFr} & \\textbf{LogisticRegression} & \\textbf{0.65} & \\textbf{0.72} & \\textbf{0.86} & \\textbf{0.83} & \\textbf{0.58} & \\textbf{0.70} & \\textbf{0.72} \\\\ \n",
      "\\cmidrule(lr){1-9}\n",
      "\\multirow{2}{*}{Stacking BoF + BoFr} & \\textbf{LogisticRegression} & \\textbf{0.64} & \\textbf{0.77} & \\textbf{0.84} & \\textbf{0.83} & \\textbf{0.60} & \\textbf{0.72} & \\textbf{0.73} \\\\ \n",
      "\\cmidrule(lr){1-9}\n",
      "\\multirow{2}{*}{Stacking Stance + Texts + Timeline} & \\textbf{LogisticRegression} & \\textbf{0.74} & \\textbf{0.64} & \\textbf{0.85} & \\textbf{0.84} & \\textbf{0.69} & \\textbf{0.51} & \\textbf{0.71} \\\\ \n",
      "\\cmidrule(lr){1-9}\n",
      "\\multirow{2}{*}{Stacking Stance + Texts + BoM} & \\textbf{LogisticRegression} & \\textbf{0.86} & \\textbf{0.79} & \\textbf{0.88} & \\textbf{0.85} & \\textbf{0.87} & \\textbf{0.78} & \\textbf{0.84} \\\\ \n",
      "\\cmidrule(lr){1-9}\n",
      "\\multirow{2}{*}{Stacking Stance + Texts + BoF} & \\textbf{LogisticRegression} & \\textbf{0.82} & \\textbf{0.81} & \\textbf{0.88} & \\textbf{0.82} & \\textbf{0.87} & \\textbf{0.80} & \\textbf{0.83} \\\\ \n",
      "\\cmidrule(lr){1-9}\n",
      "\\multirow{2}{*}{Stacking Stance + Texts + BoFr} & \\textbf{LogisticRegression} & \\textbf{0.82} & \\textbf{0.80} & \\textbf{0.81} & \\textbf{0.81} & \\textbf{0.87} & \\textbf{0.75} & \\textbf{0.81} \\\\ \n",
      "\\cmidrule(lr){1-9}\n",
      "\\multirow{2}{*}{Stacking Stance + Timeline + BoM} & \\textbf{LogisticRegression} & \\textbf{0.78} & \\textbf{0.77} & \\textbf{0.91} & \\textbf{0.88} & \\textbf{0.81} & \\textbf{0.80} & \\textbf{0.82} \\\\ \n",
      "\\cmidrule(lr){1-9}\n",
      "\\multirow{2}{*}{Stacking Stance + Timeline + BoF} & \\textbf{LogisticRegression} & \\textbf{0.78} & \\textbf{0.77} & \\textbf{0.91} & \\textbf{0.88} & \\textbf{0.80} & \\textbf{0.80} & \\textbf{0.82} \\\\ \n",
      "\\cmidrule(lr){1-9}\n",
      "\\multirow{2}{*}{Stacking Stance + Timeline + BoFr} & \\textbf{LogisticRegression} & \\textbf{0.78} & \\textbf{0.77} & \\textbf{0.91} & \\textbf{0.88} & \\textbf{0.80} & \\textbf{0.80} & \\textbf{0.82} \\\\ \n",
      "\\cmidrule(lr){1-9}\n",
      "\\multirow{2}{*}{Stacking Stance + BoM + BoF} & \\textbf{LogisticRegression} & \\textbf{0.84} & \\textbf{0.76} & \\textbf{0.90} & \\textbf{0.87} & \\textbf{0.86} & \\textbf{0.81} & \\textbf{0.84} \\\\ \n",
      "\\cmidrule(lr){1-9}\n",
      "\\multirow{2}{*}{Stacking Stance + BoM + BoFr} & \\textbf{LogisticRegression} & \\textbf{0.84} & \\textbf{0.74} & \\textbf{0.89} & \\textbf{0.86} & \\textbf{0.87} & \\textbf{0.79} & \\textbf{0.83} \\\\ \n",
      "\\cmidrule(lr){1-9}\n",
      "\\multirow{2}{*}{Stacking Stance + BoF + BoFr} & \\textbf{LogisticRegression} & \\textbf{0.87} & \\textbf{0.81} & \\textbf{0.89} & \\textbf{0.87} & \\textbf{0.86} & \\textbf{0.84} & \\textbf{0.86} \\\\ \n",
      "\\cmidrule(lr){1-9}\n",
      "\\multirow{2}{*}{Stacking Texts + Timeline + BoM} & \\textbf{LogisticRegression} & \\textbf{0.69} & \\textbf{0.73} & \\textbf{0.88} & \\textbf{0.85} & \\textbf{0.58} & \\textbf{0.73} & \\textbf{0.74} \\\\ \n",
      "\\cmidrule(lr){1-9}\n",
      "\\multirow{2}{*}{Stacking Texts + Timeline + BoF} & \\textbf{LogisticRegression} & \\textbf{0.70} & \\textbf{0.73} & \\textbf{0.88} & \\textbf{0.86} & \\textbf{0.58} & \\textbf{0.75} & \\textbf{0.75} \\\\ \n",
      "\\cmidrule(lr){1-9}\n",
      "\\multirow{2}{*}{Stacking Texts + Timeline + BoFr} & \\textbf{LogisticRegression} & \\textbf{0.70} & \\textbf{0.73} & \\textbf{0.90} & \\textbf{0.87} & \\textbf{0.59} & \\textbf{0.75} & \\textbf{0.75} \\\\ \n",
      "\\cmidrule(lr){1-9}\n",
      "\\multirow{2}{*}{Stacking Texts + BoM + BoF} & \\textbf{LogisticRegression} & \\textbf{0.64} & \\textbf{0.76} & \\textbf{0.84} & \\textbf{0.82} & \\textbf{0.57} & \\textbf{0.71} & \\textbf{0.72} \\\\ \n",
      "\\cmidrule(lr){1-9}\n",
      "\\multirow{2}{*}{Stacking Texts + BoM + BoFr} & \\textbf{LogisticRegression} & \\textbf{0.64} & \\textbf{0.75} & \\textbf{0.83} & \\textbf{0.80} & \\textbf{0.59} & \\textbf{0.69} & \\textbf{0.72} \\\\ \n",
      "\\cmidrule(lr){1-9}\n",
      "\\multirow{2}{*}{Stacking Texts + BoF + BoFr} & \\textbf{LogisticRegression} & \\textbf{0.64} & \\textbf{0.80} & \\textbf{0.82} & \\textbf{0.82} & \\textbf{0.57} & \\textbf{0.70} & \\textbf{0.73} \\\\ \n",
      "\\cmidrule(lr){1-9}\n",
      "\\multirow{2}{*}{Stacking Timeline + BoM + BoF} & \\textbf{LogisticRegression} & \\textbf{0.69} & \\textbf{0.75} & \\textbf{0.91} & \\textbf{0.87} & \\textbf{0.58} & \\textbf{0.70} & \\textbf{0.75} \\\\ \n",
      "\\cmidrule(lr){1-9}\n",
      "\\multirow{2}{*}{Stacking Timeline + BoM + BoFr} & \\textbf{LogisticRegression} & \\textbf{0.65} & \\textbf{0.78} & \\textbf{0.90} & \\textbf{0.87} & \\textbf{0.57} & \\textbf{0.66} & \\textbf{0.74} \\\\ \n",
      "\\cmidrule(lr){1-9}\n",
      "\\multirow{2}{*}{Stacking Timeline + BoF + BoFr} & \\textbf{LogisticRegression} & \\textbf{0.69} & \\textbf{0.75} & \\textbf{0.90} & \\textbf{0.87} & \\textbf{0.58} & \\textbf{0.69} & \\textbf{0.75} \\\\ \n",
      "\\cmidrule(lr){1-9}\n",
      "\\multirow{2}{*}{Stacking BoM + BoF + BoFr} & \\textbf{LogisticRegression} & \\textbf{0.69} & \\textbf{0.73} & \\textbf{0.88} & \\textbf{0.86} & \\textbf{0.60} & \\textbf{0.73} & \\textbf{0.75} \\\\ \n",
      "\\cmidrule(lr){1-9}\n",
      "\\multirow{2}{*}{Stacking Stance + Texts + Timeline + BoM} & \\textbf{LogisticRegression} & \\textbf{0.70} & \\textbf{0.73} & \\textbf{0.88} & \\textbf{0.85} & \\textbf{0.61} & \\textbf{0.75} & \\textbf{0.75} \\\\ \n",
      "\\cmidrule(lr){1-9}\n",
      "\\multirow{2}{*}{Stacking Stance + Texts + Timeline + BoF} & \\textbf{LogisticRegression} & \\textbf{0.72} & \\textbf{0.73} & \\textbf{0.87} & \\textbf{0.85} & \\textbf{0.62} & \\textbf{0.75} & \\textbf{0.76} \\\\ \n",
      "\\cmidrule(lr){1-9}\n",
      "\\multirow{2}{*}{Stacking Stance + Texts + Timeline + BoFr} & \\textbf{LogisticRegression} & \\textbf{0.74} & \\textbf{0.64} & \\textbf{0.85} & \\textbf{0.84} & \\textbf{0.69} & \\textbf{0.51} & \\textbf{0.71} \\\\ \n",
      "\\cmidrule(lr){1-9}\n",
      "\\multirow{2}{*}{Stacking Stance + Texts + BoM + BoF} & \\textbf{LogisticRegression} & \\textbf{0.83} & \\textbf{0.78} & \\textbf{0.89} & \\textbf{0.85} & \\textbf{0.87} & \\textbf{0.80} & \\textbf{0.83} \\\\ \n",
      "\\cmidrule(lr){1-9}\n",
      "\\multirow{2}{*}{Stacking Stance + Texts + BoM + BoFr} & \\textbf{LogisticRegression} & \\textbf{0.86} & \\textbf{0.79} & \\textbf{0.88} & \\textbf{0.85} & \\textbf{0.87} & \\textbf{0.78} & \\textbf{0.84} \\\\ \n",
      "\\cmidrule(lr){1-9}\n",
      "\\multirow{2}{*}{Stacking Stance + Texts + BoF + BoFr} & \\textbf{LogisticRegression} & \\textbf{0.82} & \\textbf{0.83} & \\textbf{0.88} & \\textbf{0.85} & \\textbf{0.87} & \\textbf{0.79} & \\textbf{0.84} \\\\ \n",
      "\\cmidrule(lr){1-9}\n",
      "\\multirow{2}{*}{Stacking Stance + Timeline + BoM + BoF} & \\textbf{LogisticRegression} & \\textbf{0.78} & \\textbf{0.77} & \\textbf{0.88} & \\textbf{0.85} & \\textbf{0.81} & \\textbf{0.80} & \\textbf{0.81} \\\\ \n",
      "\\cmidrule(lr){1-9}\n",
      "\\multirow{2}{*}{Stacking Stance + Timeline + BoM + BoFr} & \\textbf{LogisticRegression} & \\textbf{0.78} & \\textbf{0.77} & \\textbf{0.91} & \\textbf{0.88} & \\textbf{0.81} & \\textbf{0.80} & \\textbf{0.82} \\\\ \n",
      "\\cmidrule(lr){1-9}\n",
      "\\multirow{2}{*}{Stacking Stance + Timeline + BoF + BoFr} & \\textbf{LogisticRegression} & \\textbf{0.78} & \\textbf{0.75} & \\textbf{0.92} & \\textbf{0.85} & \\textbf{0.80} & \\textbf{0.80} & \\textbf{0.81} \\\\ \n",
      "\\cmidrule(lr){1-9}\n",
      "\\multirow{2}{*}{Stacking Stance + BoM + BoF + BoFr} & \\textbf{LogisticRegression} & \\textbf{0.84} & \\textbf{0.73} & \\textbf{0.90} & \\textbf{0.87} & \\textbf{0.87} & \\textbf{0.83} & \\textbf{0.84} \\\\ \n",
      "\\cmidrule(lr){1-9}\n",
      "\\multirow{2}{*}{Stacking Texts + Timeline + BoM + BoF} & \\textbf{LogisticRegression} & \\textbf{0.70} & \\textbf{0.73} & \\textbf{0.88} & \\textbf{0.86} & \\textbf{0.58} & \\textbf{0.75} & \\textbf{0.75} \\\\ \n",
      "\\cmidrule(lr){1-9}\n",
      "\\multirow{2}{*}{Stacking Texts + Timeline + BoM + BoFr} & \\textbf{LogisticRegression} & \\textbf{0.69} & \\textbf{0.73} & \\textbf{0.88} & \\textbf{0.85} & \\textbf{0.58} & \\textbf{0.73} & \\textbf{0.74} \\\\ \n",
      "\\cmidrule(lr){1-9}\n",
      "\\multirow{2}{*}{Stacking Texts + Timeline + BoF + BoFr} & \\textbf{LogisticRegression} & \\textbf{0.70} & \\textbf{0.73} & \\textbf{0.88} & \\textbf{0.86} & \\textbf{0.59} & \\textbf{0.73} & \\textbf{0.75} \\\\ \n",
      "\\cmidrule(lr){1-9}\n",
      "\\multirow{2}{*}{Stacking Texts + BoM + BoF + BoFr} & \\textbf{LogisticRegression} & \\textbf{0.65} & \\textbf{0.75} & \\textbf{0.86} & \\textbf{0.83} & \\textbf{0.58} & \\textbf{0.72} & \\textbf{0.73} \\\\ \n",
      "\\cmidrule(lr){1-9}\n",
      "\\multirow{2}{*}{Stacking Timeline + BoM + BoF + BoFr} & \\textbf{LogisticRegression} & \\textbf{0.69} & \\textbf{0.75} & \\textbf{0.91} & \\textbf{0.87} & \\textbf{0.59} & \\textbf{0.70} & \\textbf{0.75} \\\\ \n",
      "\\cmidrule(lr){1-9}\n",
      "\\multirow{2}{*}{Stacking Stance + Texts + Timeline + BoM + BoF} & \\textbf{LogisticRegression} & \\textbf{0.73} & \\textbf{0.73} & \\textbf{0.88} & \\textbf{0.85} & \\textbf{0.62} & \\textbf{0.75} & \\textbf{0.76} \\\\ \n",
      "\\cmidrule(lr){1-9}\n",
      "\\multirow{2}{*}{Stacking Stance + Texts + Timeline + BoM + BoFr} & \\textbf{LogisticRegression} & \\textbf{0.70} & \\textbf{0.73} & \\textbf{0.88} & \\textbf{0.85} & \\textbf{0.61} & \\textbf{0.75} & \\textbf{0.75} \\\\ \n",
      "\\cmidrule(lr){1-9}\n",
      "\\multirow{2}{*}{Stacking Stance + Texts + Timeline + BoF + BoFr} & \\textbf{LogisticRegression} & \\textbf{0.72} & \\textbf{0.75} & \\textbf{0.88} & \\textbf{0.85} & \\textbf{0.63} & \\textbf{0.75} & \\textbf{0.76} \\\\ \n",
      "\\cmidrule(lr){1-9}\n",
      "\\multirow{2}{*}{Stacking Stance + Texts + BoM + BoF + BoFr} & \\textbf{LogisticRegression} & \\textbf{0.83} & \\textbf{0.78} & \\textbf{0.89} & \\textbf{0.86} & \\textbf{0.87} & \\textbf{0.80} & \\textbf{0.84} \\\\ \n",
      "\\cmidrule(lr){1-9}\n",
      "\\multirow{1}{*}{Stacking Stance + Timeline + BoM + BoF + BoFr} & \\textbf{LogisticRegression} & \\textbf{0.78} & \\textbf{0.75} & \\textbf{0.88} & \\textbf{0.85} & \\textbf{0.80} & \\textbf{0.80} & \\textbf{0.81} \\\\ \n",
      "\\cmidrule(lr){1-9}\n",
      "\\multirow{1}{*}{Stacking Texts + Timeline + BoM + BoF + BoFr} & \\textbf{LogisticRegression} & \\textbf{0.70} & \\textbf{0.73} & \\textbf{0.88} & \\textbf{0.86} & \\textbf{0.58} & \\textbf{0.75} & \\textbf{0.75} \\\\ \n",
      "\\cmidrule(lr){1-9}\n",
      "\\multirow{1}{*}{Stacking Stance + Texts + Timeline + BoM + BoF + BoFr} & \\textbf{LogisticRegression} & \\textbf{0.72} & \\textbf{0.75} & \\textbf{0.88} & \\textbf{0.85} & \\textbf{0.63} & \\textbf{0.75} & \\textbf{0.76} \\\\ \n",
      "\\cmidrule(lr){1-9}\n",
      "\\bottomrule\n",
      "\\end{tabular}\\caption{F1 macro results}\\label{table:results_f1_macro}\n",
      "\\end{table}\n"
     ]
    }
   ],
   "source": [
    "print(str_latex)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env-stance-pred",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
