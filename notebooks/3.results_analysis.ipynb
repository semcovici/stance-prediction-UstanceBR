{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.metrics import classification_report\n",
    "from tqdm import tqdm\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../src')\n",
    "\n",
    "from models.classification_methods import get_classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['DummyClassifier_bo_top_mentioned_timelines_Texts_test_results.csv',\n",
       " 'DummyClassifier_bo_users_Stance_test_results.csv',\n",
       " 'DummyClassifier_bo_users_Timeline_test_results.csv',\n",
       " 'DummyClassifier_cl_top_mentioned_timelines_Texts_test_results.csv',\n",
       " 'DummyClassifier_cl_users_Stance_test_results.csv',\n",
       " 'DummyClassifier_cl_users_Timeline_test_results.csv',\n",
       " 'DummyClassifier_co_top_mentioned_timelines_Texts_test_results.csv',\n",
       " 'DummyClassifier_co_users_Stance_test_results.csv',\n",
       " 'DummyClassifier_co_users_Timeline_test_results.csv',\n",
       " 'DummyClassifier_gl_top_mentioned_timelines_Texts_test_results.csv',\n",
       " 'DummyClassifier_gl_users_Stance_test_results.csv',\n",
       " 'DummyClassifier_gl_users_Timeline_test_results.csv',\n",
       " 'DummyClassifier_ig_top_mentioned_timelines_Texts_test_results.csv',\n",
       " 'DummyClassifier_ig_users_Stance_test_results.csv',\n",
       " 'DummyClassifier_ig_users_Timeline_test_results.csv',\n",
       " 'DummyClassifier_lu_top_mentioned_timelines_Texts_test_results.csv',\n",
       " 'DummyClassifier_lu_users_Stance_test_results.csv',\n",
       " 'DummyClassifier_lu_users_Timeline_test_results.csv',\n",
       " 'XGBClassifier_TfidfVectorizer_bo_top_mentioned_timelines_Texts_test_results.csv',\n",
       " 'XGBClassifier_TfidfVectorizer_bo_users_Stance_test_results.csv',\n",
       " 'XGBClassifier_TfidfVectorizer_bo_users_Timeline_test_results.csv',\n",
       " 'XGBClassifier_TfidfVectorizer_cl_top_mentioned_timelines_Texts_test_results.csv',\n",
       " 'XGBClassifier_TfidfVectorizer_cl_users_Stance_test_results.csv',\n",
       " 'XGBClassifier_TfidfVectorizer_cl_users_Timeline_test_results.csv',\n",
       " 'XGBClassifier_TfidfVectorizer_co_top_mentioned_timelines_Texts_test_results.csv',\n",
       " 'XGBClassifier_TfidfVectorizer_co_users_Stance_test_results.csv',\n",
       " 'XGBClassifier_TfidfVectorizer_co_users_Timeline_test_results.csv',\n",
       " 'XGBClassifier_TfidfVectorizer_gl_top_mentioned_timelines_Texts_test_results.csv',\n",
       " 'XGBClassifier_TfidfVectorizer_gl_users_Stance_test_results.csv',\n",
       " 'XGBClassifier_TfidfVectorizer_gl_users_Timeline_test_results.csv',\n",
       " 'XGBClassifier_TfidfVectorizer_ig_top_mentioned_timelines_Texts_test_results.csv',\n",
       " 'XGBClassifier_TfidfVectorizer_ig_users_Stance_test_results.csv',\n",
       " 'XGBClassifier_TfidfVectorizer_ig_users_Timeline_test_results.csv',\n",
       " 'XGBClassifier_TfidfVectorizer_lu_top_mentioned_timelines_Texts_test_results.csv',\n",
       " 'XGBClassifier_TfidfVectorizer_lu_users_Stance_test_results.csv',\n",
       " 'XGBClassifier_TfidfVectorizer_lu_users_Timeline_test_results.csv',\n",
       " 'belt_filteredTimeline10_pablocosta_bertabaporu-base-uncased_test_results.csv',\n",
       " 'belt_filteredTimeline10_pablocosta_bertabaporu-base-uncased_test_results_part_bo.csv',\n",
       " 'belt_filteredTimeline10_pablocosta_bertabaporu-base-uncased_test_results_part_cl.csv',\n",
       " 'belt_filteredTimeline10_pablocosta_bertabaporu-base-uncased_test_results_part_co.csv',\n",
       " 'belt_filteredTimeline10_pablocosta_bertabaporu-base-uncased_test_results_part_gl.csv',\n",
       " 'belt_filteredTimeline10_pablocosta_bertabaporu-base-uncased_test_results_part_ig.csv',\n",
       " 'belt_filteredTimeline10_pablocosta_bertabaporu-base-uncased_test_results_part_lu.csv',\n",
       " 'belt_filteredTimeline15_pablocosta_bertabaporu-base-uncased_test_results.csv',\n",
       " 'belt_filteredTimeline15_pablocosta_bertabaporu-base-uncased_test_results_part_bo.csv',\n",
       " 'belt_filteredTimeline15_pablocosta_bertabaporu-base-uncased_test_results_part_cl.csv',\n",
       " 'belt_filteredTimeline15_pablocosta_bertabaporu-base-uncased_test_results_part_co.csv',\n",
       " 'belt_filteredTimeline15_pablocosta_bertabaporu-base-uncased_test_results_part_gl.csv',\n",
       " 'belt_filteredTimeline15_pablocosta_bertabaporu-base-uncased_test_results_part_ig.csv',\n",
       " 'belt_filteredTimeline15_pablocosta_bertabaporu-base-uncased_test_results_part_lu.csv',\n",
       " 'belt_filteredTimeline5_pablocosta_bertabaporu-base-uncased_test_results.csv',\n",
       " 'belt_filteredTimeline5_pablocosta_bertabaporu-base-uncased_test_results_part_bo.csv',\n",
       " 'belt_filteredTimeline5_pablocosta_bertabaporu-base-uncased_test_results_part_cl.csv',\n",
       " 'belt_filteredTimeline5_pablocosta_bertabaporu-base-uncased_test_results_part_co.csv',\n",
       " 'belt_filteredTimeline5_pablocosta_bertabaporu-base-uncased_test_results_part_gl.csv',\n",
       " 'belt_filteredTimeline5_pablocosta_bertabaporu-base-uncased_test_results_part_ig.csv',\n",
       " 'belt_filteredTimeline5_pablocosta_bertabaporu-base-uncased_test_results_part_lu.csv',\n",
       " 'belt_filtered_Texts10_pablocosta_bertabaporu-base-uncased_test_results.csv',\n",
       " 'belt_filtered_Texts10_pablocosta_bertabaporu-base-uncased_test_results_part_bo.csv',\n",
       " 'belt_filtered_Texts10_pablocosta_bertabaporu-base-uncased_test_results_part_cl.csv',\n",
       " 'belt_filtered_Texts10_pablocosta_bertabaporu-base-uncased_test_results_part_co.csv',\n",
       " 'belt_filtered_Texts10_pablocosta_bertabaporu-base-uncased_test_results_part_gl.csv',\n",
       " 'belt_filtered_Texts10_pablocosta_bertabaporu-base-uncased_test_results_part_ig.csv',\n",
       " 'belt_filtered_Texts10_pablocosta_bertabaporu-base-uncased_test_results_part_lu.csv',\n",
       " 'belt_filtered_Texts15_pablocosta_bertabaporu-base-uncased_test_results.csv',\n",
       " 'belt_filtered_Texts15_pablocosta_bertabaporu-base-uncased_test_results_part_bo.csv',\n",
       " 'belt_filtered_Texts15_pablocosta_bertabaporu-base-uncased_test_results_part_cl.csv',\n",
       " 'belt_filtered_Texts15_pablocosta_bertabaporu-base-uncased_test_results_part_co.csv',\n",
       " 'belt_filtered_Texts15_pablocosta_bertabaporu-base-uncased_test_results_part_gl.csv',\n",
       " 'belt_filtered_Texts15_pablocosta_bertabaporu-base-uncased_test_results_part_ig.csv',\n",
       " 'belt_filtered_Texts15_pablocosta_bertabaporu-base-uncased_test_results_part_lu.csv',\n",
       " 'belt_filtered_Texts5_pablocosta_bertabaporu-base-uncased_test_results.csv',\n",
       " 'belt_filtered_Texts5_pablocosta_bertabaporu-base-uncased_test_results_part_bo.csv',\n",
       " 'belt_filtered_Texts5_pablocosta_bertabaporu-base-uncased_test_results_part_cl.csv',\n",
       " 'belt_filtered_Texts5_pablocosta_bertabaporu-base-uncased_test_results_part_co.csv',\n",
       " 'belt_filtered_Texts5_pablocosta_bertabaporu-base-uncased_test_results_part_gl.csv',\n",
       " 'belt_filtered_Texts5_pablocosta_bertabaporu-base-uncased_test_results_part_ig.csv',\n",
       " 'belt_filtered_Texts5_pablocosta_bertabaporu-base-uncased_test_results_part_lu.csv',\n",
       " 'bert_classifier_pablocosta_bertabaporu_base_uncased_bo_Stance_test_results.csv',\n",
       " 'bert_classifier_pablocosta_bertabaporu_base_uncased_bo_Texts_test_results.csv',\n",
       " 'bert_classifier_pablocosta_bertabaporu_base_uncased_bo_Timeline_test_results.csv',\n",
       " 'bert_classifier_pablocosta_bertabaporu_base_uncased_bo_scored_Timeline_test_results.csv',\n",
       " 'bert_classifier_pablocosta_bertabaporu_base_uncased_cl_Stance_test_results.csv',\n",
       " 'bert_classifier_pablocosta_bertabaporu_base_uncased_cl_Texts_test_results.csv',\n",
       " 'bert_classifier_pablocosta_bertabaporu_base_uncased_cl_Timeline_test_results.csv',\n",
       " 'bert_classifier_pablocosta_bertabaporu_base_uncased_cl_scored_Timeline_test_results.csv',\n",
       " 'bert_classifier_pablocosta_bertabaporu_base_uncased_co_Stance_test_results.csv',\n",
       " 'bert_classifier_pablocosta_bertabaporu_base_uncased_co_Texts_test_results.csv',\n",
       " 'bert_classifier_pablocosta_bertabaporu_base_uncased_co_Timeline_test_results.csv',\n",
       " 'bert_classifier_pablocosta_bertabaporu_base_uncased_co_scored_Timeline_test_results.csv',\n",
       " 'bert_classifier_pablocosta_bertabaporu_base_uncased_gl_Stance_test_results.csv',\n",
       " 'bert_classifier_pablocosta_bertabaporu_base_uncased_gl_Texts_test_results.csv',\n",
       " 'bert_classifier_pablocosta_bertabaporu_base_uncased_gl_Timeline_test_results.csv',\n",
       " 'bert_classifier_pablocosta_bertabaporu_base_uncased_gl_scored_Timeline_test_results.csv',\n",
       " 'bert_classifier_pablocosta_bertabaporu_base_uncased_ig_Stance_test_results.csv',\n",
       " 'bert_classifier_pablocosta_bertabaporu_base_uncased_ig_Texts_test_results.csv',\n",
       " 'bert_classifier_pablocosta_bertabaporu_base_uncased_ig_Timeline_test_results.csv',\n",
       " 'bert_classifier_pablocosta_bertabaporu_base_uncased_ig_scored_Timeline_test_results.csv',\n",
       " 'bert_classifier_pablocosta_bertabaporu_base_uncased_lu_Stance_test_results.csv',\n",
       " 'bert_classifier_pablocosta_bertabaporu_base_uncased_lu_Texts_test_results.csv',\n",
       " 'bert_classifier_pablocosta_bertabaporu_base_uncased_lu_Timeline_test_results.csv',\n",
       " 'bert_classifier_pablocosta_bertabaporu_base_uncased_lu_scored_Timeline_test_results.csv',\n",
       " 'bertimbau_xgb_bo_top_mentioned_timelines_emb_Texts_test_results.csv',\n",
       " 'bertimbau_xgb_bo_users_emb_Stance_test_results.csv',\n",
       " 'bertimbau_xgb_bo_users_emb_Timeline_test_results.csv',\n",
       " 'bertimbau_xgb_cl_top_mentioned_timelines_emb_Texts_test_results.csv',\n",
       " 'bertimbau_xgb_cl_users_emb_Stance_test_results.csv',\n",
       " 'bertimbau_xgb_cl_users_emb_Timeline_test_results.csv',\n",
       " 'bertimbau_xgb_co_top_mentioned_timelines_emb_Texts_test_results.csv',\n",
       " 'bertimbau_xgb_co_users_emb_Stance_test_results.csv',\n",
       " 'bertimbau_xgb_co_users_emb_Timeline_test_results.csv',\n",
       " 'bertimbau_xgb_gl_top_mentioned_timelines_emb_Texts_test_results.csv',\n",
       " 'bertimbau_xgb_gl_users_emb_Stance_test_results.csv',\n",
       " 'bertimbau_xgb_gl_users_emb_Timeline_test_results.csv',\n",
       " 'bertimbau_xgb_ig_top_mentioned_timelines_emb_Texts_test_results.csv',\n",
       " 'bertimbau_xgb_ig_users_emb_Stance_test_results.csv',\n",
       " 'bertimbau_xgb_ig_users_emb_Timeline_test_results.csv',\n",
       " 'bertimbau_xgb_lu_top_mentioned_timelines_emb_Texts_test_results.csv',\n",
       " 'bertimbau_xgb_lu_users_emb_Stance_test_results.csv',\n",
       " 'bertimbau_xgb_lu_users_emb_Timeline_test_results.csv',\n",
       " 'llama3_bo_Stance_prompt2_Stance_test_results.csv',\n",
       " 'llama3_bo_filteredTimeline10_prompt2_Timeline_test_results.csv',\n",
       " 'llama3_bo_filteredTimeline15_prompt2_Timeline_test_results.csv',\n",
       " 'llama3_bo_filteredTimeline5_prompt2_Timeline_test_results.csv',\n",
       " 'llama3_bo_filtered_Texts10_prompt2_Texts_test_results.csv',\n",
       " 'llama3_bo_filtered_Texts15_prompt2_Texts_test_results.csv',\n",
       " 'llama3_bo_filtered_Texts20_prompt2_Texts_test_results.csv',\n",
       " 'llama3_bo_filtered_Texts5_prompt2_Texts_test_results.csv',\n",
       " 'llama3_cl_Stance_prompt2_Stance_test_results.csv',\n",
       " 'llama3_cl_filteredTimeline10_prompt2_Timeline_test_results.csv',\n",
       " 'llama3_cl_filteredTimeline15_prompt2_Timeline_test_results.csv',\n",
       " 'llama3_cl_filteredTimeline5_prompt2_Timeline_test_results.csv',\n",
       " 'llama3_cl_filtered_Texts10_prompt2_Texts_test_results.csv',\n",
       " 'llama3_cl_filtered_Texts15_prompt2_Texts_test_results.csv',\n",
       " 'llama3_cl_filtered_Texts20_prompt2_Texts_test_results.csv',\n",
       " 'llama3_cl_filtered_Texts5_prompt2_Texts_test_results.csv',\n",
       " 'llama3_co_Stance_prompt2_Stance_test_results.csv',\n",
       " 'llama3_co_filteredTimeline10_prompt2_Timeline_test_results.csv',\n",
       " 'llama3_co_filteredTimeline15_prompt2_Timeline_test_results.csv',\n",
       " 'llama3_co_filteredTimeline5_prompt2_Timeline_test_results.csv',\n",
       " 'llama3_co_filtered_Texts10_prompt2_Texts_test_results.csv',\n",
       " 'llama3_co_filtered_Texts15_prompt2_Texts_test_results.csv',\n",
       " 'llama3_co_filtered_Texts5_prompt2_Texts_test_results.csv',\n",
       " 'llama3_gl_Stance_prompt2_Stance_test_results.csv',\n",
       " 'llama3_gl_filteredTimeline10_prompt2_Timeline_test_results.csv',\n",
       " 'llama3_gl_filteredTimeline15_prompt2_Timeline_test_results.csv',\n",
       " 'llama3_gl_filteredTimeline5_prompt2_Timeline_test_results.csv',\n",
       " 'llama3_gl_filtered_Texts10_prompt2_Texts_test_results.csv',\n",
       " 'llama3_gl_filtered_Texts15_prompt2_Texts_test_results.csv',\n",
       " 'llama3_gl_filtered_Texts5_prompt2_Texts_test_results.csv',\n",
       " 'llama3_ig_Stance_prompt2_Stance_test_results.csv',\n",
       " 'llama3_ig_filteredTimeline10_prompt2_Timeline_test_results.csv',\n",
       " 'llama3_ig_filteredTimeline15_prompt2_Timeline_test_results.csv',\n",
       " 'llama3_ig_filteredTimeline5_prompt2_Timeline_test_results.csv',\n",
       " 'llama3_ig_filtered_Texts10_prompt2_Texts_test_results.csv',\n",
       " 'llama3_ig_filtered_Texts15_prompt2_Texts_test_results.csv',\n",
       " 'llama3_ig_filtered_Texts20_prompt2_Texts_test_results.csv',\n",
       " 'llama3_ig_filtered_Texts5_prompt2_Texts_test_results.csv',\n",
       " 'llama3_lu_Stance_prompt2_Stance_test_results.csv',\n",
       " 'llama3_lu_filteredTimeline10_prompt2_Timeline_test_results.csv',\n",
       " 'llama3_lu_filteredTimeline15_prompt2_Timeline_test_results.csv',\n",
       " 'llama3_lu_filteredTimeline5_prompt2_Timeline_test_results.csv',\n",
       " 'llama3_lu_filtered_Texts10_prompt2_Texts_test_results.csv',\n",
       " 'llama3_lu_filtered_Texts15_prompt2_Texts_test_results.csv',\n",
       " 'llama3_lu_filtered_Texts5_prompt2_Texts_test_results.csv',\n",
       " 'old']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_results_path = '../reports/test_results/'\n",
    "\n",
    "list_df_t = os.listdir(test_results_path)\n",
    "list_df_t.sort()\n",
    "list_df_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hydrox.', 'Lula', 'Sinovac', 'Church', 'Globo TV', 'Bolsonaro']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Target list\n",
    "target_list = [\n",
    "    'ig',\n",
    "    'bo', \n",
    "    'cl', \n",
    "    'co', \n",
    "    'gl', \n",
    "    'lu'\n",
    "]\n",
    "\n",
    "dict_cp = {\n",
    "    'cl':'Hydrox.',\n",
    "    'lu':'Lula',\n",
    "    'co':'Sinovac',\n",
    "    'ig':'Church',\n",
    "    'gl':'Globo TV',\n",
    "    'bo':'Bolsonaro',\n",
    "}\n",
    "\n",
    "names = list(dict_cp.values())\n",
    "names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create complete table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (vectorizer,estimator, path_sring) \n",
    "results_tuples_stance = [\n",
    "    # Stance\n",
    "    (\"Stance\", \"-\" ,\"dummy\", \"DummyClassifier_{target}_users_Stance_test_results.csv\"),\n",
    "    (\"Stance\", \"tf-idf\" ,\"xgb\", \"XGBClassifier_TfidfVectorizer_{target}_users_Stance_test_results.csv\"),\n",
    "    (\"Stance\", \"bertabaporu-base\" ,\"xgb\", \"bertimbau_xgb_{target}_users_emb_Stance_test_results.csv\"),\n",
    "    (\"Stance\", \"-\" ,\"bertabaporu-base\", \"bert_classifier_pablocosta_bertabaporu_base_uncased_{target}_Stance_test_results.csv\"),\n",
    "    (\"Stance\", \"-\",  \"llama3:7b zero-shot\", \"llama3_{target}_Stance_prompt2_Stance_test_results.csv\"),\n",
    "    \n",
    "    # Texts\n",
    "    (\"Texts\", \"-\" ,\"dummy\", \"DummyClassifier_{target}_top_mentioned_timelines_Texts_test_results.csv\"),\n",
    "    (\"Texts\", \"tf-idf\" ,\"xgb\", \"XGBClassifier_TfidfVectorizer_{target}_top_mentioned_timelines_Texts_test_results.csv\"),\n",
    "    (\"Texts\", \"bertabaporu-base\" ,\"xgb\", \"bertimbau_xgb_{target}_top_mentioned_timelines_emb_Texts_test_results.csv\"),\n",
    "    (\"Texts\", \"-\" ,\"bertabaporu-base\", \"bert_classifier_pablocosta_bertabaporu_base_uncased_{target}_Texts_test_results.csv\"),\n",
    "    (\"Texts\", \"-\" ,\"bertabaporu-base (R)\", \"bert_classifier_pablocosta_bertabaporu_base_uncased_{target}_scored_Texts_test_results.csv\"),\n",
    "    (\"Texts\", \"-\", \"llama3:7b zero-shot [5] (R)\", \"llama3_{target}_filtered_Texts5_prompt2_Texts_test_results.csv\"),\n",
    "    (\"Texts\", \"-\", \"llama3:7b zero-shot [10] (R)\", \"llama3_{target}_filtered_Texts10_prompt2_Texts_test_results.csv\"),\n",
    "    (\"Texts\", \"-\", \"llama3:7b zero-shot [15] (R)\", \"llama3_{target}_filtered_Texts15_prompt2_Texts_test_results.csv\"),\n",
    "    \n",
    "    # Timeline\n",
    "    (\"Timeline\", \"-\" ,\"dummy\", \"DummyClassifier_{target}_users_Timeline_test_results.csv\"),\n",
    "    (\"Timeline\", \"tf-idf\" ,\"xgb\", \"XGBClassifier_TfidfVectorizer_{target}_users_Timeline_test_results.csv\"),\n",
    "    (\"Timeline\", \"bertabaporu-base\" ,\"xgb\", \"bertimbau_xgb_{target}_users_emb_Timeline_test_results.csv\"),\n",
    "    (\"Timeline\", \"-\" ,\"bertabaporu-base\", \"bert_classifier_pablocosta_bertabaporu_base_uncased_{target}_Timeline_test_results.csv\"),\n",
    "    (\"Timeline\", \"-\" ,\"bertabaporu-base (R)\", \"bert_classifier_pablocosta_bertabaporu_base_uncased_{target}_scored_Timeline_test_results.csv\"),\n",
    "    (\"Timeline\", \"-\", \"llama3:7b zero-shot [5] (R)\", \"llama3_{target}_filteredTimeline5_prompt2_Timeline_test_results.csv\"),\n",
    "    (\"Timeline\", \"-\", \"llama3:7b zero-shot [10] (R)\", \"llama3_{target}_filteredTimeline10_prompt2_Timeline_test_results.csv\"),\n",
    "    (\"Timeline\", \"-\", \"llama3:7b zero-shot [15] (R)\", \"llama3_{target}_filteredTimeline15_prompt2_Timeline_test_results.csv\"),\n",
    "]\n",
    "\n",
    "list_results = []\n",
    "for text_col, vectorizer, estimator, path_results in results_tuples_stance:\n",
    "    \n",
    "    list_cr = []\n",
    "    \n",
    "    for target in target_list:\n",
    "        \n",
    "        \n",
    "        path = test_results_path + path_results.format(target = target)\n",
    "        df_results = pd.read_csv(path)\n",
    "        df_results_or = df_results.copy()\n",
    "        \n",
    "        # get classification report df\n",
    "        df_classification_report = get_classification_report(df_results.test, df_results.pred, cr_args = {})\n",
    "        \n",
    "        # create multindex\n",
    "        column_indexes = [(metric,dict_cp[target]) for metric in df_classification_report.columns]\n",
    "        multi_index_cols = pd.MultiIndex.from_tuples(column_indexes, names=['metric', 'target'])\n",
    "        rows_indexes = [(text_col, vectorizer, estimator, cl) for cl in df_classification_report.index]\n",
    "        multi_index_rows = pd.MultiIndex.from_tuples(rows_indexes, names=['text_col','vectorizer', 'estimator', 'class'])\n",
    "        df_classification_report.columns = multi_index_cols\n",
    "        df_classification_report.index = multi_index_rows\n",
    "        \n",
    "        # print(text_col, vectorizer, estimator,target)\n",
    "        # print(path)\n",
    "        # display(df_classification_report)\n",
    "        \n",
    "        list_cr.append(df_classification_report)\n",
    "        \n",
    "    df_results = pd.concat(list_cr, axis = 1)\n",
    "    \n",
    "    list_results.append(df_results)\n",
    "    \n",
    "df_results_final = pd.concat(list_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>metric</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>...</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>Church</th>\n",
       "      <th>Church</th>\n",
       "      <th>Church</th>\n",
       "      <th>Church</th>\n",
       "      <th>Bolsonaro</th>\n",
       "      <th>Bolsonaro</th>\n",
       "      <th>Bolsonaro</th>\n",
       "      <th>Bolsonaro</th>\n",
       "      <th>Hydrox.</th>\n",
       "      <th>Hydrox.</th>\n",
       "      <th>...</th>\n",
       "      <th>Sinovac</th>\n",
       "      <th>Sinovac</th>\n",
       "      <th>Globo TV</th>\n",
       "      <th>Globo TV</th>\n",
       "      <th>Globo TV</th>\n",
       "      <th>Globo TV</th>\n",
       "      <th>Lula</th>\n",
       "      <th>Lula</th>\n",
       "      <th>Lula</th>\n",
       "      <th>Lula</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text_col</th>\n",
       "      <th>vectorizer</th>\n",
       "      <th>estimator</th>\n",
       "      <th>class</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">Stance</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">-</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">dummy</th>\n",
       "      <th>against</th>\n",
       "      <td>0.565943</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.722814</td>\n",
       "      <td>339.000000</td>\n",
       "      <td>0.861702</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.925714</td>\n",
       "      <td>162.000000</td>\n",
       "      <td>0.503484</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>354.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>167.000000</td>\n",
       "      <td>0.525735</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.689157</td>\n",
       "      <td>143.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.565943</td>\n",
       "      <td>0.565943</td>\n",
       "      <td>0.565943</td>\n",
       "      <td>0.565943</td>\n",
       "      <td>0.861702</td>\n",
       "      <td>0.861702</td>\n",
       "      <td>0.861702</td>\n",
       "      <td>0.861702</td>\n",
       "      <td>0.503484</td>\n",
       "      <td>0.503484</td>\n",
       "      <td>...</td>\n",
       "      <td>0.542636</td>\n",
       "      <td>0.542636</td>\n",
       "      <td>0.593674</td>\n",
       "      <td>0.593674</td>\n",
       "      <td>0.593674</td>\n",
       "      <td>0.593674</td>\n",
       "      <td>0.525735</td>\n",
       "      <td>0.525735</td>\n",
       "      <td>0.525735</td>\n",
       "      <td>0.525735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.320292</td>\n",
       "      <td>0.565943</td>\n",
       "      <td>0.409072</td>\n",
       "      <td>599.000000</td>\n",
       "      <td>0.742531</td>\n",
       "      <td>0.861702</td>\n",
       "      <td>0.797690</td>\n",
       "      <td>188.000000</td>\n",
       "      <td>0.253496</td>\n",
       "      <td>0.503484</td>\n",
       "      <td>...</td>\n",
       "      <td>0.381754</td>\n",
       "      <td>774.000000</td>\n",
       "      <td>0.352449</td>\n",
       "      <td>0.593674</td>\n",
       "      <td>0.442310</td>\n",
       "      <td>411.000000</td>\n",
       "      <td>0.276398</td>\n",
       "      <td>0.525735</td>\n",
       "      <td>0.362314</td>\n",
       "      <td>272.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.282972</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.361407</td>\n",
       "      <td>599.000000</td>\n",
       "      <td>0.430851</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.462857</td>\n",
       "      <td>188.000000</td>\n",
       "      <td>0.251742</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.351759</td>\n",
       "      <td>774.000000</td>\n",
       "      <td>0.296837</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.372519</td>\n",
       "      <td>411.000000</td>\n",
       "      <td>0.262868</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.344578</td>\n",
       "      <td>272.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>for</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>260.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.703518</td>\n",
       "      <td>420.000000</td>\n",
       "      <td>0.593674</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.745038</td>\n",
       "      <td>244.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>129.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">Timeline</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">-</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">llama3:7b zero-shot [15] (R)</th>\n",
       "      <th>against</th>\n",
       "      <td>0.640306</td>\n",
       "      <td>0.740413</td>\n",
       "      <td>0.686731</td>\n",
       "      <td>339.000000</td>\n",
       "      <td>0.915385</td>\n",
       "      <td>0.734568</td>\n",
       "      <td>0.815068</td>\n",
       "      <td>162.000000</td>\n",
       "      <td>0.719298</td>\n",
       "      <td>0.425606</td>\n",
       "      <td>...</td>\n",
       "      <td>0.488276</td>\n",
       "      <td>354.000000</td>\n",
       "      <td>0.424084</td>\n",
       "      <td>0.485030</td>\n",
       "      <td>0.452514</td>\n",
       "      <td>167.000000</td>\n",
       "      <td>0.552632</td>\n",
       "      <td>0.587413</td>\n",
       "      <td>0.569492</td>\n",
       "      <td>143.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.617696</td>\n",
       "      <td>0.617696</td>\n",
       "      <td>0.617696</td>\n",
       "      <td>0.617696</td>\n",
       "      <td>0.712766</td>\n",
       "      <td>0.712766</td>\n",
       "      <td>0.712766</td>\n",
       "      <td>0.712766</td>\n",
       "      <td>0.627178</td>\n",
       "      <td>0.627178</td>\n",
       "      <td>...</td>\n",
       "      <td>0.520672</td>\n",
       "      <td>0.520672</td>\n",
       "      <td>0.523114</td>\n",
       "      <td>0.523114</td>\n",
       "      <td>0.523114</td>\n",
       "      <td>0.523114</td>\n",
       "      <td>0.533088</td>\n",
       "      <td>0.533088</td>\n",
       "      <td>0.533088</td>\n",
       "      <td>0.533088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.611907</td>\n",
       "      <td>0.617696</td>\n",
       "      <td>0.609861</td>\n",
       "      <td>599.000000</td>\n",
       "      <td>0.824556</td>\n",
       "      <td>0.712766</td>\n",
       "      <td>0.751738</td>\n",
       "      <td>188.000000</td>\n",
       "      <td>0.654151</td>\n",
       "      <td>0.627178</td>\n",
       "      <td>...</td>\n",
       "      <td>0.521341</td>\n",
       "      <td>774.000000</td>\n",
       "      <td>0.533918</td>\n",
       "      <td>0.523114</td>\n",
       "      <td>0.526766</td>\n",
       "      <td>411.000000</td>\n",
       "      <td>0.531622</td>\n",
       "      <td>0.533088</td>\n",
       "      <td>0.531772</td>\n",
       "      <td>272.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.607593</td>\n",
       "      <td>0.599053</td>\n",
       "      <td>0.598183</td>\n",
       "      <td>599.000000</td>\n",
       "      <td>0.587003</td>\n",
       "      <td>0.655745</td>\n",
       "      <td>0.586106</td>\n",
       "      <td>188.000000</td>\n",
       "      <td>0.653694</td>\n",
       "      <td>0.628592</td>\n",
       "      <td>...</td>\n",
       "      <td>0.518743</td>\n",
       "      <td>774.000000</td>\n",
       "      <td>0.516587</td>\n",
       "      <td>0.517105</td>\n",
       "      <td>0.515050</td>\n",
       "      <td>411.000000</td>\n",
       "      <td>0.530482</td>\n",
       "      <td>0.530140</td>\n",
       "      <td>0.529726</td>\n",
       "      <td>272.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>for</th>\n",
       "      <td>0.574879</td>\n",
       "      <td>0.457692</td>\n",
       "      <td>0.509636</td>\n",
       "      <td>260.000000</td>\n",
       "      <td>0.258621</td>\n",
       "      <td>0.576923</td>\n",
       "      <td>0.357143</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>0.588089</td>\n",
       "      <td>0.831579</td>\n",
       "      <td>...</td>\n",
       "      <td>0.549210</td>\n",
       "      <td>420.000000</td>\n",
       "      <td>0.609091</td>\n",
       "      <td>0.549180</td>\n",
       "      <td>0.577586</td>\n",
       "      <td>244.000000</td>\n",
       "      <td>0.508333</td>\n",
       "      <td>0.472868</td>\n",
       "      <td>0.489960</td>\n",
       "      <td>129.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows Ã— 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "metric                                                        precision  \\\n",
       "target                                                           Church   \n",
       "text_col vectorizer estimator                    class                    \n",
       "Stance   -          dummy                        against       0.565943   \n",
       "                                                 accuracy      0.565943   \n",
       "                                                 weighted avg  0.320292   \n",
       "                                                 macro avg     0.282972   \n",
       "                                                 for           0.000000   \n",
       "...                                                                 ...   \n",
       "Timeline -          llama3:7b zero-shot [15] (R) against       0.640306   \n",
       "                                                 accuracy      0.617696   \n",
       "                                                 weighted avg  0.611907   \n",
       "                                                 macro avg     0.607593   \n",
       "                                                 for           0.574879   \n",
       "\n",
       "metric                                                           recall  \\\n",
       "target                                                           Church   \n",
       "text_col vectorizer estimator                    class                    \n",
       "Stance   -          dummy                        against       1.000000   \n",
       "                                                 accuracy      0.565943   \n",
       "                                                 weighted avg  0.565943   \n",
       "                                                 macro avg     0.500000   \n",
       "                                                 for           0.000000   \n",
       "...                                                                 ...   \n",
       "Timeline -          llama3:7b zero-shot [15] (R) against       0.740413   \n",
       "                                                 accuracy      0.617696   \n",
       "                                                 weighted avg  0.617696   \n",
       "                                                 macro avg     0.599053   \n",
       "                                                 for           0.457692   \n",
       "\n",
       "metric                                                         f1-score  \\\n",
       "target                                                           Church   \n",
       "text_col vectorizer estimator                    class                    \n",
       "Stance   -          dummy                        against       0.722814   \n",
       "                                                 accuracy      0.565943   \n",
       "                                                 weighted avg  0.409072   \n",
       "                                                 macro avg     0.361407   \n",
       "                                                 for           0.000000   \n",
       "...                                                                 ...   \n",
       "Timeline -          llama3:7b zero-shot [15] (R) against       0.686731   \n",
       "                                                 accuracy      0.617696   \n",
       "                                                 weighted avg  0.609861   \n",
       "                                                 macro avg     0.598183   \n",
       "                                                 for           0.509636   \n",
       "\n",
       "metric                                                            support  \\\n",
       "target                                                             Church   \n",
       "text_col vectorizer estimator                    class                      \n",
       "Stance   -          dummy                        against       339.000000   \n",
       "                                                 accuracy        0.565943   \n",
       "                                                 weighted avg  599.000000   \n",
       "                                                 macro avg     599.000000   \n",
       "                                                 for           260.000000   \n",
       "...                                                                   ...   \n",
       "Timeline -          llama3:7b zero-shot [15] (R) against       339.000000   \n",
       "                                                 accuracy        0.617696   \n",
       "                                                 weighted avg  599.000000   \n",
       "                                                 macro avg     599.000000   \n",
       "                                                 for           260.000000   \n",
       "\n",
       "metric                                                        precision  \\\n",
       "target                                                        Bolsonaro   \n",
       "text_col vectorizer estimator                    class                    \n",
       "Stance   -          dummy                        against       0.861702   \n",
       "                                                 accuracy      0.861702   \n",
       "                                                 weighted avg  0.742531   \n",
       "                                                 macro avg     0.430851   \n",
       "                                                 for           0.000000   \n",
       "...                                                                 ...   \n",
       "Timeline -          llama3:7b zero-shot [15] (R) against       0.915385   \n",
       "                                                 accuracy      0.712766   \n",
       "                                                 weighted avg  0.824556   \n",
       "                                                 macro avg     0.587003   \n",
       "                                                 for           0.258621   \n",
       "\n",
       "metric                                                           recall  \\\n",
       "target                                                        Bolsonaro   \n",
       "text_col vectorizer estimator                    class                    \n",
       "Stance   -          dummy                        against       1.000000   \n",
       "                                                 accuracy      0.861702   \n",
       "                                                 weighted avg  0.861702   \n",
       "                                                 macro avg     0.500000   \n",
       "                                                 for           0.000000   \n",
       "...                                                                 ...   \n",
       "Timeline -          llama3:7b zero-shot [15] (R) against       0.734568   \n",
       "                                                 accuracy      0.712766   \n",
       "                                                 weighted avg  0.712766   \n",
       "                                                 macro avg     0.655745   \n",
       "                                                 for           0.576923   \n",
       "\n",
       "metric                                                         f1-score  \\\n",
       "target                                                        Bolsonaro   \n",
       "text_col vectorizer estimator                    class                    \n",
       "Stance   -          dummy                        against       0.925714   \n",
       "                                                 accuracy      0.861702   \n",
       "                                                 weighted avg  0.797690   \n",
       "                                                 macro avg     0.462857   \n",
       "                                                 for           0.000000   \n",
       "...                                                                 ...   \n",
       "Timeline -          llama3:7b zero-shot [15] (R) against       0.815068   \n",
       "                                                 accuracy      0.712766   \n",
       "                                                 weighted avg  0.751738   \n",
       "                                                 macro avg     0.586106   \n",
       "                                                 for           0.357143   \n",
       "\n",
       "metric                                                            support  \\\n",
       "target                                                          Bolsonaro   \n",
       "text_col vectorizer estimator                    class                      \n",
       "Stance   -          dummy                        against       162.000000   \n",
       "                                                 accuracy        0.861702   \n",
       "                                                 weighted avg  188.000000   \n",
       "                                                 macro avg     188.000000   \n",
       "                                                 for            26.000000   \n",
       "...                                                                   ...   \n",
       "Timeline -          llama3:7b zero-shot [15] (R) against       162.000000   \n",
       "                                                 accuracy        0.712766   \n",
       "                                                 weighted avg  188.000000   \n",
       "                                                 macro avg     188.000000   \n",
       "                                                 for            26.000000   \n",
       "\n",
       "metric                                                        precision  \\\n",
       "target                                                          Hydrox.   \n",
       "text_col vectorizer estimator                    class                    \n",
       "Stance   -          dummy                        against       0.503484   \n",
       "                                                 accuracy      0.503484   \n",
       "                                                 weighted avg  0.253496   \n",
       "                                                 macro avg     0.251742   \n",
       "                                                 for           0.000000   \n",
       "...                                                                 ...   \n",
       "Timeline -          llama3:7b zero-shot [15] (R) against       0.719298   \n",
       "                                                 accuracy      0.627178   \n",
       "                                                 weighted avg  0.654151   \n",
       "                                                 macro avg     0.653694   \n",
       "                                                 for           0.588089   \n",
       "\n",
       "metric                                                           recall  ...  \\\n",
       "target                                                          Hydrox.  ...   \n",
       "text_col vectorizer estimator                    class                   ...   \n",
       "Stance   -          dummy                        against       1.000000  ...   \n",
       "                                                 accuracy      0.503484  ...   \n",
       "                                                 weighted avg  0.503484  ...   \n",
       "                                                 macro avg     0.500000  ...   \n",
       "                                                 for           0.000000  ...   \n",
       "...                                                                 ...  ...   \n",
       "Timeline -          llama3:7b zero-shot [15] (R) against       0.425606  ...   \n",
       "                                                 accuracy      0.627178  ...   \n",
       "                                                 weighted avg  0.627178  ...   \n",
       "                                                 macro avg     0.628592  ...   \n",
       "                                                 for           0.831579  ...   \n",
       "\n",
       "metric                                                         f1-score  \\\n",
       "target                                                          Sinovac   \n",
       "text_col vectorizer estimator                    class                    \n",
       "Stance   -          dummy                        against       0.000000   \n",
       "                                                 accuracy      0.542636   \n",
       "                                                 weighted avg  0.381754   \n",
       "                                                 macro avg     0.351759   \n",
       "                                                 for           0.703518   \n",
       "...                                                                 ...   \n",
       "Timeline -          llama3:7b zero-shot [15] (R) against       0.488276   \n",
       "                                                 accuracy      0.520672   \n",
       "                                                 weighted avg  0.521341   \n",
       "                                                 macro avg     0.518743   \n",
       "                                                 for           0.549210   \n",
       "\n",
       "metric                                                            support  \\\n",
       "target                                                            Sinovac   \n",
       "text_col vectorizer estimator                    class                      \n",
       "Stance   -          dummy                        against       354.000000   \n",
       "                                                 accuracy        0.542636   \n",
       "                                                 weighted avg  774.000000   \n",
       "                                                 macro avg     774.000000   \n",
       "                                                 for           420.000000   \n",
       "...                                                                   ...   \n",
       "Timeline -          llama3:7b zero-shot [15] (R) against       354.000000   \n",
       "                                                 accuracy        0.520672   \n",
       "                                                 weighted avg  774.000000   \n",
       "                                                 macro avg     774.000000   \n",
       "                                                 for           420.000000   \n",
       "\n",
       "metric                                                        precision  \\\n",
       "target                                                         Globo TV   \n",
       "text_col vectorizer estimator                    class                    \n",
       "Stance   -          dummy                        against       0.000000   \n",
       "                                                 accuracy      0.593674   \n",
       "                                                 weighted avg  0.352449   \n",
       "                                                 macro avg     0.296837   \n",
       "                                                 for           0.593674   \n",
       "...                                                                 ...   \n",
       "Timeline -          llama3:7b zero-shot [15] (R) against       0.424084   \n",
       "                                                 accuracy      0.523114   \n",
       "                                                 weighted avg  0.533918   \n",
       "                                                 macro avg     0.516587   \n",
       "                                                 for           0.609091   \n",
       "\n",
       "metric                                                           recall  \\\n",
       "target                                                         Globo TV   \n",
       "text_col vectorizer estimator                    class                    \n",
       "Stance   -          dummy                        against       0.000000   \n",
       "                                                 accuracy      0.593674   \n",
       "                                                 weighted avg  0.593674   \n",
       "                                                 macro avg     0.500000   \n",
       "                                                 for           1.000000   \n",
       "...                                                                 ...   \n",
       "Timeline -          llama3:7b zero-shot [15] (R) against       0.485030   \n",
       "                                                 accuracy      0.523114   \n",
       "                                                 weighted avg  0.523114   \n",
       "                                                 macro avg     0.517105   \n",
       "                                                 for           0.549180   \n",
       "\n",
       "metric                                                         f1-score  \\\n",
       "target                                                         Globo TV   \n",
       "text_col vectorizer estimator                    class                    \n",
       "Stance   -          dummy                        against       0.000000   \n",
       "                                                 accuracy      0.593674   \n",
       "                                                 weighted avg  0.442310   \n",
       "                                                 macro avg     0.372519   \n",
       "                                                 for           0.745038   \n",
       "...                                                                 ...   \n",
       "Timeline -          llama3:7b zero-shot [15] (R) against       0.452514   \n",
       "                                                 accuracy      0.523114   \n",
       "                                                 weighted avg  0.526766   \n",
       "                                                 macro avg     0.515050   \n",
       "                                                 for           0.577586   \n",
       "\n",
       "metric                                                            support  \\\n",
       "target                                                           Globo TV   \n",
       "text_col vectorizer estimator                    class                      \n",
       "Stance   -          dummy                        against       167.000000   \n",
       "                                                 accuracy        0.593674   \n",
       "                                                 weighted avg  411.000000   \n",
       "                                                 macro avg     411.000000   \n",
       "                                                 for           244.000000   \n",
       "...                                                                   ...   \n",
       "Timeline -          llama3:7b zero-shot [15] (R) against       167.000000   \n",
       "                                                 accuracy        0.523114   \n",
       "                                                 weighted avg  411.000000   \n",
       "                                                 macro avg     411.000000   \n",
       "                                                 for           244.000000   \n",
       "\n",
       "metric                                                        precision  \\\n",
       "target                                                             Lula   \n",
       "text_col vectorizer estimator                    class                    \n",
       "Stance   -          dummy                        against       0.525735   \n",
       "                                                 accuracy      0.525735   \n",
       "                                                 weighted avg  0.276398   \n",
       "                                                 macro avg     0.262868   \n",
       "                                                 for           0.000000   \n",
       "...                                                                 ...   \n",
       "Timeline -          llama3:7b zero-shot [15] (R) against       0.552632   \n",
       "                                                 accuracy      0.533088   \n",
       "                                                 weighted avg  0.531622   \n",
       "                                                 macro avg     0.530482   \n",
       "                                                 for           0.508333   \n",
       "\n",
       "metric                                                           recall  \\\n",
       "target                                                             Lula   \n",
       "text_col vectorizer estimator                    class                    \n",
       "Stance   -          dummy                        against       1.000000   \n",
       "                                                 accuracy      0.525735   \n",
       "                                                 weighted avg  0.525735   \n",
       "                                                 macro avg     0.500000   \n",
       "                                                 for           0.000000   \n",
       "...                                                                 ...   \n",
       "Timeline -          llama3:7b zero-shot [15] (R) against       0.587413   \n",
       "                                                 accuracy      0.533088   \n",
       "                                                 weighted avg  0.533088   \n",
       "                                                 macro avg     0.530140   \n",
       "                                                 for           0.472868   \n",
       "\n",
       "metric                                                         f1-score  \\\n",
       "target                                                             Lula   \n",
       "text_col vectorizer estimator                    class                    \n",
       "Stance   -          dummy                        against       0.689157   \n",
       "                                                 accuracy      0.525735   \n",
       "                                                 weighted avg  0.362314   \n",
       "                                                 macro avg     0.344578   \n",
       "                                                 for           0.000000   \n",
       "...                                                                 ...   \n",
       "Timeline -          llama3:7b zero-shot [15] (R) against       0.569492   \n",
       "                                                 accuracy      0.533088   \n",
       "                                                 weighted avg  0.531772   \n",
       "                                                 macro avg     0.529726   \n",
       "                                                 for           0.489960   \n",
       "\n",
       "metric                                                            support  \n",
       "target                                                               Lula  \n",
       "text_col vectorizer estimator                    class                     \n",
       "Stance   -          dummy                        against       143.000000  \n",
       "                                                 accuracy        0.525735  \n",
       "                                                 weighted avg  272.000000  \n",
       "                                                 macro avg     272.000000  \n",
       "                                                 for           129.000000  \n",
       "...                                                                   ...  \n",
       "Timeline -          llama3:7b zero-shot [15] (R) against       143.000000  \n",
       "                                                 accuracy        0.533088  \n",
       "                                                 weighted avg  272.000000  \n",
       "                                                 macro avg     272.000000  \n",
       "                                                 for           129.000000  \n",
       "\n",
       "[100 rows x 24 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results_final.to_excel(\"../reports/table_complete_results.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create table f1 macro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>metric</th>\n",
       "      <th colspan=\"7\" halign=\"left\">f1-score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>Church</th>\n",
       "      <th>Bolsonaro</th>\n",
       "      <th>Hydrox.</th>\n",
       "      <th>Sinovac</th>\n",
       "      <th>Globo TV</th>\n",
       "      <th>Lula</th>\n",
       "      <th>overall</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text_col</th>\n",
       "      <th>vectorizer</th>\n",
       "      <th>estimator</th>\n",
       "      <th>class</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">Stance</th>\n",
       "      <th>-</th>\n",
       "      <th>dummy</th>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.361407</td>\n",
       "      <td>0.462857</td>\n",
       "      <td>0.334878</td>\n",
       "      <td>0.351759</td>\n",
       "      <td>0.372519</td>\n",
       "      <td>0.344578</td>\n",
       "      <td>0.371333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tf-idf</th>\n",
       "      <th>xgb</th>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.702021</td>\n",
       "      <td>0.595312</td>\n",
       "      <td>0.734366</td>\n",
       "      <td>0.752640</td>\n",
       "      <td>0.665243</td>\n",
       "      <td>0.654412</td>\n",
       "      <td>0.683999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bertabaporu-base</th>\n",
       "      <th>xgb</th>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.853801</td>\n",
       "      <td>0.625289</td>\n",
       "      <td>0.830948</td>\n",
       "      <td>0.808036</td>\n",
       "      <td>0.781858</td>\n",
       "      <td>0.766993</td>\n",
       "      <td>0.777821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">-</th>\n",
       "      <th>bertabaporu-base</th>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.866276</td>\n",
       "      <td>0.734945</td>\n",
       "      <td>0.844740</td>\n",
       "      <td>0.823002</td>\n",
       "      <td>0.875418</td>\n",
       "      <td>0.782733</td>\n",
       "      <td>0.821186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>llama3:7b zero-shot</th>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.729458</td>\n",
       "      <td>0.462857</td>\n",
       "      <td>0.638889</td>\n",
       "      <td>0.578779</td>\n",
       "      <td>0.770678</td>\n",
       "      <td>0.699381</td>\n",
       "      <td>0.646674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"7\" valign=\"top\">Texts</th>\n",
       "      <th>-</th>\n",
       "      <th>dummy</th>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.361407</td>\n",
       "      <td>0.462857</td>\n",
       "      <td>0.334878</td>\n",
       "      <td>0.351759</td>\n",
       "      <td>0.372519</td>\n",
       "      <td>0.344578</td>\n",
       "      <td>0.371333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tf-idf</th>\n",
       "      <th>xgb</th>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.596115</td>\n",
       "      <td>0.501220</td>\n",
       "      <td>0.603727</td>\n",
       "      <td>0.670805</td>\n",
       "      <td>0.545620</td>\n",
       "      <td>0.579427</td>\n",
       "      <td>0.582819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bertabaporu-base</th>\n",
       "      <th>xgb</th>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.594754</td>\n",
       "      <td>0.495578</td>\n",
       "      <td>0.609524</td>\n",
       "      <td>0.660542</td>\n",
       "      <td>0.534455</td>\n",
       "      <td>0.569597</td>\n",
       "      <td>0.577408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">-</th>\n",
       "      <th>bertabaporu-base</th>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.586611</td>\n",
       "      <td>0.462857</td>\n",
       "      <td>0.446504</td>\n",
       "      <td>0.608972</td>\n",
       "      <td>0.507381</td>\n",
       "      <td>0.482520</td>\n",
       "      <td>0.515808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>llama3:7b zero-shot [5] (R)</th>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.499052</td>\n",
       "      <td>0.296142</td>\n",
       "      <td>0.469796</td>\n",
       "      <td>0.470381</td>\n",
       "      <td>0.490101</td>\n",
       "      <td>0.512954</td>\n",
       "      <td>0.456404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>llama3:7b zero-shot [10] (R)</th>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.561274</td>\n",
       "      <td>0.328245</td>\n",
       "      <td>0.440347</td>\n",
       "      <td>0.460580</td>\n",
       "      <td>0.494646</td>\n",
       "      <td>0.478244</td>\n",
       "      <td>0.460556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>llama3:7b zero-shot [15] (R)</th>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.503966</td>\n",
       "      <td>0.285253</td>\n",
       "      <td>0.416946</td>\n",
       "      <td>0.464074</td>\n",
       "      <td>0.475797</td>\n",
       "      <td>0.542401</td>\n",
       "      <td>0.448073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"8\" valign=\"top\">Timeline</th>\n",
       "      <th>-</th>\n",
       "      <th>dummy</th>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.361407</td>\n",
       "      <td>0.462857</td>\n",
       "      <td>0.334878</td>\n",
       "      <td>0.351759</td>\n",
       "      <td>0.372519</td>\n",
       "      <td>0.344578</td>\n",
       "      <td>0.371333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tf-idf</th>\n",
       "      <th>xgb</th>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.699122</td>\n",
       "      <td>0.728220</td>\n",
       "      <td>0.898944</td>\n",
       "      <td>0.863813</td>\n",
       "      <td>0.598358</td>\n",
       "      <td>0.752710</td>\n",
       "      <td>0.756861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bertabaporu-base</th>\n",
       "      <th>xgb</th>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.661773</td>\n",
       "      <td>0.692262</td>\n",
       "      <td>0.776979</td>\n",
       "      <td>0.778471</td>\n",
       "      <td>0.585105</td>\n",
       "      <td>0.645518</td>\n",
       "      <td>0.690018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">-</th>\n",
       "      <th>bertabaporu-base</th>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.652707</td>\n",
       "      <td>0.767310</td>\n",
       "      <td>0.822297</td>\n",
       "      <td>0.819813</td>\n",
       "      <td>0.580105</td>\n",
       "      <td>0.614923</td>\n",
       "      <td>0.709526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bertabaporu-base (R)</th>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.701990</td>\n",
       "      <td>0.822060</td>\n",
       "      <td>0.872170</td>\n",
       "      <td>0.860531</td>\n",
       "      <td>0.597442</td>\n",
       "      <td>0.711676</td>\n",
       "      <td>0.760978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>llama3:7b zero-shot [5] (R)</th>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.605633</td>\n",
       "      <td>0.588752</td>\n",
       "      <td>0.639513</td>\n",
       "      <td>0.528509</td>\n",
       "      <td>0.560086</td>\n",
       "      <td>0.514680</td>\n",
       "      <td>0.572862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>llama3:7b zero-shot [10] (R)</th>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.563199</td>\n",
       "      <td>0.611771</td>\n",
       "      <td>0.609199</td>\n",
       "      <td>0.529703</td>\n",
       "      <td>0.507579</td>\n",
       "      <td>0.516021</td>\n",
       "      <td>0.556245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>llama3:7b zero-shot [15] (R)</th>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.598183</td>\n",
       "      <td>0.586106</td>\n",
       "      <td>0.611868</td>\n",
       "      <td>0.518743</td>\n",
       "      <td>0.515050</td>\n",
       "      <td>0.529726</td>\n",
       "      <td>0.559946</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "metric                                                            f1-score  \\\n",
       "target                                                              Church   \n",
       "text_col vectorizer       estimator                    class                 \n",
       "Stance   -                dummy                        macro avg  0.361407   \n",
       "         tf-idf           xgb                          macro avg  0.702021   \n",
       "         bertabaporu-base xgb                          macro avg  0.853801   \n",
       "         -                bertabaporu-base             macro avg  0.866276   \n",
       "                          llama3:7b zero-shot          macro avg  0.729458   \n",
       "Texts    -                dummy                        macro avg  0.361407   \n",
       "         tf-idf           xgb                          macro avg  0.596115   \n",
       "         bertabaporu-base xgb                          macro avg  0.594754   \n",
       "         -                bertabaporu-base             macro avg  0.586611   \n",
       "                          llama3:7b zero-shot [5] (R)  macro avg  0.499052   \n",
       "                          llama3:7b zero-shot [10] (R) macro avg  0.561274   \n",
       "                          llama3:7b zero-shot [15] (R) macro avg  0.503966   \n",
       "Timeline -                dummy                        macro avg  0.361407   \n",
       "         tf-idf           xgb                          macro avg  0.699122   \n",
       "         bertabaporu-base xgb                          macro avg  0.661773   \n",
       "         -                bertabaporu-base             macro avg  0.652707   \n",
       "                          bertabaporu-base (R)         macro avg  0.701990   \n",
       "                          llama3:7b zero-shot [5] (R)  macro avg  0.605633   \n",
       "                          llama3:7b zero-shot [10] (R) macro avg  0.563199   \n",
       "                          llama3:7b zero-shot [15] (R) macro avg  0.598183   \n",
       "\n",
       "metric                                                                      \\\n",
       "target                                                           Bolsonaro   \n",
       "text_col vectorizer       estimator                    class                 \n",
       "Stance   -                dummy                        macro avg  0.462857   \n",
       "         tf-idf           xgb                          macro avg  0.595312   \n",
       "         bertabaporu-base xgb                          macro avg  0.625289   \n",
       "         -                bertabaporu-base             macro avg  0.734945   \n",
       "                          llama3:7b zero-shot          macro avg  0.462857   \n",
       "Texts    -                dummy                        macro avg  0.462857   \n",
       "         tf-idf           xgb                          macro avg  0.501220   \n",
       "         bertabaporu-base xgb                          macro avg  0.495578   \n",
       "         -                bertabaporu-base             macro avg  0.462857   \n",
       "                          llama3:7b zero-shot [5] (R)  macro avg  0.296142   \n",
       "                          llama3:7b zero-shot [10] (R) macro avg  0.328245   \n",
       "                          llama3:7b zero-shot [15] (R) macro avg  0.285253   \n",
       "Timeline -                dummy                        macro avg  0.462857   \n",
       "         tf-idf           xgb                          macro avg  0.728220   \n",
       "         bertabaporu-base xgb                          macro avg  0.692262   \n",
       "         -                bertabaporu-base             macro avg  0.767310   \n",
       "                          bertabaporu-base (R)         macro avg  0.822060   \n",
       "                          llama3:7b zero-shot [5] (R)  macro avg  0.588752   \n",
       "                          llama3:7b zero-shot [10] (R) macro avg  0.611771   \n",
       "                          llama3:7b zero-shot [15] (R) macro avg  0.586106   \n",
       "\n",
       "metric                                                                      \\\n",
       "target                                                             Hydrox.   \n",
       "text_col vectorizer       estimator                    class                 \n",
       "Stance   -                dummy                        macro avg  0.334878   \n",
       "         tf-idf           xgb                          macro avg  0.734366   \n",
       "         bertabaporu-base xgb                          macro avg  0.830948   \n",
       "         -                bertabaporu-base             macro avg  0.844740   \n",
       "                          llama3:7b zero-shot          macro avg  0.638889   \n",
       "Texts    -                dummy                        macro avg  0.334878   \n",
       "         tf-idf           xgb                          macro avg  0.603727   \n",
       "         bertabaporu-base xgb                          macro avg  0.609524   \n",
       "         -                bertabaporu-base             macro avg  0.446504   \n",
       "                          llama3:7b zero-shot [5] (R)  macro avg  0.469796   \n",
       "                          llama3:7b zero-shot [10] (R) macro avg  0.440347   \n",
       "                          llama3:7b zero-shot [15] (R) macro avg  0.416946   \n",
       "Timeline -                dummy                        macro avg  0.334878   \n",
       "         tf-idf           xgb                          macro avg  0.898944   \n",
       "         bertabaporu-base xgb                          macro avg  0.776979   \n",
       "         -                bertabaporu-base             macro avg  0.822297   \n",
       "                          bertabaporu-base (R)         macro avg  0.872170   \n",
       "                          llama3:7b zero-shot [5] (R)  macro avg  0.639513   \n",
       "                          llama3:7b zero-shot [10] (R) macro avg  0.609199   \n",
       "                          llama3:7b zero-shot [15] (R) macro avg  0.611868   \n",
       "\n",
       "metric                                                                      \\\n",
       "target                                                             Sinovac   \n",
       "text_col vectorizer       estimator                    class                 \n",
       "Stance   -                dummy                        macro avg  0.351759   \n",
       "         tf-idf           xgb                          macro avg  0.752640   \n",
       "         bertabaporu-base xgb                          macro avg  0.808036   \n",
       "         -                bertabaporu-base             macro avg  0.823002   \n",
       "                          llama3:7b zero-shot          macro avg  0.578779   \n",
       "Texts    -                dummy                        macro avg  0.351759   \n",
       "         tf-idf           xgb                          macro avg  0.670805   \n",
       "         bertabaporu-base xgb                          macro avg  0.660542   \n",
       "         -                bertabaporu-base             macro avg  0.608972   \n",
       "                          llama3:7b zero-shot [5] (R)  macro avg  0.470381   \n",
       "                          llama3:7b zero-shot [10] (R) macro avg  0.460580   \n",
       "                          llama3:7b zero-shot [15] (R) macro avg  0.464074   \n",
       "Timeline -                dummy                        macro avg  0.351759   \n",
       "         tf-idf           xgb                          macro avg  0.863813   \n",
       "         bertabaporu-base xgb                          macro avg  0.778471   \n",
       "         -                bertabaporu-base             macro avg  0.819813   \n",
       "                          bertabaporu-base (R)         macro avg  0.860531   \n",
       "                          llama3:7b zero-shot [5] (R)  macro avg  0.528509   \n",
       "                          llama3:7b zero-shot [10] (R) macro avg  0.529703   \n",
       "                          llama3:7b zero-shot [15] (R) macro avg  0.518743   \n",
       "\n",
       "metric                                                                      \\\n",
       "target                                                            Globo TV   \n",
       "text_col vectorizer       estimator                    class                 \n",
       "Stance   -                dummy                        macro avg  0.372519   \n",
       "         tf-idf           xgb                          macro avg  0.665243   \n",
       "         bertabaporu-base xgb                          macro avg  0.781858   \n",
       "         -                bertabaporu-base             macro avg  0.875418   \n",
       "                          llama3:7b zero-shot          macro avg  0.770678   \n",
       "Texts    -                dummy                        macro avg  0.372519   \n",
       "         tf-idf           xgb                          macro avg  0.545620   \n",
       "         bertabaporu-base xgb                          macro avg  0.534455   \n",
       "         -                bertabaporu-base             macro avg  0.507381   \n",
       "                          llama3:7b zero-shot [5] (R)  macro avg  0.490101   \n",
       "                          llama3:7b zero-shot [10] (R) macro avg  0.494646   \n",
       "                          llama3:7b zero-shot [15] (R) macro avg  0.475797   \n",
       "Timeline -                dummy                        macro avg  0.372519   \n",
       "         tf-idf           xgb                          macro avg  0.598358   \n",
       "         bertabaporu-base xgb                          macro avg  0.585105   \n",
       "         -                bertabaporu-base             macro avg  0.580105   \n",
       "                          bertabaporu-base (R)         macro avg  0.597442   \n",
       "                          llama3:7b zero-shot [5] (R)  macro avg  0.560086   \n",
       "                          llama3:7b zero-shot [10] (R) macro avg  0.507579   \n",
       "                          llama3:7b zero-shot [15] (R) macro avg  0.515050   \n",
       "\n",
       "metric                                                                      \\\n",
       "target                                                                Lula   \n",
       "text_col vectorizer       estimator                    class                 \n",
       "Stance   -                dummy                        macro avg  0.344578   \n",
       "         tf-idf           xgb                          macro avg  0.654412   \n",
       "         bertabaporu-base xgb                          macro avg  0.766993   \n",
       "         -                bertabaporu-base             macro avg  0.782733   \n",
       "                          llama3:7b zero-shot          macro avg  0.699381   \n",
       "Texts    -                dummy                        macro avg  0.344578   \n",
       "         tf-idf           xgb                          macro avg  0.579427   \n",
       "         bertabaporu-base xgb                          macro avg  0.569597   \n",
       "         -                bertabaporu-base             macro avg  0.482520   \n",
       "                          llama3:7b zero-shot [5] (R)  macro avg  0.512954   \n",
       "                          llama3:7b zero-shot [10] (R) macro avg  0.478244   \n",
       "                          llama3:7b zero-shot [15] (R) macro avg  0.542401   \n",
       "Timeline -                dummy                        macro avg  0.344578   \n",
       "         tf-idf           xgb                          macro avg  0.752710   \n",
       "         bertabaporu-base xgb                          macro avg  0.645518   \n",
       "         -                bertabaporu-base             macro avg  0.614923   \n",
       "                          bertabaporu-base (R)         macro avg  0.711676   \n",
       "                          llama3:7b zero-shot [5] (R)  macro avg  0.514680   \n",
       "                          llama3:7b zero-shot [10] (R) macro avg  0.516021   \n",
       "                          llama3:7b zero-shot [15] (R) macro avg  0.529726   \n",
       "\n",
       "metric                                                                      \n",
       "target                                                             overall  \n",
       "text_col vectorizer       estimator                    class                \n",
       "Stance   -                dummy                        macro avg  0.371333  \n",
       "         tf-idf           xgb                          macro avg  0.683999  \n",
       "         bertabaporu-base xgb                          macro avg  0.777821  \n",
       "         -                bertabaporu-base             macro avg  0.821186  \n",
       "                          llama3:7b zero-shot          macro avg  0.646674  \n",
       "Texts    -                dummy                        macro avg  0.371333  \n",
       "         tf-idf           xgb                          macro avg  0.582819  \n",
       "         bertabaporu-base xgb                          macro avg  0.577408  \n",
       "         -                bertabaporu-base             macro avg  0.515808  \n",
       "                          llama3:7b zero-shot [5] (R)  macro avg  0.456404  \n",
       "                          llama3:7b zero-shot [10] (R) macro avg  0.460556  \n",
       "                          llama3:7b zero-shot [15] (R) macro avg  0.448073  \n",
       "Timeline -                dummy                        macro avg  0.371333  \n",
       "         tf-idf           xgb                          macro avg  0.756861  \n",
       "         bertabaporu-base xgb                          macro avg  0.690018  \n",
       "         -                bertabaporu-base             macro avg  0.709526  \n",
       "                          bertabaporu-base (R)         macro avg  0.760978  \n",
       "                          llama3:7b zero-shot [5] (R)  macro avg  0.572862  \n",
       "                          llama3:7b zero-shot [10] (R) macro avg  0.556245  \n",
       "                          llama3:7b zero-shot [15] (R) macro avg  0.559946  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask_f1 = [True if  \"f1-score\" in col else False for col in df_results_final.columns]\n",
    "mask_macro = [True if  \"macro avg\" in col else False for col in df_results_final.index]\n",
    "\n",
    "f1_macro_df = df_results_final.loc[mask_macro,mask_f1]\n",
    "f1_macro_df[('f1-score','overall')] = f1_macro_df.mean(axis=1)\n",
    "\n",
    "f1_macro_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Table for docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>metric</th>\n",
       "      <th colspan=\"7\" halign=\"left\">f1-score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>Church</th>\n",
       "      <th>Bolsonaro</th>\n",
       "      <th>Hydrox.</th>\n",
       "      <th>Sinovac</th>\n",
       "      <th>Globo TV</th>\n",
       "      <th>Lula</th>\n",
       "      <th>overall</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text_col</th>\n",
       "      <th>vectorizer</th>\n",
       "      <th>estimator</th>\n",
       "      <th>class</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">Stance</th>\n",
       "      <th>-</th>\n",
       "      <th>dummy</th>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.361407</td>\n",
       "      <td>0.462857</td>\n",
       "      <td>0.334878</td>\n",
       "      <td>0.351759</td>\n",
       "      <td>0.372519</td>\n",
       "      <td>0.344578</td>\n",
       "      <td>0.371333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tf-idf</th>\n",
       "      <th>xgb</th>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.702021</td>\n",
       "      <td>0.595312</td>\n",
       "      <td>0.734366</td>\n",
       "      <td>0.752640</td>\n",
       "      <td>0.665243</td>\n",
       "      <td>0.654412</td>\n",
       "      <td>0.683999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bertabaporu-base</th>\n",
       "      <th>xgb</th>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.853801</td>\n",
       "      <td>0.625289</td>\n",
       "      <td>0.830948</td>\n",
       "      <td>0.808036</td>\n",
       "      <td>0.781858</td>\n",
       "      <td>0.766993</td>\n",
       "      <td>0.777821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">-</th>\n",
       "      <th>bertabaporu-base</th>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.866276</td>\n",
       "      <td>0.734945</td>\n",
       "      <td>0.844740</td>\n",
       "      <td>0.823002</td>\n",
       "      <td>0.875418</td>\n",
       "      <td>0.782733</td>\n",
       "      <td>0.821186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>llama3:7b zero-shot</th>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.729458</td>\n",
       "      <td>0.462857</td>\n",
       "      <td>0.638889</td>\n",
       "      <td>0.578779</td>\n",
       "      <td>0.770678</td>\n",
       "      <td>0.699381</td>\n",
       "      <td>0.646674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"7\" valign=\"top\">Texts</th>\n",
       "      <th>-</th>\n",
       "      <th>dummy</th>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.361407</td>\n",
       "      <td>0.462857</td>\n",
       "      <td>0.334878</td>\n",
       "      <td>0.351759</td>\n",
       "      <td>0.372519</td>\n",
       "      <td>0.344578</td>\n",
       "      <td>0.371333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tf-idf</th>\n",
       "      <th>xgb</th>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.596115</td>\n",
       "      <td>0.501220</td>\n",
       "      <td>0.603727</td>\n",
       "      <td>0.670805</td>\n",
       "      <td>0.545620</td>\n",
       "      <td>0.579427</td>\n",
       "      <td>0.582819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bertabaporu-base</th>\n",
       "      <th>xgb</th>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.594754</td>\n",
       "      <td>0.495578</td>\n",
       "      <td>0.609524</td>\n",
       "      <td>0.660542</td>\n",
       "      <td>0.534455</td>\n",
       "      <td>0.569597</td>\n",
       "      <td>0.577408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">-</th>\n",
       "      <th>bertabaporu-base</th>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.586611</td>\n",
       "      <td>0.462857</td>\n",
       "      <td>0.446504</td>\n",
       "      <td>0.608972</td>\n",
       "      <td>0.507381</td>\n",
       "      <td>0.482520</td>\n",
       "      <td>0.515808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>llama3:7b zero-shot [5] (R)</th>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.499052</td>\n",
       "      <td>0.296142</td>\n",
       "      <td>0.469796</td>\n",
       "      <td>0.470381</td>\n",
       "      <td>0.490101</td>\n",
       "      <td>0.512954</td>\n",
       "      <td>0.456404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>llama3:7b zero-shot [10] (R)</th>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.561274</td>\n",
       "      <td>0.328245</td>\n",
       "      <td>0.440347</td>\n",
       "      <td>0.460580</td>\n",
       "      <td>0.494646</td>\n",
       "      <td>0.478244</td>\n",
       "      <td>0.460556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>llama3:7b zero-shot [15] (R)</th>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.503966</td>\n",
       "      <td>0.285253</td>\n",
       "      <td>0.416946</td>\n",
       "      <td>0.464074</td>\n",
       "      <td>0.475797</td>\n",
       "      <td>0.542401</td>\n",
       "      <td>0.448073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"8\" valign=\"top\">Timeline</th>\n",
       "      <th>-</th>\n",
       "      <th>dummy</th>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.361407</td>\n",
       "      <td>0.462857</td>\n",
       "      <td>0.334878</td>\n",
       "      <td>0.351759</td>\n",
       "      <td>0.372519</td>\n",
       "      <td>0.344578</td>\n",
       "      <td>0.371333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tf-idf</th>\n",
       "      <th>xgb</th>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.699122</td>\n",
       "      <td>0.728220</td>\n",
       "      <td>0.898944</td>\n",
       "      <td>0.863813</td>\n",
       "      <td>0.598358</td>\n",
       "      <td>0.752710</td>\n",
       "      <td>0.756861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bertabaporu-base</th>\n",
       "      <th>xgb</th>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.661773</td>\n",
       "      <td>0.692262</td>\n",
       "      <td>0.776979</td>\n",
       "      <td>0.778471</td>\n",
       "      <td>0.585105</td>\n",
       "      <td>0.645518</td>\n",
       "      <td>0.690018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">-</th>\n",
       "      <th>bertabaporu-base</th>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.652707</td>\n",
       "      <td>0.767310</td>\n",
       "      <td>0.822297</td>\n",
       "      <td>0.819813</td>\n",
       "      <td>0.580105</td>\n",
       "      <td>0.614923</td>\n",
       "      <td>0.709526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bertabaporu-base (R)</th>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.701990</td>\n",
       "      <td>0.822060</td>\n",
       "      <td>0.872170</td>\n",
       "      <td>0.860531</td>\n",
       "      <td>0.597442</td>\n",
       "      <td>0.711676</td>\n",
       "      <td>0.760978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>llama3:7b zero-shot [5] (R)</th>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.605633</td>\n",
       "      <td>0.588752</td>\n",
       "      <td>0.639513</td>\n",
       "      <td>0.528509</td>\n",
       "      <td>0.560086</td>\n",
       "      <td>0.514680</td>\n",
       "      <td>0.572862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>llama3:7b zero-shot [10] (R)</th>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.563199</td>\n",
       "      <td>0.611771</td>\n",
       "      <td>0.609199</td>\n",
       "      <td>0.529703</td>\n",
       "      <td>0.507579</td>\n",
       "      <td>0.516021</td>\n",
       "      <td>0.556245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>llama3:7b zero-shot [15] (R)</th>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.598183</td>\n",
       "      <td>0.586106</td>\n",
       "      <td>0.611868</td>\n",
       "      <td>0.518743</td>\n",
       "      <td>0.515050</td>\n",
       "      <td>0.529726</td>\n",
       "      <td>0.559946</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "metric                                                            f1-score  \\\n",
       "target                                                              Church   \n",
       "text_col vectorizer       estimator                    class                 \n",
       "Stance   -                dummy                        macro avg  0.361407   \n",
       "         tf-idf           xgb                          macro avg  0.702021   \n",
       "         bertabaporu-base xgb                          macro avg  0.853801   \n",
       "         -                bertabaporu-base             macro avg  0.866276   \n",
       "                          llama3:7b zero-shot          macro avg  0.729458   \n",
       "Texts    -                dummy                        macro avg  0.361407   \n",
       "         tf-idf           xgb                          macro avg  0.596115   \n",
       "         bertabaporu-base xgb                          macro avg  0.594754   \n",
       "         -                bertabaporu-base             macro avg  0.586611   \n",
       "                          llama3:7b zero-shot [5] (R)  macro avg  0.499052   \n",
       "                          llama3:7b zero-shot [10] (R) macro avg  0.561274   \n",
       "                          llama3:7b zero-shot [15] (R) macro avg  0.503966   \n",
       "Timeline -                dummy                        macro avg  0.361407   \n",
       "         tf-idf           xgb                          macro avg  0.699122   \n",
       "         bertabaporu-base xgb                          macro avg  0.661773   \n",
       "         -                bertabaporu-base             macro avg  0.652707   \n",
       "                          bertabaporu-base (R)         macro avg  0.701990   \n",
       "                          llama3:7b zero-shot [5] (R)  macro avg  0.605633   \n",
       "                          llama3:7b zero-shot [10] (R) macro avg  0.563199   \n",
       "                          llama3:7b zero-shot [15] (R) macro avg  0.598183   \n",
       "\n",
       "metric                                                                      \\\n",
       "target                                                           Bolsonaro   \n",
       "text_col vectorizer       estimator                    class                 \n",
       "Stance   -                dummy                        macro avg  0.462857   \n",
       "         tf-idf           xgb                          macro avg  0.595312   \n",
       "         bertabaporu-base xgb                          macro avg  0.625289   \n",
       "         -                bertabaporu-base             macro avg  0.734945   \n",
       "                          llama3:7b zero-shot          macro avg  0.462857   \n",
       "Texts    -                dummy                        macro avg  0.462857   \n",
       "         tf-idf           xgb                          macro avg  0.501220   \n",
       "         bertabaporu-base xgb                          macro avg  0.495578   \n",
       "         -                bertabaporu-base             macro avg  0.462857   \n",
       "                          llama3:7b zero-shot [5] (R)  macro avg  0.296142   \n",
       "                          llama3:7b zero-shot [10] (R) macro avg  0.328245   \n",
       "                          llama3:7b zero-shot [15] (R) macro avg  0.285253   \n",
       "Timeline -                dummy                        macro avg  0.462857   \n",
       "         tf-idf           xgb                          macro avg  0.728220   \n",
       "         bertabaporu-base xgb                          macro avg  0.692262   \n",
       "         -                bertabaporu-base             macro avg  0.767310   \n",
       "                          bertabaporu-base (R)         macro avg  0.822060   \n",
       "                          llama3:7b zero-shot [5] (R)  macro avg  0.588752   \n",
       "                          llama3:7b zero-shot [10] (R) macro avg  0.611771   \n",
       "                          llama3:7b zero-shot [15] (R) macro avg  0.586106   \n",
       "\n",
       "metric                                                                      \\\n",
       "target                                                             Hydrox.   \n",
       "text_col vectorizer       estimator                    class                 \n",
       "Stance   -                dummy                        macro avg  0.334878   \n",
       "         tf-idf           xgb                          macro avg  0.734366   \n",
       "         bertabaporu-base xgb                          macro avg  0.830948   \n",
       "         -                bertabaporu-base             macro avg  0.844740   \n",
       "                          llama3:7b zero-shot          macro avg  0.638889   \n",
       "Texts    -                dummy                        macro avg  0.334878   \n",
       "         tf-idf           xgb                          macro avg  0.603727   \n",
       "         bertabaporu-base xgb                          macro avg  0.609524   \n",
       "         -                bertabaporu-base             macro avg  0.446504   \n",
       "                          llama3:7b zero-shot [5] (R)  macro avg  0.469796   \n",
       "                          llama3:7b zero-shot [10] (R) macro avg  0.440347   \n",
       "                          llama3:7b zero-shot [15] (R) macro avg  0.416946   \n",
       "Timeline -                dummy                        macro avg  0.334878   \n",
       "         tf-idf           xgb                          macro avg  0.898944   \n",
       "         bertabaporu-base xgb                          macro avg  0.776979   \n",
       "         -                bertabaporu-base             macro avg  0.822297   \n",
       "                          bertabaporu-base (R)         macro avg  0.872170   \n",
       "                          llama3:7b zero-shot [5] (R)  macro avg  0.639513   \n",
       "                          llama3:7b zero-shot [10] (R) macro avg  0.609199   \n",
       "                          llama3:7b zero-shot [15] (R) macro avg  0.611868   \n",
       "\n",
       "metric                                                                      \\\n",
       "target                                                             Sinovac   \n",
       "text_col vectorizer       estimator                    class                 \n",
       "Stance   -                dummy                        macro avg  0.351759   \n",
       "         tf-idf           xgb                          macro avg  0.752640   \n",
       "         bertabaporu-base xgb                          macro avg  0.808036   \n",
       "         -                bertabaporu-base             macro avg  0.823002   \n",
       "                          llama3:7b zero-shot          macro avg  0.578779   \n",
       "Texts    -                dummy                        macro avg  0.351759   \n",
       "         tf-idf           xgb                          macro avg  0.670805   \n",
       "         bertabaporu-base xgb                          macro avg  0.660542   \n",
       "         -                bertabaporu-base             macro avg  0.608972   \n",
       "                          llama3:7b zero-shot [5] (R)  macro avg  0.470381   \n",
       "                          llama3:7b zero-shot [10] (R) macro avg  0.460580   \n",
       "                          llama3:7b zero-shot [15] (R) macro avg  0.464074   \n",
       "Timeline -                dummy                        macro avg  0.351759   \n",
       "         tf-idf           xgb                          macro avg  0.863813   \n",
       "         bertabaporu-base xgb                          macro avg  0.778471   \n",
       "         -                bertabaporu-base             macro avg  0.819813   \n",
       "                          bertabaporu-base (R)         macro avg  0.860531   \n",
       "                          llama3:7b zero-shot [5] (R)  macro avg  0.528509   \n",
       "                          llama3:7b zero-shot [10] (R) macro avg  0.529703   \n",
       "                          llama3:7b zero-shot [15] (R) macro avg  0.518743   \n",
       "\n",
       "metric                                                                      \\\n",
       "target                                                            Globo TV   \n",
       "text_col vectorizer       estimator                    class                 \n",
       "Stance   -                dummy                        macro avg  0.372519   \n",
       "         tf-idf           xgb                          macro avg  0.665243   \n",
       "         bertabaporu-base xgb                          macro avg  0.781858   \n",
       "         -                bertabaporu-base             macro avg  0.875418   \n",
       "                          llama3:7b zero-shot          macro avg  0.770678   \n",
       "Texts    -                dummy                        macro avg  0.372519   \n",
       "         tf-idf           xgb                          macro avg  0.545620   \n",
       "         bertabaporu-base xgb                          macro avg  0.534455   \n",
       "         -                bertabaporu-base             macro avg  0.507381   \n",
       "                          llama3:7b zero-shot [5] (R)  macro avg  0.490101   \n",
       "                          llama3:7b zero-shot [10] (R) macro avg  0.494646   \n",
       "                          llama3:7b zero-shot [15] (R) macro avg  0.475797   \n",
       "Timeline -                dummy                        macro avg  0.372519   \n",
       "         tf-idf           xgb                          macro avg  0.598358   \n",
       "         bertabaporu-base xgb                          macro avg  0.585105   \n",
       "         -                bertabaporu-base             macro avg  0.580105   \n",
       "                          bertabaporu-base (R)         macro avg  0.597442   \n",
       "                          llama3:7b zero-shot [5] (R)  macro avg  0.560086   \n",
       "                          llama3:7b zero-shot [10] (R) macro avg  0.507579   \n",
       "                          llama3:7b zero-shot [15] (R) macro avg  0.515050   \n",
       "\n",
       "metric                                                                      \\\n",
       "target                                                                Lula   \n",
       "text_col vectorizer       estimator                    class                 \n",
       "Stance   -                dummy                        macro avg  0.344578   \n",
       "         tf-idf           xgb                          macro avg  0.654412   \n",
       "         bertabaporu-base xgb                          macro avg  0.766993   \n",
       "         -                bertabaporu-base             macro avg  0.782733   \n",
       "                          llama3:7b zero-shot          macro avg  0.699381   \n",
       "Texts    -                dummy                        macro avg  0.344578   \n",
       "         tf-idf           xgb                          macro avg  0.579427   \n",
       "         bertabaporu-base xgb                          macro avg  0.569597   \n",
       "         -                bertabaporu-base             macro avg  0.482520   \n",
       "                          llama3:7b zero-shot [5] (R)  macro avg  0.512954   \n",
       "                          llama3:7b zero-shot [10] (R) macro avg  0.478244   \n",
       "                          llama3:7b zero-shot [15] (R) macro avg  0.542401   \n",
       "Timeline -                dummy                        macro avg  0.344578   \n",
       "         tf-idf           xgb                          macro avg  0.752710   \n",
       "         bertabaporu-base xgb                          macro avg  0.645518   \n",
       "         -                bertabaporu-base             macro avg  0.614923   \n",
       "                          bertabaporu-base (R)         macro avg  0.711676   \n",
       "                          llama3:7b zero-shot [5] (R)  macro avg  0.514680   \n",
       "                          llama3:7b zero-shot [10] (R) macro avg  0.516021   \n",
       "                          llama3:7b zero-shot [15] (R) macro avg  0.529726   \n",
       "\n",
       "metric                                                                      \n",
       "target                                                             overall  \n",
       "text_col vectorizer       estimator                    class                \n",
       "Stance   -                dummy                        macro avg  0.371333  \n",
       "         tf-idf           xgb                          macro avg  0.683999  \n",
       "         bertabaporu-base xgb                          macro avg  0.777821  \n",
       "         -                bertabaporu-base             macro avg  0.821186  \n",
       "                          llama3:7b zero-shot          macro avg  0.646674  \n",
       "Texts    -                dummy                        macro avg  0.371333  \n",
       "         tf-idf           xgb                          macro avg  0.582819  \n",
       "         bertabaporu-base xgb                          macro avg  0.577408  \n",
       "         -                bertabaporu-base             macro avg  0.515808  \n",
       "                          llama3:7b zero-shot [5] (R)  macro avg  0.456404  \n",
       "                          llama3:7b zero-shot [10] (R) macro avg  0.460556  \n",
       "                          llama3:7b zero-shot [15] (R) macro avg  0.448073  \n",
       "Timeline -                dummy                        macro avg  0.371333  \n",
       "         tf-idf           xgb                          macro avg  0.756861  \n",
       "         bertabaporu-base xgb                          macro avg  0.690018  \n",
       "         -                bertabaporu-base             macro avg  0.709526  \n",
       "                          bertabaporu-base (R)         macro avg  0.760978  \n",
       "                          llama3:7b zero-shot [5] (R)  macro avg  0.572862  \n",
       "                          llama3:7b zero-shot [10] (R) macro avg  0.556245  \n",
       "                          llama3:7b zero-shot [15] (R) macro avg  0.559946  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_report = f1_macro_df.copy()\n",
    "f1_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>metric</th>\n",
       "      <th>text_col</th>\n",
       "      <th>vectorizer</th>\n",
       "      <th>estimator</th>\n",
       "      <th>class</th>\n",
       "      <th colspan=\"7\" halign=\"left\">f1-score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>target</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Church</th>\n",
       "      <th>Bolsonaro</th>\n",
       "      <th>Hydrox.</th>\n",
       "      <th>Sinovac</th>\n",
       "      <th>Globo TV</th>\n",
       "      <th>Lula</th>\n",
       "      <th>overall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Stance</td>\n",
       "      <td>-</td>\n",
       "      <td>dummy</td>\n",
       "      <td>macro avg</td>\n",
       "      <td>0.361407</td>\n",
       "      <td>0.462857</td>\n",
       "      <td>0.334878</td>\n",
       "      <td>0.351759</td>\n",
       "      <td>0.372519</td>\n",
       "      <td>0.344578</td>\n",
       "      <td>0.371333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Stance</td>\n",
       "      <td>tf-idf</td>\n",
       "      <td>xgb</td>\n",
       "      <td>macro avg</td>\n",
       "      <td>0.702021</td>\n",
       "      <td>0.595312</td>\n",
       "      <td>0.734366</td>\n",
       "      <td>0.752640</td>\n",
       "      <td>0.665243</td>\n",
       "      <td>0.654412</td>\n",
       "      <td>0.683999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Stance</td>\n",
       "      <td>bertabaporu-base</td>\n",
       "      <td>xgb</td>\n",
       "      <td>macro avg</td>\n",
       "      <td>0.853801</td>\n",
       "      <td>0.625289</td>\n",
       "      <td>0.830948</td>\n",
       "      <td>0.808036</td>\n",
       "      <td>0.781858</td>\n",
       "      <td>0.766993</td>\n",
       "      <td>0.777821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Stance</td>\n",
       "      <td>-</td>\n",
       "      <td>bertabaporu-base</td>\n",
       "      <td>macro avg</td>\n",
       "      <td>0.866276</td>\n",
       "      <td>0.734945</td>\n",
       "      <td>0.844740</td>\n",
       "      <td>0.823002</td>\n",
       "      <td>0.875418</td>\n",
       "      <td>0.782733</td>\n",
       "      <td>0.821186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Stance</td>\n",
       "      <td>-</td>\n",
       "      <td>llama3:7b zero-shot</td>\n",
       "      <td>macro avg</td>\n",
       "      <td>0.729458</td>\n",
       "      <td>0.462857</td>\n",
       "      <td>0.638889</td>\n",
       "      <td>0.578779</td>\n",
       "      <td>0.770678</td>\n",
       "      <td>0.699381</td>\n",
       "      <td>0.646674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Texts</td>\n",
       "      <td>-</td>\n",
       "      <td>dummy</td>\n",
       "      <td>macro avg</td>\n",
       "      <td>0.361407</td>\n",
       "      <td>0.462857</td>\n",
       "      <td>0.334878</td>\n",
       "      <td>0.351759</td>\n",
       "      <td>0.372519</td>\n",
       "      <td>0.344578</td>\n",
       "      <td>0.371333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Texts</td>\n",
       "      <td>tf-idf</td>\n",
       "      <td>xgb</td>\n",
       "      <td>macro avg</td>\n",
       "      <td>0.596115</td>\n",
       "      <td>0.501220</td>\n",
       "      <td>0.603727</td>\n",
       "      <td>0.670805</td>\n",
       "      <td>0.545620</td>\n",
       "      <td>0.579427</td>\n",
       "      <td>0.582819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Texts</td>\n",
       "      <td>bertabaporu-base</td>\n",
       "      <td>xgb</td>\n",
       "      <td>macro avg</td>\n",
       "      <td>0.594754</td>\n",
       "      <td>0.495578</td>\n",
       "      <td>0.609524</td>\n",
       "      <td>0.660542</td>\n",
       "      <td>0.534455</td>\n",
       "      <td>0.569597</td>\n",
       "      <td>0.577408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Texts</td>\n",
       "      <td>-</td>\n",
       "      <td>bertabaporu-base</td>\n",
       "      <td>macro avg</td>\n",
       "      <td>0.586611</td>\n",
       "      <td>0.462857</td>\n",
       "      <td>0.446504</td>\n",
       "      <td>0.608972</td>\n",
       "      <td>0.507381</td>\n",
       "      <td>0.482520</td>\n",
       "      <td>0.515808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Texts</td>\n",
       "      <td>-</td>\n",
       "      <td>llama3:7b zero-shot [5] (R)</td>\n",
       "      <td>macro avg</td>\n",
       "      <td>0.499052</td>\n",
       "      <td>0.296142</td>\n",
       "      <td>0.469796</td>\n",
       "      <td>0.470381</td>\n",
       "      <td>0.490101</td>\n",
       "      <td>0.512954</td>\n",
       "      <td>0.456404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Texts</td>\n",
       "      <td>-</td>\n",
       "      <td>llama3:7b zero-shot [10] (R)</td>\n",
       "      <td>macro avg</td>\n",
       "      <td>0.561274</td>\n",
       "      <td>0.328245</td>\n",
       "      <td>0.440347</td>\n",
       "      <td>0.460580</td>\n",
       "      <td>0.494646</td>\n",
       "      <td>0.478244</td>\n",
       "      <td>0.460556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Texts</td>\n",
       "      <td>-</td>\n",
       "      <td>llama3:7b zero-shot [15] (R)</td>\n",
       "      <td>macro avg</td>\n",
       "      <td>0.503966</td>\n",
       "      <td>0.285253</td>\n",
       "      <td>0.416946</td>\n",
       "      <td>0.464074</td>\n",
       "      <td>0.475797</td>\n",
       "      <td>0.542401</td>\n",
       "      <td>0.448073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Timeline</td>\n",
       "      <td>-</td>\n",
       "      <td>dummy</td>\n",
       "      <td>macro avg</td>\n",
       "      <td>0.361407</td>\n",
       "      <td>0.462857</td>\n",
       "      <td>0.334878</td>\n",
       "      <td>0.351759</td>\n",
       "      <td>0.372519</td>\n",
       "      <td>0.344578</td>\n",
       "      <td>0.371333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Timeline</td>\n",
       "      <td>tf-idf</td>\n",
       "      <td>xgb</td>\n",
       "      <td>macro avg</td>\n",
       "      <td>0.699122</td>\n",
       "      <td>0.728220</td>\n",
       "      <td>0.898944</td>\n",
       "      <td>0.863813</td>\n",
       "      <td>0.598358</td>\n",
       "      <td>0.752710</td>\n",
       "      <td>0.756861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Timeline</td>\n",
       "      <td>bertabaporu-base</td>\n",
       "      <td>xgb</td>\n",
       "      <td>macro avg</td>\n",
       "      <td>0.661773</td>\n",
       "      <td>0.692262</td>\n",
       "      <td>0.776979</td>\n",
       "      <td>0.778471</td>\n",
       "      <td>0.585105</td>\n",
       "      <td>0.645518</td>\n",
       "      <td>0.690018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Timeline</td>\n",
       "      <td>-</td>\n",
       "      <td>bertabaporu-base</td>\n",
       "      <td>macro avg</td>\n",
       "      <td>0.652707</td>\n",
       "      <td>0.767310</td>\n",
       "      <td>0.822297</td>\n",
       "      <td>0.819813</td>\n",
       "      <td>0.580105</td>\n",
       "      <td>0.614923</td>\n",
       "      <td>0.709526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Timeline</td>\n",
       "      <td>-</td>\n",
       "      <td>bertabaporu-base (R)</td>\n",
       "      <td>macro avg</td>\n",
       "      <td>0.701990</td>\n",
       "      <td>0.822060</td>\n",
       "      <td>0.872170</td>\n",
       "      <td>0.860531</td>\n",
       "      <td>0.597442</td>\n",
       "      <td>0.711676</td>\n",
       "      <td>0.760978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Timeline</td>\n",
       "      <td>-</td>\n",
       "      <td>llama3:7b zero-shot [5] (R)</td>\n",
       "      <td>macro avg</td>\n",
       "      <td>0.605633</td>\n",
       "      <td>0.588752</td>\n",
       "      <td>0.639513</td>\n",
       "      <td>0.528509</td>\n",
       "      <td>0.560086</td>\n",
       "      <td>0.514680</td>\n",
       "      <td>0.572862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Timeline</td>\n",
       "      <td>-</td>\n",
       "      <td>llama3:7b zero-shot [10] (R)</td>\n",
       "      <td>macro avg</td>\n",
       "      <td>0.563199</td>\n",
       "      <td>0.611771</td>\n",
       "      <td>0.609199</td>\n",
       "      <td>0.529703</td>\n",
       "      <td>0.507579</td>\n",
       "      <td>0.516021</td>\n",
       "      <td>0.556245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Timeline</td>\n",
       "      <td>-</td>\n",
       "      <td>llama3:7b zero-shot [15] (R)</td>\n",
       "      <td>macro avg</td>\n",
       "      <td>0.598183</td>\n",
       "      <td>0.586106</td>\n",
       "      <td>0.611868</td>\n",
       "      <td>0.518743</td>\n",
       "      <td>0.515050</td>\n",
       "      <td>0.529726</td>\n",
       "      <td>0.559946</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "metric  text_col        vectorizer                     estimator      class  \\\n",
       "target                                                                        \n",
       "0         Stance                 -                         dummy  macro avg   \n",
       "1         Stance            tf-idf                           xgb  macro avg   \n",
       "2         Stance  bertabaporu-base                           xgb  macro avg   \n",
       "3         Stance                 -              bertabaporu-base  macro avg   \n",
       "4         Stance                 -           llama3:7b zero-shot  macro avg   \n",
       "5          Texts                 -                         dummy  macro avg   \n",
       "6          Texts            tf-idf                           xgb  macro avg   \n",
       "7          Texts  bertabaporu-base                           xgb  macro avg   \n",
       "8          Texts                 -              bertabaporu-base  macro avg   \n",
       "9          Texts                 -   llama3:7b zero-shot [5] (R)  macro avg   \n",
       "10         Texts                 -  llama3:7b zero-shot [10] (R)  macro avg   \n",
       "11         Texts                 -  llama3:7b zero-shot [15] (R)  macro avg   \n",
       "12      Timeline                 -                         dummy  macro avg   \n",
       "13      Timeline            tf-idf                           xgb  macro avg   \n",
       "14      Timeline  bertabaporu-base                           xgb  macro avg   \n",
       "15      Timeline                 -              bertabaporu-base  macro avg   \n",
       "16      Timeline                 -          bertabaporu-base (R)  macro avg   \n",
       "17      Timeline                 -   llama3:7b zero-shot [5] (R)  macro avg   \n",
       "18      Timeline                 -  llama3:7b zero-shot [10] (R)  macro avg   \n",
       "19      Timeline                 -  llama3:7b zero-shot [15] (R)  macro avg   \n",
       "\n",
       "metric  f1-score                                                              \n",
       "target    Church Bolsonaro   Hydrox.   Sinovac  Globo TV      Lula   overall  \n",
       "0       0.361407  0.462857  0.334878  0.351759  0.372519  0.344578  0.371333  \n",
       "1       0.702021  0.595312  0.734366  0.752640  0.665243  0.654412  0.683999  \n",
       "2       0.853801  0.625289  0.830948  0.808036  0.781858  0.766993  0.777821  \n",
       "3       0.866276  0.734945  0.844740  0.823002  0.875418  0.782733  0.821186  \n",
       "4       0.729458  0.462857  0.638889  0.578779  0.770678  0.699381  0.646674  \n",
       "5       0.361407  0.462857  0.334878  0.351759  0.372519  0.344578  0.371333  \n",
       "6       0.596115  0.501220  0.603727  0.670805  0.545620  0.579427  0.582819  \n",
       "7       0.594754  0.495578  0.609524  0.660542  0.534455  0.569597  0.577408  \n",
       "8       0.586611  0.462857  0.446504  0.608972  0.507381  0.482520  0.515808  \n",
       "9       0.499052  0.296142  0.469796  0.470381  0.490101  0.512954  0.456404  \n",
       "10      0.561274  0.328245  0.440347  0.460580  0.494646  0.478244  0.460556  \n",
       "11      0.503966  0.285253  0.416946  0.464074  0.475797  0.542401  0.448073  \n",
       "12      0.361407  0.462857  0.334878  0.351759  0.372519  0.344578  0.371333  \n",
       "13      0.699122  0.728220  0.898944  0.863813  0.598358  0.752710  0.756861  \n",
       "14      0.661773  0.692262  0.776979  0.778471  0.585105  0.645518  0.690018  \n",
       "15      0.652707  0.767310  0.822297  0.819813  0.580105  0.614923  0.709526  \n",
       "16      0.701990  0.822060  0.872170  0.860531  0.597442  0.711676  0.760978  \n",
       "17      0.605633  0.588752  0.639513  0.528509  0.560086  0.514680  0.572862  \n",
       "18      0.563199  0.611771  0.609199  0.529703  0.507579  0.516021  0.556245  \n",
       "19      0.598183  0.586106  0.611868  0.518743  0.515050  0.529726  0.559946  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_report.reset_index(drop=False, inplace=True)\n",
    "f1_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultiIndex([(  'text_col',          ''),\n",
       "            ('vectorizer',          ''),\n",
       "            ( 'estimator',          ''),\n",
       "            (     'class',          ''),\n",
       "            (  'f1-score',    'Church'),\n",
       "            (  'f1-score', 'Bolsonaro'),\n",
       "            (  'f1-score',   'Hydrox.'),\n",
       "            (  'f1-score',   'Sinovac'),\n",
       "            (  'f1-score',  'Globo TV'),\n",
       "            (  'f1-score',      'Lula'),\n",
       "            (  'f1-score',   'overall')],\n",
       "           names=['metric', 'target'])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_report.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['text_col',\n",
       " 'vectorizer',\n",
       " 'estimator',\n",
       " 'class',\n",
       " 'Church',\n",
       " 'Bolsonaro',\n",
       " 'Hydrox.',\n",
       " 'Sinovac',\n",
       " 'Globo TV',\n",
       " 'Lula',\n",
       " 'overall']"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_columns = [col[0] if col[1] == '' else col[1] for col in f1_report.columns]\n",
    "new_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_col</th>\n",
       "      <th>vectorizer</th>\n",
       "      <th>estimator</th>\n",
       "      <th>class</th>\n",
       "      <th>Church</th>\n",
       "      <th>Bolsonaro</th>\n",
       "      <th>Hydrox.</th>\n",
       "      <th>Sinovac</th>\n",
       "      <th>Globo TV</th>\n",
       "      <th>Lula</th>\n",
       "      <th>overall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Stance</td>\n",
       "      <td>-</td>\n",
       "      <td>dummy</td>\n",
       "      <td>macro avg</td>\n",
       "      <td>0.361407</td>\n",
       "      <td>0.462857</td>\n",
       "      <td>0.334878</td>\n",
       "      <td>0.351759</td>\n",
       "      <td>0.372519</td>\n",
       "      <td>0.344578</td>\n",
       "      <td>0.371333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Stance</td>\n",
       "      <td>tf-idf</td>\n",
       "      <td>xgb</td>\n",
       "      <td>macro avg</td>\n",
       "      <td>0.702021</td>\n",
       "      <td>0.595312</td>\n",
       "      <td>0.734366</td>\n",
       "      <td>0.752640</td>\n",
       "      <td>0.665243</td>\n",
       "      <td>0.654412</td>\n",
       "      <td>0.683999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Stance</td>\n",
       "      <td>bertabaporu-base</td>\n",
       "      <td>xgb</td>\n",
       "      <td>macro avg</td>\n",
       "      <td>0.853801</td>\n",
       "      <td>0.625289</td>\n",
       "      <td>0.830948</td>\n",
       "      <td>0.808036</td>\n",
       "      <td>0.781858</td>\n",
       "      <td>0.766993</td>\n",
       "      <td>0.777821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Stance</td>\n",
       "      <td>-</td>\n",
       "      <td>bertabaporu-base</td>\n",
       "      <td>macro avg</td>\n",
       "      <td>0.866276</td>\n",
       "      <td>0.734945</td>\n",
       "      <td>0.844740</td>\n",
       "      <td>0.823002</td>\n",
       "      <td>0.875418</td>\n",
       "      <td>0.782733</td>\n",
       "      <td>0.821186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Stance</td>\n",
       "      <td>-</td>\n",
       "      <td>llama3:7b zero-shot</td>\n",
       "      <td>macro avg</td>\n",
       "      <td>0.729458</td>\n",
       "      <td>0.462857</td>\n",
       "      <td>0.638889</td>\n",
       "      <td>0.578779</td>\n",
       "      <td>0.770678</td>\n",
       "      <td>0.699381</td>\n",
       "      <td>0.646674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Texts</td>\n",
       "      <td>-</td>\n",
       "      <td>dummy</td>\n",
       "      <td>macro avg</td>\n",
       "      <td>0.361407</td>\n",
       "      <td>0.462857</td>\n",
       "      <td>0.334878</td>\n",
       "      <td>0.351759</td>\n",
       "      <td>0.372519</td>\n",
       "      <td>0.344578</td>\n",
       "      <td>0.371333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Texts</td>\n",
       "      <td>tf-idf</td>\n",
       "      <td>xgb</td>\n",
       "      <td>macro avg</td>\n",
       "      <td>0.596115</td>\n",
       "      <td>0.501220</td>\n",
       "      <td>0.603727</td>\n",
       "      <td>0.670805</td>\n",
       "      <td>0.545620</td>\n",
       "      <td>0.579427</td>\n",
       "      <td>0.582819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Texts</td>\n",
       "      <td>bertabaporu-base</td>\n",
       "      <td>xgb</td>\n",
       "      <td>macro avg</td>\n",
       "      <td>0.594754</td>\n",
       "      <td>0.495578</td>\n",
       "      <td>0.609524</td>\n",
       "      <td>0.660542</td>\n",
       "      <td>0.534455</td>\n",
       "      <td>0.569597</td>\n",
       "      <td>0.577408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Texts</td>\n",
       "      <td>-</td>\n",
       "      <td>bertabaporu-base</td>\n",
       "      <td>macro avg</td>\n",
       "      <td>0.586611</td>\n",
       "      <td>0.462857</td>\n",
       "      <td>0.446504</td>\n",
       "      <td>0.608972</td>\n",
       "      <td>0.507381</td>\n",
       "      <td>0.482520</td>\n",
       "      <td>0.515808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Texts</td>\n",
       "      <td>-</td>\n",
       "      <td>llama3:7b zero-shot [5] (R)</td>\n",
       "      <td>macro avg</td>\n",
       "      <td>0.499052</td>\n",
       "      <td>0.296142</td>\n",
       "      <td>0.469796</td>\n",
       "      <td>0.470381</td>\n",
       "      <td>0.490101</td>\n",
       "      <td>0.512954</td>\n",
       "      <td>0.456404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Texts</td>\n",
       "      <td>-</td>\n",
       "      <td>llama3:7b zero-shot [10] (R)</td>\n",
       "      <td>macro avg</td>\n",
       "      <td>0.561274</td>\n",
       "      <td>0.328245</td>\n",
       "      <td>0.440347</td>\n",
       "      <td>0.460580</td>\n",
       "      <td>0.494646</td>\n",
       "      <td>0.478244</td>\n",
       "      <td>0.460556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Texts</td>\n",
       "      <td>-</td>\n",
       "      <td>llama3:7b zero-shot [15] (R)</td>\n",
       "      <td>macro avg</td>\n",
       "      <td>0.503966</td>\n",
       "      <td>0.285253</td>\n",
       "      <td>0.416946</td>\n",
       "      <td>0.464074</td>\n",
       "      <td>0.475797</td>\n",
       "      <td>0.542401</td>\n",
       "      <td>0.448073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Timeline</td>\n",
       "      <td>-</td>\n",
       "      <td>dummy</td>\n",
       "      <td>macro avg</td>\n",
       "      <td>0.361407</td>\n",
       "      <td>0.462857</td>\n",
       "      <td>0.334878</td>\n",
       "      <td>0.351759</td>\n",
       "      <td>0.372519</td>\n",
       "      <td>0.344578</td>\n",
       "      <td>0.371333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Timeline</td>\n",
       "      <td>tf-idf</td>\n",
       "      <td>xgb</td>\n",
       "      <td>macro avg</td>\n",
       "      <td>0.699122</td>\n",
       "      <td>0.728220</td>\n",
       "      <td>0.898944</td>\n",
       "      <td>0.863813</td>\n",
       "      <td>0.598358</td>\n",
       "      <td>0.752710</td>\n",
       "      <td>0.756861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Timeline</td>\n",
       "      <td>bertabaporu-base</td>\n",
       "      <td>xgb</td>\n",
       "      <td>macro avg</td>\n",
       "      <td>0.661773</td>\n",
       "      <td>0.692262</td>\n",
       "      <td>0.776979</td>\n",
       "      <td>0.778471</td>\n",
       "      <td>0.585105</td>\n",
       "      <td>0.645518</td>\n",
       "      <td>0.690018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Timeline</td>\n",
       "      <td>-</td>\n",
       "      <td>bertabaporu-base</td>\n",
       "      <td>macro avg</td>\n",
       "      <td>0.652707</td>\n",
       "      <td>0.767310</td>\n",
       "      <td>0.822297</td>\n",
       "      <td>0.819813</td>\n",
       "      <td>0.580105</td>\n",
       "      <td>0.614923</td>\n",
       "      <td>0.709526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Timeline</td>\n",
       "      <td>-</td>\n",
       "      <td>bertabaporu-base (R)</td>\n",
       "      <td>macro avg</td>\n",
       "      <td>0.701990</td>\n",
       "      <td>0.822060</td>\n",
       "      <td>0.872170</td>\n",
       "      <td>0.860531</td>\n",
       "      <td>0.597442</td>\n",
       "      <td>0.711676</td>\n",
       "      <td>0.760978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Timeline</td>\n",
       "      <td>-</td>\n",
       "      <td>llama3:7b zero-shot [5] (R)</td>\n",
       "      <td>macro avg</td>\n",
       "      <td>0.605633</td>\n",
       "      <td>0.588752</td>\n",
       "      <td>0.639513</td>\n",
       "      <td>0.528509</td>\n",
       "      <td>0.560086</td>\n",
       "      <td>0.514680</td>\n",
       "      <td>0.572862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Timeline</td>\n",
       "      <td>-</td>\n",
       "      <td>llama3:7b zero-shot [10] (R)</td>\n",
       "      <td>macro avg</td>\n",
       "      <td>0.563199</td>\n",
       "      <td>0.611771</td>\n",
       "      <td>0.609199</td>\n",
       "      <td>0.529703</td>\n",
       "      <td>0.507579</td>\n",
       "      <td>0.516021</td>\n",
       "      <td>0.556245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Timeline</td>\n",
       "      <td>-</td>\n",
       "      <td>llama3:7b zero-shot [15] (R)</td>\n",
       "      <td>macro avg</td>\n",
       "      <td>0.598183</td>\n",
       "      <td>0.586106</td>\n",
       "      <td>0.611868</td>\n",
       "      <td>0.518743</td>\n",
       "      <td>0.515050</td>\n",
       "      <td>0.529726</td>\n",
       "      <td>0.559946</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    text_col        vectorizer                     estimator      class  \\\n",
       "0     Stance                 -                         dummy  macro avg   \n",
       "1     Stance            tf-idf                           xgb  macro avg   \n",
       "2     Stance  bertabaporu-base                           xgb  macro avg   \n",
       "3     Stance                 -              bertabaporu-base  macro avg   \n",
       "4     Stance                 -           llama3:7b zero-shot  macro avg   \n",
       "5      Texts                 -                         dummy  macro avg   \n",
       "6      Texts            tf-idf                           xgb  macro avg   \n",
       "7      Texts  bertabaporu-base                           xgb  macro avg   \n",
       "8      Texts                 -              bertabaporu-base  macro avg   \n",
       "9      Texts                 -   llama3:7b zero-shot [5] (R)  macro avg   \n",
       "10     Texts                 -  llama3:7b zero-shot [10] (R)  macro avg   \n",
       "11     Texts                 -  llama3:7b zero-shot [15] (R)  macro avg   \n",
       "12  Timeline                 -                         dummy  macro avg   \n",
       "13  Timeline            tf-idf                           xgb  macro avg   \n",
       "14  Timeline  bertabaporu-base                           xgb  macro avg   \n",
       "15  Timeline                 -              bertabaporu-base  macro avg   \n",
       "16  Timeline                 -          bertabaporu-base (R)  macro avg   \n",
       "17  Timeline                 -   llama3:7b zero-shot [5] (R)  macro avg   \n",
       "18  Timeline                 -  llama3:7b zero-shot [10] (R)  macro avg   \n",
       "19  Timeline                 -  llama3:7b zero-shot [15] (R)  macro avg   \n",
       "\n",
       "      Church  Bolsonaro   Hydrox.   Sinovac  Globo TV      Lula   overall  \n",
       "0   0.361407   0.462857  0.334878  0.351759  0.372519  0.344578  0.371333  \n",
       "1   0.702021   0.595312  0.734366  0.752640  0.665243  0.654412  0.683999  \n",
       "2   0.853801   0.625289  0.830948  0.808036  0.781858  0.766993  0.777821  \n",
       "3   0.866276   0.734945  0.844740  0.823002  0.875418  0.782733  0.821186  \n",
       "4   0.729458   0.462857  0.638889  0.578779  0.770678  0.699381  0.646674  \n",
       "5   0.361407   0.462857  0.334878  0.351759  0.372519  0.344578  0.371333  \n",
       "6   0.596115   0.501220  0.603727  0.670805  0.545620  0.579427  0.582819  \n",
       "7   0.594754   0.495578  0.609524  0.660542  0.534455  0.569597  0.577408  \n",
       "8   0.586611   0.462857  0.446504  0.608972  0.507381  0.482520  0.515808  \n",
       "9   0.499052   0.296142  0.469796  0.470381  0.490101  0.512954  0.456404  \n",
       "10  0.561274   0.328245  0.440347  0.460580  0.494646  0.478244  0.460556  \n",
       "11  0.503966   0.285253  0.416946  0.464074  0.475797  0.542401  0.448073  \n",
       "12  0.361407   0.462857  0.334878  0.351759  0.372519  0.344578  0.371333  \n",
       "13  0.699122   0.728220  0.898944  0.863813  0.598358  0.752710  0.756861  \n",
       "14  0.661773   0.692262  0.776979  0.778471  0.585105  0.645518  0.690018  \n",
       "15  0.652707   0.767310  0.822297  0.819813  0.580105  0.614923  0.709526  \n",
       "16  0.701990   0.822060  0.872170  0.860531  0.597442  0.711676  0.760978  \n",
       "17  0.605633   0.588752  0.639513  0.528509  0.560086  0.514680  0.572862  \n",
       "18  0.563199   0.611771  0.609199  0.529703  0.507579  0.516021  0.556245  \n",
       "19  0.598183   0.586106  0.611868  0.518743  0.515050  0.529726  0.559946  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_report.columns = new_columns\n",
    "f1_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_col</th>\n",
       "      <th>vectorizer</th>\n",
       "      <th>estimator</th>\n",
       "      <th>Church</th>\n",
       "      <th>Bolsonaro</th>\n",
       "      <th>Hydrox.</th>\n",
       "      <th>Sinovac</th>\n",
       "      <th>Globo TV</th>\n",
       "      <th>Lula</th>\n",
       "      <th>overall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Stance</td>\n",
       "      <td>-</td>\n",
       "      <td>dummy</td>\n",
       "      <td>0.361407</td>\n",
       "      <td>0.462857</td>\n",
       "      <td>0.334878</td>\n",
       "      <td>0.351759</td>\n",
       "      <td>0.372519</td>\n",
       "      <td>0.344578</td>\n",
       "      <td>0.371333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Stance</td>\n",
       "      <td>tf-idf</td>\n",
       "      <td>xgb</td>\n",
       "      <td>0.702021</td>\n",
       "      <td>0.595312</td>\n",
       "      <td>0.734366</td>\n",
       "      <td>0.752640</td>\n",
       "      <td>0.665243</td>\n",
       "      <td>0.654412</td>\n",
       "      <td>0.683999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Stance</td>\n",
       "      <td>bertabaporu-base</td>\n",
       "      <td>xgb</td>\n",
       "      <td>0.853801</td>\n",
       "      <td>0.625289</td>\n",
       "      <td>0.830948</td>\n",
       "      <td>0.808036</td>\n",
       "      <td>0.781858</td>\n",
       "      <td>0.766993</td>\n",
       "      <td>0.777821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Stance</td>\n",
       "      <td>-</td>\n",
       "      <td>bertabaporu-base</td>\n",
       "      <td>0.866276</td>\n",
       "      <td>0.734945</td>\n",
       "      <td>0.844740</td>\n",
       "      <td>0.823002</td>\n",
       "      <td>0.875418</td>\n",
       "      <td>0.782733</td>\n",
       "      <td>0.821186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Stance</td>\n",
       "      <td>-</td>\n",
       "      <td>llama3:7b zero-shot</td>\n",
       "      <td>0.729458</td>\n",
       "      <td>0.462857</td>\n",
       "      <td>0.638889</td>\n",
       "      <td>0.578779</td>\n",
       "      <td>0.770678</td>\n",
       "      <td>0.699381</td>\n",
       "      <td>0.646674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Texts</td>\n",
       "      <td>-</td>\n",
       "      <td>dummy</td>\n",
       "      <td>0.361407</td>\n",
       "      <td>0.462857</td>\n",
       "      <td>0.334878</td>\n",
       "      <td>0.351759</td>\n",
       "      <td>0.372519</td>\n",
       "      <td>0.344578</td>\n",
       "      <td>0.371333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Texts</td>\n",
       "      <td>tf-idf</td>\n",
       "      <td>xgb</td>\n",
       "      <td>0.596115</td>\n",
       "      <td>0.501220</td>\n",
       "      <td>0.603727</td>\n",
       "      <td>0.670805</td>\n",
       "      <td>0.545620</td>\n",
       "      <td>0.579427</td>\n",
       "      <td>0.582819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Texts</td>\n",
       "      <td>bertabaporu-base</td>\n",
       "      <td>xgb</td>\n",
       "      <td>0.594754</td>\n",
       "      <td>0.495578</td>\n",
       "      <td>0.609524</td>\n",
       "      <td>0.660542</td>\n",
       "      <td>0.534455</td>\n",
       "      <td>0.569597</td>\n",
       "      <td>0.577408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Texts</td>\n",
       "      <td>-</td>\n",
       "      <td>bertabaporu-base</td>\n",
       "      <td>0.586611</td>\n",
       "      <td>0.462857</td>\n",
       "      <td>0.446504</td>\n",
       "      <td>0.608972</td>\n",
       "      <td>0.507381</td>\n",
       "      <td>0.482520</td>\n",
       "      <td>0.515808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Texts</td>\n",
       "      <td>-</td>\n",
       "      <td>llama3:7b zero-shot [5] (R)</td>\n",
       "      <td>0.499052</td>\n",
       "      <td>0.296142</td>\n",
       "      <td>0.469796</td>\n",
       "      <td>0.470381</td>\n",
       "      <td>0.490101</td>\n",
       "      <td>0.512954</td>\n",
       "      <td>0.456404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Texts</td>\n",
       "      <td>-</td>\n",
       "      <td>llama3:7b zero-shot [10] (R)</td>\n",
       "      <td>0.561274</td>\n",
       "      <td>0.328245</td>\n",
       "      <td>0.440347</td>\n",
       "      <td>0.460580</td>\n",
       "      <td>0.494646</td>\n",
       "      <td>0.478244</td>\n",
       "      <td>0.460556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Texts</td>\n",
       "      <td>-</td>\n",
       "      <td>llama3:7b zero-shot [15] (R)</td>\n",
       "      <td>0.503966</td>\n",
       "      <td>0.285253</td>\n",
       "      <td>0.416946</td>\n",
       "      <td>0.464074</td>\n",
       "      <td>0.475797</td>\n",
       "      <td>0.542401</td>\n",
       "      <td>0.448073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Timeline</td>\n",
       "      <td>-</td>\n",
       "      <td>dummy</td>\n",
       "      <td>0.361407</td>\n",
       "      <td>0.462857</td>\n",
       "      <td>0.334878</td>\n",
       "      <td>0.351759</td>\n",
       "      <td>0.372519</td>\n",
       "      <td>0.344578</td>\n",
       "      <td>0.371333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Timeline</td>\n",
       "      <td>tf-idf</td>\n",
       "      <td>xgb</td>\n",
       "      <td>0.699122</td>\n",
       "      <td>0.728220</td>\n",
       "      <td>0.898944</td>\n",
       "      <td>0.863813</td>\n",
       "      <td>0.598358</td>\n",
       "      <td>0.752710</td>\n",
       "      <td>0.756861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Timeline</td>\n",
       "      <td>bertabaporu-base</td>\n",
       "      <td>xgb</td>\n",
       "      <td>0.661773</td>\n",
       "      <td>0.692262</td>\n",
       "      <td>0.776979</td>\n",
       "      <td>0.778471</td>\n",
       "      <td>0.585105</td>\n",
       "      <td>0.645518</td>\n",
       "      <td>0.690018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Timeline</td>\n",
       "      <td>-</td>\n",
       "      <td>bertabaporu-base</td>\n",
       "      <td>0.652707</td>\n",
       "      <td>0.767310</td>\n",
       "      <td>0.822297</td>\n",
       "      <td>0.819813</td>\n",
       "      <td>0.580105</td>\n",
       "      <td>0.614923</td>\n",
       "      <td>0.709526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Timeline</td>\n",
       "      <td>-</td>\n",
       "      <td>bertabaporu-base (R)</td>\n",
       "      <td>0.701990</td>\n",
       "      <td>0.822060</td>\n",
       "      <td>0.872170</td>\n",
       "      <td>0.860531</td>\n",
       "      <td>0.597442</td>\n",
       "      <td>0.711676</td>\n",
       "      <td>0.760978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Timeline</td>\n",
       "      <td>-</td>\n",
       "      <td>llama3:7b zero-shot [5] (R)</td>\n",
       "      <td>0.605633</td>\n",
       "      <td>0.588752</td>\n",
       "      <td>0.639513</td>\n",
       "      <td>0.528509</td>\n",
       "      <td>0.560086</td>\n",
       "      <td>0.514680</td>\n",
       "      <td>0.572862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Timeline</td>\n",
       "      <td>-</td>\n",
       "      <td>llama3:7b zero-shot [10] (R)</td>\n",
       "      <td>0.563199</td>\n",
       "      <td>0.611771</td>\n",
       "      <td>0.609199</td>\n",
       "      <td>0.529703</td>\n",
       "      <td>0.507579</td>\n",
       "      <td>0.516021</td>\n",
       "      <td>0.556245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Timeline</td>\n",
       "      <td>-</td>\n",
       "      <td>llama3:7b zero-shot [15] (R)</td>\n",
       "      <td>0.598183</td>\n",
       "      <td>0.586106</td>\n",
       "      <td>0.611868</td>\n",
       "      <td>0.518743</td>\n",
       "      <td>0.515050</td>\n",
       "      <td>0.529726</td>\n",
       "      <td>0.559946</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    text_col        vectorizer                     estimator    Church  \\\n",
       "0     Stance                 -                         dummy  0.361407   \n",
       "1     Stance            tf-idf                           xgb  0.702021   \n",
       "2     Stance  bertabaporu-base                           xgb  0.853801   \n",
       "3     Stance                 -              bertabaporu-base  0.866276   \n",
       "4     Stance                 -           llama3:7b zero-shot  0.729458   \n",
       "5      Texts                 -                         dummy  0.361407   \n",
       "6      Texts            tf-idf                           xgb  0.596115   \n",
       "7      Texts  bertabaporu-base                           xgb  0.594754   \n",
       "8      Texts                 -              bertabaporu-base  0.586611   \n",
       "9      Texts                 -   llama3:7b zero-shot [5] (R)  0.499052   \n",
       "10     Texts                 -  llama3:7b zero-shot [10] (R)  0.561274   \n",
       "11     Texts                 -  llama3:7b zero-shot [15] (R)  0.503966   \n",
       "12  Timeline                 -                         dummy  0.361407   \n",
       "13  Timeline            tf-idf                           xgb  0.699122   \n",
       "14  Timeline  bertabaporu-base                           xgb  0.661773   \n",
       "15  Timeline                 -              bertabaporu-base  0.652707   \n",
       "16  Timeline                 -          bertabaporu-base (R)  0.701990   \n",
       "17  Timeline                 -   llama3:7b zero-shot [5] (R)  0.605633   \n",
       "18  Timeline                 -  llama3:7b zero-shot [10] (R)  0.563199   \n",
       "19  Timeline                 -  llama3:7b zero-shot [15] (R)  0.598183   \n",
       "\n",
       "    Bolsonaro   Hydrox.   Sinovac  Globo TV      Lula   overall  \n",
       "0    0.462857  0.334878  0.351759  0.372519  0.344578  0.371333  \n",
       "1    0.595312  0.734366  0.752640  0.665243  0.654412  0.683999  \n",
       "2    0.625289  0.830948  0.808036  0.781858  0.766993  0.777821  \n",
       "3    0.734945  0.844740  0.823002  0.875418  0.782733  0.821186  \n",
       "4    0.462857  0.638889  0.578779  0.770678  0.699381  0.646674  \n",
       "5    0.462857  0.334878  0.351759  0.372519  0.344578  0.371333  \n",
       "6    0.501220  0.603727  0.670805  0.545620  0.579427  0.582819  \n",
       "7    0.495578  0.609524  0.660542  0.534455  0.569597  0.577408  \n",
       "8    0.462857  0.446504  0.608972  0.507381  0.482520  0.515808  \n",
       "9    0.296142  0.469796  0.470381  0.490101  0.512954  0.456404  \n",
       "10   0.328245  0.440347  0.460580  0.494646  0.478244  0.460556  \n",
       "11   0.285253  0.416946  0.464074  0.475797  0.542401  0.448073  \n",
       "12   0.462857  0.334878  0.351759  0.372519  0.344578  0.371333  \n",
       "13   0.728220  0.898944  0.863813  0.598358  0.752710  0.756861  \n",
       "14   0.692262  0.776979  0.778471  0.585105  0.645518  0.690018  \n",
       "15   0.767310  0.822297  0.819813  0.580105  0.614923  0.709526  \n",
       "16   0.822060  0.872170  0.860531  0.597442  0.711676  0.760978  \n",
       "17   0.588752  0.639513  0.528509  0.560086  0.514680  0.572862  \n",
       "18   0.611771  0.609199  0.529703  0.507579  0.516021  0.556245  \n",
       "19   0.586106  0.611868  0.518743  0.515050  0.529726  0.559946  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_report.drop(['class'],axis = 1, inplace=True)\n",
    "f1_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_col</th>\n",
       "      <th>classifier</th>\n",
       "      <th>Church</th>\n",
       "      <th>Bolsonaro</th>\n",
       "      <th>Hydrox.</th>\n",
       "      <th>Sinovac</th>\n",
       "      <th>Globo TV</th>\n",
       "      <th>Lula</th>\n",
       "      <th>overall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Stance</td>\n",
       "      <td>dummy</td>\n",
       "      <td>0.361407</td>\n",
       "      <td>0.462857</td>\n",
       "      <td>0.334878</td>\n",
       "      <td>0.351759</td>\n",
       "      <td>0.372519</td>\n",
       "      <td>0.344578</td>\n",
       "      <td>0.371333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Stance</td>\n",
       "      <td>tf-idf + xgb</td>\n",
       "      <td>0.702021</td>\n",
       "      <td>0.595312</td>\n",
       "      <td>0.734366</td>\n",
       "      <td>0.752640</td>\n",
       "      <td>0.665243</td>\n",
       "      <td>0.654412</td>\n",
       "      <td>0.683999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Stance</td>\n",
       "      <td>bertabaporu-base + xgb</td>\n",
       "      <td>0.853801</td>\n",
       "      <td>0.625289</td>\n",
       "      <td>0.830948</td>\n",
       "      <td>0.808036</td>\n",
       "      <td>0.781858</td>\n",
       "      <td>0.766993</td>\n",
       "      <td>0.777821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Stance</td>\n",
       "      <td>bertabaporu-base</td>\n",
       "      <td>0.866276</td>\n",
       "      <td>0.734945</td>\n",
       "      <td>0.844740</td>\n",
       "      <td>0.823002</td>\n",
       "      <td>0.875418</td>\n",
       "      <td>0.782733</td>\n",
       "      <td>0.821186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Stance</td>\n",
       "      <td>llama3:7b zero-shot</td>\n",
       "      <td>0.729458</td>\n",
       "      <td>0.462857</td>\n",
       "      <td>0.638889</td>\n",
       "      <td>0.578779</td>\n",
       "      <td>0.770678</td>\n",
       "      <td>0.699381</td>\n",
       "      <td>0.646674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Texts</td>\n",
       "      <td>dummy</td>\n",
       "      <td>0.361407</td>\n",
       "      <td>0.462857</td>\n",
       "      <td>0.334878</td>\n",
       "      <td>0.351759</td>\n",
       "      <td>0.372519</td>\n",
       "      <td>0.344578</td>\n",
       "      <td>0.371333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Texts</td>\n",
       "      <td>tf-idf + xgb</td>\n",
       "      <td>0.596115</td>\n",
       "      <td>0.501220</td>\n",
       "      <td>0.603727</td>\n",
       "      <td>0.670805</td>\n",
       "      <td>0.545620</td>\n",
       "      <td>0.579427</td>\n",
       "      <td>0.582819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Texts</td>\n",
       "      <td>bertabaporu-base + xgb</td>\n",
       "      <td>0.594754</td>\n",
       "      <td>0.495578</td>\n",
       "      <td>0.609524</td>\n",
       "      <td>0.660542</td>\n",
       "      <td>0.534455</td>\n",
       "      <td>0.569597</td>\n",
       "      <td>0.577408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Texts</td>\n",
       "      <td>bertabaporu-base</td>\n",
       "      <td>0.586611</td>\n",
       "      <td>0.462857</td>\n",
       "      <td>0.446504</td>\n",
       "      <td>0.608972</td>\n",
       "      <td>0.507381</td>\n",
       "      <td>0.482520</td>\n",
       "      <td>0.515808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Texts</td>\n",
       "      <td>llama3:7b zero-shot [5] (R)</td>\n",
       "      <td>0.499052</td>\n",
       "      <td>0.296142</td>\n",
       "      <td>0.469796</td>\n",
       "      <td>0.470381</td>\n",
       "      <td>0.490101</td>\n",
       "      <td>0.512954</td>\n",
       "      <td>0.456404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Texts</td>\n",
       "      <td>llama3:7b zero-shot [10] (R)</td>\n",
       "      <td>0.561274</td>\n",
       "      <td>0.328245</td>\n",
       "      <td>0.440347</td>\n",
       "      <td>0.460580</td>\n",
       "      <td>0.494646</td>\n",
       "      <td>0.478244</td>\n",
       "      <td>0.460556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Texts</td>\n",
       "      <td>llama3:7b zero-shot [15] (R)</td>\n",
       "      <td>0.503966</td>\n",
       "      <td>0.285253</td>\n",
       "      <td>0.416946</td>\n",
       "      <td>0.464074</td>\n",
       "      <td>0.475797</td>\n",
       "      <td>0.542401</td>\n",
       "      <td>0.448073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Timeline</td>\n",
       "      <td>dummy</td>\n",
       "      <td>0.361407</td>\n",
       "      <td>0.462857</td>\n",
       "      <td>0.334878</td>\n",
       "      <td>0.351759</td>\n",
       "      <td>0.372519</td>\n",
       "      <td>0.344578</td>\n",
       "      <td>0.371333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Timeline</td>\n",
       "      <td>tf-idf + xgb</td>\n",
       "      <td>0.699122</td>\n",
       "      <td>0.728220</td>\n",
       "      <td>0.898944</td>\n",
       "      <td>0.863813</td>\n",
       "      <td>0.598358</td>\n",
       "      <td>0.752710</td>\n",
       "      <td>0.756861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Timeline</td>\n",
       "      <td>bertabaporu-base + xgb</td>\n",
       "      <td>0.661773</td>\n",
       "      <td>0.692262</td>\n",
       "      <td>0.776979</td>\n",
       "      <td>0.778471</td>\n",
       "      <td>0.585105</td>\n",
       "      <td>0.645518</td>\n",
       "      <td>0.690018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Timeline</td>\n",
       "      <td>bertabaporu-base</td>\n",
       "      <td>0.652707</td>\n",
       "      <td>0.767310</td>\n",
       "      <td>0.822297</td>\n",
       "      <td>0.819813</td>\n",
       "      <td>0.580105</td>\n",
       "      <td>0.614923</td>\n",
       "      <td>0.709526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Timeline</td>\n",
       "      <td>bertabaporu-base (R)</td>\n",
       "      <td>0.701990</td>\n",
       "      <td>0.822060</td>\n",
       "      <td>0.872170</td>\n",
       "      <td>0.860531</td>\n",
       "      <td>0.597442</td>\n",
       "      <td>0.711676</td>\n",
       "      <td>0.760978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Timeline</td>\n",
       "      <td>llama3:7b zero-shot [5] (R)</td>\n",
       "      <td>0.605633</td>\n",
       "      <td>0.588752</td>\n",
       "      <td>0.639513</td>\n",
       "      <td>0.528509</td>\n",
       "      <td>0.560086</td>\n",
       "      <td>0.514680</td>\n",
       "      <td>0.572862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Timeline</td>\n",
       "      <td>llama3:7b zero-shot [10] (R)</td>\n",
       "      <td>0.563199</td>\n",
       "      <td>0.611771</td>\n",
       "      <td>0.609199</td>\n",
       "      <td>0.529703</td>\n",
       "      <td>0.507579</td>\n",
       "      <td>0.516021</td>\n",
       "      <td>0.556245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Timeline</td>\n",
       "      <td>llama3:7b zero-shot [15] (R)</td>\n",
       "      <td>0.598183</td>\n",
       "      <td>0.586106</td>\n",
       "      <td>0.611868</td>\n",
       "      <td>0.518743</td>\n",
       "      <td>0.515050</td>\n",
       "      <td>0.529726</td>\n",
       "      <td>0.559946</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    text_col                    classifier    Church  Bolsonaro   Hydrox.  \\\n",
       "0     Stance                         dummy  0.361407   0.462857  0.334878   \n",
       "1     Stance                  tf-idf + xgb  0.702021   0.595312  0.734366   \n",
       "2     Stance        bertabaporu-base + xgb  0.853801   0.625289  0.830948   \n",
       "3     Stance              bertabaporu-base  0.866276   0.734945  0.844740   \n",
       "4     Stance           llama3:7b zero-shot  0.729458   0.462857  0.638889   \n",
       "5      Texts                         dummy  0.361407   0.462857  0.334878   \n",
       "6      Texts                  tf-idf + xgb  0.596115   0.501220  0.603727   \n",
       "7      Texts        bertabaporu-base + xgb  0.594754   0.495578  0.609524   \n",
       "8      Texts              bertabaporu-base  0.586611   0.462857  0.446504   \n",
       "9      Texts   llama3:7b zero-shot [5] (R)  0.499052   0.296142  0.469796   \n",
       "10     Texts  llama3:7b zero-shot [10] (R)  0.561274   0.328245  0.440347   \n",
       "11     Texts  llama3:7b zero-shot [15] (R)  0.503966   0.285253  0.416946   \n",
       "12  Timeline                         dummy  0.361407   0.462857  0.334878   \n",
       "13  Timeline                  tf-idf + xgb  0.699122   0.728220  0.898944   \n",
       "14  Timeline        bertabaporu-base + xgb  0.661773   0.692262  0.776979   \n",
       "15  Timeline              bertabaporu-base  0.652707   0.767310  0.822297   \n",
       "16  Timeline          bertabaporu-base (R)  0.701990   0.822060  0.872170   \n",
       "17  Timeline   llama3:7b zero-shot [5] (R)  0.605633   0.588752  0.639513   \n",
       "18  Timeline  llama3:7b zero-shot [10] (R)  0.563199   0.611771  0.609199   \n",
       "19  Timeline  llama3:7b zero-shot [15] (R)  0.598183   0.586106  0.611868   \n",
       "\n",
       "     Sinovac  Globo TV      Lula   overall  \n",
       "0   0.351759  0.372519  0.344578  0.371333  \n",
       "1   0.752640  0.665243  0.654412  0.683999  \n",
       "2   0.808036  0.781858  0.766993  0.777821  \n",
       "3   0.823002  0.875418  0.782733  0.821186  \n",
       "4   0.578779  0.770678  0.699381  0.646674  \n",
       "5   0.351759  0.372519  0.344578  0.371333  \n",
       "6   0.670805  0.545620  0.579427  0.582819  \n",
       "7   0.660542  0.534455  0.569597  0.577408  \n",
       "8   0.608972  0.507381  0.482520  0.515808  \n",
       "9   0.470381  0.490101  0.512954  0.456404  \n",
       "10  0.460580  0.494646  0.478244  0.460556  \n",
       "11  0.464074  0.475797  0.542401  0.448073  \n",
       "12  0.351759  0.372519  0.344578  0.371333  \n",
       "13  0.863813  0.598358  0.752710  0.756861  \n",
       "14  0.778471  0.585105  0.645518  0.690018  \n",
       "15  0.819813  0.580105  0.614923  0.709526  \n",
       "16  0.860531  0.597442  0.711676  0.760978  \n",
       "17  0.528509  0.560086  0.514680  0.572862  \n",
       "18  0.529703  0.507579  0.516021  0.556245  \n",
       "19  0.518743  0.515050  0.529726  0.559946  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_report.insert(\n",
    "    1, \n",
    "    \"classifier\", \n",
    "    f1_report.apply(\n",
    "        lambda x: f\"{x['vectorizer']} + {x['estimator']}\" if x['vectorizer'] != '-' else x['estimator'],\n",
    "        axis = 1\n",
    "        ).to_list()\n",
    "\n",
    ")\n",
    "f1_report.drop(['estimator', 'vectorizer'],axis =1, inplace = True)\n",
    "f1_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input</th>\n",
       "      <th>classifier</th>\n",
       "      <th>Church</th>\n",
       "      <th>Bolsonaro</th>\n",
       "      <th>Hydrox.</th>\n",
       "      <th>Sinovac</th>\n",
       "      <th>Globo TV</th>\n",
       "      <th>Lula</th>\n",
       "      <th>overall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Stance</td>\n",
       "      <td>dummy</td>\n",
       "      <td>0.361407</td>\n",
       "      <td>0.462857</td>\n",
       "      <td>0.334878</td>\n",
       "      <td>0.351759</td>\n",
       "      <td>0.372519</td>\n",
       "      <td>0.344578</td>\n",
       "      <td>0.371333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Stance</td>\n",
       "      <td>tf-idf + xgb</td>\n",
       "      <td>0.702021</td>\n",
       "      <td>0.595312</td>\n",
       "      <td>0.734366</td>\n",
       "      <td>0.752640</td>\n",
       "      <td>0.665243</td>\n",
       "      <td>0.654412</td>\n",
       "      <td>0.683999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Stance</td>\n",
       "      <td>bertabaporu-base + xgb</td>\n",
       "      <td>0.853801</td>\n",
       "      <td>0.625289</td>\n",
       "      <td>0.830948</td>\n",
       "      <td>0.808036</td>\n",
       "      <td>0.781858</td>\n",
       "      <td>0.766993</td>\n",
       "      <td>0.777821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Stance</td>\n",
       "      <td>bertabaporu-base</td>\n",
       "      <td>0.866276</td>\n",
       "      <td>0.734945</td>\n",
       "      <td>0.844740</td>\n",
       "      <td>0.823002</td>\n",
       "      <td>0.875418</td>\n",
       "      <td>0.782733</td>\n",
       "      <td>0.821186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Stance</td>\n",
       "      <td>llama3:7b zero-shot</td>\n",
       "      <td>0.729458</td>\n",
       "      <td>0.462857</td>\n",
       "      <td>0.638889</td>\n",
       "      <td>0.578779</td>\n",
       "      <td>0.770678</td>\n",
       "      <td>0.699381</td>\n",
       "      <td>0.646674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Texts</td>\n",
       "      <td>dummy</td>\n",
       "      <td>0.361407</td>\n",
       "      <td>0.462857</td>\n",
       "      <td>0.334878</td>\n",
       "      <td>0.351759</td>\n",
       "      <td>0.372519</td>\n",
       "      <td>0.344578</td>\n",
       "      <td>0.371333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Texts</td>\n",
       "      <td>tf-idf + xgb</td>\n",
       "      <td>0.596115</td>\n",
       "      <td>0.501220</td>\n",
       "      <td>0.603727</td>\n",
       "      <td>0.670805</td>\n",
       "      <td>0.545620</td>\n",
       "      <td>0.579427</td>\n",
       "      <td>0.582819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Texts</td>\n",
       "      <td>bertabaporu-base + xgb</td>\n",
       "      <td>0.594754</td>\n",
       "      <td>0.495578</td>\n",
       "      <td>0.609524</td>\n",
       "      <td>0.660542</td>\n",
       "      <td>0.534455</td>\n",
       "      <td>0.569597</td>\n",
       "      <td>0.577408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Texts</td>\n",
       "      <td>bertabaporu-base</td>\n",
       "      <td>0.586611</td>\n",
       "      <td>0.462857</td>\n",
       "      <td>0.446504</td>\n",
       "      <td>0.608972</td>\n",
       "      <td>0.507381</td>\n",
       "      <td>0.482520</td>\n",
       "      <td>0.515808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Texts</td>\n",
       "      <td>llama3:7b zero-shot [5] (R)</td>\n",
       "      <td>0.499052</td>\n",
       "      <td>0.296142</td>\n",
       "      <td>0.469796</td>\n",
       "      <td>0.470381</td>\n",
       "      <td>0.490101</td>\n",
       "      <td>0.512954</td>\n",
       "      <td>0.456404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Texts</td>\n",
       "      <td>llama3:7b zero-shot [10] (R)</td>\n",
       "      <td>0.561274</td>\n",
       "      <td>0.328245</td>\n",
       "      <td>0.440347</td>\n",
       "      <td>0.460580</td>\n",
       "      <td>0.494646</td>\n",
       "      <td>0.478244</td>\n",
       "      <td>0.460556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Texts</td>\n",
       "      <td>llama3:7b zero-shot [15] (R)</td>\n",
       "      <td>0.503966</td>\n",
       "      <td>0.285253</td>\n",
       "      <td>0.416946</td>\n",
       "      <td>0.464074</td>\n",
       "      <td>0.475797</td>\n",
       "      <td>0.542401</td>\n",
       "      <td>0.448073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Timeline</td>\n",
       "      <td>dummy</td>\n",
       "      <td>0.361407</td>\n",
       "      <td>0.462857</td>\n",
       "      <td>0.334878</td>\n",
       "      <td>0.351759</td>\n",
       "      <td>0.372519</td>\n",
       "      <td>0.344578</td>\n",
       "      <td>0.371333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Timeline</td>\n",
       "      <td>tf-idf + xgb</td>\n",
       "      <td>0.699122</td>\n",
       "      <td>0.728220</td>\n",
       "      <td>0.898944</td>\n",
       "      <td>0.863813</td>\n",
       "      <td>0.598358</td>\n",
       "      <td>0.752710</td>\n",
       "      <td>0.756861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Timeline</td>\n",
       "      <td>bertabaporu-base + xgb</td>\n",
       "      <td>0.661773</td>\n",
       "      <td>0.692262</td>\n",
       "      <td>0.776979</td>\n",
       "      <td>0.778471</td>\n",
       "      <td>0.585105</td>\n",
       "      <td>0.645518</td>\n",
       "      <td>0.690018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Timeline</td>\n",
       "      <td>bertabaporu-base</td>\n",
       "      <td>0.652707</td>\n",
       "      <td>0.767310</td>\n",
       "      <td>0.822297</td>\n",
       "      <td>0.819813</td>\n",
       "      <td>0.580105</td>\n",
       "      <td>0.614923</td>\n",
       "      <td>0.709526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Timeline</td>\n",
       "      <td>bertabaporu-base (R)</td>\n",
       "      <td>0.701990</td>\n",
       "      <td>0.822060</td>\n",
       "      <td>0.872170</td>\n",
       "      <td>0.860531</td>\n",
       "      <td>0.597442</td>\n",
       "      <td>0.711676</td>\n",
       "      <td>0.760978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Timeline</td>\n",
       "      <td>llama3:7b zero-shot [5] (R)</td>\n",
       "      <td>0.605633</td>\n",
       "      <td>0.588752</td>\n",
       "      <td>0.639513</td>\n",
       "      <td>0.528509</td>\n",
       "      <td>0.560086</td>\n",
       "      <td>0.514680</td>\n",
       "      <td>0.572862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Timeline</td>\n",
       "      <td>llama3:7b zero-shot [10] (R)</td>\n",
       "      <td>0.563199</td>\n",
       "      <td>0.611771</td>\n",
       "      <td>0.609199</td>\n",
       "      <td>0.529703</td>\n",
       "      <td>0.507579</td>\n",
       "      <td>0.516021</td>\n",
       "      <td>0.556245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Timeline</td>\n",
       "      <td>llama3:7b zero-shot [15] (R)</td>\n",
       "      <td>0.598183</td>\n",
       "      <td>0.586106</td>\n",
       "      <td>0.611868</td>\n",
       "      <td>0.518743</td>\n",
       "      <td>0.515050</td>\n",
       "      <td>0.529726</td>\n",
       "      <td>0.559946</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       input                    classifier    Church  Bolsonaro   Hydrox.  \\\n",
       "0     Stance                         dummy  0.361407   0.462857  0.334878   \n",
       "1     Stance                  tf-idf + xgb  0.702021   0.595312  0.734366   \n",
       "2     Stance        bertabaporu-base + xgb  0.853801   0.625289  0.830948   \n",
       "3     Stance              bertabaporu-base  0.866276   0.734945  0.844740   \n",
       "4     Stance           llama3:7b zero-shot  0.729458   0.462857  0.638889   \n",
       "5      Texts                         dummy  0.361407   0.462857  0.334878   \n",
       "6      Texts                  tf-idf + xgb  0.596115   0.501220  0.603727   \n",
       "7      Texts        bertabaporu-base + xgb  0.594754   0.495578  0.609524   \n",
       "8      Texts              bertabaporu-base  0.586611   0.462857  0.446504   \n",
       "9      Texts   llama3:7b zero-shot [5] (R)  0.499052   0.296142  0.469796   \n",
       "10     Texts  llama3:7b zero-shot [10] (R)  0.561274   0.328245  0.440347   \n",
       "11     Texts  llama3:7b zero-shot [15] (R)  0.503966   0.285253  0.416946   \n",
       "12  Timeline                         dummy  0.361407   0.462857  0.334878   \n",
       "13  Timeline                  tf-idf + xgb  0.699122   0.728220  0.898944   \n",
       "14  Timeline        bertabaporu-base + xgb  0.661773   0.692262  0.776979   \n",
       "15  Timeline              bertabaporu-base  0.652707   0.767310  0.822297   \n",
       "16  Timeline          bertabaporu-base (R)  0.701990   0.822060  0.872170   \n",
       "17  Timeline   llama3:7b zero-shot [5] (R)  0.605633   0.588752  0.639513   \n",
       "18  Timeline  llama3:7b zero-shot [10] (R)  0.563199   0.611771  0.609199   \n",
       "19  Timeline  llama3:7b zero-shot [15] (R)  0.598183   0.586106  0.611868   \n",
       "\n",
       "     Sinovac  Globo TV      Lula   overall  \n",
       "0   0.351759  0.372519  0.344578  0.371333  \n",
       "1   0.752640  0.665243  0.654412  0.683999  \n",
       "2   0.808036  0.781858  0.766993  0.777821  \n",
       "3   0.823002  0.875418  0.782733  0.821186  \n",
       "4   0.578779  0.770678  0.699381  0.646674  \n",
       "5   0.351759  0.372519  0.344578  0.371333  \n",
       "6   0.670805  0.545620  0.579427  0.582819  \n",
       "7   0.660542  0.534455  0.569597  0.577408  \n",
       "8   0.608972  0.507381  0.482520  0.515808  \n",
       "9   0.470381  0.490101  0.512954  0.456404  \n",
       "10  0.460580  0.494646  0.478244  0.460556  \n",
       "11  0.464074  0.475797  0.542401  0.448073  \n",
       "12  0.351759  0.372519  0.344578  0.371333  \n",
       "13  0.863813  0.598358  0.752710  0.756861  \n",
       "14  0.778471  0.585105  0.645518  0.690018  \n",
       "15  0.819813  0.580105  0.614923  0.709526  \n",
       "16  0.860531  0.597442  0.711676  0.760978  \n",
       "17  0.528509  0.560086  0.514680  0.572862  \n",
       "18  0.529703  0.507579  0.516021  0.556245  \n",
       "19  0.518743  0.515050  0.529726  0.559946  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_report.rename({\"text_col\":\"input\"}, axis = 1, inplace=True)\n",
    "f1_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#f1_report.set_index(['input'],inplace=True)\n",
    "#f1_report.drop('input', axis = 1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_latex_with_multirow_and_bold(df):\n",
    "    latex_code = ''\n",
    "    latex_code += '\\\\begin{table}[H]'\n",
    "    latex_code += \"\\\\begin{tabular}{ll|rrrrrrr}\\n\\\\toprule\\n\"\n",
    "    latex_code += \"input & classifier & Church & Bolsonaro & Hydrox. & Sinovac & Globo TV & Lula & overall \\\\\\\\ \\n\\\\midrule\\n\"\n",
    "\n",
    "    last_input = None\n",
    "    multirow_count = 0\n",
    "\n",
    "    for input_value in df['input'].unique():\n",
    "        subset = df[df['input'] == input_value]\n",
    "        max_overall_idx = subset['overall'].idxmax()\n",
    "\n",
    "        for i, row in subset.iterrows():\n",
    "            if row['input'] == last_input:\n",
    "                latex_code += \"& \"\n",
    "                multirow_count += 1\n",
    "            else:\n",
    "                if multirow_count > 0:\n",
    "                    latex_code = latex_code.replace(f\"multirow{{{multirow_count}}}\", f\"multirow{{{multirow_count + 1}}}\", 1)\n",
    "                if last_input is not None:\n",
    "                    latex_code += \"\\\\cmidrule(lr){1-9}\\n\"\n",
    "                latex_code += f\"\\\\multirow{{{1}}}{{*}}{{{row['input']}}} & \"\n",
    "                multirow_count = 1\n",
    "\n",
    "            if i == max_overall_idx:\n",
    "                row_data = [f\"\\\\textbf{{{row[col]:.2f}}}\" if col not in ['input', 'classifier'] else f\"\\\\textbf{{{row[col]}}}\" for col in df.columns[1:]]\n",
    "                latex_code += \" & \".join(row_data) + \" \\\\\\\\ \\n\"\n",
    "            else:\n",
    "                latex_code += \" & \".join([f\"{row[col]:.2f}\" if isinstance(row[col], float) else str(row[col]) for col in df.columns[1:]]) + \" \\\\\\\\ \\n\"\n",
    "            \n",
    "            last_input = row['input']\n",
    "\n",
    "    if multirow_count > 0:\n",
    "        latex_code = latex_code.replace(f\"multirow{{{multirow_count}}}\", f\"multirow{{{multirow_count + 1}}}\", 1)\n",
    "\n",
    "    latex_code += \"\\\\cmidrule(lr){1-9}\\n\"\n",
    "    latex_code += \"\\\\bottomrule\\n\\\\end{tabular}\"\n",
    "    latex_code += \"\\caption{F1 macro results}\"\n",
    "    latex_code += '\\label{table:results_f1_macro}\\n'\n",
    "    latex_code += '\\end{table}'\n",
    "\n",
    "    return latex_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_report.input = f1_report.input.map({\n",
    "    \"Stance\": \"S\",\n",
    "    \"Timeline\": 'UT',\n",
    "    \"Texts\": 'UFT'\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "str_latex = generate_latex_with_multirow_and_bold(f1_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{table}[H]\\begin{tabular}{ll|rrrrrrr}\n",
      "\\toprule\n",
      "input & classifier & Church & Bolsonaro & Hydrox. & Sinovac & Globo TV & Lula & overall \\\\ \n",
      "\\midrule\n",
      "\\multirow{1}{*}{S} & dummy & 0.36 & 0.46 & 0.33 & 0.35 & 0.37 & 0.34 & 0.37 \\\\ \n",
      "& tf-idf + xgb & 0.70 & 0.60 & 0.73 & 0.75 & 0.67 & 0.65 & 0.68 \\\\ \n",
      "& bertabaporu-base + xgb & 0.85 & 0.63 & 0.83 & 0.81 & 0.78 & 0.77 & 0.78 \\\\ \n",
      "& \\textbf{bertabaporu-base} & \\textbf{0.87} & \\textbf{0.73} & \\textbf{0.84} & \\textbf{0.82} & \\textbf{0.88} & \\textbf{0.78} & \\textbf{0.82} \\\\ \n",
      "& llama3:7b zero-shot & 0.73 & 0.46 & 0.64 & 0.58 & 0.77 & 0.70 & 0.65 \\\\ \n",
      "\\cmidrule(lr){1-9}\n",
      "\\multirow{1}{*}{UFT} & dummy & 0.36 & 0.46 & 0.33 & 0.35 & 0.37 & 0.34 & 0.37 \\\\ \n",
      "& \\textbf{tf-idf + xgb} & \\textbf{0.60} & \\textbf{0.50} & \\textbf{0.60} & \\textbf{0.67} & \\textbf{0.55} & \\textbf{0.58} & \\textbf{0.58} \\\\ \n",
      "& bertabaporu-base + xgb & 0.59 & 0.50 & 0.61 & 0.66 & 0.53 & 0.57 & 0.58 \\\\ \n",
      "& bertabaporu-base & 0.59 & 0.46 & 0.45 & 0.61 & 0.51 & 0.48 & 0.52 \\\\ \n",
      "& llama3:7b zero-shot [5] (R) & 0.50 & 0.30 & 0.47 & 0.47 & 0.49 & 0.51 & 0.46 \\\\ \n",
      "& llama3:7b zero-shot [10] (R) & 0.56 & 0.33 & 0.44 & 0.46 & 0.49 & 0.48 & 0.46 \\\\ \n",
      "& llama3:7b zero-shot [15] (R) & 0.50 & 0.29 & 0.42 & 0.46 & 0.48 & 0.54 & 0.45 \\\\ \n",
      "\\cmidrule(lr){1-9}\n",
      "\\multirow{1}{*}{UT} & dummy & 0.36 & 0.46 & 0.33 & 0.35 & 0.37 & 0.34 & 0.37 \\\\ \n",
      "& tf-idf + xgb & 0.70 & 0.73 & 0.90 & 0.86 & 0.60 & 0.75 & 0.76 \\\\ \n",
      "& bertabaporu-base + xgb & 0.66 & 0.69 & 0.78 & 0.78 & 0.59 & 0.65 & 0.69 \\\\ \n",
      "& bertabaporu-base & 0.65 & 0.77 & 0.82 & 0.82 & 0.58 & 0.61 & 0.71 \\\\ \n",
      "& \\textbf{bertabaporu-base (R)} & \\textbf{0.70} & \\textbf{0.82} & \\textbf{0.87} & \\textbf{0.86} & \\textbf{0.60} & \\textbf{0.71} & \\textbf{0.76} \\\\ \n",
      "& llama3:7b zero-shot [5] (R) & 0.61 & 0.59 & 0.64 & 0.53 & 0.56 & 0.51 & 0.57 \\\\ \n",
      "& llama3:7b zero-shot [10] (R) & 0.56 & 0.61 & 0.61 & 0.53 & 0.51 & 0.52 & 0.56 \\\\ \n",
      "& llama3:7b zero-shot [15] (R) & 0.60 & 0.59 & 0.61 & 0.52 & 0.52 & 0.53 & 0.56 \\\\ \n",
      "\\cmidrule(lr){1-9}\n",
      "\\bottomrule\n",
      "\\end{tabular}\\caption{F1 macro results}\\label{table:results_f1_macro}\n",
      "\\end{table}\n"
     ]
    }
   ],
   "source": [
    "print(str_latex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[7, 7, 6, 5, 4, 3, 1]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[1,3,4,5,6,7,7][::-1]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env-stance-pred",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
