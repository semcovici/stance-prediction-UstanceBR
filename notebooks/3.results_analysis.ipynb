{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.metrics import classification_report\n",
    "from tqdm import tqdm\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../src')\n",
    "\n",
    "from models.classification_methods import get_classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['DummyClassifier_bo_top_mentioned_timelines_Texts_test_results.csv',\n",
       " 'DummyClassifier_bo_users_Stance_test_results.csv',\n",
       " 'DummyClassifier_bo_users_Timeline_test_results.csv',\n",
       " 'DummyClassifier_cl_top_mentioned_timelines_Texts_test_results.csv',\n",
       " 'DummyClassifier_cl_users_Stance_test_results.csv',\n",
       " 'DummyClassifier_cl_users_Timeline_test_results.csv',\n",
       " 'DummyClassifier_co_top_mentioned_timelines_Texts_test_results.csv',\n",
       " 'DummyClassifier_co_users_Stance_test_results.csv',\n",
       " 'DummyClassifier_co_users_Timeline_test_results.csv',\n",
       " 'DummyClassifier_gl_top_mentioned_timelines_Texts_test_results.csv',\n",
       " 'DummyClassifier_gl_users_Stance_test_results.csv',\n",
       " 'DummyClassifier_gl_users_Timeline_test_results.csv',\n",
       " 'DummyClassifier_ig_top_mentioned_timelines_Texts_test_results.csv',\n",
       " 'DummyClassifier_ig_users_Stance_test_results.csv',\n",
       " 'DummyClassifier_ig_users_Timeline_test_results.csv',\n",
       " 'DummyClassifier_lu_top_mentioned_timelines_Texts_test_results.csv',\n",
       " 'DummyClassifier_lu_users_Stance_test_results.csv',\n",
       " 'DummyClassifier_lu_users_Timeline_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_bo_Stance_Timeline_Texts_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_bo_Stance_Timeline_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_bo_Texts_Stance_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_bo_Texts_Timeline_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_cl_Stance_Timeline_Texts_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_cl_Stance_Timeline_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_cl_Texts_Stance_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_cl_Texts_Timeline_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_co_Stance_Timeline_Texts_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_co_Stance_Timeline_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_co_Texts_Stance_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_co_Texts_Timeline_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_gl_Stance_Timeline_Texts_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_gl_Stance_Timeline_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_gl_Texts_Stance_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_gl_Texts_Timeline_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_ig_Stance_Timeline_Texts_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_ig_Stance_Timeline_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_ig_Texts_Stance_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_ig_Texts_Timeline_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_lu_Stance_Timeline_Texts_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_lu_Stance_Timeline_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_lu_Texts_Stance_test_results.csv',\n",
       " 'Ensemble_LogisticRegression_lu_Texts_Timeline_test_results.csv',\n",
       " 'XGBClassifier_TfidfVectorizer_bo_top_mentioned_timelines_Texts_test_results.csv',\n",
       " 'XGBClassifier_TfidfVectorizer_bo_users_Stance_test_results.csv',\n",
       " 'XGBClassifier_TfidfVectorizer_bo_users_Timeline_test_results.csv',\n",
       " 'XGBClassifier_TfidfVectorizer_cl_top_mentioned_timelines_Texts_test_results.csv',\n",
       " 'XGBClassifier_TfidfVectorizer_cl_users_Stance_test_results.csv',\n",
       " 'XGBClassifier_TfidfVectorizer_cl_users_Timeline_test_results.csv',\n",
       " 'XGBClassifier_TfidfVectorizer_co_top_mentioned_timelines_Texts_test_results.csv',\n",
       " 'XGBClassifier_TfidfVectorizer_co_users_Stance_test_results.csv',\n",
       " 'XGBClassifier_TfidfVectorizer_co_users_Timeline_test_results.csv',\n",
       " 'XGBClassifier_TfidfVectorizer_gl_top_mentioned_timelines_Texts_test_results.csv',\n",
       " 'XGBClassifier_TfidfVectorizer_gl_users_Stance_test_results.csv',\n",
       " 'XGBClassifier_TfidfVectorizer_gl_users_Timeline_test_results.csv',\n",
       " 'XGBClassifier_TfidfVectorizer_ig_top_mentioned_timelines_Texts_test_results.csv',\n",
       " 'XGBClassifier_TfidfVectorizer_ig_users_Stance_test_results.csv',\n",
       " 'XGBClassifier_TfidfVectorizer_ig_users_Timeline_test_results.csv',\n",
       " 'XGBClassifier_TfidfVectorizer_lu_top_mentioned_timelines_Texts_test_results.csv',\n",
       " 'XGBClassifier_TfidfVectorizer_lu_users_Stance_test_results.csv',\n",
       " 'XGBClassifier_TfidfVectorizer_lu_users_Timeline_test_results.csv',\n",
       " 'belt_filteredTimeline10_pablocosta_bertabaporu-base-uncased_test_results.csv',\n",
       " 'belt_filteredTimeline10_pablocosta_bertabaporu-base-uncased_test_results_part_bo.csv',\n",
       " 'belt_filteredTimeline10_pablocosta_bertabaporu-base-uncased_test_results_part_cl.csv',\n",
       " 'belt_filteredTimeline10_pablocosta_bertabaporu-base-uncased_test_results_part_co.csv',\n",
       " 'belt_filteredTimeline10_pablocosta_bertabaporu-base-uncased_test_results_part_gl.csv',\n",
       " 'belt_filteredTimeline10_pablocosta_bertabaporu-base-uncased_test_results_part_ig.csv',\n",
       " 'belt_filteredTimeline10_pablocosta_bertabaporu-base-uncased_test_results_part_lu.csv',\n",
       " 'belt_filteredTimeline15_pablocosta_bertabaporu-base-uncased_test_results.csv',\n",
       " 'belt_filteredTimeline15_pablocosta_bertabaporu-base-uncased_test_results_part_bo.csv',\n",
       " 'belt_filteredTimeline15_pablocosta_bertabaporu-base-uncased_test_results_part_cl.csv',\n",
       " 'belt_filteredTimeline15_pablocosta_bertabaporu-base-uncased_test_results_part_co.csv',\n",
       " 'belt_filteredTimeline15_pablocosta_bertabaporu-base-uncased_test_results_part_gl.csv',\n",
       " 'belt_filteredTimeline15_pablocosta_bertabaporu-base-uncased_test_results_part_ig.csv',\n",
       " 'belt_filteredTimeline15_pablocosta_bertabaporu-base-uncased_test_results_part_lu.csv',\n",
       " 'belt_filteredTimeline5_pablocosta_bertabaporu-base-uncased_test_results.csv',\n",
       " 'belt_filteredTimeline5_pablocosta_bertabaporu-base-uncased_test_results_part_bo.csv',\n",
       " 'belt_filteredTimeline5_pablocosta_bertabaporu-base-uncased_test_results_part_cl.csv',\n",
       " 'belt_filteredTimeline5_pablocosta_bertabaporu-base-uncased_test_results_part_co.csv',\n",
       " 'belt_filteredTimeline5_pablocosta_bertabaporu-base-uncased_test_results_part_gl.csv',\n",
       " 'belt_filteredTimeline5_pablocosta_bertabaporu-base-uncased_test_results_part_ig.csv',\n",
       " 'belt_filteredTimeline5_pablocosta_bertabaporu-base-uncased_test_results_part_lu.csv',\n",
       " 'belt_filtered_Texts10_pablocosta_bertabaporu-base-uncased_test_results.csv',\n",
       " 'belt_filtered_Texts10_pablocosta_bertabaporu-base-uncased_test_results_part_bo.csv',\n",
       " 'belt_filtered_Texts10_pablocosta_bertabaporu-base-uncased_test_results_part_cl.csv',\n",
       " 'belt_filtered_Texts10_pablocosta_bertabaporu-base-uncased_test_results_part_co.csv',\n",
       " 'belt_filtered_Texts10_pablocosta_bertabaporu-base-uncased_test_results_part_gl.csv',\n",
       " 'belt_filtered_Texts10_pablocosta_bertabaporu-base-uncased_test_results_part_ig.csv',\n",
       " 'belt_filtered_Texts10_pablocosta_bertabaporu-base-uncased_test_results_part_lu.csv',\n",
       " 'belt_filtered_Texts15_pablocosta_bertabaporu-base-uncased_test_results.csv',\n",
       " 'belt_filtered_Texts15_pablocosta_bertabaporu-base-uncased_test_results_part_bo.csv',\n",
       " 'belt_filtered_Texts15_pablocosta_bertabaporu-base-uncased_test_results_part_cl.csv',\n",
       " 'belt_filtered_Texts15_pablocosta_bertabaporu-base-uncased_test_results_part_co.csv',\n",
       " 'belt_filtered_Texts15_pablocosta_bertabaporu-base-uncased_test_results_part_gl.csv',\n",
       " 'belt_filtered_Texts15_pablocosta_bertabaporu-base-uncased_test_results_part_ig.csv',\n",
       " 'belt_filtered_Texts15_pablocosta_bertabaporu-base-uncased_test_results_part_lu.csv',\n",
       " 'belt_filtered_Texts5_pablocosta_bertabaporu-base-uncased_test_results.csv',\n",
       " 'belt_filtered_Texts5_pablocosta_bertabaporu-base-uncased_test_results_part_bo.csv',\n",
       " 'belt_filtered_Texts5_pablocosta_bertabaporu-base-uncased_test_results_part_cl.csv',\n",
       " 'belt_filtered_Texts5_pablocosta_bertabaporu-base-uncased_test_results_part_co.csv',\n",
       " 'belt_filtered_Texts5_pablocosta_bertabaporu-base-uncased_test_results_part_gl.csv',\n",
       " 'belt_filtered_Texts5_pablocosta_bertabaporu-base-uncased_test_results_part_ig.csv',\n",
       " 'belt_filtered_Texts5_pablocosta_bertabaporu-base-uncased_test_results_part_lu.csv',\n",
       " 'bert_classifier_pablocosta_bertabaporu_base_uncased_bo_Stance_test_results.csv',\n",
       " 'bert_classifier_pablocosta_bertabaporu_base_uncased_bo_Texts_test_results.csv',\n",
       " 'bert_classifier_pablocosta_bertabaporu_base_uncased_bo_Timeline_test_results.csv',\n",
       " 'bert_classifier_pablocosta_bertabaporu_base_uncased_bo_scored_Texts_test_results.csv',\n",
       " 'bert_classifier_pablocosta_bertabaporu_base_uncased_bo_scored_Timeline_test_results.csv',\n",
       " 'bert_classifier_pablocosta_bertabaporu_base_uncased_cl_Stance_test_results.csv',\n",
       " 'bert_classifier_pablocosta_bertabaporu_base_uncased_cl_Texts_test_results.csv',\n",
       " 'bert_classifier_pablocosta_bertabaporu_base_uncased_cl_Timeline_test_results.csv',\n",
       " 'bert_classifier_pablocosta_bertabaporu_base_uncased_cl_scored_Texts_test_results.csv',\n",
       " 'bert_classifier_pablocosta_bertabaporu_base_uncased_cl_scored_Timeline_test_results.csv',\n",
       " 'bert_classifier_pablocosta_bertabaporu_base_uncased_co_Stance_test_results.csv',\n",
       " 'bert_classifier_pablocosta_bertabaporu_base_uncased_co_Texts_test_results.csv',\n",
       " 'bert_classifier_pablocosta_bertabaporu_base_uncased_co_Timeline_test_results.csv',\n",
       " 'bert_classifier_pablocosta_bertabaporu_base_uncased_co_scored_Texts_test_results.csv',\n",
       " 'bert_classifier_pablocosta_bertabaporu_base_uncased_co_scored_Timeline_test_results.csv',\n",
       " 'bert_classifier_pablocosta_bertabaporu_base_uncased_gl_Stance_test_results.csv',\n",
       " 'bert_classifier_pablocosta_bertabaporu_base_uncased_gl_Texts_test_results.csv',\n",
       " 'bert_classifier_pablocosta_bertabaporu_base_uncased_gl_Timeline_test_results.csv',\n",
       " 'bert_classifier_pablocosta_bertabaporu_base_uncased_gl_scored_Texts_test_results.csv',\n",
       " 'bert_classifier_pablocosta_bertabaporu_base_uncased_gl_scored_Timeline_test_results.csv',\n",
       " 'bert_classifier_pablocosta_bertabaporu_base_uncased_ig_Stance_test_results.csv',\n",
       " 'bert_classifier_pablocosta_bertabaporu_base_uncased_ig_Texts_test_results.csv',\n",
       " 'bert_classifier_pablocosta_bertabaporu_base_uncased_ig_Timeline_test_results.csv',\n",
       " 'bert_classifier_pablocosta_bertabaporu_base_uncased_ig_scored_Texts_test_results.csv',\n",
       " 'bert_classifier_pablocosta_bertabaporu_base_uncased_ig_scored_Timeline_test_results.csv',\n",
       " 'bert_classifier_pablocosta_bertabaporu_base_uncased_lu_Stance_test_results.csv',\n",
       " 'bert_classifier_pablocosta_bertabaporu_base_uncased_lu_Texts_test_results.csv',\n",
       " 'bert_classifier_pablocosta_bertabaporu_base_uncased_lu_Timeline_test_results.csv',\n",
       " 'bert_classifier_pablocosta_bertabaporu_base_uncased_lu_scored_Texts_test_results.csv',\n",
       " 'bert_classifier_pablocosta_bertabaporu_base_uncased_lu_scored_Timeline_test_results.csv',\n",
       " 'bertimbau_xgb_bo_top_mentioned_timelines_emb_Texts_test_results.csv',\n",
       " 'bertimbau_xgb_bo_users_emb_Stance_test_results.csv',\n",
       " 'bertimbau_xgb_bo_users_emb_Timeline_test_results.csv',\n",
       " 'bertimbau_xgb_cl_top_mentioned_timelines_emb_Texts_test_results.csv',\n",
       " 'bertimbau_xgb_cl_users_emb_Stance_test_results.csv',\n",
       " 'bertimbau_xgb_cl_users_emb_Timeline_test_results.csv',\n",
       " 'bertimbau_xgb_co_top_mentioned_timelines_emb_Texts_test_results.csv',\n",
       " 'bertimbau_xgb_co_users_emb_Stance_test_results.csv',\n",
       " 'bertimbau_xgb_co_users_emb_Timeline_test_results.csv',\n",
       " 'bertimbau_xgb_gl_top_mentioned_timelines_emb_Texts_test_results.csv',\n",
       " 'bertimbau_xgb_gl_users_emb_Stance_test_results.csv',\n",
       " 'bertimbau_xgb_gl_users_emb_Timeline_test_results.csv',\n",
       " 'bertimbau_xgb_ig_top_mentioned_timelines_emb_Texts_test_results.csv',\n",
       " 'bertimbau_xgb_ig_users_emb_Stance_test_results.csv',\n",
       " 'bertimbau_xgb_ig_users_emb_Timeline_test_results.csv',\n",
       " 'bertimbau_xgb_lu_top_mentioned_timelines_emb_Texts_test_results.csv',\n",
       " 'bertimbau_xgb_lu_users_emb_Stance_test_results.csv',\n",
       " 'bertimbau_xgb_lu_users_emb_Timeline_test_results.csv',\n",
       " 'llama3_bo_Stance_prompt2_Stance_test_results.csv',\n",
       " 'llama3_bo_filteredTimeline10_prompt2_Timeline_test_results.csv',\n",
       " 'llama3_bo_filteredTimeline15_prompt2_Timeline_test_results.csv',\n",
       " 'llama3_bo_filteredTimeline5_prompt2_Timeline_test_results.csv',\n",
       " 'llama3_bo_filtered_Texts10_prompt2_Texts_test_results.csv',\n",
       " 'llama3_bo_filtered_Texts15_prompt2_Texts_test_results.csv',\n",
       " 'llama3_bo_filtered_Texts20_prompt2_Texts_test_results.csv',\n",
       " 'llama3_bo_filtered_Texts5_prompt2_Texts_test_results.csv',\n",
       " 'llama3_cl_Stance_prompt2_Stance_test_results.csv',\n",
       " 'llama3_cl_filteredTimeline10_prompt2_Timeline_test_results.csv',\n",
       " 'llama3_cl_filteredTimeline15_prompt2_Timeline_test_results.csv',\n",
       " 'llama3_cl_filteredTimeline5_prompt2_Timeline_test_results.csv',\n",
       " 'llama3_cl_filtered_Texts10_prompt2_Texts_test_results.csv',\n",
       " 'llama3_cl_filtered_Texts15_prompt2_Texts_test_results.csv',\n",
       " 'llama3_cl_filtered_Texts20_prompt2_Texts_test_results.csv',\n",
       " 'llama3_cl_filtered_Texts5_prompt2_Texts_test_results.csv',\n",
       " 'llama3_co_Stance_prompt2_Stance_test_results.csv',\n",
       " 'llama3_co_filteredTimeline10_prompt2_Timeline_test_results.csv',\n",
       " 'llama3_co_filteredTimeline15_prompt2_Timeline_test_results.csv',\n",
       " 'llama3_co_filteredTimeline5_prompt2_Timeline_test_results.csv',\n",
       " 'llama3_co_filtered_Texts10_prompt2_Texts_test_results.csv',\n",
       " 'llama3_co_filtered_Texts15_prompt2_Texts_test_results.csv',\n",
       " 'llama3_co_filtered_Texts5_prompt2_Texts_test_results.csv',\n",
       " 'llama3_gl_Stance_prompt2_Stance_test_results.csv',\n",
       " 'llama3_gl_filteredTimeline10_prompt2_Timeline_test_results.csv',\n",
       " 'llama3_gl_filteredTimeline15_prompt2_Timeline_test_results.csv',\n",
       " 'llama3_gl_filteredTimeline5_prompt2_Timeline_test_results.csv',\n",
       " 'llama3_gl_filtered_Texts10_prompt2_Texts_test_results.csv',\n",
       " 'llama3_gl_filtered_Texts15_prompt2_Texts_test_results.csv',\n",
       " 'llama3_gl_filtered_Texts5_prompt2_Texts_test_results.csv',\n",
       " 'llama3_ig_Stance_prompt2_Stance_test_results.csv',\n",
       " 'llama3_ig_filteredTimeline10_prompt2_Timeline_test_results.csv',\n",
       " 'llama3_ig_filteredTimeline15_prompt2_Timeline_test_results.csv',\n",
       " 'llama3_ig_filteredTimeline5_prompt2_Timeline_test_results.csv',\n",
       " 'llama3_ig_filtered_Texts10_prompt2_Texts_test_results.csv',\n",
       " 'llama3_ig_filtered_Texts15_prompt2_Texts_test_results.csv',\n",
       " 'llama3_ig_filtered_Texts20_prompt2_Texts_test_results.csv',\n",
       " 'llama3_ig_filtered_Texts5_prompt2_Texts_test_results.csv',\n",
       " 'llama3_lu_Stance_prompt2_Stance_test_results.csv',\n",
       " 'llama3_lu_filteredTimeline10_prompt2_Timeline_test_results.csv',\n",
       " 'llama3_lu_filteredTimeline15_prompt2_Timeline_test_results.csv',\n",
       " 'llama3_lu_filteredTimeline5_prompt2_Timeline_test_results.csv',\n",
       " 'llama3_lu_filtered_Texts10_prompt2_Texts_test_results.csv',\n",
       " 'llama3_lu_filtered_Texts15_prompt2_Texts_test_results.csv',\n",
       " 'llama3_lu_filtered_Texts5_prompt2_Texts_test_results.csv',\n",
       " 'old']"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_results_path = '../reports/test_results/'\n",
    "\n",
    "list_df_t = os.listdir(test_results_path)\n",
    "list_df_t.sort()\n",
    "list_df_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hydrox.', 'Lula', 'Sinovac', 'Church', 'Globo TV', 'Bolsonaro']"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Target list\n",
    "target_list = [\n",
    "    'ig',\n",
    "    'bo', \n",
    "    'cl', \n",
    "    'co', \n",
    "    'gl', \n",
    "    'lu'\n",
    "]\n",
    "\n",
    "dict_cp = {\n",
    "    'cl':'Hydrox.',\n",
    "    'lu':'Lula',\n",
    "    'co':'Sinovac',\n",
    "    'ig':'Church',\n",
    "    'gl':'Globo TV',\n",
    "    'bo':'Bolsonaro',\n",
    "}\n",
    "\n",
    "names = list(dict_cp.values())\n",
    "names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create complete table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (vectorizer,estimator, path_sring) \n",
    "results_tuples_stance = [\n",
    "    # Stance\n",
    "    (\"Stance\", \"-\" ,\"dummy\", \"DummyClassifier_{target}_users_Stance_test_results.csv\"),\n",
    "    (\"Stance\", \"tf-idf\" ,\"xgb\", \"XGBClassifier_TfidfVectorizer_{target}_users_Stance_test_results.csv\"),\n",
    "    (\"Stance\", \"bertabaporu-base\" ,\"xgb\", \"bertimbau_xgb_{target}_users_emb_Stance_test_results.csv\"),\n",
    "    (\"Stance\", \"-\" ,\"bertabaporu-base\", \"bert_classifier_pablocosta_bertabaporu_base_uncased_{target}_Stance_test_results.csv\"),\n",
    "    (\"Stance\", \"-\",  \"llama3:7b zero-shot\", \"llama3_{target}_Stance_prompt2_Stance_test_results.csv\"),\n",
    "    \n",
    "    # Texts\n",
    "    (\"Texts\", \"-\" ,\"dummy\", \"DummyClassifier_{target}_top_mentioned_timelines_Texts_test_results.csv\"),\n",
    "    (\"Texts\", \"tf-idf\" ,\"xgb\", \"XGBClassifier_TfidfVectorizer_{target}_top_mentioned_timelines_Texts_test_results.csv\"),\n",
    "    (\"Texts\", \"bertabaporu-base\" ,\"xgb\", \"bertimbau_xgb_{target}_top_mentioned_timelines_emb_Texts_test_results.csv\"),\n",
    "    (\"Texts\", \"-\" ,\"bertabaporu-base\", \"bert_classifier_pablocosta_bertabaporu_base_uncased_{target}_Texts_test_results.csv\"),\n",
    "    (\"Texts\", \"-\" ,\"bertabaporu-base (R)\", \"bert_classifier_pablocosta_bertabaporu_base_uncased_{target}_scored_Texts_test_results.csv\"),\n",
    "    (\"Texts\", \"-\", \"llama3:7b zero-shot [5] (R)\", \"llama3_{target}_filtered_Texts5_prompt2_Texts_test_results.csv\"),\n",
    "    (\"Texts\", \"-\", \"llama3:7b zero-shot [10] (R)\", \"llama3_{target}_filtered_Texts10_prompt2_Texts_test_results.csv\"),\n",
    "    (\"Texts\", \"-\", \"llama3:7b zero-shot [15] (R)\", \"llama3_{target}_filtered_Texts15_prompt2_Texts_test_results.csv\"),\n",
    "    \n",
    "    # Timeline\n",
    "    (\"Timeline\", \"-\" ,\"dummy\", \"DummyClassifier_{target}_users_Timeline_test_results.csv\"),\n",
    "    (\"Timeline\", \"tf-idf\" ,\"xgb\", \"XGBClassifier_TfidfVectorizer_{target}_users_Timeline_test_results.csv\"),\n",
    "    (\"Timeline\", \"bertabaporu-base\" ,\"xgb\", \"bertimbau_xgb_{target}_users_emb_Timeline_test_results.csv\"),\n",
    "    (\"Timeline\", \"-\" ,\"bertabaporu-base\", \"bert_classifier_pablocosta_bertabaporu_base_uncased_{target}_Timeline_test_results.csv\"),\n",
    "    (\"Timeline\", \"-\" ,\"bertabaporu-base (R)\", \"bert_classifier_pablocosta_bertabaporu_base_uncased_{target}_scored_Timeline_test_results.csv\"),\n",
    "    (\"Timeline\", \"-\", \"llama3:7b zero-shot [5] (R)\", \"llama3_{target}_filteredTimeline5_prompt2_Timeline_test_results.csv\"),\n",
    "    (\"Timeline\", \"-\", \"llama3:7b zero-shot [10] (R)\", \"llama3_{target}_filteredTimeline10_prompt2_Timeline_test_results.csv\"),\n",
    "    (\"Timeline\", \"-\", \"llama3:7b zero-shot [15] (R)\", \"llama3_{target}_filteredTimeline15_prompt2_Timeline_test_results.csv\"),\n",
    "    \n",
    "    (\"Ensemble Texts + Timeline\", \"-\", \"LogisticRegression\", \"Ensemble_LogisticRegression_{target}_Texts_Timeline_test_results.csv\"),\n",
    "    (\"Ensemble Texts + Stance\", \"-\", \"LogisticRegression\", \"Ensemble_LogisticRegression_{target}_Texts_Stance_test_results.csv\"),\n",
    "    (\"Ensemble Stance + Timeline\", \"-\", \"LogisticRegression\", \"Ensemble_LogisticRegression_{target}_Stance_Timeline_test_results.csv\"),\n",
    "    (\"Ensemble Stance + Timeline + Texts\", \"-\", \"LogisticRegression\", \"Ensemble_LogisticRegression_{target}_Stance_Timeline_Texts_test_results.csv\")\n",
    "]\n",
    "\n",
    "list_results = []\n",
    "for text_col, vectorizer, estimator, path_results in results_tuples_stance:\n",
    "    \n",
    "    list_cr = []\n",
    "    \n",
    "    for target in target_list:\n",
    "        \n",
    "        \n",
    "        path = test_results_path + path_results.format(target = target)\n",
    "        df_results = pd.read_csv(path)\n",
    "        df_results_or = df_results.copy()\n",
    "        \n",
    "        # get classification report df\n",
    "        df_classification_report = get_classification_report(df_results.test, df_results.pred, cr_args = {})\n",
    "        \n",
    "        # create multindex\n",
    "        column_indexes = [(metric,dict_cp[target]) for metric in df_classification_report.columns]\n",
    "        multi_index_cols = pd.MultiIndex.from_tuples(column_indexes, names=['metric', 'target'])\n",
    "        rows_indexes = [(text_col, vectorizer, estimator, cl) for cl in df_classification_report.index]\n",
    "        multi_index_rows = pd.MultiIndex.from_tuples(rows_indexes, names=['text_col','vectorizer', 'estimator', 'class'])\n",
    "        df_classification_report.columns = multi_index_cols\n",
    "        df_classification_report.index = multi_index_rows\n",
    "        \n",
    "        # print(text_col, vectorizer, estimator,target)\n",
    "        # print(path)\n",
    "        # display(df_classification_report)\n",
    "        \n",
    "        list_cr.append(df_classification_report)\n",
    "        \n",
    "    df_results = pd.concat(list_cr, axis = 1)\n",
    "    \n",
    "    list_results.append(df_results)\n",
    "    \n",
    "df_results_final = pd.concat(list_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>metric</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>...</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>Church</th>\n",
       "      <th>Church</th>\n",
       "      <th>Church</th>\n",
       "      <th>Church</th>\n",
       "      <th>Bolsonaro</th>\n",
       "      <th>Bolsonaro</th>\n",
       "      <th>Bolsonaro</th>\n",
       "      <th>Bolsonaro</th>\n",
       "      <th>Hydrox.</th>\n",
       "      <th>Hydrox.</th>\n",
       "      <th>...</th>\n",
       "      <th>Sinovac</th>\n",
       "      <th>Sinovac</th>\n",
       "      <th>Globo TV</th>\n",
       "      <th>Globo TV</th>\n",
       "      <th>Globo TV</th>\n",
       "      <th>Globo TV</th>\n",
       "      <th>Lula</th>\n",
       "      <th>Lula</th>\n",
       "      <th>Lula</th>\n",
       "      <th>Lula</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text_col</th>\n",
       "      <th>vectorizer</th>\n",
       "      <th>estimator</th>\n",
       "      <th>class</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">Stance</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">-</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">dummy</th>\n",
       "      <th>against</th>\n",
       "      <td>0.565943</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.722814</td>\n",
       "      <td>339.000000</td>\n",
       "      <td>0.861702</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.925714</td>\n",
       "      <td>162.000000</td>\n",
       "      <td>0.503484</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>354.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>167.000000</td>\n",
       "      <td>0.525735</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.689157</td>\n",
       "      <td>143.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.565943</td>\n",
       "      <td>0.565943</td>\n",
       "      <td>0.565943</td>\n",
       "      <td>0.565943</td>\n",
       "      <td>0.861702</td>\n",
       "      <td>0.861702</td>\n",
       "      <td>0.861702</td>\n",
       "      <td>0.861702</td>\n",
       "      <td>0.503484</td>\n",
       "      <td>0.503484</td>\n",
       "      <td>...</td>\n",
       "      <td>0.542636</td>\n",
       "      <td>0.542636</td>\n",
       "      <td>0.593674</td>\n",
       "      <td>0.593674</td>\n",
       "      <td>0.593674</td>\n",
       "      <td>0.593674</td>\n",
       "      <td>0.525735</td>\n",
       "      <td>0.525735</td>\n",
       "      <td>0.525735</td>\n",
       "      <td>0.525735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.320292</td>\n",
       "      <td>0.565943</td>\n",
       "      <td>0.409072</td>\n",
       "      <td>599.000000</td>\n",
       "      <td>0.742531</td>\n",
       "      <td>0.861702</td>\n",
       "      <td>0.797690</td>\n",
       "      <td>188.000000</td>\n",
       "      <td>0.253496</td>\n",
       "      <td>0.503484</td>\n",
       "      <td>...</td>\n",
       "      <td>0.381754</td>\n",
       "      <td>774.000000</td>\n",
       "      <td>0.352449</td>\n",
       "      <td>0.593674</td>\n",
       "      <td>0.442310</td>\n",
       "      <td>411.000000</td>\n",
       "      <td>0.276398</td>\n",
       "      <td>0.525735</td>\n",
       "      <td>0.362314</td>\n",
       "      <td>272.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.282972</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.361407</td>\n",
       "      <td>599.000000</td>\n",
       "      <td>0.430851</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.462857</td>\n",
       "      <td>188.000000</td>\n",
       "      <td>0.251742</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.351759</td>\n",
       "      <td>774.000000</td>\n",
       "      <td>0.296837</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.372519</td>\n",
       "      <td>411.000000</td>\n",
       "      <td>0.262868</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.344578</td>\n",
       "      <td>272.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>for</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>260.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.703518</td>\n",
       "      <td>420.000000</td>\n",
       "      <td>0.593674</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.745038</td>\n",
       "      <td>244.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>129.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">Ensemble Stance + Timeline + Texts</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">-</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">LogisticRegression</th>\n",
       "      <th>against</th>\n",
       "      <td>0.762570</td>\n",
       "      <td>0.805310</td>\n",
       "      <td>0.783357</td>\n",
       "      <td>339.000000</td>\n",
       "      <td>0.891429</td>\n",
       "      <td>0.962963</td>\n",
       "      <td>0.925816</td>\n",
       "      <td>162.000000</td>\n",
       "      <td>0.865455</td>\n",
       "      <td>0.823529</td>\n",
       "      <td>...</td>\n",
       "      <td>0.817073</td>\n",
       "      <td>354.000000</td>\n",
       "      <td>0.813187</td>\n",
       "      <td>0.443114</td>\n",
       "      <td>0.573643</td>\n",
       "      <td>167.000000</td>\n",
       "      <td>0.538462</td>\n",
       "      <td>0.538462</td>\n",
       "      <td>0.538462</td>\n",
       "      <td>143.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.747913</td>\n",
       "      <td>0.747913</td>\n",
       "      <td>0.747913</td>\n",
       "      <td>0.747913</td>\n",
       "      <td>0.867021</td>\n",
       "      <td>0.867021</td>\n",
       "      <td>0.867021</td>\n",
       "      <td>0.867021</td>\n",
       "      <td>0.846690</td>\n",
       "      <td>0.846690</td>\n",
       "      <td>...</td>\n",
       "      <td>0.844961</td>\n",
       "      <td>0.844961</td>\n",
       "      <td>0.732360</td>\n",
       "      <td>0.732360</td>\n",
       "      <td>0.732360</td>\n",
       "      <td>0.732360</td>\n",
       "      <td>0.514706</td>\n",
       "      <td>0.514706</td>\n",
       "      <td>0.514706</td>\n",
       "      <td>0.514706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.746758</td>\n",
       "      <td>0.747913</td>\n",
       "      <td>0.746569</td>\n",
       "      <td>599.000000</td>\n",
       "      <td>0.842614</td>\n",
       "      <td>0.867021</td>\n",
       "      <td>0.847423</td>\n",
       "      <td>188.000000</td>\n",
       "      <td>0.847569</td>\n",
       "      <td>0.846690</td>\n",
       "      <td>...</td>\n",
       "      <td>0.843335</td>\n",
       "      <td>774.000000</td>\n",
       "      <td>0.751556</td>\n",
       "      <td>0.732360</td>\n",
       "      <td>0.710973</td>\n",
       "      <td>411.000000</td>\n",
       "      <td>0.514706</td>\n",
       "      <td>0.514706</td>\n",
       "      <td>0.514706</td>\n",
       "      <td>272.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.744355</td>\n",
       "      <td>0.739193</td>\n",
       "      <td>0.740980</td>\n",
       "      <td>599.000000</td>\n",
       "      <td>0.714945</td>\n",
       "      <td>0.616097</td>\n",
       "      <td>0.642395</td>\n",
       "      <td>188.000000</td>\n",
       "      <td>0.847443</td>\n",
       "      <td>0.846852</td>\n",
       "      <td>...</td>\n",
       "      <td>0.841272</td>\n",
       "      <td>774.000000</td>\n",
       "      <td>0.761281</td>\n",
       "      <td>0.686721</td>\n",
       "      <td>0.689304</td>\n",
       "      <td>411.000000</td>\n",
       "      <td>0.513417</td>\n",
       "      <td>0.513417</td>\n",
       "      <td>0.513417</td>\n",
       "      <td>272.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>for</th>\n",
       "      <td>0.726141</td>\n",
       "      <td>0.673077</td>\n",
       "      <td>0.698603</td>\n",
       "      <td>260.000000</td>\n",
       "      <td>0.538462</td>\n",
       "      <td>0.269231</td>\n",
       "      <td>0.358974</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>0.829431</td>\n",
       "      <td>0.870175</td>\n",
       "      <td>...</td>\n",
       "      <td>0.865471</td>\n",
       "      <td>420.000000</td>\n",
       "      <td>0.709375</td>\n",
       "      <td>0.930328</td>\n",
       "      <td>0.804965</td>\n",
       "      <td>244.000000</td>\n",
       "      <td>0.488372</td>\n",
       "      <td>0.488372</td>\n",
       "      <td>0.488372</td>\n",
       "      <td>129.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>125 rows Ã— 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "metric                                                                        precision  \\\n",
       "target                                                                           Church   \n",
       "text_col                           vectorizer estimator          class                    \n",
       "Stance                             -          dummy              against       0.565943   \n",
       "                                                                 accuracy      0.565943   \n",
       "                                                                 weighted avg  0.320292   \n",
       "                                                                 macro avg     0.282972   \n",
       "                                                                 for           0.000000   \n",
       "...                                                                                 ...   \n",
       "Ensemble Stance + Timeline + Texts -          LogisticRegression against       0.762570   \n",
       "                                                                 accuracy      0.747913   \n",
       "                                                                 weighted avg  0.746758   \n",
       "                                                                 macro avg     0.744355   \n",
       "                                                                 for           0.726141   \n",
       "\n",
       "metric                                                                           recall  \\\n",
       "target                                                                           Church   \n",
       "text_col                           vectorizer estimator          class                    \n",
       "Stance                             -          dummy              against       1.000000   \n",
       "                                                                 accuracy      0.565943   \n",
       "                                                                 weighted avg  0.565943   \n",
       "                                                                 macro avg     0.500000   \n",
       "                                                                 for           0.000000   \n",
       "...                                                                                 ...   \n",
       "Ensemble Stance + Timeline + Texts -          LogisticRegression against       0.805310   \n",
       "                                                                 accuracy      0.747913   \n",
       "                                                                 weighted avg  0.747913   \n",
       "                                                                 macro avg     0.739193   \n",
       "                                                                 for           0.673077   \n",
       "\n",
       "metric                                                                         f1-score  \\\n",
       "target                                                                           Church   \n",
       "text_col                           vectorizer estimator          class                    \n",
       "Stance                             -          dummy              against       0.722814   \n",
       "                                                                 accuracy      0.565943   \n",
       "                                                                 weighted avg  0.409072   \n",
       "                                                                 macro avg     0.361407   \n",
       "                                                                 for           0.000000   \n",
       "...                                                                                 ...   \n",
       "Ensemble Stance + Timeline + Texts -          LogisticRegression against       0.783357   \n",
       "                                                                 accuracy      0.747913   \n",
       "                                                                 weighted avg  0.746569   \n",
       "                                                                 macro avg     0.740980   \n",
       "                                                                 for           0.698603   \n",
       "\n",
       "metric                                                                            support  \\\n",
       "target                                                                             Church   \n",
       "text_col                           vectorizer estimator          class                      \n",
       "Stance                             -          dummy              against       339.000000   \n",
       "                                                                 accuracy        0.565943   \n",
       "                                                                 weighted avg  599.000000   \n",
       "                                                                 macro avg     599.000000   \n",
       "                                                                 for           260.000000   \n",
       "...                                                                                   ...   \n",
       "Ensemble Stance + Timeline + Texts -          LogisticRegression against       339.000000   \n",
       "                                                                 accuracy        0.747913   \n",
       "                                                                 weighted avg  599.000000   \n",
       "                                                                 macro avg     599.000000   \n",
       "                                                                 for           260.000000   \n",
       "\n",
       "metric                                                                        precision  \\\n",
       "target                                                                        Bolsonaro   \n",
       "text_col                           vectorizer estimator          class                    \n",
       "Stance                             -          dummy              against       0.861702   \n",
       "                                                                 accuracy      0.861702   \n",
       "                                                                 weighted avg  0.742531   \n",
       "                                                                 macro avg     0.430851   \n",
       "                                                                 for           0.000000   \n",
       "...                                                                                 ...   \n",
       "Ensemble Stance + Timeline + Texts -          LogisticRegression against       0.891429   \n",
       "                                                                 accuracy      0.867021   \n",
       "                                                                 weighted avg  0.842614   \n",
       "                                                                 macro avg     0.714945   \n",
       "                                                                 for           0.538462   \n",
       "\n",
       "metric                                                                           recall  \\\n",
       "target                                                                        Bolsonaro   \n",
       "text_col                           vectorizer estimator          class                    \n",
       "Stance                             -          dummy              against       1.000000   \n",
       "                                                                 accuracy      0.861702   \n",
       "                                                                 weighted avg  0.861702   \n",
       "                                                                 macro avg     0.500000   \n",
       "                                                                 for           0.000000   \n",
       "...                                                                                 ...   \n",
       "Ensemble Stance + Timeline + Texts -          LogisticRegression against       0.962963   \n",
       "                                                                 accuracy      0.867021   \n",
       "                                                                 weighted avg  0.867021   \n",
       "                                                                 macro avg     0.616097   \n",
       "                                                                 for           0.269231   \n",
       "\n",
       "metric                                                                         f1-score  \\\n",
       "target                                                                        Bolsonaro   \n",
       "text_col                           vectorizer estimator          class                    \n",
       "Stance                             -          dummy              against       0.925714   \n",
       "                                                                 accuracy      0.861702   \n",
       "                                                                 weighted avg  0.797690   \n",
       "                                                                 macro avg     0.462857   \n",
       "                                                                 for           0.000000   \n",
       "...                                                                                 ...   \n",
       "Ensemble Stance + Timeline + Texts -          LogisticRegression against       0.925816   \n",
       "                                                                 accuracy      0.867021   \n",
       "                                                                 weighted avg  0.847423   \n",
       "                                                                 macro avg     0.642395   \n",
       "                                                                 for           0.358974   \n",
       "\n",
       "metric                                                                            support  \\\n",
       "target                                                                          Bolsonaro   \n",
       "text_col                           vectorizer estimator          class                      \n",
       "Stance                             -          dummy              against       162.000000   \n",
       "                                                                 accuracy        0.861702   \n",
       "                                                                 weighted avg  188.000000   \n",
       "                                                                 macro avg     188.000000   \n",
       "                                                                 for            26.000000   \n",
       "...                                                                                   ...   \n",
       "Ensemble Stance + Timeline + Texts -          LogisticRegression against       162.000000   \n",
       "                                                                 accuracy        0.867021   \n",
       "                                                                 weighted avg  188.000000   \n",
       "                                                                 macro avg     188.000000   \n",
       "                                                                 for            26.000000   \n",
       "\n",
       "metric                                                                        precision  \\\n",
       "target                                                                          Hydrox.   \n",
       "text_col                           vectorizer estimator          class                    \n",
       "Stance                             -          dummy              against       0.503484   \n",
       "                                                                 accuracy      0.503484   \n",
       "                                                                 weighted avg  0.253496   \n",
       "                                                                 macro avg     0.251742   \n",
       "                                                                 for           0.000000   \n",
       "...                                                                                 ...   \n",
       "Ensemble Stance + Timeline + Texts -          LogisticRegression against       0.865455   \n",
       "                                                                 accuracy      0.846690   \n",
       "                                                                 weighted avg  0.847569   \n",
       "                                                                 macro avg     0.847443   \n",
       "                                                                 for           0.829431   \n",
       "\n",
       "metric                                                                           recall  \\\n",
       "target                                                                          Hydrox.   \n",
       "text_col                           vectorizer estimator          class                    \n",
       "Stance                             -          dummy              against       1.000000   \n",
       "                                                                 accuracy      0.503484   \n",
       "                                                                 weighted avg  0.503484   \n",
       "                                                                 macro avg     0.500000   \n",
       "                                                                 for           0.000000   \n",
       "...                                                                                 ...   \n",
       "Ensemble Stance + Timeline + Texts -          LogisticRegression against       0.823529   \n",
       "                                                                 accuracy      0.846690   \n",
       "                                                                 weighted avg  0.846690   \n",
       "                                                                 macro avg     0.846852   \n",
       "                                                                 for           0.870175   \n",
       "\n",
       "metric                                                                         ...  \\\n",
       "target                                                                         ...   \n",
       "text_col                           vectorizer estimator          class         ...   \n",
       "Stance                             -          dummy              against       ...   \n",
       "                                                                 accuracy      ...   \n",
       "                                                                 weighted avg  ...   \n",
       "                                                                 macro avg     ...   \n",
       "                                                                 for           ...   \n",
       "...                                                                            ...   \n",
       "Ensemble Stance + Timeline + Texts -          LogisticRegression against       ...   \n",
       "                                                                 accuracy      ...   \n",
       "                                                                 weighted avg  ...   \n",
       "                                                                 macro avg     ...   \n",
       "                                                                 for           ...   \n",
       "\n",
       "metric                                                                         f1-score  \\\n",
       "target                                                                          Sinovac   \n",
       "text_col                           vectorizer estimator          class                    \n",
       "Stance                             -          dummy              against       0.000000   \n",
       "                                                                 accuracy      0.542636   \n",
       "                                                                 weighted avg  0.381754   \n",
       "                                                                 macro avg     0.351759   \n",
       "                                                                 for           0.703518   \n",
       "...                                                                                 ...   \n",
       "Ensemble Stance + Timeline + Texts -          LogisticRegression against       0.817073   \n",
       "                                                                 accuracy      0.844961   \n",
       "                                                                 weighted avg  0.843335   \n",
       "                                                                 macro avg     0.841272   \n",
       "                                                                 for           0.865471   \n",
       "\n",
       "metric                                                                            support  \\\n",
       "target                                                                            Sinovac   \n",
       "text_col                           vectorizer estimator          class                      \n",
       "Stance                             -          dummy              against       354.000000   \n",
       "                                                                 accuracy        0.542636   \n",
       "                                                                 weighted avg  774.000000   \n",
       "                                                                 macro avg     774.000000   \n",
       "                                                                 for           420.000000   \n",
       "...                                                                                   ...   \n",
       "Ensemble Stance + Timeline + Texts -          LogisticRegression against       354.000000   \n",
       "                                                                 accuracy        0.844961   \n",
       "                                                                 weighted avg  774.000000   \n",
       "                                                                 macro avg     774.000000   \n",
       "                                                                 for           420.000000   \n",
       "\n",
       "metric                                                                        precision  \\\n",
       "target                                                                         Globo TV   \n",
       "text_col                           vectorizer estimator          class                    \n",
       "Stance                             -          dummy              against       0.000000   \n",
       "                                                                 accuracy      0.593674   \n",
       "                                                                 weighted avg  0.352449   \n",
       "                                                                 macro avg     0.296837   \n",
       "                                                                 for           0.593674   \n",
       "...                                                                                 ...   \n",
       "Ensemble Stance + Timeline + Texts -          LogisticRegression against       0.813187   \n",
       "                                                                 accuracy      0.732360   \n",
       "                                                                 weighted avg  0.751556   \n",
       "                                                                 macro avg     0.761281   \n",
       "                                                                 for           0.709375   \n",
       "\n",
       "metric                                                                           recall  \\\n",
       "target                                                                         Globo TV   \n",
       "text_col                           vectorizer estimator          class                    \n",
       "Stance                             -          dummy              against       0.000000   \n",
       "                                                                 accuracy      0.593674   \n",
       "                                                                 weighted avg  0.593674   \n",
       "                                                                 macro avg     0.500000   \n",
       "                                                                 for           1.000000   \n",
       "...                                                                                 ...   \n",
       "Ensemble Stance + Timeline + Texts -          LogisticRegression against       0.443114   \n",
       "                                                                 accuracy      0.732360   \n",
       "                                                                 weighted avg  0.732360   \n",
       "                                                                 macro avg     0.686721   \n",
       "                                                                 for           0.930328   \n",
       "\n",
       "metric                                                                         f1-score  \\\n",
       "target                                                                         Globo TV   \n",
       "text_col                           vectorizer estimator          class                    \n",
       "Stance                             -          dummy              against       0.000000   \n",
       "                                                                 accuracy      0.593674   \n",
       "                                                                 weighted avg  0.442310   \n",
       "                                                                 macro avg     0.372519   \n",
       "                                                                 for           0.745038   \n",
       "...                                                                                 ...   \n",
       "Ensemble Stance + Timeline + Texts -          LogisticRegression against       0.573643   \n",
       "                                                                 accuracy      0.732360   \n",
       "                                                                 weighted avg  0.710973   \n",
       "                                                                 macro avg     0.689304   \n",
       "                                                                 for           0.804965   \n",
       "\n",
       "metric                                                                            support  \\\n",
       "target                                                                           Globo TV   \n",
       "text_col                           vectorizer estimator          class                      \n",
       "Stance                             -          dummy              against       167.000000   \n",
       "                                                                 accuracy        0.593674   \n",
       "                                                                 weighted avg  411.000000   \n",
       "                                                                 macro avg     411.000000   \n",
       "                                                                 for           244.000000   \n",
       "...                                                                                   ...   \n",
       "Ensemble Stance + Timeline + Texts -          LogisticRegression against       167.000000   \n",
       "                                                                 accuracy        0.732360   \n",
       "                                                                 weighted avg  411.000000   \n",
       "                                                                 macro avg     411.000000   \n",
       "                                                                 for           244.000000   \n",
       "\n",
       "metric                                                                        precision  \\\n",
       "target                                                                             Lula   \n",
       "text_col                           vectorizer estimator          class                    \n",
       "Stance                             -          dummy              against       0.525735   \n",
       "                                                                 accuracy      0.525735   \n",
       "                                                                 weighted avg  0.276398   \n",
       "                                                                 macro avg     0.262868   \n",
       "                                                                 for           0.000000   \n",
       "...                                                                                 ...   \n",
       "Ensemble Stance + Timeline + Texts -          LogisticRegression against       0.538462   \n",
       "                                                                 accuracy      0.514706   \n",
       "                                                                 weighted avg  0.514706   \n",
       "                                                                 macro avg     0.513417   \n",
       "                                                                 for           0.488372   \n",
       "\n",
       "metric                                                                           recall  \\\n",
       "target                                                                             Lula   \n",
       "text_col                           vectorizer estimator          class                    \n",
       "Stance                             -          dummy              against       1.000000   \n",
       "                                                                 accuracy      0.525735   \n",
       "                                                                 weighted avg  0.525735   \n",
       "                                                                 macro avg     0.500000   \n",
       "                                                                 for           0.000000   \n",
       "...                                                                                 ...   \n",
       "Ensemble Stance + Timeline + Texts -          LogisticRegression against       0.538462   \n",
       "                                                                 accuracy      0.514706   \n",
       "                                                                 weighted avg  0.514706   \n",
       "                                                                 macro avg     0.513417   \n",
       "                                                                 for           0.488372   \n",
       "\n",
       "metric                                                                         f1-score  \\\n",
       "target                                                                             Lula   \n",
       "text_col                           vectorizer estimator          class                    \n",
       "Stance                             -          dummy              against       0.689157   \n",
       "                                                                 accuracy      0.525735   \n",
       "                                                                 weighted avg  0.362314   \n",
       "                                                                 macro avg     0.344578   \n",
       "                                                                 for           0.000000   \n",
       "...                                                                                 ...   \n",
       "Ensemble Stance + Timeline + Texts -          LogisticRegression against       0.538462   \n",
       "                                                                 accuracy      0.514706   \n",
       "                                                                 weighted avg  0.514706   \n",
       "                                                                 macro avg     0.513417   \n",
       "                                                                 for           0.488372   \n",
       "\n",
       "metric                                                                            support  \n",
       "target                                                                               Lula  \n",
       "text_col                           vectorizer estimator          class                     \n",
       "Stance                             -          dummy              against       143.000000  \n",
       "                                                                 accuracy        0.525735  \n",
       "                                                                 weighted avg  272.000000  \n",
       "                                                                 macro avg     272.000000  \n",
       "                                                                 for           129.000000  \n",
       "...                                                                                   ...  \n",
       "Ensemble Stance + Timeline + Texts -          LogisticRegression against       143.000000  \n",
       "                                                                 accuracy        0.514706  \n",
       "                                                                 weighted avg  272.000000  \n",
       "                                                                 macro avg     272.000000  \n",
       "                                                                 for           129.000000  \n",
       "\n",
       "[125 rows x 24 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results_final.to_excel(\"../reports/table_complete_results.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create table f1 macro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>metric</th>\n",
       "      <th colspan=\"7\" halign=\"left\">f1-score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>Church</th>\n",
       "      <th>Bolsonaro</th>\n",
       "      <th>Hydrox.</th>\n",
       "      <th>Sinovac</th>\n",
       "      <th>Globo TV</th>\n",
       "      <th>Lula</th>\n",
       "      <th>overall</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text_col</th>\n",
       "      <th>vectorizer</th>\n",
       "      <th>estimator</th>\n",
       "      <th>class</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">Stance</th>\n",
       "      <th>-</th>\n",
       "      <th>dummy</th>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.361407</td>\n",
       "      <td>0.462857</td>\n",
       "      <td>0.334878</td>\n",
       "      <td>0.351759</td>\n",
       "      <td>0.372519</td>\n",
       "      <td>0.344578</td>\n",
       "      <td>0.371333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tf-idf</th>\n",
       "      <th>xgb</th>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.702021</td>\n",
       "      <td>0.595312</td>\n",
       "      <td>0.734366</td>\n",
       "      <td>0.752640</td>\n",
       "      <td>0.665243</td>\n",
       "      <td>0.654412</td>\n",
       "      <td>0.683999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bertabaporu-base</th>\n",
       "      <th>xgb</th>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.853801</td>\n",
       "      <td>0.625289</td>\n",
       "      <td>0.830948</td>\n",
       "      <td>0.808036</td>\n",
       "      <td>0.781858</td>\n",
       "      <td>0.766993</td>\n",
       "      <td>0.777821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">-</th>\n",
       "      <th>bertabaporu-base</th>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.866276</td>\n",
       "      <td>0.737297</td>\n",
       "      <td>0.848144</td>\n",
       "      <td>0.834984</td>\n",
       "      <td>0.860252</td>\n",
       "      <td>0.789802</td>\n",
       "      <td>0.822792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>llama3:7b zero-shot</th>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.729458</td>\n",
       "      <td>0.462857</td>\n",
       "      <td>0.638889</td>\n",
       "      <td>0.578779</td>\n",
       "      <td>0.770678</td>\n",
       "      <td>0.699381</td>\n",
       "      <td>0.646674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"8\" valign=\"top\">Texts</th>\n",
       "      <th>-</th>\n",
       "      <th>dummy</th>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.361407</td>\n",
       "      <td>0.462857</td>\n",
       "      <td>0.334878</td>\n",
       "      <td>0.351759</td>\n",
       "      <td>0.372519</td>\n",
       "      <td>0.344578</td>\n",
       "      <td>0.371333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tf-idf</th>\n",
       "      <th>xgb</th>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.596115</td>\n",
       "      <td>0.501220</td>\n",
       "      <td>0.603727</td>\n",
       "      <td>0.670805</td>\n",
       "      <td>0.545620</td>\n",
       "      <td>0.579427</td>\n",
       "      <td>0.582819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bertabaporu-base</th>\n",
       "      <th>xgb</th>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.594754</td>\n",
       "      <td>0.495578</td>\n",
       "      <td>0.609524</td>\n",
       "      <td>0.660542</td>\n",
       "      <td>0.534455</td>\n",
       "      <td>0.569597</td>\n",
       "      <td>0.577408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">-</th>\n",
       "      <th>bertabaporu-base</th>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.586611</td>\n",
       "      <td>0.462857</td>\n",
       "      <td>0.446504</td>\n",
       "      <td>0.608972</td>\n",
       "      <td>0.507381</td>\n",
       "      <td>0.482520</td>\n",
       "      <td>0.515808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bertabaporu-base (R)</th>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.583417</td>\n",
       "      <td>0.462857</td>\n",
       "      <td>0.570531</td>\n",
       "      <td>0.637369</td>\n",
       "      <td>0.586967</td>\n",
       "      <td>0.602167</td>\n",
       "      <td>0.573885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>llama3:7b zero-shot [5] (R)</th>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.499052</td>\n",
       "      <td>0.296142</td>\n",
       "      <td>0.469796</td>\n",
       "      <td>0.470381</td>\n",
       "      <td>0.490101</td>\n",
       "      <td>0.512954</td>\n",
       "      <td>0.456404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>llama3:7b zero-shot [10] (R)</th>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.561274</td>\n",
       "      <td>0.328245</td>\n",
       "      <td>0.440347</td>\n",
       "      <td>0.460580</td>\n",
       "      <td>0.494646</td>\n",
       "      <td>0.478244</td>\n",
       "      <td>0.460556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>llama3:7b zero-shot [15] (R)</th>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.503966</td>\n",
       "      <td>0.285253</td>\n",
       "      <td>0.416946</td>\n",
       "      <td>0.464074</td>\n",
       "      <td>0.475797</td>\n",
       "      <td>0.542401</td>\n",
       "      <td>0.448073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"8\" valign=\"top\">Timeline</th>\n",
       "      <th>-</th>\n",
       "      <th>dummy</th>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.361407</td>\n",
       "      <td>0.462857</td>\n",
       "      <td>0.334878</td>\n",
       "      <td>0.351759</td>\n",
       "      <td>0.372519</td>\n",
       "      <td>0.344578</td>\n",
       "      <td>0.371333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tf-idf</th>\n",
       "      <th>xgb</th>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.699122</td>\n",
       "      <td>0.728220</td>\n",
       "      <td>0.898944</td>\n",
       "      <td>0.863813</td>\n",
       "      <td>0.598358</td>\n",
       "      <td>0.752710</td>\n",
       "      <td>0.756861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bertabaporu-base</th>\n",
       "      <th>xgb</th>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.661773</td>\n",
       "      <td>0.692262</td>\n",
       "      <td>0.776979</td>\n",
       "      <td>0.778471</td>\n",
       "      <td>0.585105</td>\n",
       "      <td>0.645518</td>\n",
       "      <td>0.690018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">-</th>\n",
       "      <th>bertabaporu-base</th>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.652707</td>\n",
       "      <td>0.767310</td>\n",
       "      <td>0.809799</td>\n",
       "      <td>0.799052</td>\n",
       "      <td>0.576324</td>\n",
       "      <td>0.632407</td>\n",
       "      <td>0.706266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bertabaporu-base (R)</th>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.701990</td>\n",
       "      <td>0.822060</td>\n",
       "      <td>0.872170</td>\n",
       "      <td>0.860531</td>\n",
       "      <td>0.597442</td>\n",
       "      <td>0.711676</td>\n",
       "      <td>0.760978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>llama3:7b zero-shot [5] (R)</th>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.605633</td>\n",
       "      <td>0.588752</td>\n",
       "      <td>0.639513</td>\n",
       "      <td>0.528509</td>\n",
       "      <td>0.560086</td>\n",
       "      <td>0.514680</td>\n",
       "      <td>0.572862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>llama3:7b zero-shot [10] (R)</th>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.563199</td>\n",
       "      <td>0.611771</td>\n",
       "      <td>0.609199</td>\n",
       "      <td>0.529703</td>\n",
       "      <td>0.507579</td>\n",
       "      <td>0.516021</td>\n",
       "      <td>0.556245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>llama3:7b zero-shot [15] (R)</th>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.598183</td>\n",
       "      <td>0.586106</td>\n",
       "      <td>0.611868</td>\n",
       "      <td>0.518743</td>\n",
       "      <td>0.515050</td>\n",
       "      <td>0.529726</td>\n",
       "      <td>0.559946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ensemble Texts + Timeline</th>\n",
       "      <th>-</th>\n",
       "      <th>LogisticRegression</th>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.698596</td>\n",
       "      <td>0.728220</td>\n",
       "      <td>0.898944</td>\n",
       "      <td>0.867509</td>\n",
       "      <td>0.586353</td>\n",
       "      <td>0.745550</td>\n",
       "      <td>0.754195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ensemble Texts + Stance</th>\n",
       "      <th>-</th>\n",
       "      <th>LogisticRegression</th>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.820220</td>\n",
       "      <td>0.800537</td>\n",
       "      <td>0.811570</td>\n",
       "      <td>0.805406</td>\n",
       "      <td>0.867826</td>\n",
       "      <td>0.752925</td>\n",
       "      <td>0.809747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ensemble Stance + Timeline</th>\n",
       "      <th>-</th>\n",
       "      <th>LogisticRegression</th>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.781126</td>\n",
       "      <td>0.767310</td>\n",
       "      <td>0.905882</td>\n",
       "      <td>0.883599</td>\n",
       "      <td>0.802880</td>\n",
       "      <td>0.800597</td>\n",
       "      <td>0.823566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ensemble Stance + Timeline + Texts</th>\n",
       "      <th>-</th>\n",
       "      <th>LogisticRegression</th>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.740980</td>\n",
       "      <td>0.642395</td>\n",
       "      <td>0.846643</td>\n",
       "      <td>0.841272</td>\n",
       "      <td>0.689304</td>\n",
       "      <td>0.513417</td>\n",
       "      <td>0.712335</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "metric                                                                                      f1-score  \\\n",
       "target                                                                                        Church   \n",
       "text_col                           vectorizer       estimator                    class                 \n",
       "Stance                             -                dummy                        macro avg  0.361407   \n",
       "                                   tf-idf           xgb                          macro avg  0.702021   \n",
       "                                   bertabaporu-base xgb                          macro avg  0.853801   \n",
       "                                   -                bertabaporu-base             macro avg  0.866276   \n",
       "                                                    llama3:7b zero-shot          macro avg  0.729458   \n",
       "Texts                              -                dummy                        macro avg  0.361407   \n",
       "                                   tf-idf           xgb                          macro avg  0.596115   \n",
       "                                   bertabaporu-base xgb                          macro avg  0.594754   \n",
       "                                   -                bertabaporu-base             macro avg  0.586611   \n",
       "                                                    bertabaporu-base (R)         macro avg  0.583417   \n",
       "                                                    llama3:7b zero-shot [5] (R)  macro avg  0.499052   \n",
       "                                                    llama3:7b zero-shot [10] (R) macro avg  0.561274   \n",
       "                                                    llama3:7b zero-shot [15] (R) macro avg  0.503966   \n",
       "Timeline                           -                dummy                        macro avg  0.361407   \n",
       "                                   tf-idf           xgb                          macro avg  0.699122   \n",
       "                                   bertabaporu-base xgb                          macro avg  0.661773   \n",
       "                                   -                bertabaporu-base             macro avg  0.652707   \n",
       "                                                    bertabaporu-base (R)         macro avg  0.701990   \n",
       "                                                    llama3:7b zero-shot [5] (R)  macro avg  0.605633   \n",
       "                                                    llama3:7b zero-shot [10] (R) macro avg  0.563199   \n",
       "                                                    llama3:7b zero-shot [15] (R) macro avg  0.598183   \n",
       "Ensemble Texts + Timeline          -                LogisticRegression           macro avg  0.698596   \n",
       "Ensemble Texts + Stance            -                LogisticRegression           macro avg  0.820220   \n",
       "Ensemble Stance + Timeline         -                LogisticRegression           macro avg  0.781126   \n",
       "Ensemble Stance + Timeline + Texts -                LogisticRegression           macro avg  0.740980   \n",
       "\n",
       "metric                                                                                                \\\n",
       "target                                                                                     Bolsonaro   \n",
       "text_col                           vectorizer       estimator                    class                 \n",
       "Stance                             -                dummy                        macro avg  0.462857   \n",
       "                                   tf-idf           xgb                          macro avg  0.595312   \n",
       "                                   bertabaporu-base xgb                          macro avg  0.625289   \n",
       "                                   -                bertabaporu-base             macro avg  0.737297   \n",
       "                                                    llama3:7b zero-shot          macro avg  0.462857   \n",
       "Texts                              -                dummy                        macro avg  0.462857   \n",
       "                                   tf-idf           xgb                          macro avg  0.501220   \n",
       "                                   bertabaporu-base xgb                          macro avg  0.495578   \n",
       "                                   -                bertabaporu-base             macro avg  0.462857   \n",
       "                                                    bertabaporu-base (R)         macro avg  0.462857   \n",
       "                                                    llama3:7b zero-shot [5] (R)  macro avg  0.296142   \n",
       "                                                    llama3:7b zero-shot [10] (R) macro avg  0.328245   \n",
       "                                                    llama3:7b zero-shot [15] (R) macro avg  0.285253   \n",
       "Timeline                           -                dummy                        macro avg  0.462857   \n",
       "                                   tf-idf           xgb                          macro avg  0.728220   \n",
       "                                   bertabaporu-base xgb                          macro avg  0.692262   \n",
       "                                   -                bertabaporu-base             macro avg  0.767310   \n",
       "                                                    bertabaporu-base (R)         macro avg  0.822060   \n",
       "                                                    llama3:7b zero-shot [5] (R)  macro avg  0.588752   \n",
       "                                                    llama3:7b zero-shot [10] (R) macro avg  0.611771   \n",
       "                                                    llama3:7b zero-shot [15] (R) macro avg  0.586106   \n",
       "Ensemble Texts + Timeline          -                LogisticRegression           macro avg  0.728220   \n",
       "Ensemble Texts + Stance            -                LogisticRegression           macro avg  0.800537   \n",
       "Ensemble Stance + Timeline         -                LogisticRegression           macro avg  0.767310   \n",
       "Ensemble Stance + Timeline + Texts -                LogisticRegression           macro avg  0.642395   \n",
       "\n",
       "metric                                                                                                \\\n",
       "target                                                                                       Hydrox.   \n",
       "text_col                           vectorizer       estimator                    class                 \n",
       "Stance                             -                dummy                        macro avg  0.334878   \n",
       "                                   tf-idf           xgb                          macro avg  0.734366   \n",
       "                                   bertabaporu-base xgb                          macro avg  0.830948   \n",
       "                                   -                bertabaporu-base             macro avg  0.848144   \n",
       "                                                    llama3:7b zero-shot          macro avg  0.638889   \n",
       "Texts                              -                dummy                        macro avg  0.334878   \n",
       "                                   tf-idf           xgb                          macro avg  0.603727   \n",
       "                                   bertabaporu-base xgb                          macro avg  0.609524   \n",
       "                                   -                bertabaporu-base             macro avg  0.446504   \n",
       "                                                    bertabaporu-base (R)         macro avg  0.570531   \n",
       "                                                    llama3:7b zero-shot [5] (R)  macro avg  0.469796   \n",
       "                                                    llama3:7b zero-shot [10] (R) macro avg  0.440347   \n",
       "                                                    llama3:7b zero-shot [15] (R) macro avg  0.416946   \n",
       "Timeline                           -                dummy                        macro avg  0.334878   \n",
       "                                   tf-idf           xgb                          macro avg  0.898944   \n",
       "                                   bertabaporu-base xgb                          macro avg  0.776979   \n",
       "                                   -                bertabaporu-base             macro avg  0.809799   \n",
       "                                                    bertabaporu-base (R)         macro avg  0.872170   \n",
       "                                                    llama3:7b zero-shot [5] (R)  macro avg  0.639513   \n",
       "                                                    llama3:7b zero-shot [10] (R) macro avg  0.609199   \n",
       "                                                    llama3:7b zero-shot [15] (R) macro avg  0.611868   \n",
       "Ensemble Texts + Timeline          -                LogisticRegression           macro avg  0.898944   \n",
       "Ensemble Texts + Stance            -                LogisticRegression           macro avg  0.811570   \n",
       "Ensemble Stance + Timeline         -                LogisticRegression           macro avg  0.905882   \n",
       "Ensemble Stance + Timeline + Texts -                LogisticRegression           macro avg  0.846643   \n",
       "\n",
       "metric                                                                                                \\\n",
       "target                                                                                       Sinovac   \n",
       "text_col                           vectorizer       estimator                    class                 \n",
       "Stance                             -                dummy                        macro avg  0.351759   \n",
       "                                   tf-idf           xgb                          macro avg  0.752640   \n",
       "                                   bertabaporu-base xgb                          macro avg  0.808036   \n",
       "                                   -                bertabaporu-base             macro avg  0.834984   \n",
       "                                                    llama3:7b zero-shot          macro avg  0.578779   \n",
       "Texts                              -                dummy                        macro avg  0.351759   \n",
       "                                   tf-idf           xgb                          macro avg  0.670805   \n",
       "                                   bertabaporu-base xgb                          macro avg  0.660542   \n",
       "                                   -                bertabaporu-base             macro avg  0.608972   \n",
       "                                                    bertabaporu-base (R)         macro avg  0.637369   \n",
       "                                                    llama3:7b zero-shot [5] (R)  macro avg  0.470381   \n",
       "                                                    llama3:7b zero-shot [10] (R) macro avg  0.460580   \n",
       "                                                    llama3:7b zero-shot [15] (R) macro avg  0.464074   \n",
       "Timeline                           -                dummy                        macro avg  0.351759   \n",
       "                                   tf-idf           xgb                          macro avg  0.863813   \n",
       "                                   bertabaporu-base xgb                          macro avg  0.778471   \n",
       "                                   -                bertabaporu-base             macro avg  0.799052   \n",
       "                                                    bertabaporu-base (R)         macro avg  0.860531   \n",
       "                                                    llama3:7b zero-shot [5] (R)  macro avg  0.528509   \n",
       "                                                    llama3:7b zero-shot [10] (R) macro avg  0.529703   \n",
       "                                                    llama3:7b zero-shot [15] (R) macro avg  0.518743   \n",
       "Ensemble Texts + Timeline          -                LogisticRegression           macro avg  0.867509   \n",
       "Ensemble Texts + Stance            -                LogisticRegression           macro avg  0.805406   \n",
       "Ensemble Stance + Timeline         -                LogisticRegression           macro avg  0.883599   \n",
       "Ensemble Stance + Timeline + Texts -                LogisticRegression           macro avg  0.841272   \n",
       "\n",
       "metric                                                                                                \\\n",
       "target                                                                                      Globo TV   \n",
       "text_col                           vectorizer       estimator                    class                 \n",
       "Stance                             -                dummy                        macro avg  0.372519   \n",
       "                                   tf-idf           xgb                          macro avg  0.665243   \n",
       "                                   bertabaporu-base xgb                          macro avg  0.781858   \n",
       "                                   -                bertabaporu-base             macro avg  0.860252   \n",
       "                                                    llama3:7b zero-shot          macro avg  0.770678   \n",
       "Texts                              -                dummy                        macro avg  0.372519   \n",
       "                                   tf-idf           xgb                          macro avg  0.545620   \n",
       "                                   bertabaporu-base xgb                          macro avg  0.534455   \n",
       "                                   -                bertabaporu-base             macro avg  0.507381   \n",
       "                                                    bertabaporu-base (R)         macro avg  0.586967   \n",
       "                                                    llama3:7b zero-shot [5] (R)  macro avg  0.490101   \n",
       "                                                    llama3:7b zero-shot [10] (R) macro avg  0.494646   \n",
       "                                                    llama3:7b zero-shot [15] (R) macro avg  0.475797   \n",
       "Timeline                           -                dummy                        macro avg  0.372519   \n",
       "                                   tf-idf           xgb                          macro avg  0.598358   \n",
       "                                   bertabaporu-base xgb                          macro avg  0.585105   \n",
       "                                   -                bertabaporu-base             macro avg  0.576324   \n",
       "                                                    bertabaporu-base (R)         macro avg  0.597442   \n",
       "                                                    llama3:7b zero-shot [5] (R)  macro avg  0.560086   \n",
       "                                                    llama3:7b zero-shot [10] (R) macro avg  0.507579   \n",
       "                                                    llama3:7b zero-shot [15] (R) macro avg  0.515050   \n",
       "Ensemble Texts + Timeline          -                LogisticRegression           macro avg  0.586353   \n",
       "Ensemble Texts + Stance            -                LogisticRegression           macro avg  0.867826   \n",
       "Ensemble Stance + Timeline         -                LogisticRegression           macro avg  0.802880   \n",
       "Ensemble Stance + Timeline + Texts -                LogisticRegression           macro avg  0.689304   \n",
       "\n",
       "metric                                                                                                \\\n",
       "target                                                                                          Lula   \n",
       "text_col                           vectorizer       estimator                    class                 \n",
       "Stance                             -                dummy                        macro avg  0.344578   \n",
       "                                   tf-idf           xgb                          macro avg  0.654412   \n",
       "                                   bertabaporu-base xgb                          macro avg  0.766993   \n",
       "                                   -                bertabaporu-base             macro avg  0.789802   \n",
       "                                                    llama3:7b zero-shot          macro avg  0.699381   \n",
       "Texts                              -                dummy                        macro avg  0.344578   \n",
       "                                   tf-idf           xgb                          macro avg  0.579427   \n",
       "                                   bertabaporu-base xgb                          macro avg  0.569597   \n",
       "                                   -                bertabaporu-base             macro avg  0.482520   \n",
       "                                                    bertabaporu-base (R)         macro avg  0.602167   \n",
       "                                                    llama3:7b zero-shot [5] (R)  macro avg  0.512954   \n",
       "                                                    llama3:7b zero-shot [10] (R) macro avg  0.478244   \n",
       "                                                    llama3:7b zero-shot [15] (R) macro avg  0.542401   \n",
       "Timeline                           -                dummy                        macro avg  0.344578   \n",
       "                                   tf-idf           xgb                          macro avg  0.752710   \n",
       "                                   bertabaporu-base xgb                          macro avg  0.645518   \n",
       "                                   -                bertabaporu-base             macro avg  0.632407   \n",
       "                                                    bertabaporu-base (R)         macro avg  0.711676   \n",
       "                                                    llama3:7b zero-shot [5] (R)  macro avg  0.514680   \n",
       "                                                    llama3:7b zero-shot [10] (R) macro avg  0.516021   \n",
       "                                                    llama3:7b zero-shot [15] (R) macro avg  0.529726   \n",
       "Ensemble Texts + Timeline          -                LogisticRegression           macro avg  0.745550   \n",
       "Ensemble Texts + Stance            -                LogisticRegression           macro avg  0.752925   \n",
       "Ensemble Stance + Timeline         -                LogisticRegression           macro avg  0.800597   \n",
       "Ensemble Stance + Timeline + Texts -                LogisticRegression           macro avg  0.513417   \n",
       "\n",
       "metric                                                                                                \n",
       "target                                                                                       overall  \n",
       "text_col                           vectorizer       estimator                    class                \n",
       "Stance                             -                dummy                        macro avg  0.371333  \n",
       "                                   tf-idf           xgb                          macro avg  0.683999  \n",
       "                                   bertabaporu-base xgb                          macro avg  0.777821  \n",
       "                                   -                bertabaporu-base             macro avg  0.822792  \n",
       "                                                    llama3:7b zero-shot          macro avg  0.646674  \n",
       "Texts                              -                dummy                        macro avg  0.371333  \n",
       "                                   tf-idf           xgb                          macro avg  0.582819  \n",
       "                                   bertabaporu-base xgb                          macro avg  0.577408  \n",
       "                                   -                bertabaporu-base             macro avg  0.515808  \n",
       "                                                    bertabaporu-base (R)         macro avg  0.573885  \n",
       "                                                    llama3:7b zero-shot [5] (R)  macro avg  0.456404  \n",
       "                                                    llama3:7b zero-shot [10] (R) macro avg  0.460556  \n",
       "                                                    llama3:7b zero-shot [15] (R) macro avg  0.448073  \n",
       "Timeline                           -                dummy                        macro avg  0.371333  \n",
       "                                   tf-idf           xgb                          macro avg  0.756861  \n",
       "                                   bertabaporu-base xgb                          macro avg  0.690018  \n",
       "                                   -                bertabaporu-base             macro avg  0.706266  \n",
       "                                                    bertabaporu-base (R)         macro avg  0.760978  \n",
       "                                                    llama3:7b zero-shot [5] (R)  macro avg  0.572862  \n",
       "                                                    llama3:7b zero-shot [10] (R) macro avg  0.556245  \n",
       "                                                    llama3:7b zero-shot [15] (R) macro avg  0.559946  \n",
       "Ensemble Texts + Timeline          -                LogisticRegression           macro avg  0.754195  \n",
       "Ensemble Texts + Stance            -                LogisticRegression           macro avg  0.809747  \n",
       "Ensemble Stance + Timeline         -                LogisticRegression           macro avg  0.823566  \n",
       "Ensemble Stance + Timeline + Texts -                LogisticRegression           macro avg  0.712335  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask_f1 = [True if  \"f1-score\" in col else False for col in df_results_final.columns]\n",
    "mask_macro = [True if  \"macro avg\" in col else False for col in df_results_final.index]\n",
    "\n",
    "f1_macro_df = df_results_final.loc[mask_macro,mask_f1]\n",
    "f1_macro_df[('f1-score','overall')] = f1_macro_df.mean(axis=1)\n",
    "\n",
    "f1_macro_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Table for docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>metric</th>\n",
       "      <th colspan=\"7\" halign=\"left\">f1-score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>Church</th>\n",
       "      <th>Bolsonaro</th>\n",
       "      <th>Hydrox.</th>\n",
       "      <th>Sinovac</th>\n",
       "      <th>Globo TV</th>\n",
       "      <th>Lula</th>\n",
       "      <th>overall</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text_col</th>\n",
       "      <th>vectorizer</th>\n",
       "      <th>estimator</th>\n",
       "      <th>class</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">Stance</th>\n",
       "      <th>-</th>\n",
       "      <th>dummy</th>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.361407</td>\n",
       "      <td>0.462857</td>\n",
       "      <td>0.334878</td>\n",
       "      <td>0.351759</td>\n",
       "      <td>0.372519</td>\n",
       "      <td>0.344578</td>\n",
       "      <td>0.371333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tf-idf</th>\n",
       "      <th>xgb</th>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.702021</td>\n",
       "      <td>0.595312</td>\n",
       "      <td>0.734366</td>\n",
       "      <td>0.752640</td>\n",
       "      <td>0.665243</td>\n",
       "      <td>0.654412</td>\n",
       "      <td>0.683999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bertabaporu-base</th>\n",
       "      <th>xgb</th>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.853801</td>\n",
       "      <td>0.625289</td>\n",
       "      <td>0.830948</td>\n",
       "      <td>0.808036</td>\n",
       "      <td>0.781858</td>\n",
       "      <td>0.766993</td>\n",
       "      <td>0.777821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">-</th>\n",
       "      <th>bertabaporu-base</th>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.866276</td>\n",
       "      <td>0.737297</td>\n",
       "      <td>0.848144</td>\n",
       "      <td>0.834984</td>\n",
       "      <td>0.860252</td>\n",
       "      <td>0.789802</td>\n",
       "      <td>0.822792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>llama3:7b zero-shot</th>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.729458</td>\n",
       "      <td>0.462857</td>\n",
       "      <td>0.638889</td>\n",
       "      <td>0.578779</td>\n",
       "      <td>0.770678</td>\n",
       "      <td>0.699381</td>\n",
       "      <td>0.646674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"8\" valign=\"top\">Texts</th>\n",
       "      <th>-</th>\n",
       "      <th>dummy</th>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.361407</td>\n",
       "      <td>0.462857</td>\n",
       "      <td>0.334878</td>\n",
       "      <td>0.351759</td>\n",
       "      <td>0.372519</td>\n",
       "      <td>0.344578</td>\n",
       "      <td>0.371333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tf-idf</th>\n",
       "      <th>xgb</th>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.596115</td>\n",
       "      <td>0.501220</td>\n",
       "      <td>0.603727</td>\n",
       "      <td>0.670805</td>\n",
       "      <td>0.545620</td>\n",
       "      <td>0.579427</td>\n",
       "      <td>0.582819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bertabaporu-base</th>\n",
       "      <th>xgb</th>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.594754</td>\n",
       "      <td>0.495578</td>\n",
       "      <td>0.609524</td>\n",
       "      <td>0.660542</td>\n",
       "      <td>0.534455</td>\n",
       "      <td>0.569597</td>\n",
       "      <td>0.577408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">-</th>\n",
       "      <th>bertabaporu-base</th>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.586611</td>\n",
       "      <td>0.462857</td>\n",
       "      <td>0.446504</td>\n",
       "      <td>0.608972</td>\n",
       "      <td>0.507381</td>\n",
       "      <td>0.482520</td>\n",
       "      <td>0.515808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bertabaporu-base (R)</th>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.583417</td>\n",
       "      <td>0.462857</td>\n",
       "      <td>0.570531</td>\n",
       "      <td>0.637369</td>\n",
       "      <td>0.586967</td>\n",
       "      <td>0.602167</td>\n",
       "      <td>0.573885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>llama3:7b zero-shot [5] (R)</th>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.499052</td>\n",
       "      <td>0.296142</td>\n",
       "      <td>0.469796</td>\n",
       "      <td>0.470381</td>\n",
       "      <td>0.490101</td>\n",
       "      <td>0.512954</td>\n",
       "      <td>0.456404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>llama3:7b zero-shot [10] (R)</th>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.561274</td>\n",
       "      <td>0.328245</td>\n",
       "      <td>0.440347</td>\n",
       "      <td>0.460580</td>\n",
       "      <td>0.494646</td>\n",
       "      <td>0.478244</td>\n",
       "      <td>0.460556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>llama3:7b zero-shot [15] (R)</th>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.503966</td>\n",
       "      <td>0.285253</td>\n",
       "      <td>0.416946</td>\n",
       "      <td>0.464074</td>\n",
       "      <td>0.475797</td>\n",
       "      <td>0.542401</td>\n",
       "      <td>0.448073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"8\" valign=\"top\">Timeline</th>\n",
       "      <th>-</th>\n",
       "      <th>dummy</th>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.361407</td>\n",
       "      <td>0.462857</td>\n",
       "      <td>0.334878</td>\n",
       "      <td>0.351759</td>\n",
       "      <td>0.372519</td>\n",
       "      <td>0.344578</td>\n",
       "      <td>0.371333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tf-idf</th>\n",
       "      <th>xgb</th>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.699122</td>\n",
       "      <td>0.728220</td>\n",
       "      <td>0.898944</td>\n",
       "      <td>0.863813</td>\n",
       "      <td>0.598358</td>\n",
       "      <td>0.752710</td>\n",
       "      <td>0.756861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bertabaporu-base</th>\n",
       "      <th>xgb</th>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.661773</td>\n",
       "      <td>0.692262</td>\n",
       "      <td>0.776979</td>\n",
       "      <td>0.778471</td>\n",
       "      <td>0.585105</td>\n",
       "      <td>0.645518</td>\n",
       "      <td>0.690018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">-</th>\n",
       "      <th>bertabaporu-base</th>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.652707</td>\n",
       "      <td>0.767310</td>\n",
       "      <td>0.809799</td>\n",
       "      <td>0.799052</td>\n",
       "      <td>0.576324</td>\n",
       "      <td>0.632407</td>\n",
       "      <td>0.706266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bertabaporu-base (R)</th>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.701990</td>\n",
       "      <td>0.822060</td>\n",
       "      <td>0.872170</td>\n",
       "      <td>0.860531</td>\n",
       "      <td>0.597442</td>\n",
       "      <td>0.711676</td>\n",
       "      <td>0.760978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>llama3:7b zero-shot [5] (R)</th>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.605633</td>\n",
       "      <td>0.588752</td>\n",
       "      <td>0.639513</td>\n",
       "      <td>0.528509</td>\n",
       "      <td>0.560086</td>\n",
       "      <td>0.514680</td>\n",
       "      <td>0.572862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>llama3:7b zero-shot [10] (R)</th>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.563199</td>\n",
       "      <td>0.611771</td>\n",
       "      <td>0.609199</td>\n",
       "      <td>0.529703</td>\n",
       "      <td>0.507579</td>\n",
       "      <td>0.516021</td>\n",
       "      <td>0.556245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>llama3:7b zero-shot [15] (R)</th>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.598183</td>\n",
       "      <td>0.586106</td>\n",
       "      <td>0.611868</td>\n",
       "      <td>0.518743</td>\n",
       "      <td>0.515050</td>\n",
       "      <td>0.529726</td>\n",
       "      <td>0.559946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ensemble Texts + Timeline</th>\n",
       "      <th>-</th>\n",
       "      <th>LogisticRegression</th>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.698596</td>\n",
       "      <td>0.728220</td>\n",
       "      <td>0.898944</td>\n",
       "      <td>0.867509</td>\n",
       "      <td>0.586353</td>\n",
       "      <td>0.745550</td>\n",
       "      <td>0.754195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ensemble Texts + Stance</th>\n",
       "      <th>-</th>\n",
       "      <th>LogisticRegression</th>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.820220</td>\n",
       "      <td>0.800537</td>\n",
       "      <td>0.811570</td>\n",
       "      <td>0.805406</td>\n",
       "      <td>0.867826</td>\n",
       "      <td>0.752925</td>\n",
       "      <td>0.809747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ensemble Stance + Timeline</th>\n",
       "      <th>-</th>\n",
       "      <th>LogisticRegression</th>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.781126</td>\n",
       "      <td>0.767310</td>\n",
       "      <td>0.905882</td>\n",
       "      <td>0.883599</td>\n",
       "      <td>0.802880</td>\n",
       "      <td>0.800597</td>\n",
       "      <td>0.823566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ensemble Stance + Timeline + Texts</th>\n",
       "      <th>-</th>\n",
       "      <th>LogisticRegression</th>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.740980</td>\n",
       "      <td>0.642395</td>\n",
       "      <td>0.846643</td>\n",
       "      <td>0.841272</td>\n",
       "      <td>0.689304</td>\n",
       "      <td>0.513417</td>\n",
       "      <td>0.712335</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "metric                                                                                      f1-score  \\\n",
       "target                                                                                        Church   \n",
       "text_col                           vectorizer       estimator                    class                 \n",
       "Stance                             -                dummy                        macro avg  0.361407   \n",
       "                                   tf-idf           xgb                          macro avg  0.702021   \n",
       "                                   bertabaporu-base xgb                          macro avg  0.853801   \n",
       "                                   -                bertabaporu-base             macro avg  0.866276   \n",
       "                                                    llama3:7b zero-shot          macro avg  0.729458   \n",
       "Texts                              -                dummy                        macro avg  0.361407   \n",
       "                                   tf-idf           xgb                          macro avg  0.596115   \n",
       "                                   bertabaporu-base xgb                          macro avg  0.594754   \n",
       "                                   -                bertabaporu-base             macro avg  0.586611   \n",
       "                                                    bertabaporu-base (R)         macro avg  0.583417   \n",
       "                                                    llama3:7b zero-shot [5] (R)  macro avg  0.499052   \n",
       "                                                    llama3:7b zero-shot [10] (R) macro avg  0.561274   \n",
       "                                                    llama3:7b zero-shot [15] (R) macro avg  0.503966   \n",
       "Timeline                           -                dummy                        macro avg  0.361407   \n",
       "                                   tf-idf           xgb                          macro avg  0.699122   \n",
       "                                   bertabaporu-base xgb                          macro avg  0.661773   \n",
       "                                   -                bertabaporu-base             macro avg  0.652707   \n",
       "                                                    bertabaporu-base (R)         macro avg  0.701990   \n",
       "                                                    llama3:7b zero-shot [5] (R)  macro avg  0.605633   \n",
       "                                                    llama3:7b zero-shot [10] (R) macro avg  0.563199   \n",
       "                                                    llama3:7b zero-shot [15] (R) macro avg  0.598183   \n",
       "Ensemble Texts + Timeline          -                LogisticRegression           macro avg  0.698596   \n",
       "Ensemble Texts + Stance            -                LogisticRegression           macro avg  0.820220   \n",
       "Ensemble Stance + Timeline         -                LogisticRegression           macro avg  0.781126   \n",
       "Ensemble Stance + Timeline + Texts -                LogisticRegression           macro avg  0.740980   \n",
       "\n",
       "metric                                                                                                \\\n",
       "target                                                                                     Bolsonaro   \n",
       "text_col                           vectorizer       estimator                    class                 \n",
       "Stance                             -                dummy                        macro avg  0.462857   \n",
       "                                   tf-idf           xgb                          macro avg  0.595312   \n",
       "                                   bertabaporu-base xgb                          macro avg  0.625289   \n",
       "                                   -                bertabaporu-base             macro avg  0.737297   \n",
       "                                                    llama3:7b zero-shot          macro avg  0.462857   \n",
       "Texts                              -                dummy                        macro avg  0.462857   \n",
       "                                   tf-idf           xgb                          macro avg  0.501220   \n",
       "                                   bertabaporu-base xgb                          macro avg  0.495578   \n",
       "                                   -                bertabaporu-base             macro avg  0.462857   \n",
       "                                                    bertabaporu-base (R)         macro avg  0.462857   \n",
       "                                                    llama3:7b zero-shot [5] (R)  macro avg  0.296142   \n",
       "                                                    llama3:7b zero-shot [10] (R) macro avg  0.328245   \n",
       "                                                    llama3:7b zero-shot [15] (R) macro avg  0.285253   \n",
       "Timeline                           -                dummy                        macro avg  0.462857   \n",
       "                                   tf-idf           xgb                          macro avg  0.728220   \n",
       "                                   bertabaporu-base xgb                          macro avg  0.692262   \n",
       "                                   -                bertabaporu-base             macro avg  0.767310   \n",
       "                                                    bertabaporu-base (R)         macro avg  0.822060   \n",
       "                                                    llama3:7b zero-shot [5] (R)  macro avg  0.588752   \n",
       "                                                    llama3:7b zero-shot [10] (R) macro avg  0.611771   \n",
       "                                                    llama3:7b zero-shot [15] (R) macro avg  0.586106   \n",
       "Ensemble Texts + Timeline          -                LogisticRegression           macro avg  0.728220   \n",
       "Ensemble Texts + Stance            -                LogisticRegression           macro avg  0.800537   \n",
       "Ensemble Stance + Timeline         -                LogisticRegression           macro avg  0.767310   \n",
       "Ensemble Stance + Timeline + Texts -                LogisticRegression           macro avg  0.642395   \n",
       "\n",
       "metric                                                                                                \\\n",
       "target                                                                                       Hydrox.   \n",
       "text_col                           vectorizer       estimator                    class                 \n",
       "Stance                             -                dummy                        macro avg  0.334878   \n",
       "                                   tf-idf           xgb                          macro avg  0.734366   \n",
       "                                   bertabaporu-base xgb                          macro avg  0.830948   \n",
       "                                   -                bertabaporu-base             macro avg  0.848144   \n",
       "                                                    llama3:7b zero-shot          macro avg  0.638889   \n",
       "Texts                              -                dummy                        macro avg  0.334878   \n",
       "                                   tf-idf           xgb                          macro avg  0.603727   \n",
       "                                   bertabaporu-base xgb                          macro avg  0.609524   \n",
       "                                   -                bertabaporu-base             macro avg  0.446504   \n",
       "                                                    bertabaporu-base (R)         macro avg  0.570531   \n",
       "                                                    llama3:7b zero-shot [5] (R)  macro avg  0.469796   \n",
       "                                                    llama3:7b zero-shot [10] (R) macro avg  0.440347   \n",
       "                                                    llama3:7b zero-shot [15] (R) macro avg  0.416946   \n",
       "Timeline                           -                dummy                        macro avg  0.334878   \n",
       "                                   tf-idf           xgb                          macro avg  0.898944   \n",
       "                                   bertabaporu-base xgb                          macro avg  0.776979   \n",
       "                                   -                bertabaporu-base             macro avg  0.809799   \n",
       "                                                    bertabaporu-base (R)         macro avg  0.872170   \n",
       "                                                    llama3:7b zero-shot [5] (R)  macro avg  0.639513   \n",
       "                                                    llama3:7b zero-shot [10] (R) macro avg  0.609199   \n",
       "                                                    llama3:7b zero-shot [15] (R) macro avg  0.611868   \n",
       "Ensemble Texts + Timeline          -                LogisticRegression           macro avg  0.898944   \n",
       "Ensemble Texts + Stance            -                LogisticRegression           macro avg  0.811570   \n",
       "Ensemble Stance + Timeline         -                LogisticRegression           macro avg  0.905882   \n",
       "Ensemble Stance + Timeline + Texts -                LogisticRegression           macro avg  0.846643   \n",
       "\n",
       "metric                                                                                                \\\n",
       "target                                                                                       Sinovac   \n",
       "text_col                           vectorizer       estimator                    class                 \n",
       "Stance                             -                dummy                        macro avg  0.351759   \n",
       "                                   tf-idf           xgb                          macro avg  0.752640   \n",
       "                                   bertabaporu-base xgb                          macro avg  0.808036   \n",
       "                                   -                bertabaporu-base             macro avg  0.834984   \n",
       "                                                    llama3:7b zero-shot          macro avg  0.578779   \n",
       "Texts                              -                dummy                        macro avg  0.351759   \n",
       "                                   tf-idf           xgb                          macro avg  0.670805   \n",
       "                                   bertabaporu-base xgb                          macro avg  0.660542   \n",
       "                                   -                bertabaporu-base             macro avg  0.608972   \n",
       "                                                    bertabaporu-base (R)         macro avg  0.637369   \n",
       "                                                    llama3:7b zero-shot [5] (R)  macro avg  0.470381   \n",
       "                                                    llama3:7b zero-shot [10] (R) macro avg  0.460580   \n",
       "                                                    llama3:7b zero-shot [15] (R) macro avg  0.464074   \n",
       "Timeline                           -                dummy                        macro avg  0.351759   \n",
       "                                   tf-idf           xgb                          macro avg  0.863813   \n",
       "                                   bertabaporu-base xgb                          macro avg  0.778471   \n",
       "                                   -                bertabaporu-base             macro avg  0.799052   \n",
       "                                                    bertabaporu-base (R)         macro avg  0.860531   \n",
       "                                                    llama3:7b zero-shot [5] (R)  macro avg  0.528509   \n",
       "                                                    llama3:7b zero-shot [10] (R) macro avg  0.529703   \n",
       "                                                    llama3:7b zero-shot [15] (R) macro avg  0.518743   \n",
       "Ensemble Texts + Timeline          -                LogisticRegression           macro avg  0.867509   \n",
       "Ensemble Texts + Stance            -                LogisticRegression           macro avg  0.805406   \n",
       "Ensemble Stance + Timeline         -                LogisticRegression           macro avg  0.883599   \n",
       "Ensemble Stance + Timeline + Texts -                LogisticRegression           macro avg  0.841272   \n",
       "\n",
       "metric                                                                                                \\\n",
       "target                                                                                      Globo TV   \n",
       "text_col                           vectorizer       estimator                    class                 \n",
       "Stance                             -                dummy                        macro avg  0.372519   \n",
       "                                   tf-idf           xgb                          macro avg  0.665243   \n",
       "                                   bertabaporu-base xgb                          macro avg  0.781858   \n",
       "                                   -                bertabaporu-base             macro avg  0.860252   \n",
       "                                                    llama3:7b zero-shot          macro avg  0.770678   \n",
       "Texts                              -                dummy                        macro avg  0.372519   \n",
       "                                   tf-idf           xgb                          macro avg  0.545620   \n",
       "                                   bertabaporu-base xgb                          macro avg  0.534455   \n",
       "                                   -                bertabaporu-base             macro avg  0.507381   \n",
       "                                                    bertabaporu-base (R)         macro avg  0.586967   \n",
       "                                                    llama3:7b zero-shot [5] (R)  macro avg  0.490101   \n",
       "                                                    llama3:7b zero-shot [10] (R) macro avg  0.494646   \n",
       "                                                    llama3:7b zero-shot [15] (R) macro avg  0.475797   \n",
       "Timeline                           -                dummy                        macro avg  0.372519   \n",
       "                                   tf-idf           xgb                          macro avg  0.598358   \n",
       "                                   bertabaporu-base xgb                          macro avg  0.585105   \n",
       "                                   -                bertabaporu-base             macro avg  0.576324   \n",
       "                                                    bertabaporu-base (R)         macro avg  0.597442   \n",
       "                                                    llama3:7b zero-shot [5] (R)  macro avg  0.560086   \n",
       "                                                    llama3:7b zero-shot [10] (R) macro avg  0.507579   \n",
       "                                                    llama3:7b zero-shot [15] (R) macro avg  0.515050   \n",
       "Ensemble Texts + Timeline          -                LogisticRegression           macro avg  0.586353   \n",
       "Ensemble Texts + Stance            -                LogisticRegression           macro avg  0.867826   \n",
       "Ensemble Stance + Timeline         -                LogisticRegression           macro avg  0.802880   \n",
       "Ensemble Stance + Timeline + Texts -                LogisticRegression           macro avg  0.689304   \n",
       "\n",
       "metric                                                                                                \\\n",
       "target                                                                                          Lula   \n",
       "text_col                           vectorizer       estimator                    class                 \n",
       "Stance                             -                dummy                        macro avg  0.344578   \n",
       "                                   tf-idf           xgb                          macro avg  0.654412   \n",
       "                                   bertabaporu-base xgb                          macro avg  0.766993   \n",
       "                                   -                bertabaporu-base             macro avg  0.789802   \n",
       "                                                    llama3:7b zero-shot          macro avg  0.699381   \n",
       "Texts                              -                dummy                        macro avg  0.344578   \n",
       "                                   tf-idf           xgb                          macro avg  0.579427   \n",
       "                                   bertabaporu-base xgb                          macro avg  0.569597   \n",
       "                                   -                bertabaporu-base             macro avg  0.482520   \n",
       "                                                    bertabaporu-base (R)         macro avg  0.602167   \n",
       "                                                    llama3:7b zero-shot [5] (R)  macro avg  0.512954   \n",
       "                                                    llama3:7b zero-shot [10] (R) macro avg  0.478244   \n",
       "                                                    llama3:7b zero-shot [15] (R) macro avg  0.542401   \n",
       "Timeline                           -                dummy                        macro avg  0.344578   \n",
       "                                   tf-idf           xgb                          macro avg  0.752710   \n",
       "                                   bertabaporu-base xgb                          macro avg  0.645518   \n",
       "                                   -                bertabaporu-base             macro avg  0.632407   \n",
       "                                                    bertabaporu-base (R)         macro avg  0.711676   \n",
       "                                                    llama3:7b zero-shot [5] (R)  macro avg  0.514680   \n",
       "                                                    llama3:7b zero-shot [10] (R) macro avg  0.516021   \n",
       "                                                    llama3:7b zero-shot [15] (R) macro avg  0.529726   \n",
       "Ensemble Texts + Timeline          -                LogisticRegression           macro avg  0.745550   \n",
       "Ensemble Texts + Stance            -                LogisticRegression           macro avg  0.752925   \n",
       "Ensemble Stance + Timeline         -                LogisticRegression           macro avg  0.800597   \n",
       "Ensemble Stance + Timeline + Texts -                LogisticRegression           macro avg  0.513417   \n",
       "\n",
       "metric                                                                                                \n",
       "target                                                                                       overall  \n",
       "text_col                           vectorizer       estimator                    class                \n",
       "Stance                             -                dummy                        macro avg  0.371333  \n",
       "                                   tf-idf           xgb                          macro avg  0.683999  \n",
       "                                   bertabaporu-base xgb                          macro avg  0.777821  \n",
       "                                   -                bertabaporu-base             macro avg  0.822792  \n",
       "                                                    llama3:7b zero-shot          macro avg  0.646674  \n",
       "Texts                              -                dummy                        macro avg  0.371333  \n",
       "                                   tf-idf           xgb                          macro avg  0.582819  \n",
       "                                   bertabaporu-base xgb                          macro avg  0.577408  \n",
       "                                   -                bertabaporu-base             macro avg  0.515808  \n",
       "                                                    bertabaporu-base (R)         macro avg  0.573885  \n",
       "                                                    llama3:7b zero-shot [5] (R)  macro avg  0.456404  \n",
       "                                                    llama3:7b zero-shot [10] (R) macro avg  0.460556  \n",
       "                                                    llama3:7b zero-shot [15] (R) macro avg  0.448073  \n",
       "Timeline                           -                dummy                        macro avg  0.371333  \n",
       "                                   tf-idf           xgb                          macro avg  0.756861  \n",
       "                                   bertabaporu-base xgb                          macro avg  0.690018  \n",
       "                                   -                bertabaporu-base             macro avg  0.706266  \n",
       "                                                    bertabaporu-base (R)         macro avg  0.760978  \n",
       "                                                    llama3:7b zero-shot [5] (R)  macro avg  0.572862  \n",
       "                                                    llama3:7b zero-shot [10] (R) macro avg  0.556245  \n",
       "                                                    llama3:7b zero-shot [15] (R) macro avg  0.559946  \n",
       "Ensemble Texts + Timeline          -                LogisticRegression           macro avg  0.754195  \n",
       "Ensemble Texts + Stance            -                LogisticRegression           macro avg  0.809747  \n",
       "Ensemble Stance + Timeline         -                LogisticRegression           macro avg  0.823566  \n",
       "Ensemble Stance + Timeline + Texts -                LogisticRegression           macro avg  0.712335  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_report = f1_macro_df.copy()\n",
    "f1_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>metric</th>\n",
       "      <th>text_col</th>\n",
       "      <th>vectorizer</th>\n",
       "      <th>estimator</th>\n",
       "      <th>class</th>\n",
       "      <th colspan=\"7\" halign=\"left\">f1-score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>target</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Church</th>\n",
       "      <th>Bolsonaro</th>\n",
       "      <th>Hydrox.</th>\n",
       "      <th>Sinovac</th>\n",
       "      <th>Globo TV</th>\n",
       "      <th>Lula</th>\n",
       "      <th>overall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Stance</td>\n",
       "      <td>-</td>\n",
       "      <td>dummy</td>\n",
       "      <td>macro avg</td>\n",
       "      <td>0.361407</td>\n",
       "      <td>0.462857</td>\n",
       "      <td>0.334878</td>\n",
       "      <td>0.351759</td>\n",
       "      <td>0.372519</td>\n",
       "      <td>0.344578</td>\n",
       "      <td>0.371333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Stance</td>\n",
       "      <td>tf-idf</td>\n",
       "      <td>xgb</td>\n",
       "      <td>macro avg</td>\n",
       "      <td>0.702021</td>\n",
       "      <td>0.595312</td>\n",
       "      <td>0.734366</td>\n",
       "      <td>0.752640</td>\n",
       "      <td>0.665243</td>\n",
       "      <td>0.654412</td>\n",
       "      <td>0.683999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Stance</td>\n",
       "      <td>bertabaporu-base</td>\n",
       "      <td>xgb</td>\n",
       "      <td>macro avg</td>\n",
       "      <td>0.853801</td>\n",
       "      <td>0.625289</td>\n",
       "      <td>0.830948</td>\n",
       "      <td>0.808036</td>\n",
       "      <td>0.781858</td>\n",
       "      <td>0.766993</td>\n",
       "      <td>0.777821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Stance</td>\n",
       "      <td>-</td>\n",
       "      <td>bertabaporu-base</td>\n",
       "      <td>macro avg</td>\n",
       "      <td>0.866276</td>\n",
       "      <td>0.737297</td>\n",
       "      <td>0.848144</td>\n",
       "      <td>0.834984</td>\n",
       "      <td>0.860252</td>\n",
       "      <td>0.789802</td>\n",
       "      <td>0.822792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Stance</td>\n",
       "      <td>-</td>\n",
       "      <td>llama3:7b zero-shot</td>\n",
       "      <td>macro avg</td>\n",
       "      <td>0.729458</td>\n",
       "      <td>0.462857</td>\n",
       "      <td>0.638889</td>\n",
       "      <td>0.578779</td>\n",
       "      <td>0.770678</td>\n",
       "      <td>0.699381</td>\n",
       "      <td>0.646674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Texts</td>\n",
       "      <td>-</td>\n",
       "      <td>dummy</td>\n",
       "      <td>macro avg</td>\n",
       "      <td>0.361407</td>\n",
       "      <td>0.462857</td>\n",
       "      <td>0.334878</td>\n",
       "      <td>0.351759</td>\n",
       "      <td>0.372519</td>\n",
       "      <td>0.344578</td>\n",
       "      <td>0.371333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Texts</td>\n",
       "      <td>tf-idf</td>\n",
       "      <td>xgb</td>\n",
       "      <td>macro avg</td>\n",
       "      <td>0.596115</td>\n",
       "      <td>0.501220</td>\n",
       "      <td>0.603727</td>\n",
       "      <td>0.670805</td>\n",
       "      <td>0.545620</td>\n",
       "      <td>0.579427</td>\n",
       "      <td>0.582819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Texts</td>\n",
       "      <td>bertabaporu-base</td>\n",
       "      <td>xgb</td>\n",
       "      <td>macro avg</td>\n",
       "      <td>0.594754</td>\n",
       "      <td>0.495578</td>\n",
       "      <td>0.609524</td>\n",
       "      <td>0.660542</td>\n",
       "      <td>0.534455</td>\n",
       "      <td>0.569597</td>\n",
       "      <td>0.577408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Texts</td>\n",
       "      <td>-</td>\n",
       "      <td>bertabaporu-base</td>\n",
       "      <td>macro avg</td>\n",
       "      <td>0.586611</td>\n",
       "      <td>0.462857</td>\n",
       "      <td>0.446504</td>\n",
       "      <td>0.608972</td>\n",
       "      <td>0.507381</td>\n",
       "      <td>0.482520</td>\n",
       "      <td>0.515808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Texts</td>\n",
       "      <td>-</td>\n",
       "      <td>bertabaporu-base (R)</td>\n",
       "      <td>macro avg</td>\n",
       "      <td>0.583417</td>\n",
       "      <td>0.462857</td>\n",
       "      <td>0.570531</td>\n",
       "      <td>0.637369</td>\n",
       "      <td>0.586967</td>\n",
       "      <td>0.602167</td>\n",
       "      <td>0.573885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Texts</td>\n",
       "      <td>-</td>\n",
       "      <td>llama3:7b zero-shot [5] (R)</td>\n",
       "      <td>macro avg</td>\n",
       "      <td>0.499052</td>\n",
       "      <td>0.296142</td>\n",
       "      <td>0.469796</td>\n",
       "      <td>0.470381</td>\n",
       "      <td>0.490101</td>\n",
       "      <td>0.512954</td>\n",
       "      <td>0.456404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Texts</td>\n",
       "      <td>-</td>\n",
       "      <td>llama3:7b zero-shot [10] (R)</td>\n",
       "      <td>macro avg</td>\n",
       "      <td>0.561274</td>\n",
       "      <td>0.328245</td>\n",
       "      <td>0.440347</td>\n",
       "      <td>0.460580</td>\n",
       "      <td>0.494646</td>\n",
       "      <td>0.478244</td>\n",
       "      <td>0.460556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Texts</td>\n",
       "      <td>-</td>\n",
       "      <td>llama3:7b zero-shot [15] (R)</td>\n",
       "      <td>macro avg</td>\n",
       "      <td>0.503966</td>\n",
       "      <td>0.285253</td>\n",
       "      <td>0.416946</td>\n",
       "      <td>0.464074</td>\n",
       "      <td>0.475797</td>\n",
       "      <td>0.542401</td>\n",
       "      <td>0.448073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Timeline</td>\n",
       "      <td>-</td>\n",
       "      <td>dummy</td>\n",
       "      <td>macro avg</td>\n",
       "      <td>0.361407</td>\n",
       "      <td>0.462857</td>\n",
       "      <td>0.334878</td>\n",
       "      <td>0.351759</td>\n",
       "      <td>0.372519</td>\n",
       "      <td>0.344578</td>\n",
       "      <td>0.371333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Timeline</td>\n",
       "      <td>tf-idf</td>\n",
       "      <td>xgb</td>\n",
       "      <td>macro avg</td>\n",
       "      <td>0.699122</td>\n",
       "      <td>0.728220</td>\n",
       "      <td>0.898944</td>\n",
       "      <td>0.863813</td>\n",
       "      <td>0.598358</td>\n",
       "      <td>0.752710</td>\n",
       "      <td>0.756861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Timeline</td>\n",
       "      <td>bertabaporu-base</td>\n",
       "      <td>xgb</td>\n",
       "      <td>macro avg</td>\n",
       "      <td>0.661773</td>\n",
       "      <td>0.692262</td>\n",
       "      <td>0.776979</td>\n",
       "      <td>0.778471</td>\n",
       "      <td>0.585105</td>\n",
       "      <td>0.645518</td>\n",
       "      <td>0.690018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Timeline</td>\n",
       "      <td>-</td>\n",
       "      <td>bertabaporu-base</td>\n",
       "      <td>macro avg</td>\n",
       "      <td>0.652707</td>\n",
       "      <td>0.767310</td>\n",
       "      <td>0.809799</td>\n",
       "      <td>0.799052</td>\n",
       "      <td>0.576324</td>\n",
       "      <td>0.632407</td>\n",
       "      <td>0.706266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Timeline</td>\n",
       "      <td>-</td>\n",
       "      <td>bertabaporu-base (R)</td>\n",
       "      <td>macro avg</td>\n",
       "      <td>0.701990</td>\n",
       "      <td>0.822060</td>\n",
       "      <td>0.872170</td>\n",
       "      <td>0.860531</td>\n",
       "      <td>0.597442</td>\n",
       "      <td>0.711676</td>\n",
       "      <td>0.760978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Timeline</td>\n",
       "      <td>-</td>\n",
       "      <td>llama3:7b zero-shot [5] (R)</td>\n",
       "      <td>macro avg</td>\n",
       "      <td>0.605633</td>\n",
       "      <td>0.588752</td>\n",
       "      <td>0.639513</td>\n",
       "      <td>0.528509</td>\n",
       "      <td>0.560086</td>\n",
       "      <td>0.514680</td>\n",
       "      <td>0.572862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Timeline</td>\n",
       "      <td>-</td>\n",
       "      <td>llama3:7b zero-shot [10] (R)</td>\n",
       "      <td>macro avg</td>\n",
       "      <td>0.563199</td>\n",
       "      <td>0.611771</td>\n",
       "      <td>0.609199</td>\n",
       "      <td>0.529703</td>\n",
       "      <td>0.507579</td>\n",
       "      <td>0.516021</td>\n",
       "      <td>0.556245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Timeline</td>\n",
       "      <td>-</td>\n",
       "      <td>llama3:7b zero-shot [15] (R)</td>\n",
       "      <td>macro avg</td>\n",
       "      <td>0.598183</td>\n",
       "      <td>0.586106</td>\n",
       "      <td>0.611868</td>\n",
       "      <td>0.518743</td>\n",
       "      <td>0.515050</td>\n",
       "      <td>0.529726</td>\n",
       "      <td>0.559946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Ensemble Texts + Timeline</td>\n",
       "      <td>-</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>macro avg</td>\n",
       "      <td>0.698596</td>\n",
       "      <td>0.728220</td>\n",
       "      <td>0.898944</td>\n",
       "      <td>0.867509</td>\n",
       "      <td>0.586353</td>\n",
       "      <td>0.745550</td>\n",
       "      <td>0.754195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Ensemble Texts + Stance</td>\n",
       "      <td>-</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>macro avg</td>\n",
       "      <td>0.820220</td>\n",
       "      <td>0.800537</td>\n",
       "      <td>0.811570</td>\n",
       "      <td>0.805406</td>\n",
       "      <td>0.867826</td>\n",
       "      <td>0.752925</td>\n",
       "      <td>0.809747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Ensemble Stance + Timeline</td>\n",
       "      <td>-</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>macro avg</td>\n",
       "      <td>0.781126</td>\n",
       "      <td>0.767310</td>\n",
       "      <td>0.905882</td>\n",
       "      <td>0.883599</td>\n",
       "      <td>0.802880</td>\n",
       "      <td>0.800597</td>\n",
       "      <td>0.823566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Ensemble Stance + Timeline + Texts</td>\n",
       "      <td>-</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>macro avg</td>\n",
       "      <td>0.740980</td>\n",
       "      <td>0.642395</td>\n",
       "      <td>0.846643</td>\n",
       "      <td>0.841272</td>\n",
       "      <td>0.689304</td>\n",
       "      <td>0.513417</td>\n",
       "      <td>0.712335</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "metric                            text_col        vectorizer  \\\n",
       "target                                                         \n",
       "0                                   Stance                 -   \n",
       "1                                   Stance            tf-idf   \n",
       "2                                   Stance  bertabaporu-base   \n",
       "3                                   Stance                 -   \n",
       "4                                   Stance                 -   \n",
       "5                                    Texts                 -   \n",
       "6                                    Texts            tf-idf   \n",
       "7                                    Texts  bertabaporu-base   \n",
       "8                                    Texts                 -   \n",
       "9                                    Texts                 -   \n",
       "10                                   Texts                 -   \n",
       "11                                   Texts                 -   \n",
       "12                                   Texts                 -   \n",
       "13                                Timeline                 -   \n",
       "14                                Timeline            tf-idf   \n",
       "15                                Timeline  bertabaporu-base   \n",
       "16                                Timeline                 -   \n",
       "17                                Timeline                 -   \n",
       "18                                Timeline                 -   \n",
       "19                                Timeline                 -   \n",
       "20                                Timeline                 -   \n",
       "21               Ensemble Texts + Timeline                 -   \n",
       "22                 Ensemble Texts + Stance                 -   \n",
       "23              Ensemble Stance + Timeline                 -   \n",
       "24      Ensemble Stance + Timeline + Texts                 -   \n",
       "\n",
       "metric                     estimator      class  f1-score                      \\\n",
       "target                                             Church Bolsonaro   Hydrox.   \n",
       "0                              dummy  macro avg  0.361407  0.462857  0.334878   \n",
       "1                                xgb  macro avg  0.702021  0.595312  0.734366   \n",
       "2                                xgb  macro avg  0.853801  0.625289  0.830948   \n",
       "3                   bertabaporu-base  macro avg  0.866276  0.737297  0.848144   \n",
       "4                llama3:7b zero-shot  macro avg  0.729458  0.462857  0.638889   \n",
       "5                              dummy  macro avg  0.361407  0.462857  0.334878   \n",
       "6                                xgb  macro avg  0.596115  0.501220  0.603727   \n",
       "7                                xgb  macro avg  0.594754  0.495578  0.609524   \n",
       "8                   bertabaporu-base  macro avg  0.586611  0.462857  0.446504   \n",
       "9               bertabaporu-base (R)  macro avg  0.583417  0.462857  0.570531   \n",
       "10       llama3:7b zero-shot [5] (R)  macro avg  0.499052  0.296142  0.469796   \n",
       "11      llama3:7b zero-shot [10] (R)  macro avg  0.561274  0.328245  0.440347   \n",
       "12      llama3:7b zero-shot [15] (R)  macro avg  0.503966  0.285253  0.416946   \n",
       "13                             dummy  macro avg  0.361407  0.462857  0.334878   \n",
       "14                               xgb  macro avg  0.699122  0.728220  0.898944   \n",
       "15                               xgb  macro avg  0.661773  0.692262  0.776979   \n",
       "16                  bertabaporu-base  macro avg  0.652707  0.767310  0.809799   \n",
       "17              bertabaporu-base (R)  macro avg  0.701990  0.822060  0.872170   \n",
       "18       llama3:7b zero-shot [5] (R)  macro avg  0.605633  0.588752  0.639513   \n",
       "19      llama3:7b zero-shot [10] (R)  macro avg  0.563199  0.611771  0.609199   \n",
       "20      llama3:7b zero-shot [15] (R)  macro avg  0.598183  0.586106  0.611868   \n",
       "21                LogisticRegression  macro avg  0.698596  0.728220  0.898944   \n",
       "22                LogisticRegression  macro avg  0.820220  0.800537  0.811570   \n",
       "23                LogisticRegression  macro avg  0.781126  0.767310  0.905882   \n",
       "24                LogisticRegression  macro avg  0.740980  0.642395  0.846643   \n",
       "\n",
       "metric                                          \n",
       "target   Sinovac  Globo TV      Lula   overall  \n",
       "0       0.351759  0.372519  0.344578  0.371333  \n",
       "1       0.752640  0.665243  0.654412  0.683999  \n",
       "2       0.808036  0.781858  0.766993  0.777821  \n",
       "3       0.834984  0.860252  0.789802  0.822792  \n",
       "4       0.578779  0.770678  0.699381  0.646674  \n",
       "5       0.351759  0.372519  0.344578  0.371333  \n",
       "6       0.670805  0.545620  0.579427  0.582819  \n",
       "7       0.660542  0.534455  0.569597  0.577408  \n",
       "8       0.608972  0.507381  0.482520  0.515808  \n",
       "9       0.637369  0.586967  0.602167  0.573885  \n",
       "10      0.470381  0.490101  0.512954  0.456404  \n",
       "11      0.460580  0.494646  0.478244  0.460556  \n",
       "12      0.464074  0.475797  0.542401  0.448073  \n",
       "13      0.351759  0.372519  0.344578  0.371333  \n",
       "14      0.863813  0.598358  0.752710  0.756861  \n",
       "15      0.778471  0.585105  0.645518  0.690018  \n",
       "16      0.799052  0.576324  0.632407  0.706266  \n",
       "17      0.860531  0.597442  0.711676  0.760978  \n",
       "18      0.528509  0.560086  0.514680  0.572862  \n",
       "19      0.529703  0.507579  0.516021  0.556245  \n",
       "20      0.518743  0.515050  0.529726  0.559946  \n",
       "21      0.867509  0.586353  0.745550  0.754195  \n",
       "22      0.805406  0.867826  0.752925  0.809747  \n",
       "23      0.883599  0.802880  0.800597  0.823566  \n",
       "24      0.841272  0.689304  0.513417  0.712335  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_report.reset_index(drop=False, inplace=True)\n",
    "f1_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultiIndex([(  'text_col',          ''),\n",
       "            ('vectorizer',          ''),\n",
       "            ( 'estimator',          ''),\n",
       "            (     'class',          ''),\n",
       "            (  'f1-score',    'Church'),\n",
       "            (  'f1-score', 'Bolsonaro'),\n",
       "            (  'f1-score',   'Hydrox.'),\n",
       "            (  'f1-score',   'Sinovac'),\n",
       "            (  'f1-score',  'Globo TV'),\n",
       "            (  'f1-score',      'Lula'),\n",
       "            (  'f1-score',   'overall')],\n",
       "           names=['metric', 'target'])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_report.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['text_col',\n",
       " 'vectorizer',\n",
       " 'estimator',\n",
       " 'class',\n",
       " 'Church',\n",
       " 'Bolsonaro',\n",
       " 'Hydrox.',\n",
       " 'Sinovac',\n",
       " 'Globo TV',\n",
       " 'Lula',\n",
       " 'overall']"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_columns = [col[0] if col[1] == '' else col[1] for col in f1_report.columns]\n",
    "new_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_col</th>\n",
       "      <th>vectorizer</th>\n",
       "      <th>estimator</th>\n",
       "      <th>class</th>\n",
       "      <th>Church</th>\n",
       "      <th>Bolsonaro</th>\n",
       "      <th>Hydrox.</th>\n",
       "      <th>Sinovac</th>\n",
       "      <th>Globo TV</th>\n",
       "      <th>Lula</th>\n",
       "      <th>overall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Stance</td>\n",
       "      <td>-</td>\n",
       "      <td>dummy</td>\n",
       "      <td>macro avg</td>\n",
       "      <td>0.361407</td>\n",
       "      <td>0.462857</td>\n",
       "      <td>0.334878</td>\n",
       "      <td>0.351759</td>\n",
       "      <td>0.372519</td>\n",
       "      <td>0.344578</td>\n",
       "      <td>0.371333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Stance</td>\n",
       "      <td>tf-idf</td>\n",
       "      <td>xgb</td>\n",
       "      <td>macro avg</td>\n",
       "      <td>0.702021</td>\n",
       "      <td>0.595312</td>\n",
       "      <td>0.734366</td>\n",
       "      <td>0.752640</td>\n",
       "      <td>0.665243</td>\n",
       "      <td>0.654412</td>\n",
       "      <td>0.683999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Stance</td>\n",
       "      <td>bertabaporu-base</td>\n",
       "      <td>xgb</td>\n",
       "      <td>macro avg</td>\n",
       "      <td>0.853801</td>\n",
       "      <td>0.625289</td>\n",
       "      <td>0.830948</td>\n",
       "      <td>0.808036</td>\n",
       "      <td>0.781858</td>\n",
       "      <td>0.766993</td>\n",
       "      <td>0.777821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Stance</td>\n",
       "      <td>-</td>\n",
       "      <td>bertabaporu-base</td>\n",
       "      <td>macro avg</td>\n",
       "      <td>0.866276</td>\n",
       "      <td>0.737297</td>\n",
       "      <td>0.848144</td>\n",
       "      <td>0.834984</td>\n",
       "      <td>0.860252</td>\n",
       "      <td>0.789802</td>\n",
       "      <td>0.822792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Stance</td>\n",
       "      <td>-</td>\n",
       "      <td>llama3:7b zero-shot</td>\n",
       "      <td>macro avg</td>\n",
       "      <td>0.729458</td>\n",
       "      <td>0.462857</td>\n",
       "      <td>0.638889</td>\n",
       "      <td>0.578779</td>\n",
       "      <td>0.770678</td>\n",
       "      <td>0.699381</td>\n",
       "      <td>0.646674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Texts</td>\n",
       "      <td>-</td>\n",
       "      <td>dummy</td>\n",
       "      <td>macro avg</td>\n",
       "      <td>0.361407</td>\n",
       "      <td>0.462857</td>\n",
       "      <td>0.334878</td>\n",
       "      <td>0.351759</td>\n",
       "      <td>0.372519</td>\n",
       "      <td>0.344578</td>\n",
       "      <td>0.371333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Texts</td>\n",
       "      <td>tf-idf</td>\n",
       "      <td>xgb</td>\n",
       "      <td>macro avg</td>\n",
       "      <td>0.596115</td>\n",
       "      <td>0.501220</td>\n",
       "      <td>0.603727</td>\n",
       "      <td>0.670805</td>\n",
       "      <td>0.545620</td>\n",
       "      <td>0.579427</td>\n",
       "      <td>0.582819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Texts</td>\n",
       "      <td>bertabaporu-base</td>\n",
       "      <td>xgb</td>\n",
       "      <td>macro avg</td>\n",
       "      <td>0.594754</td>\n",
       "      <td>0.495578</td>\n",
       "      <td>0.609524</td>\n",
       "      <td>0.660542</td>\n",
       "      <td>0.534455</td>\n",
       "      <td>0.569597</td>\n",
       "      <td>0.577408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Texts</td>\n",
       "      <td>-</td>\n",
       "      <td>bertabaporu-base</td>\n",
       "      <td>macro avg</td>\n",
       "      <td>0.586611</td>\n",
       "      <td>0.462857</td>\n",
       "      <td>0.446504</td>\n",
       "      <td>0.608972</td>\n",
       "      <td>0.507381</td>\n",
       "      <td>0.482520</td>\n",
       "      <td>0.515808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Texts</td>\n",
       "      <td>-</td>\n",
       "      <td>bertabaporu-base (R)</td>\n",
       "      <td>macro avg</td>\n",
       "      <td>0.583417</td>\n",
       "      <td>0.462857</td>\n",
       "      <td>0.570531</td>\n",
       "      <td>0.637369</td>\n",
       "      <td>0.586967</td>\n",
       "      <td>0.602167</td>\n",
       "      <td>0.573885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Texts</td>\n",
       "      <td>-</td>\n",
       "      <td>llama3:7b zero-shot [5] (R)</td>\n",
       "      <td>macro avg</td>\n",
       "      <td>0.499052</td>\n",
       "      <td>0.296142</td>\n",
       "      <td>0.469796</td>\n",
       "      <td>0.470381</td>\n",
       "      <td>0.490101</td>\n",
       "      <td>0.512954</td>\n",
       "      <td>0.456404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Texts</td>\n",
       "      <td>-</td>\n",
       "      <td>llama3:7b zero-shot [10] (R)</td>\n",
       "      <td>macro avg</td>\n",
       "      <td>0.561274</td>\n",
       "      <td>0.328245</td>\n",
       "      <td>0.440347</td>\n",
       "      <td>0.460580</td>\n",
       "      <td>0.494646</td>\n",
       "      <td>0.478244</td>\n",
       "      <td>0.460556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Texts</td>\n",
       "      <td>-</td>\n",
       "      <td>llama3:7b zero-shot [15] (R)</td>\n",
       "      <td>macro avg</td>\n",
       "      <td>0.503966</td>\n",
       "      <td>0.285253</td>\n",
       "      <td>0.416946</td>\n",
       "      <td>0.464074</td>\n",
       "      <td>0.475797</td>\n",
       "      <td>0.542401</td>\n",
       "      <td>0.448073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Timeline</td>\n",
       "      <td>-</td>\n",
       "      <td>dummy</td>\n",
       "      <td>macro avg</td>\n",
       "      <td>0.361407</td>\n",
       "      <td>0.462857</td>\n",
       "      <td>0.334878</td>\n",
       "      <td>0.351759</td>\n",
       "      <td>0.372519</td>\n",
       "      <td>0.344578</td>\n",
       "      <td>0.371333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Timeline</td>\n",
       "      <td>tf-idf</td>\n",
       "      <td>xgb</td>\n",
       "      <td>macro avg</td>\n",
       "      <td>0.699122</td>\n",
       "      <td>0.728220</td>\n",
       "      <td>0.898944</td>\n",
       "      <td>0.863813</td>\n",
       "      <td>0.598358</td>\n",
       "      <td>0.752710</td>\n",
       "      <td>0.756861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Timeline</td>\n",
       "      <td>bertabaporu-base</td>\n",
       "      <td>xgb</td>\n",
       "      <td>macro avg</td>\n",
       "      <td>0.661773</td>\n",
       "      <td>0.692262</td>\n",
       "      <td>0.776979</td>\n",
       "      <td>0.778471</td>\n",
       "      <td>0.585105</td>\n",
       "      <td>0.645518</td>\n",
       "      <td>0.690018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Timeline</td>\n",
       "      <td>-</td>\n",
       "      <td>bertabaporu-base</td>\n",
       "      <td>macro avg</td>\n",
       "      <td>0.652707</td>\n",
       "      <td>0.767310</td>\n",
       "      <td>0.809799</td>\n",
       "      <td>0.799052</td>\n",
       "      <td>0.576324</td>\n",
       "      <td>0.632407</td>\n",
       "      <td>0.706266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Timeline</td>\n",
       "      <td>-</td>\n",
       "      <td>bertabaporu-base (R)</td>\n",
       "      <td>macro avg</td>\n",
       "      <td>0.701990</td>\n",
       "      <td>0.822060</td>\n",
       "      <td>0.872170</td>\n",
       "      <td>0.860531</td>\n",
       "      <td>0.597442</td>\n",
       "      <td>0.711676</td>\n",
       "      <td>0.760978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Timeline</td>\n",
       "      <td>-</td>\n",
       "      <td>llama3:7b zero-shot [5] (R)</td>\n",
       "      <td>macro avg</td>\n",
       "      <td>0.605633</td>\n",
       "      <td>0.588752</td>\n",
       "      <td>0.639513</td>\n",
       "      <td>0.528509</td>\n",
       "      <td>0.560086</td>\n",
       "      <td>0.514680</td>\n",
       "      <td>0.572862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Timeline</td>\n",
       "      <td>-</td>\n",
       "      <td>llama3:7b zero-shot [10] (R)</td>\n",
       "      <td>macro avg</td>\n",
       "      <td>0.563199</td>\n",
       "      <td>0.611771</td>\n",
       "      <td>0.609199</td>\n",
       "      <td>0.529703</td>\n",
       "      <td>0.507579</td>\n",
       "      <td>0.516021</td>\n",
       "      <td>0.556245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Timeline</td>\n",
       "      <td>-</td>\n",
       "      <td>llama3:7b zero-shot [15] (R)</td>\n",
       "      <td>macro avg</td>\n",
       "      <td>0.598183</td>\n",
       "      <td>0.586106</td>\n",
       "      <td>0.611868</td>\n",
       "      <td>0.518743</td>\n",
       "      <td>0.515050</td>\n",
       "      <td>0.529726</td>\n",
       "      <td>0.559946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Ensemble Texts + Timeline</td>\n",
       "      <td>-</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>macro avg</td>\n",
       "      <td>0.698596</td>\n",
       "      <td>0.728220</td>\n",
       "      <td>0.898944</td>\n",
       "      <td>0.867509</td>\n",
       "      <td>0.586353</td>\n",
       "      <td>0.745550</td>\n",
       "      <td>0.754195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Ensemble Texts + Stance</td>\n",
       "      <td>-</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>macro avg</td>\n",
       "      <td>0.820220</td>\n",
       "      <td>0.800537</td>\n",
       "      <td>0.811570</td>\n",
       "      <td>0.805406</td>\n",
       "      <td>0.867826</td>\n",
       "      <td>0.752925</td>\n",
       "      <td>0.809747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Ensemble Stance + Timeline</td>\n",
       "      <td>-</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>macro avg</td>\n",
       "      <td>0.781126</td>\n",
       "      <td>0.767310</td>\n",
       "      <td>0.905882</td>\n",
       "      <td>0.883599</td>\n",
       "      <td>0.802880</td>\n",
       "      <td>0.800597</td>\n",
       "      <td>0.823566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Ensemble Stance + Timeline + Texts</td>\n",
       "      <td>-</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>macro avg</td>\n",
       "      <td>0.740980</td>\n",
       "      <td>0.642395</td>\n",
       "      <td>0.846643</td>\n",
       "      <td>0.841272</td>\n",
       "      <td>0.689304</td>\n",
       "      <td>0.513417</td>\n",
       "      <td>0.712335</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              text_col        vectorizer  \\\n",
       "0                               Stance                 -   \n",
       "1                               Stance            tf-idf   \n",
       "2                               Stance  bertabaporu-base   \n",
       "3                               Stance                 -   \n",
       "4                               Stance                 -   \n",
       "5                                Texts                 -   \n",
       "6                                Texts            tf-idf   \n",
       "7                                Texts  bertabaporu-base   \n",
       "8                                Texts                 -   \n",
       "9                                Texts                 -   \n",
       "10                               Texts                 -   \n",
       "11                               Texts                 -   \n",
       "12                               Texts                 -   \n",
       "13                            Timeline                 -   \n",
       "14                            Timeline            tf-idf   \n",
       "15                            Timeline  bertabaporu-base   \n",
       "16                            Timeline                 -   \n",
       "17                            Timeline                 -   \n",
       "18                            Timeline                 -   \n",
       "19                            Timeline                 -   \n",
       "20                            Timeline                 -   \n",
       "21           Ensemble Texts + Timeline                 -   \n",
       "22             Ensemble Texts + Stance                 -   \n",
       "23          Ensemble Stance + Timeline                 -   \n",
       "24  Ensemble Stance + Timeline + Texts                 -   \n",
       "\n",
       "                       estimator      class    Church  Bolsonaro   Hydrox.  \\\n",
       "0                          dummy  macro avg  0.361407   0.462857  0.334878   \n",
       "1                            xgb  macro avg  0.702021   0.595312  0.734366   \n",
       "2                            xgb  macro avg  0.853801   0.625289  0.830948   \n",
       "3               bertabaporu-base  macro avg  0.866276   0.737297  0.848144   \n",
       "4            llama3:7b zero-shot  macro avg  0.729458   0.462857  0.638889   \n",
       "5                          dummy  macro avg  0.361407   0.462857  0.334878   \n",
       "6                            xgb  macro avg  0.596115   0.501220  0.603727   \n",
       "7                            xgb  macro avg  0.594754   0.495578  0.609524   \n",
       "8               bertabaporu-base  macro avg  0.586611   0.462857  0.446504   \n",
       "9           bertabaporu-base (R)  macro avg  0.583417   0.462857  0.570531   \n",
       "10   llama3:7b zero-shot [5] (R)  macro avg  0.499052   0.296142  0.469796   \n",
       "11  llama3:7b zero-shot [10] (R)  macro avg  0.561274   0.328245  0.440347   \n",
       "12  llama3:7b zero-shot [15] (R)  macro avg  0.503966   0.285253  0.416946   \n",
       "13                         dummy  macro avg  0.361407   0.462857  0.334878   \n",
       "14                           xgb  macro avg  0.699122   0.728220  0.898944   \n",
       "15                           xgb  macro avg  0.661773   0.692262  0.776979   \n",
       "16              bertabaporu-base  macro avg  0.652707   0.767310  0.809799   \n",
       "17          bertabaporu-base (R)  macro avg  0.701990   0.822060  0.872170   \n",
       "18   llama3:7b zero-shot [5] (R)  macro avg  0.605633   0.588752  0.639513   \n",
       "19  llama3:7b zero-shot [10] (R)  macro avg  0.563199   0.611771  0.609199   \n",
       "20  llama3:7b zero-shot [15] (R)  macro avg  0.598183   0.586106  0.611868   \n",
       "21            LogisticRegression  macro avg  0.698596   0.728220  0.898944   \n",
       "22            LogisticRegression  macro avg  0.820220   0.800537  0.811570   \n",
       "23            LogisticRegression  macro avg  0.781126   0.767310  0.905882   \n",
       "24            LogisticRegression  macro avg  0.740980   0.642395  0.846643   \n",
       "\n",
       "     Sinovac  Globo TV      Lula   overall  \n",
       "0   0.351759  0.372519  0.344578  0.371333  \n",
       "1   0.752640  0.665243  0.654412  0.683999  \n",
       "2   0.808036  0.781858  0.766993  0.777821  \n",
       "3   0.834984  0.860252  0.789802  0.822792  \n",
       "4   0.578779  0.770678  0.699381  0.646674  \n",
       "5   0.351759  0.372519  0.344578  0.371333  \n",
       "6   0.670805  0.545620  0.579427  0.582819  \n",
       "7   0.660542  0.534455  0.569597  0.577408  \n",
       "8   0.608972  0.507381  0.482520  0.515808  \n",
       "9   0.637369  0.586967  0.602167  0.573885  \n",
       "10  0.470381  0.490101  0.512954  0.456404  \n",
       "11  0.460580  0.494646  0.478244  0.460556  \n",
       "12  0.464074  0.475797  0.542401  0.448073  \n",
       "13  0.351759  0.372519  0.344578  0.371333  \n",
       "14  0.863813  0.598358  0.752710  0.756861  \n",
       "15  0.778471  0.585105  0.645518  0.690018  \n",
       "16  0.799052  0.576324  0.632407  0.706266  \n",
       "17  0.860531  0.597442  0.711676  0.760978  \n",
       "18  0.528509  0.560086  0.514680  0.572862  \n",
       "19  0.529703  0.507579  0.516021  0.556245  \n",
       "20  0.518743  0.515050  0.529726  0.559946  \n",
       "21  0.867509  0.586353  0.745550  0.754195  \n",
       "22  0.805406  0.867826  0.752925  0.809747  \n",
       "23  0.883599  0.802880  0.800597  0.823566  \n",
       "24  0.841272  0.689304  0.513417  0.712335  "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_report.columns = new_columns\n",
    "f1_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_col</th>\n",
       "      <th>vectorizer</th>\n",
       "      <th>estimator</th>\n",
       "      <th>Church</th>\n",
       "      <th>Bolsonaro</th>\n",
       "      <th>Hydrox.</th>\n",
       "      <th>Sinovac</th>\n",
       "      <th>Globo TV</th>\n",
       "      <th>Lula</th>\n",
       "      <th>overall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Stance</td>\n",
       "      <td>-</td>\n",
       "      <td>dummy</td>\n",
       "      <td>0.361407</td>\n",
       "      <td>0.462857</td>\n",
       "      <td>0.334878</td>\n",
       "      <td>0.351759</td>\n",
       "      <td>0.372519</td>\n",
       "      <td>0.344578</td>\n",
       "      <td>0.371333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Stance</td>\n",
       "      <td>tf-idf</td>\n",
       "      <td>xgb</td>\n",
       "      <td>0.702021</td>\n",
       "      <td>0.595312</td>\n",
       "      <td>0.734366</td>\n",
       "      <td>0.752640</td>\n",
       "      <td>0.665243</td>\n",
       "      <td>0.654412</td>\n",
       "      <td>0.683999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Stance</td>\n",
       "      <td>bertabaporu-base</td>\n",
       "      <td>xgb</td>\n",
       "      <td>0.853801</td>\n",
       "      <td>0.625289</td>\n",
       "      <td>0.830948</td>\n",
       "      <td>0.808036</td>\n",
       "      <td>0.781858</td>\n",
       "      <td>0.766993</td>\n",
       "      <td>0.777821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Stance</td>\n",
       "      <td>-</td>\n",
       "      <td>bertabaporu-base</td>\n",
       "      <td>0.866276</td>\n",
       "      <td>0.737297</td>\n",
       "      <td>0.848144</td>\n",
       "      <td>0.834984</td>\n",
       "      <td>0.860252</td>\n",
       "      <td>0.789802</td>\n",
       "      <td>0.822792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Stance</td>\n",
       "      <td>-</td>\n",
       "      <td>llama3:7b zero-shot</td>\n",
       "      <td>0.729458</td>\n",
       "      <td>0.462857</td>\n",
       "      <td>0.638889</td>\n",
       "      <td>0.578779</td>\n",
       "      <td>0.770678</td>\n",
       "      <td>0.699381</td>\n",
       "      <td>0.646674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Texts</td>\n",
       "      <td>-</td>\n",
       "      <td>dummy</td>\n",
       "      <td>0.361407</td>\n",
       "      <td>0.462857</td>\n",
       "      <td>0.334878</td>\n",
       "      <td>0.351759</td>\n",
       "      <td>0.372519</td>\n",
       "      <td>0.344578</td>\n",
       "      <td>0.371333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Texts</td>\n",
       "      <td>tf-idf</td>\n",
       "      <td>xgb</td>\n",
       "      <td>0.596115</td>\n",
       "      <td>0.501220</td>\n",
       "      <td>0.603727</td>\n",
       "      <td>0.670805</td>\n",
       "      <td>0.545620</td>\n",
       "      <td>0.579427</td>\n",
       "      <td>0.582819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Texts</td>\n",
       "      <td>bertabaporu-base</td>\n",
       "      <td>xgb</td>\n",
       "      <td>0.594754</td>\n",
       "      <td>0.495578</td>\n",
       "      <td>0.609524</td>\n",
       "      <td>0.660542</td>\n",
       "      <td>0.534455</td>\n",
       "      <td>0.569597</td>\n",
       "      <td>0.577408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Texts</td>\n",
       "      <td>-</td>\n",
       "      <td>bertabaporu-base</td>\n",
       "      <td>0.586611</td>\n",
       "      <td>0.462857</td>\n",
       "      <td>0.446504</td>\n",
       "      <td>0.608972</td>\n",
       "      <td>0.507381</td>\n",
       "      <td>0.482520</td>\n",
       "      <td>0.515808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Texts</td>\n",
       "      <td>-</td>\n",
       "      <td>bertabaporu-base (R)</td>\n",
       "      <td>0.583417</td>\n",
       "      <td>0.462857</td>\n",
       "      <td>0.570531</td>\n",
       "      <td>0.637369</td>\n",
       "      <td>0.586967</td>\n",
       "      <td>0.602167</td>\n",
       "      <td>0.573885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Texts</td>\n",
       "      <td>-</td>\n",
       "      <td>llama3:7b zero-shot [5] (R)</td>\n",
       "      <td>0.499052</td>\n",
       "      <td>0.296142</td>\n",
       "      <td>0.469796</td>\n",
       "      <td>0.470381</td>\n",
       "      <td>0.490101</td>\n",
       "      <td>0.512954</td>\n",
       "      <td>0.456404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Texts</td>\n",
       "      <td>-</td>\n",
       "      <td>llama3:7b zero-shot [10] (R)</td>\n",
       "      <td>0.561274</td>\n",
       "      <td>0.328245</td>\n",
       "      <td>0.440347</td>\n",
       "      <td>0.460580</td>\n",
       "      <td>0.494646</td>\n",
       "      <td>0.478244</td>\n",
       "      <td>0.460556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Texts</td>\n",
       "      <td>-</td>\n",
       "      <td>llama3:7b zero-shot [15] (R)</td>\n",
       "      <td>0.503966</td>\n",
       "      <td>0.285253</td>\n",
       "      <td>0.416946</td>\n",
       "      <td>0.464074</td>\n",
       "      <td>0.475797</td>\n",
       "      <td>0.542401</td>\n",
       "      <td>0.448073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Timeline</td>\n",
       "      <td>-</td>\n",
       "      <td>dummy</td>\n",
       "      <td>0.361407</td>\n",
       "      <td>0.462857</td>\n",
       "      <td>0.334878</td>\n",
       "      <td>0.351759</td>\n",
       "      <td>0.372519</td>\n",
       "      <td>0.344578</td>\n",
       "      <td>0.371333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Timeline</td>\n",
       "      <td>tf-idf</td>\n",
       "      <td>xgb</td>\n",
       "      <td>0.699122</td>\n",
       "      <td>0.728220</td>\n",
       "      <td>0.898944</td>\n",
       "      <td>0.863813</td>\n",
       "      <td>0.598358</td>\n",
       "      <td>0.752710</td>\n",
       "      <td>0.756861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Timeline</td>\n",
       "      <td>bertabaporu-base</td>\n",
       "      <td>xgb</td>\n",
       "      <td>0.661773</td>\n",
       "      <td>0.692262</td>\n",
       "      <td>0.776979</td>\n",
       "      <td>0.778471</td>\n",
       "      <td>0.585105</td>\n",
       "      <td>0.645518</td>\n",
       "      <td>0.690018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Timeline</td>\n",
       "      <td>-</td>\n",
       "      <td>bertabaporu-base</td>\n",
       "      <td>0.652707</td>\n",
       "      <td>0.767310</td>\n",
       "      <td>0.809799</td>\n",
       "      <td>0.799052</td>\n",
       "      <td>0.576324</td>\n",
       "      <td>0.632407</td>\n",
       "      <td>0.706266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Timeline</td>\n",
       "      <td>-</td>\n",
       "      <td>bertabaporu-base (R)</td>\n",
       "      <td>0.701990</td>\n",
       "      <td>0.822060</td>\n",
       "      <td>0.872170</td>\n",
       "      <td>0.860531</td>\n",
       "      <td>0.597442</td>\n",
       "      <td>0.711676</td>\n",
       "      <td>0.760978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Timeline</td>\n",
       "      <td>-</td>\n",
       "      <td>llama3:7b zero-shot [5] (R)</td>\n",
       "      <td>0.605633</td>\n",
       "      <td>0.588752</td>\n",
       "      <td>0.639513</td>\n",
       "      <td>0.528509</td>\n",
       "      <td>0.560086</td>\n",
       "      <td>0.514680</td>\n",
       "      <td>0.572862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Timeline</td>\n",
       "      <td>-</td>\n",
       "      <td>llama3:7b zero-shot [10] (R)</td>\n",
       "      <td>0.563199</td>\n",
       "      <td>0.611771</td>\n",
       "      <td>0.609199</td>\n",
       "      <td>0.529703</td>\n",
       "      <td>0.507579</td>\n",
       "      <td>0.516021</td>\n",
       "      <td>0.556245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Timeline</td>\n",
       "      <td>-</td>\n",
       "      <td>llama3:7b zero-shot [15] (R)</td>\n",
       "      <td>0.598183</td>\n",
       "      <td>0.586106</td>\n",
       "      <td>0.611868</td>\n",
       "      <td>0.518743</td>\n",
       "      <td>0.515050</td>\n",
       "      <td>0.529726</td>\n",
       "      <td>0.559946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Ensemble Texts + Timeline</td>\n",
       "      <td>-</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.698596</td>\n",
       "      <td>0.728220</td>\n",
       "      <td>0.898944</td>\n",
       "      <td>0.867509</td>\n",
       "      <td>0.586353</td>\n",
       "      <td>0.745550</td>\n",
       "      <td>0.754195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Ensemble Texts + Stance</td>\n",
       "      <td>-</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.820220</td>\n",
       "      <td>0.800537</td>\n",
       "      <td>0.811570</td>\n",
       "      <td>0.805406</td>\n",
       "      <td>0.867826</td>\n",
       "      <td>0.752925</td>\n",
       "      <td>0.809747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Ensemble Stance + Timeline</td>\n",
       "      <td>-</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.781126</td>\n",
       "      <td>0.767310</td>\n",
       "      <td>0.905882</td>\n",
       "      <td>0.883599</td>\n",
       "      <td>0.802880</td>\n",
       "      <td>0.800597</td>\n",
       "      <td>0.823566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Ensemble Stance + Timeline + Texts</td>\n",
       "      <td>-</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.740980</td>\n",
       "      <td>0.642395</td>\n",
       "      <td>0.846643</td>\n",
       "      <td>0.841272</td>\n",
       "      <td>0.689304</td>\n",
       "      <td>0.513417</td>\n",
       "      <td>0.712335</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              text_col        vectorizer  \\\n",
       "0                               Stance                 -   \n",
       "1                               Stance            tf-idf   \n",
       "2                               Stance  bertabaporu-base   \n",
       "3                               Stance                 -   \n",
       "4                               Stance                 -   \n",
       "5                                Texts                 -   \n",
       "6                                Texts            tf-idf   \n",
       "7                                Texts  bertabaporu-base   \n",
       "8                                Texts                 -   \n",
       "9                                Texts                 -   \n",
       "10                               Texts                 -   \n",
       "11                               Texts                 -   \n",
       "12                               Texts                 -   \n",
       "13                            Timeline                 -   \n",
       "14                            Timeline            tf-idf   \n",
       "15                            Timeline  bertabaporu-base   \n",
       "16                            Timeline                 -   \n",
       "17                            Timeline                 -   \n",
       "18                            Timeline                 -   \n",
       "19                            Timeline                 -   \n",
       "20                            Timeline                 -   \n",
       "21           Ensemble Texts + Timeline                 -   \n",
       "22             Ensemble Texts + Stance                 -   \n",
       "23          Ensemble Stance + Timeline                 -   \n",
       "24  Ensemble Stance + Timeline + Texts                 -   \n",
       "\n",
       "                       estimator    Church  Bolsonaro   Hydrox.   Sinovac  \\\n",
       "0                          dummy  0.361407   0.462857  0.334878  0.351759   \n",
       "1                            xgb  0.702021   0.595312  0.734366  0.752640   \n",
       "2                            xgb  0.853801   0.625289  0.830948  0.808036   \n",
       "3               bertabaporu-base  0.866276   0.737297  0.848144  0.834984   \n",
       "4            llama3:7b zero-shot  0.729458   0.462857  0.638889  0.578779   \n",
       "5                          dummy  0.361407   0.462857  0.334878  0.351759   \n",
       "6                            xgb  0.596115   0.501220  0.603727  0.670805   \n",
       "7                            xgb  0.594754   0.495578  0.609524  0.660542   \n",
       "8               bertabaporu-base  0.586611   0.462857  0.446504  0.608972   \n",
       "9           bertabaporu-base (R)  0.583417   0.462857  0.570531  0.637369   \n",
       "10   llama3:7b zero-shot [5] (R)  0.499052   0.296142  0.469796  0.470381   \n",
       "11  llama3:7b zero-shot [10] (R)  0.561274   0.328245  0.440347  0.460580   \n",
       "12  llama3:7b zero-shot [15] (R)  0.503966   0.285253  0.416946  0.464074   \n",
       "13                         dummy  0.361407   0.462857  0.334878  0.351759   \n",
       "14                           xgb  0.699122   0.728220  0.898944  0.863813   \n",
       "15                           xgb  0.661773   0.692262  0.776979  0.778471   \n",
       "16              bertabaporu-base  0.652707   0.767310  0.809799  0.799052   \n",
       "17          bertabaporu-base (R)  0.701990   0.822060  0.872170  0.860531   \n",
       "18   llama3:7b zero-shot [5] (R)  0.605633   0.588752  0.639513  0.528509   \n",
       "19  llama3:7b zero-shot [10] (R)  0.563199   0.611771  0.609199  0.529703   \n",
       "20  llama3:7b zero-shot [15] (R)  0.598183   0.586106  0.611868  0.518743   \n",
       "21            LogisticRegression  0.698596   0.728220  0.898944  0.867509   \n",
       "22            LogisticRegression  0.820220   0.800537  0.811570  0.805406   \n",
       "23            LogisticRegression  0.781126   0.767310  0.905882  0.883599   \n",
       "24            LogisticRegression  0.740980   0.642395  0.846643  0.841272   \n",
       "\n",
       "    Globo TV      Lula   overall  \n",
       "0   0.372519  0.344578  0.371333  \n",
       "1   0.665243  0.654412  0.683999  \n",
       "2   0.781858  0.766993  0.777821  \n",
       "3   0.860252  0.789802  0.822792  \n",
       "4   0.770678  0.699381  0.646674  \n",
       "5   0.372519  0.344578  0.371333  \n",
       "6   0.545620  0.579427  0.582819  \n",
       "7   0.534455  0.569597  0.577408  \n",
       "8   0.507381  0.482520  0.515808  \n",
       "9   0.586967  0.602167  0.573885  \n",
       "10  0.490101  0.512954  0.456404  \n",
       "11  0.494646  0.478244  0.460556  \n",
       "12  0.475797  0.542401  0.448073  \n",
       "13  0.372519  0.344578  0.371333  \n",
       "14  0.598358  0.752710  0.756861  \n",
       "15  0.585105  0.645518  0.690018  \n",
       "16  0.576324  0.632407  0.706266  \n",
       "17  0.597442  0.711676  0.760978  \n",
       "18  0.560086  0.514680  0.572862  \n",
       "19  0.507579  0.516021  0.556245  \n",
       "20  0.515050  0.529726  0.559946  \n",
       "21  0.586353  0.745550  0.754195  \n",
       "22  0.867826  0.752925  0.809747  \n",
       "23  0.802880  0.800597  0.823566  \n",
       "24  0.689304  0.513417  0.712335  "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_report.drop(['class'],axis = 1, inplace=True)\n",
    "f1_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_col</th>\n",
       "      <th>classifier</th>\n",
       "      <th>Church</th>\n",
       "      <th>Bolsonaro</th>\n",
       "      <th>Hydrox.</th>\n",
       "      <th>Sinovac</th>\n",
       "      <th>Globo TV</th>\n",
       "      <th>Lula</th>\n",
       "      <th>overall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Stance</td>\n",
       "      <td>dummy</td>\n",
       "      <td>0.361407</td>\n",
       "      <td>0.462857</td>\n",
       "      <td>0.334878</td>\n",
       "      <td>0.351759</td>\n",
       "      <td>0.372519</td>\n",
       "      <td>0.344578</td>\n",
       "      <td>0.371333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Stance</td>\n",
       "      <td>tf-idf + xgb</td>\n",
       "      <td>0.702021</td>\n",
       "      <td>0.595312</td>\n",
       "      <td>0.734366</td>\n",
       "      <td>0.752640</td>\n",
       "      <td>0.665243</td>\n",
       "      <td>0.654412</td>\n",
       "      <td>0.683999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Stance</td>\n",
       "      <td>bertabaporu-base + xgb</td>\n",
       "      <td>0.853801</td>\n",
       "      <td>0.625289</td>\n",
       "      <td>0.830948</td>\n",
       "      <td>0.808036</td>\n",
       "      <td>0.781858</td>\n",
       "      <td>0.766993</td>\n",
       "      <td>0.777821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Stance</td>\n",
       "      <td>bertabaporu-base</td>\n",
       "      <td>0.866276</td>\n",
       "      <td>0.737297</td>\n",
       "      <td>0.848144</td>\n",
       "      <td>0.834984</td>\n",
       "      <td>0.860252</td>\n",
       "      <td>0.789802</td>\n",
       "      <td>0.822792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Stance</td>\n",
       "      <td>llama3:7b zero-shot</td>\n",
       "      <td>0.729458</td>\n",
       "      <td>0.462857</td>\n",
       "      <td>0.638889</td>\n",
       "      <td>0.578779</td>\n",
       "      <td>0.770678</td>\n",
       "      <td>0.699381</td>\n",
       "      <td>0.646674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Texts</td>\n",
       "      <td>dummy</td>\n",
       "      <td>0.361407</td>\n",
       "      <td>0.462857</td>\n",
       "      <td>0.334878</td>\n",
       "      <td>0.351759</td>\n",
       "      <td>0.372519</td>\n",
       "      <td>0.344578</td>\n",
       "      <td>0.371333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Texts</td>\n",
       "      <td>tf-idf + xgb</td>\n",
       "      <td>0.596115</td>\n",
       "      <td>0.501220</td>\n",
       "      <td>0.603727</td>\n",
       "      <td>0.670805</td>\n",
       "      <td>0.545620</td>\n",
       "      <td>0.579427</td>\n",
       "      <td>0.582819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Texts</td>\n",
       "      <td>bertabaporu-base + xgb</td>\n",
       "      <td>0.594754</td>\n",
       "      <td>0.495578</td>\n",
       "      <td>0.609524</td>\n",
       "      <td>0.660542</td>\n",
       "      <td>0.534455</td>\n",
       "      <td>0.569597</td>\n",
       "      <td>0.577408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Texts</td>\n",
       "      <td>bertabaporu-base</td>\n",
       "      <td>0.586611</td>\n",
       "      <td>0.462857</td>\n",
       "      <td>0.446504</td>\n",
       "      <td>0.608972</td>\n",
       "      <td>0.507381</td>\n",
       "      <td>0.482520</td>\n",
       "      <td>0.515808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Texts</td>\n",
       "      <td>bertabaporu-base (R)</td>\n",
       "      <td>0.583417</td>\n",
       "      <td>0.462857</td>\n",
       "      <td>0.570531</td>\n",
       "      <td>0.637369</td>\n",
       "      <td>0.586967</td>\n",
       "      <td>0.602167</td>\n",
       "      <td>0.573885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Texts</td>\n",
       "      <td>llama3:7b zero-shot [5] (R)</td>\n",
       "      <td>0.499052</td>\n",
       "      <td>0.296142</td>\n",
       "      <td>0.469796</td>\n",
       "      <td>0.470381</td>\n",
       "      <td>0.490101</td>\n",
       "      <td>0.512954</td>\n",
       "      <td>0.456404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Texts</td>\n",
       "      <td>llama3:7b zero-shot [10] (R)</td>\n",
       "      <td>0.561274</td>\n",
       "      <td>0.328245</td>\n",
       "      <td>0.440347</td>\n",
       "      <td>0.460580</td>\n",
       "      <td>0.494646</td>\n",
       "      <td>0.478244</td>\n",
       "      <td>0.460556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Texts</td>\n",
       "      <td>llama3:7b zero-shot [15] (R)</td>\n",
       "      <td>0.503966</td>\n",
       "      <td>0.285253</td>\n",
       "      <td>0.416946</td>\n",
       "      <td>0.464074</td>\n",
       "      <td>0.475797</td>\n",
       "      <td>0.542401</td>\n",
       "      <td>0.448073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Timeline</td>\n",
       "      <td>dummy</td>\n",
       "      <td>0.361407</td>\n",
       "      <td>0.462857</td>\n",
       "      <td>0.334878</td>\n",
       "      <td>0.351759</td>\n",
       "      <td>0.372519</td>\n",
       "      <td>0.344578</td>\n",
       "      <td>0.371333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Timeline</td>\n",
       "      <td>tf-idf + xgb</td>\n",
       "      <td>0.699122</td>\n",
       "      <td>0.728220</td>\n",
       "      <td>0.898944</td>\n",
       "      <td>0.863813</td>\n",
       "      <td>0.598358</td>\n",
       "      <td>0.752710</td>\n",
       "      <td>0.756861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Timeline</td>\n",
       "      <td>bertabaporu-base + xgb</td>\n",
       "      <td>0.661773</td>\n",
       "      <td>0.692262</td>\n",
       "      <td>0.776979</td>\n",
       "      <td>0.778471</td>\n",
       "      <td>0.585105</td>\n",
       "      <td>0.645518</td>\n",
       "      <td>0.690018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Timeline</td>\n",
       "      <td>bertabaporu-base</td>\n",
       "      <td>0.652707</td>\n",
       "      <td>0.767310</td>\n",
       "      <td>0.809799</td>\n",
       "      <td>0.799052</td>\n",
       "      <td>0.576324</td>\n",
       "      <td>0.632407</td>\n",
       "      <td>0.706266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Timeline</td>\n",
       "      <td>bertabaporu-base (R)</td>\n",
       "      <td>0.701990</td>\n",
       "      <td>0.822060</td>\n",
       "      <td>0.872170</td>\n",
       "      <td>0.860531</td>\n",
       "      <td>0.597442</td>\n",
       "      <td>0.711676</td>\n",
       "      <td>0.760978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Timeline</td>\n",
       "      <td>llama3:7b zero-shot [5] (R)</td>\n",
       "      <td>0.605633</td>\n",
       "      <td>0.588752</td>\n",
       "      <td>0.639513</td>\n",
       "      <td>0.528509</td>\n",
       "      <td>0.560086</td>\n",
       "      <td>0.514680</td>\n",
       "      <td>0.572862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Timeline</td>\n",
       "      <td>llama3:7b zero-shot [10] (R)</td>\n",
       "      <td>0.563199</td>\n",
       "      <td>0.611771</td>\n",
       "      <td>0.609199</td>\n",
       "      <td>0.529703</td>\n",
       "      <td>0.507579</td>\n",
       "      <td>0.516021</td>\n",
       "      <td>0.556245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Timeline</td>\n",
       "      <td>llama3:7b zero-shot [15] (R)</td>\n",
       "      <td>0.598183</td>\n",
       "      <td>0.586106</td>\n",
       "      <td>0.611868</td>\n",
       "      <td>0.518743</td>\n",
       "      <td>0.515050</td>\n",
       "      <td>0.529726</td>\n",
       "      <td>0.559946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Ensemble Texts + Timeline</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.698596</td>\n",
       "      <td>0.728220</td>\n",
       "      <td>0.898944</td>\n",
       "      <td>0.867509</td>\n",
       "      <td>0.586353</td>\n",
       "      <td>0.745550</td>\n",
       "      <td>0.754195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Ensemble Texts + Stance</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.820220</td>\n",
       "      <td>0.800537</td>\n",
       "      <td>0.811570</td>\n",
       "      <td>0.805406</td>\n",
       "      <td>0.867826</td>\n",
       "      <td>0.752925</td>\n",
       "      <td>0.809747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Ensemble Stance + Timeline</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.781126</td>\n",
       "      <td>0.767310</td>\n",
       "      <td>0.905882</td>\n",
       "      <td>0.883599</td>\n",
       "      <td>0.802880</td>\n",
       "      <td>0.800597</td>\n",
       "      <td>0.823566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Ensemble Stance + Timeline + Texts</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.740980</td>\n",
       "      <td>0.642395</td>\n",
       "      <td>0.846643</td>\n",
       "      <td>0.841272</td>\n",
       "      <td>0.689304</td>\n",
       "      <td>0.513417</td>\n",
       "      <td>0.712335</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              text_col                    classifier  \\\n",
       "0                               Stance                         dummy   \n",
       "1                               Stance                  tf-idf + xgb   \n",
       "2                               Stance        bertabaporu-base + xgb   \n",
       "3                               Stance              bertabaporu-base   \n",
       "4                               Stance           llama3:7b zero-shot   \n",
       "5                                Texts                         dummy   \n",
       "6                                Texts                  tf-idf + xgb   \n",
       "7                                Texts        bertabaporu-base + xgb   \n",
       "8                                Texts              bertabaporu-base   \n",
       "9                                Texts          bertabaporu-base (R)   \n",
       "10                               Texts   llama3:7b zero-shot [5] (R)   \n",
       "11                               Texts  llama3:7b zero-shot [10] (R)   \n",
       "12                               Texts  llama3:7b zero-shot [15] (R)   \n",
       "13                            Timeline                         dummy   \n",
       "14                            Timeline                  tf-idf + xgb   \n",
       "15                            Timeline        bertabaporu-base + xgb   \n",
       "16                            Timeline              bertabaporu-base   \n",
       "17                            Timeline          bertabaporu-base (R)   \n",
       "18                            Timeline   llama3:7b zero-shot [5] (R)   \n",
       "19                            Timeline  llama3:7b zero-shot [10] (R)   \n",
       "20                            Timeline  llama3:7b zero-shot [15] (R)   \n",
       "21           Ensemble Texts + Timeline            LogisticRegression   \n",
       "22             Ensemble Texts + Stance            LogisticRegression   \n",
       "23          Ensemble Stance + Timeline            LogisticRegression   \n",
       "24  Ensemble Stance + Timeline + Texts            LogisticRegression   \n",
       "\n",
       "      Church  Bolsonaro   Hydrox.   Sinovac  Globo TV      Lula   overall  \n",
       "0   0.361407   0.462857  0.334878  0.351759  0.372519  0.344578  0.371333  \n",
       "1   0.702021   0.595312  0.734366  0.752640  0.665243  0.654412  0.683999  \n",
       "2   0.853801   0.625289  0.830948  0.808036  0.781858  0.766993  0.777821  \n",
       "3   0.866276   0.737297  0.848144  0.834984  0.860252  0.789802  0.822792  \n",
       "4   0.729458   0.462857  0.638889  0.578779  0.770678  0.699381  0.646674  \n",
       "5   0.361407   0.462857  0.334878  0.351759  0.372519  0.344578  0.371333  \n",
       "6   0.596115   0.501220  0.603727  0.670805  0.545620  0.579427  0.582819  \n",
       "7   0.594754   0.495578  0.609524  0.660542  0.534455  0.569597  0.577408  \n",
       "8   0.586611   0.462857  0.446504  0.608972  0.507381  0.482520  0.515808  \n",
       "9   0.583417   0.462857  0.570531  0.637369  0.586967  0.602167  0.573885  \n",
       "10  0.499052   0.296142  0.469796  0.470381  0.490101  0.512954  0.456404  \n",
       "11  0.561274   0.328245  0.440347  0.460580  0.494646  0.478244  0.460556  \n",
       "12  0.503966   0.285253  0.416946  0.464074  0.475797  0.542401  0.448073  \n",
       "13  0.361407   0.462857  0.334878  0.351759  0.372519  0.344578  0.371333  \n",
       "14  0.699122   0.728220  0.898944  0.863813  0.598358  0.752710  0.756861  \n",
       "15  0.661773   0.692262  0.776979  0.778471  0.585105  0.645518  0.690018  \n",
       "16  0.652707   0.767310  0.809799  0.799052  0.576324  0.632407  0.706266  \n",
       "17  0.701990   0.822060  0.872170  0.860531  0.597442  0.711676  0.760978  \n",
       "18  0.605633   0.588752  0.639513  0.528509  0.560086  0.514680  0.572862  \n",
       "19  0.563199   0.611771  0.609199  0.529703  0.507579  0.516021  0.556245  \n",
       "20  0.598183   0.586106  0.611868  0.518743  0.515050  0.529726  0.559946  \n",
       "21  0.698596   0.728220  0.898944  0.867509  0.586353  0.745550  0.754195  \n",
       "22  0.820220   0.800537  0.811570  0.805406  0.867826  0.752925  0.809747  \n",
       "23  0.781126   0.767310  0.905882  0.883599  0.802880  0.800597  0.823566  \n",
       "24  0.740980   0.642395  0.846643  0.841272  0.689304  0.513417  0.712335  "
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_report.insert(\n",
    "    1, \n",
    "    \"classifier\", \n",
    "    f1_report.apply(\n",
    "        lambda x: f\"{x['vectorizer']} + {x['estimator']}\" if x['vectorizer'] != '-' else x['estimator'],\n",
    "        axis = 1\n",
    "        ).to_list()\n",
    "\n",
    ")\n",
    "f1_report.drop(['estimator', 'vectorizer'],axis =1, inplace = True)\n",
    "f1_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input</th>\n",
       "      <th>classifier</th>\n",
       "      <th>Church</th>\n",
       "      <th>Bolsonaro</th>\n",
       "      <th>Hydrox.</th>\n",
       "      <th>Sinovac</th>\n",
       "      <th>Globo TV</th>\n",
       "      <th>Lula</th>\n",
       "      <th>overall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Stance</td>\n",
       "      <td>dummy</td>\n",
       "      <td>0.361407</td>\n",
       "      <td>0.462857</td>\n",
       "      <td>0.334878</td>\n",
       "      <td>0.351759</td>\n",
       "      <td>0.372519</td>\n",
       "      <td>0.344578</td>\n",
       "      <td>0.371333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Stance</td>\n",
       "      <td>tf-idf + xgb</td>\n",
       "      <td>0.702021</td>\n",
       "      <td>0.595312</td>\n",
       "      <td>0.734366</td>\n",
       "      <td>0.752640</td>\n",
       "      <td>0.665243</td>\n",
       "      <td>0.654412</td>\n",
       "      <td>0.683999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Stance</td>\n",
       "      <td>bertabaporu-base + xgb</td>\n",
       "      <td>0.853801</td>\n",
       "      <td>0.625289</td>\n",
       "      <td>0.830948</td>\n",
       "      <td>0.808036</td>\n",
       "      <td>0.781858</td>\n",
       "      <td>0.766993</td>\n",
       "      <td>0.777821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Stance</td>\n",
       "      <td>bertabaporu-base</td>\n",
       "      <td>0.866276</td>\n",
       "      <td>0.737297</td>\n",
       "      <td>0.848144</td>\n",
       "      <td>0.834984</td>\n",
       "      <td>0.860252</td>\n",
       "      <td>0.789802</td>\n",
       "      <td>0.822792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Stance</td>\n",
       "      <td>llama3:7b zero-shot</td>\n",
       "      <td>0.729458</td>\n",
       "      <td>0.462857</td>\n",
       "      <td>0.638889</td>\n",
       "      <td>0.578779</td>\n",
       "      <td>0.770678</td>\n",
       "      <td>0.699381</td>\n",
       "      <td>0.646674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Texts</td>\n",
       "      <td>dummy</td>\n",
       "      <td>0.361407</td>\n",
       "      <td>0.462857</td>\n",
       "      <td>0.334878</td>\n",
       "      <td>0.351759</td>\n",
       "      <td>0.372519</td>\n",
       "      <td>0.344578</td>\n",
       "      <td>0.371333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Texts</td>\n",
       "      <td>tf-idf + xgb</td>\n",
       "      <td>0.596115</td>\n",
       "      <td>0.501220</td>\n",
       "      <td>0.603727</td>\n",
       "      <td>0.670805</td>\n",
       "      <td>0.545620</td>\n",
       "      <td>0.579427</td>\n",
       "      <td>0.582819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Texts</td>\n",
       "      <td>bertabaporu-base + xgb</td>\n",
       "      <td>0.594754</td>\n",
       "      <td>0.495578</td>\n",
       "      <td>0.609524</td>\n",
       "      <td>0.660542</td>\n",
       "      <td>0.534455</td>\n",
       "      <td>0.569597</td>\n",
       "      <td>0.577408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Texts</td>\n",
       "      <td>bertabaporu-base</td>\n",
       "      <td>0.586611</td>\n",
       "      <td>0.462857</td>\n",
       "      <td>0.446504</td>\n",
       "      <td>0.608972</td>\n",
       "      <td>0.507381</td>\n",
       "      <td>0.482520</td>\n",
       "      <td>0.515808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Texts</td>\n",
       "      <td>bertabaporu-base (R)</td>\n",
       "      <td>0.583417</td>\n",
       "      <td>0.462857</td>\n",
       "      <td>0.570531</td>\n",
       "      <td>0.637369</td>\n",
       "      <td>0.586967</td>\n",
       "      <td>0.602167</td>\n",
       "      <td>0.573885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Texts</td>\n",
       "      <td>llama3:7b zero-shot [5] (R)</td>\n",
       "      <td>0.499052</td>\n",
       "      <td>0.296142</td>\n",
       "      <td>0.469796</td>\n",
       "      <td>0.470381</td>\n",
       "      <td>0.490101</td>\n",
       "      <td>0.512954</td>\n",
       "      <td>0.456404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Texts</td>\n",
       "      <td>llama3:7b zero-shot [10] (R)</td>\n",
       "      <td>0.561274</td>\n",
       "      <td>0.328245</td>\n",
       "      <td>0.440347</td>\n",
       "      <td>0.460580</td>\n",
       "      <td>0.494646</td>\n",
       "      <td>0.478244</td>\n",
       "      <td>0.460556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Texts</td>\n",
       "      <td>llama3:7b zero-shot [15] (R)</td>\n",
       "      <td>0.503966</td>\n",
       "      <td>0.285253</td>\n",
       "      <td>0.416946</td>\n",
       "      <td>0.464074</td>\n",
       "      <td>0.475797</td>\n",
       "      <td>0.542401</td>\n",
       "      <td>0.448073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Timeline</td>\n",
       "      <td>dummy</td>\n",
       "      <td>0.361407</td>\n",
       "      <td>0.462857</td>\n",
       "      <td>0.334878</td>\n",
       "      <td>0.351759</td>\n",
       "      <td>0.372519</td>\n",
       "      <td>0.344578</td>\n",
       "      <td>0.371333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Timeline</td>\n",
       "      <td>tf-idf + xgb</td>\n",
       "      <td>0.699122</td>\n",
       "      <td>0.728220</td>\n",
       "      <td>0.898944</td>\n",
       "      <td>0.863813</td>\n",
       "      <td>0.598358</td>\n",
       "      <td>0.752710</td>\n",
       "      <td>0.756861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Timeline</td>\n",
       "      <td>bertabaporu-base + xgb</td>\n",
       "      <td>0.661773</td>\n",
       "      <td>0.692262</td>\n",
       "      <td>0.776979</td>\n",
       "      <td>0.778471</td>\n",
       "      <td>0.585105</td>\n",
       "      <td>0.645518</td>\n",
       "      <td>0.690018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Timeline</td>\n",
       "      <td>bertabaporu-base</td>\n",
       "      <td>0.652707</td>\n",
       "      <td>0.767310</td>\n",
       "      <td>0.809799</td>\n",
       "      <td>0.799052</td>\n",
       "      <td>0.576324</td>\n",
       "      <td>0.632407</td>\n",
       "      <td>0.706266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Timeline</td>\n",
       "      <td>bertabaporu-base (R)</td>\n",
       "      <td>0.701990</td>\n",
       "      <td>0.822060</td>\n",
       "      <td>0.872170</td>\n",
       "      <td>0.860531</td>\n",
       "      <td>0.597442</td>\n",
       "      <td>0.711676</td>\n",
       "      <td>0.760978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Timeline</td>\n",
       "      <td>llama3:7b zero-shot [5] (R)</td>\n",
       "      <td>0.605633</td>\n",
       "      <td>0.588752</td>\n",
       "      <td>0.639513</td>\n",
       "      <td>0.528509</td>\n",
       "      <td>0.560086</td>\n",
       "      <td>0.514680</td>\n",
       "      <td>0.572862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Timeline</td>\n",
       "      <td>llama3:7b zero-shot [10] (R)</td>\n",
       "      <td>0.563199</td>\n",
       "      <td>0.611771</td>\n",
       "      <td>0.609199</td>\n",
       "      <td>0.529703</td>\n",
       "      <td>0.507579</td>\n",
       "      <td>0.516021</td>\n",
       "      <td>0.556245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Timeline</td>\n",
       "      <td>llama3:7b zero-shot [15] (R)</td>\n",
       "      <td>0.598183</td>\n",
       "      <td>0.586106</td>\n",
       "      <td>0.611868</td>\n",
       "      <td>0.518743</td>\n",
       "      <td>0.515050</td>\n",
       "      <td>0.529726</td>\n",
       "      <td>0.559946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Ensemble Texts + Timeline</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.698596</td>\n",
       "      <td>0.728220</td>\n",
       "      <td>0.898944</td>\n",
       "      <td>0.867509</td>\n",
       "      <td>0.586353</td>\n",
       "      <td>0.745550</td>\n",
       "      <td>0.754195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Ensemble Texts + Stance</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.820220</td>\n",
       "      <td>0.800537</td>\n",
       "      <td>0.811570</td>\n",
       "      <td>0.805406</td>\n",
       "      <td>0.867826</td>\n",
       "      <td>0.752925</td>\n",
       "      <td>0.809747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Ensemble Stance + Timeline</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.781126</td>\n",
       "      <td>0.767310</td>\n",
       "      <td>0.905882</td>\n",
       "      <td>0.883599</td>\n",
       "      <td>0.802880</td>\n",
       "      <td>0.800597</td>\n",
       "      <td>0.823566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Ensemble Stance + Timeline + Texts</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.740980</td>\n",
       "      <td>0.642395</td>\n",
       "      <td>0.846643</td>\n",
       "      <td>0.841272</td>\n",
       "      <td>0.689304</td>\n",
       "      <td>0.513417</td>\n",
       "      <td>0.712335</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 input                    classifier  \\\n",
       "0                               Stance                         dummy   \n",
       "1                               Stance                  tf-idf + xgb   \n",
       "2                               Stance        bertabaporu-base + xgb   \n",
       "3                               Stance              bertabaporu-base   \n",
       "4                               Stance           llama3:7b zero-shot   \n",
       "5                                Texts                         dummy   \n",
       "6                                Texts                  tf-idf + xgb   \n",
       "7                                Texts        bertabaporu-base + xgb   \n",
       "8                                Texts              bertabaporu-base   \n",
       "9                                Texts          bertabaporu-base (R)   \n",
       "10                               Texts   llama3:7b zero-shot [5] (R)   \n",
       "11                               Texts  llama3:7b zero-shot [10] (R)   \n",
       "12                               Texts  llama3:7b zero-shot [15] (R)   \n",
       "13                            Timeline                         dummy   \n",
       "14                            Timeline                  tf-idf + xgb   \n",
       "15                            Timeline        bertabaporu-base + xgb   \n",
       "16                            Timeline              bertabaporu-base   \n",
       "17                            Timeline          bertabaporu-base (R)   \n",
       "18                            Timeline   llama3:7b zero-shot [5] (R)   \n",
       "19                            Timeline  llama3:7b zero-shot [10] (R)   \n",
       "20                            Timeline  llama3:7b zero-shot [15] (R)   \n",
       "21           Ensemble Texts + Timeline            LogisticRegression   \n",
       "22             Ensemble Texts + Stance            LogisticRegression   \n",
       "23          Ensemble Stance + Timeline            LogisticRegression   \n",
       "24  Ensemble Stance + Timeline + Texts            LogisticRegression   \n",
       "\n",
       "      Church  Bolsonaro   Hydrox.   Sinovac  Globo TV      Lula   overall  \n",
       "0   0.361407   0.462857  0.334878  0.351759  0.372519  0.344578  0.371333  \n",
       "1   0.702021   0.595312  0.734366  0.752640  0.665243  0.654412  0.683999  \n",
       "2   0.853801   0.625289  0.830948  0.808036  0.781858  0.766993  0.777821  \n",
       "3   0.866276   0.737297  0.848144  0.834984  0.860252  0.789802  0.822792  \n",
       "4   0.729458   0.462857  0.638889  0.578779  0.770678  0.699381  0.646674  \n",
       "5   0.361407   0.462857  0.334878  0.351759  0.372519  0.344578  0.371333  \n",
       "6   0.596115   0.501220  0.603727  0.670805  0.545620  0.579427  0.582819  \n",
       "7   0.594754   0.495578  0.609524  0.660542  0.534455  0.569597  0.577408  \n",
       "8   0.586611   0.462857  0.446504  0.608972  0.507381  0.482520  0.515808  \n",
       "9   0.583417   0.462857  0.570531  0.637369  0.586967  0.602167  0.573885  \n",
       "10  0.499052   0.296142  0.469796  0.470381  0.490101  0.512954  0.456404  \n",
       "11  0.561274   0.328245  0.440347  0.460580  0.494646  0.478244  0.460556  \n",
       "12  0.503966   0.285253  0.416946  0.464074  0.475797  0.542401  0.448073  \n",
       "13  0.361407   0.462857  0.334878  0.351759  0.372519  0.344578  0.371333  \n",
       "14  0.699122   0.728220  0.898944  0.863813  0.598358  0.752710  0.756861  \n",
       "15  0.661773   0.692262  0.776979  0.778471  0.585105  0.645518  0.690018  \n",
       "16  0.652707   0.767310  0.809799  0.799052  0.576324  0.632407  0.706266  \n",
       "17  0.701990   0.822060  0.872170  0.860531  0.597442  0.711676  0.760978  \n",
       "18  0.605633   0.588752  0.639513  0.528509  0.560086  0.514680  0.572862  \n",
       "19  0.563199   0.611771  0.609199  0.529703  0.507579  0.516021  0.556245  \n",
       "20  0.598183   0.586106  0.611868  0.518743  0.515050  0.529726  0.559946  \n",
       "21  0.698596   0.728220  0.898944  0.867509  0.586353  0.745550  0.754195  \n",
       "22  0.820220   0.800537  0.811570  0.805406  0.867826  0.752925  0.809747  \n",
       "23  0.781126   0.767310  0.905882  0.883599  0.802880  0.800597  0.823566  \n",
       "24  0.740980   0.642395  0.846643  0.841272  0.689304  0.513417  0.712335  "
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_report.rename({\"text_col\":\"input\"}, axis = 1, inplace=True)\n",
    "f1_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "#f1_report.set_index(['input'],inplace=True)\n",
    "#f1_report.drop('input', axis = 1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_latex_with_multirow_and_bold(df):\n",
    "    latex_code = ''\n",
    "    latex_code += '\\\\begin{table}[H]'\n",
    "    latex_code += \"\\\\begin{tabular}{ll|rrrrrrr}\\n\\\\toprule\\n\"\n",
    "    latex_code += \"input & classifier & Church & Bolsonaro & Hydrox. & Sinovac & Globo TV & Lula & overall \\\\\\\\ \\n\\\\midrule\\n\"\n",
    "\n",
    "    last_input = None\n",
    "    multirow_count = 0\n",
    "\n",
    "    for input_value in df['input'].unique():\n",
    "        subset = df[df['input'] == input_value]\n",
    "        max_overall_idx = subset['overall'].idxmax()\n",
    "\n",
    "        for i, row in subset.iterrows():\n",
    "            if row['input'] == last_input:\n",
    "                latex_code += \"& \"\n",
    "                multirow_count += 1\n",
    "            else:\n",
    "                if multirow_count > 0:\n",
    "                    latex_code = latex_code.replace(f\"multirow{{{multirow_count}}}\", f\"multirow{{{multirow_count + 1}}}\", 1)\n",
    "                if last_input is not None:\n",
    "                    latex_code += \"\\\\cmidrule(lr){1-9}\\n\"\n",
    "                latex_code += f\"\\\\multirow{{{1}}}{{*}}{{{row['input']}}} & \"\n",
    "                multirow_count = 1\n",
    "\n",
    "            if i == max_overall_idx:\n",
    "                row_data = [f\"\\\\textbf{{{row[col]:.2f}}}\" if col not in ['input', 'classifier'] else f\"\\\\textbf{{{row[col]}}}\" for col in df.columns[1:]]\n",
    "                latex_code += \" & \".join(row_data) + \" \\\\\\\\ \\n\"\n",
    "            else:\n",
    "                latex_code += \" & \".join([f\"{row[col]:.2f}\" if isinstance(row[col], float) else str(row[col]) for col in df.columns[1:]]) + \" \\\\\\\\ \\n\"\n",
    "            \n",
    "            last_input = row['input']\n",
    "\n",
    "    if multirow_count > 0:\n",
    "        latex_code = latex_code.replace(f\"multirow{{{multirow_count}}}\", f\"multirow{{{multirow_count + 1}}}\", 1)\n",
    "\n",
    "    latex_code += \"\\\\cmidrule(lr){1-9}\\n\"\n",
    "    latex_code += \"\\\\bottomrule\\n\\\\end{tabular}\"\n",
    "    latex_code += \"\\caption{F1 macro results}\"\n",
    "    latex_code += '\\label{table:results_f1_macro}\\n'\n",
    "    latex_code += '\\end{table}'\n",
    "\n",
    "    return latex_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_report.input = f1_report.input.map({\n",
    "    \"Stance\": \"S\",\n",
    "    \"Timeline\": 'UT',\n",
    "    \"Texts\": 'UFT',\n",
    "    \"Ensemble Texts + Timeline\": 'E1',\n",
    "    \n",
    "    \"Ensemble Texts + Stance\":'E2',\n",
    "    \"Ensemble Stance + Timeline\":'E3',\n",
    "    \"Ensemble Stance + Timeline + Texts\":'E4'\n",
    "    \n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input</th>\n",
       "      <th>classifier</th>\n",
       "      <th>Church</th>\n",
       "      <th>Bolsonaro</th>\n",
       "      <th>Hydrox.</th>\n",
       "      <th>Sinovac</th>\n",
       "      <th>Globo TV</th>\n",
       "      <th>Lula</th>\n",
       "      <th>overall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>S</td>\n",
       "      <td>dummy</td>\n",
       "      <td>0.361407</td>\n",
       "      <td>0.462857</td>\n",
       "      <td>0.334878</td>\n",
       "      <td>0.351759</td>\n",
       "      <td>0.372519</td>\n",
       "      <td>0.344578</td>\n",
       "      <td>0.371333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>S</td>\n",
       "      <td>tf-idf + xgb</td>\n",
       "      <td>0.702021</td>\n",
       "      <td>0.595312</td>\n",
       "      <td>0.734366</td>\n",
       "      <td>0.752640</td>\n",
       "      <td>0.665243</td>\n",
       "      <td>0.654412</td>\n",
       "      <td>0.683999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>S</td>\n",
       "      <td>bertabaporu-base + xgb</td>\n",
       "      <td>0.853801</td>\n",
       "      <td>0.625289</td>\n",
       "      <td>0.830948</td>\n",
       "      <td>0.808036</td>\n",
       "      <td>0.781858</td>\n",
       "      <td>0.766993</td>\n",
       "      <td>0.777821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>S</td>\n",
       "      <td>bertabaporu-base</td>\n",
       "      <td>0.866276</td>\n",
       "      <td>0.737297</td>\n",
       "      <td>0.848144</td>\n",
       "      <td>0.834984</td>\n",
       "      <td>0.860252</td>\n",
       "      <td>0.789802</td>\n",
       "      <td>0.822792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>S</td>\n",
       "      <td>llama3:7b zero-shot</td>\n",
       "      <td>0.729458</td>\n",
       "      <td>0.462857</td>\n",
       "      <td>0.638889</td>\n",
       "      <td>0.578779</td>\n",
       "      <td>0.770678</td>\n",
       "      <td>0.699381</td>\n",
       "      <td>0.646674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>UFT</td>\n",
       "      <td>dummy</td>\n",
       "      <td>0.361407</td>\n",
       "      <td>0.462857</td>\n",
       "      <td>0.334878</td>\n",
       "      <td>0.351759</td>\n",
       "      <td>0.372519</td>\n",
       "      <td>0.344578</td>\n",
       "      <td>0.371333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>UFT</td>\n",
       "      <td>tf-idf + xgb</td>\n",
       "      <td>0.596115</td>\n",
       "      <td>0.501220</td>\n",
       "      <td>0.603727</td>\n",
       "      <td>0.670805</td>\n",
       "      <td>0.545620</td>\n",
       "      <td>0.579427</td>\n",
       "      <td>0.582819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>UFT</td>\n",
       "      <td>bertabaporu-base + xgb</td>\n",
       "      <td>0.594754</td>\n",
       "      <td>0.495578</td>\n",
       "      <td>0.609524</td>\n",
       "      <td>0.660542</td>\n",
       "      <td>0.534455</td>\n",
       "      <td>0.569597</td>\n",
       "      <td>0.577408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>UFT</td>\n",
       "      <td>bertabaporu-base</td>\n",
       "      <td>0.586611</td>\n",
       "      <td>0.462857</td>\n",
       "      <td>0.446504</td>\n",
       "      <td>0.608972</td>\n",
       "      <td>0.507381</td>\n",
       "      <td>0.482520</td>\n",
       "      <td>0.515808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>UFT</td>\n",
       "      <td>bertabaporu-base (R)</td>\n",
       "      <td>0.583417</td>\n",
       "      <td>0.462857</td>\n",
       "      <td>0.570531</td>\n",
       "      <td>0.637369</td>\n",
       "      <td>0.586967</td>\n",
       "      <td>0.602167</td>\n",
       "      <td>0.573885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>UFT</td>\n",
       "      <td>llama3:7b zero-shot [5] (R)</td>\n",
       "      <td>0.499052</td>\n",
       "      <td>0.296142</td>\n",
       "      <td>0.469796</td>\n",
       "      <td>0.470381</td>\n",
       "      <td>0.490101</td>\n",
       "      <td>0.512954</td>\n",
       "      <td>0.456404</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>UFT</td>\n",
       "      <td>llama3:7b zero-shot [10] (R)</td>\n",
       "      <td>0.561274</td>\n",
       "      <td>0.328245</td>\n",
       "      <td>0.440347</td>\n",
       "      <td>0.460580</td>\n",
       "      <td>0.494646</td>\n",
       "      <td>0.478244</td>\n",
       "      <td>0.460556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>UFT</td>\n",
       "      <td>llama3:7b zero-shot [15] (R)</td>\n",
       "      <td>0.503966</td>\n",
       "      <td>0.285253</td>\n",
       "      <td>0.416946</td>\n",
       "      <td>0.464074</td>\n",
       "      <td>0.475797</td>\n",
       "      <td>0.542401</td>\n",
       "      <td>0.448073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>UT</td>\n",
       "      <td>dummy</td>\n",
       "      <td>0.361407</td>\n",
       "      <td>0.462857</td>\n",
       "      <td>0.334878</td>\n",
       "      <td>0.351759</td>\n",
       "      <td>0.372519</td>\n",
       "      <td>0.344578</td>\n",
       "      <td>0.371333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>UT</td>\n",
       "      <td>tf-idf + xgb</td>\n",
       "      <td>0.699122</td>\n",
       "      <td>0.728220</td>\n",
       "      <td>0.898944</td>\n",
       "      <td>0.863813</td>\n",
       "      <td>0.598358</td>\n",
       "      <td>0.752710</td>\n",
       "      <td>0.756861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>UT</td>\n",
       "      <td>bertabaporu-base + xgb</td>\n",
       "      <td>0.661773</td>\n",
       "      <td>0.692262</td>\n",
       "      <td>0.776979</td>\n",
       "      <td>0.778471</td>\n",
       "      <td>0.585105</td>\n",
       "      <td>0.645518</td>\n",
       "      <td>0.690018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>UT</td>\n",
       "      <td>bertabaporu-base</td>\n",
       "      <td>0.652707</td>\n",
       "      <td>0.767310</td>\n",
       "      <td>0.809799</td>\n",
       "      <td>0.799052</td>\n",
       "      <td>0.576324</td>\n",
       "      <td>0.632407</td>\n",
       "      <td>0.706266</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>UT</td>\n",
       "      <td>bertabaporu-base (R)</td>\n",
       "      <td>0.701990</td>\n",
       "      <td>0.822060</td>\n",
       "      <td>0.872170</td>\n",
       "      <td>0.860531</td>\n",
       "      <td>0.597442</td>\n",
       "      <td>0.711676</td>\n",
       "      <td>0.760978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>UT</td>\n",
       "      <td>llama3:7b zero-shot [5] (R)</td>\n",
       "      <td>0.605633</td>\n",
       "      <td>0.588752</td>\n",
       "      <td>0.639513</td>\n",
       "      <td>0.528509</td>\n",
       "      <td>0.560086</td>\n",
       "      <td>0.514680</td>\n",
       "      <td>0.572862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>UT</td>\n",
       "      <td>llama3:7b zero-shot [10] (R)</td>\n",
       "      <td>0.563199</td>\n",
       "      <td>0.611771</td>\n",
       "      <td>0.609199</td>\n",
       "      <td>0.529703</td>\n",
       "      <td>0.507579</td>\n",
       "      <td>0.516021</td>\n",
       "      <td>0.556245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>UT</td>\n",
       "      <td>llama3:7b zero-shot [15] (R)</td>\n",
       "      <td>0.598183</td>\n",
       "      <td>0.586106</td>\n",
       "      <td>0.611868</td>\n",
       "      <td>0.518743</td>\n",
       "      <td>0.515050</td>\n",
       "      <td>0.529726</td>\n",
       "      <td>0.559946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>E1</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.698596</td>\n",
       "      <td>0.728220</td>\n",
       "      <td>0.898944</td>\n",
       "      <td>0.867509</td>\n",
       "      <td>0.586353</td>\n",
       "      <td>0.745550</td>\n",
       "      <td>0.754195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>E2</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.820220</td>\n",
       "      <td>0.800537</td>\n",
       "      <td>0.811570</td>\n",
       "      <td>0.805406</td>\n",
       "      <td>0.867826</td>\n",
       "      <td>0.752925</td>\n",
       "      <td>0.809747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>E3</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.781126</td>\n",
       "      <td>0.767310</td>\n",
       "      <td>0.905882</td>\n",
       "      <td>0.883599</td>\n",
       "      <td>0.802880</td>\n",
       "      <td>0.800597</td>\n",
       "      <td>0.823566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>E4</td>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>0.740980</td>\n",
       "      <td>0.642395</td>\n",
       "      <td>0.846643</td>\n",
       "      <td>0.841272</td>\n",
       "      <td>0.689304</td>\n",
       "      <td>0.513417</td>\n",
       "      <td>0.712335</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   input                    classifier    Church  Bolsonaro   Hydrox.  \\\n",
       "0      S                         dummy  0.361407   0.462857  0.334878   \n",
       "1      S                  tf-idf + xgb  0.702021   0.595312  0.734366   \n",
       "2      S        bertabaporu-base + xgb  0.853801   0.625289  0.830948   \n",
       "3      S              bertabaporu-base  0.866276   0.737297  0.848144   \n",
       "4      S           llama3:7b zero-shot  0.729458   0.462857  0.638889   \n",
       "5    UFT                         dummy  0.361407   0.462857  0.334878   \n",
       "6    UFT                  tf-idf + xgb  0.596115   0.501220  0.603727   \n",
       "7    UFT        bertabaporu-base + xgb  0.594754   0.495578  0.609524   \n",
       "8    UFT              bertabaporu-base  0.586611   0.462857  0.446504   \n",
       "9    UFT          bertabaporu-base (R)  0.583417   0.462857  0.570531   \n",
       "10   UFT   llama3:7b zero-shot [5] (R)  0.499052   0.296142  0.469796   \n",
       "11   UFT  llama3:7b zero-shot [10] (R)  0.561274   0.328245  0.440347   \n",
       "12   UFT  llama3:7b zero-shot [15] (R)  0.503966   0.285253  0.416946   \n",
       "13    UT                         dummy  0.361407   0.462857  0.334878   \n",
       "14    UT                  tf-idf + xgb  0.699122   0.728220  0.898944   \n",
       "15    UT        bertabaporu-base + xgb  0.661773   0.692262  0.776979   \n",
       "16    UT              bertabaporu-base  0.652707   0.767310  0.809799   \n",
       "17    UT          bertabaporu-base (R)  0.701990   0.822060  0.872170   \n",
       "18    UT   llama3:7b zero-shot [5] (R)  0.605633   0.588752  0.639513   \n",
       "19    UT  llama3:7b zero-shot [10] (R)  0.563199   0.611771  0.609199   \n",
       "20    UT  llama3:7b zero-shot [15] (R)  0.598183   0.586106  0.611868   \n",
       "21    E1            LogisticRegression  0.698596   0.728220  0.898944   \n",
       "22    E2            LogisticRegression  0.820220   0.800537  0.811570   \n",
       "23    E3            LogisticRegression  0.781126   0.767310  0.905882   \n",
       "24    E4            LogisticRegression  0.740980   0.642395  0.846643   \n",
       "\n",
       "     Sinovac  Globo TV      Lula   overall  \n",
       "0   0.351759  0.372519  0.344578  0.371333  \n",
       "1   0.752640  0.665243  0.654412  0.683999  \n",
       "2   0.808036  0.781858  0.766993  0.777821  \n",
       "3   0.834984  0.860252  0.789802  0.822792  \n",
       "4   0.578779  0.770678  0.699381  0.646674  \n",
       "5   0.351759  0.372519  0.344578  0.371333  \n",
       "6   0.670805  0.545620  0.579427  0.582819  \n",
       "7   0.660542  0.534455  0.569597  0.577408  \n",
       "8   0.608972  0.507381  0.482520  0.515808  \n",
       "9   0.637369  0.586967  0.602167  0.573885  \n",
       "10  0.470381  0.490101  0.512954  0.456404  \n",
       "11  0.460580  0.494646  0.478244  0.460556  \n",
       "12  0.464074  0.475797  0.542401  0.448073  \n",
       "13  0.351759  0.372519  0.344578  0.371333  \n",
       "14  0.863813  0.598358  0.752710  0.756861  \n",
       "15  0.778471  0.585105  0.645518  0.690018  \n",
       "16  0.799052  0.576324  0.632407  0.706266  \n",
       "17  0.860531  0.597442  0.711676  0.760978  \n",
       "18  0.528509  0.560086  0.514680  0.572862  \n",
       "19  0.529703  0.507579  0.516021  0.556245  \n",
       "20  0.518743  0.515050  0.529726  0.559946  \n",
       "21  0.867509  0.586353  0.745550  0.754195  \n",
       "22  0.805406  0.867826  0.752925  0.809747  \n",
       "23  0.883599  0.802880  0.800597  0.823566  \n",
       "24  0.841272  0.689304  0.513417  0.712335  "
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "str_latex = generate_latex_with_multirow_and_bold(f1_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{table}[H]\\begin{tabular}{ll|rrrrrrr}\n",
      "\\toprule\n",
      "input & classifier & Church & Bolsonaro & Hydrox. & Sinovac & Globo TV & Lula & overall \\\\ \n",
      "\\midrule\n",
      "\\multirow{2}{*}{S} & dummy & 0.36 & 0.46 & 0.33 & 0.35 & 0.37 & 0.34 & 0.37 \\\\ \n",
      "& tf-idf + xgb & 0.70 & 0.60 & 0.73 & 0.75 & 0.67 & 0.65 & 0.68 \\\\ \n",
      "& bertabaporu-base + xgb & 0.85 & 0.63 & 0.83 & 0.81 & 0.78 & 0.77 & 0.78 \\\\ \n",
      "& \\textbf{bertabaporu-base} & \\textbf{0.87} & \\textbf{0.74} & \\textbf{0.85} & \\textbf{0.83} & \\textbf{0.86} & \\textbf{0.79} & \\textbf{0.82} \\\\ \n",
      "& llama3:7b zero-shot & 0.73 & 0.46 & 0.64 & 0.58 & 0.77 & 0.70 & 0.65 \\\\ \n",
      "\\cmidrule(lr){1-9}\n",
      "\\multirow{2}{*}{UFT} & dummy & 0.36 & 0.46 & 0.33 & 0.35 & 0.37 & 0.34 & 0.37 \\\\ \n",
      "& \\textbf{tf-idf + xgb} & \\textbf{0.60} & \\textbf{0.50} & \\textbf{0.60} & \\textbf{0.67} & \\textbf{0.55} & \\textbf{0.58} & \\textbf{0.58} \\\\ \n",
      "& bertabaporu-base + xgb & 0.59 & 0.50 & 0.61 & 0.66 & 0.53 & 0.57 & 0.58 \\\\ \n",
      "& bertabaporu-base & 0.59 & 0.46 & 0.45 & 0.61 & 0.51 & 0.48 & 0.52 \\\\ \n",
      "& bertabaporu-base (R) & 0.58 & 0.46 & 0.57 & 0.64 & 0.59 & 0.60 & 0.57 \\\\ \n",
      "& llama3:7b zero-shot [5] (R) & 0.50 & 0.30 & 0.47 & 0.47 & 0.49 & 0.51 & 0.46 \\\\ \n",
      "& llama3:7b zero-shot [10] (R) & 0.56 & 0.33 & 0.44 & 0.46 & 0.49 & 0.48 & 0.46 \\\\ \n",
      "& llama3:7b zero-shot [15] (R) & 0.50 & 0.29 & 0.42 & 0.46 & 0.48 & 0.54 & 0.45 \\\\ \n",
      "\\cmidrule(lr){1-9}\n",
      "\\multirow{2}{*}{UT} & dummy & 0.36 & 0.46 & 0.33 & 0.35 & 0.37 & 0.34 & 0.37 \\\\ \n",
      "& tf-idf + xgb & 0.70 & 0.73 & 0.90 & 0.86 & 0.60 & 0.75 & 0.76 \\\\ \n",
      "& bertabaporu-base + xgb & 0.66 & 0.69 & 0.78 & 0.78 & 0.59 & 0.65 & 0.69 \\\\ \n",
      "& bertabaporu-base & 0.65 & 0.77 & 0.81 & 0.80 & 0.58 & 0.63 & 0.71 \\\\ \n",
      "& \\textbf{bertabaporu-base (R)} & \\textbf{0.70} & \\textbf{0.82} & \\textbf{0.87} & \\textbf{0.86} & \\textbf{0.60} & \\textbf{0.71} & \\textbf{0.76} \\\\ \n",
      "& llama3:7b zero-shot [5] (R) & 0.61 & 0.59 & 0.64 & 0.53 & 0.56 & 0.51 & 0.57 \\\\ \n",
      "& llama3:7b zero-shot [10] (R) & 0.56 & 0.61 & 0.61 & 0.53 & 0.51 & 0.52 & 0.56 \\\\ \n",
      "& llama3:7b zero-shot [15] (R) & 0.60 & 0.59 & 0.61 & 0.52 & 0.52 & 0.53 & 0.56 \\\\ \n",
      "\\cmidrule(lr){1-9}\n",
      "\\multirow{2}{*}{E1} & \\textbf{LogisticRegression} & \\textbf{0.70} & \\textbf{0.73} & \\textbf{0.90} & \\textbf{0.87} & \\textbf{0.59} & \\textbf{0.75} & \\textbf{0.75} \\\\ \n",
      "\\cmidrule(lr){1-9}\n",
      "\\multirow{1}{*}{E2} & \\textbf{LogisticRegression} & \\textbf{0.82} & \\textbf{0.80} & \\textbf{0.81} & \\textbf{0.81} & \\textbf{0.87} & \\textbf{0.75} & \\textbf{0.81} \\\\ \n",
      "\\cmidrule(lr){1-9}\n",
      "\\multirow{1}{*}{E3} & \\textbf{LogisticRegression} & \\textbf{0.78} & \\textbf{0.77} & \\textbf{0.91} & \\textbf{0.88} & \\textbf{0.80} & \\textbf{0.80} & \\textbf{0.82} \\\\ \n",
      "\\cmidrule(lr){1-9}\n",
      "\\multirow{1}{*}{E4} & \\textbf{LogisticRegression} & \\textbf{0.74} & \\textbf{0.64} & \\textbf{0.85} & \\textbf{0.84} & \\textbf{0.69} & \\textbf{0.51} & \\textbf{0.71} \\\\ \n",
      "\\cmidrule(lr){1-9}\n",
      "\\bottomrule\n",
      "\\end{tabular}\\caption{F1 macro results}\\label{table:results_f1_macro}\n",
      "\\end{table}\n"
     ]
    }
   ],
   "source": [
    "print(str_latex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env-stance-pred",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
