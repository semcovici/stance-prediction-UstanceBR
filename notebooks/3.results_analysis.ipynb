{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.metrics import classification_report\n",
    "from tqdm import tqdm\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../src')\n",
    "\n",
    "from models.classification_methods import get_classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['DummyClassifier_bo_top_mentioned_timelines_Texts_test_results.csv',\n",
       " 'DummyClassifier_bo_users_Stance_test_results.csv',\n",
       " 'DummyClassifier_bo_users_Timeline_test_results.csv',\n",
       " 'DummyClassifier_cl_top_mentioned_timelines_Texts_test_results.csv',\n",
       " 'DummyClassifier_cl_users_Stance_test_results.csv',\n",
       " 'DummyClassifier_cl_users_Timeline_test_results.csv',\n",
       " 'DummyClassifier_co_top_mentioned_timelines_Texts_test_results.csv',\n",
       " 'DummyClassifier_co_users_Stance_test_results.csv',\n",
       " 'DummyClassifier_co_users_Timeline_test_results.csv',\n",
       " 'DummyClassifier_gl_top_mentioned_timelines_Texts_test_results.csv',\n",
       " 'DummyClassifier_gl_users_Stance_test_results.csv',\n",
       " 'DummyClassifier_gl_users_Timeline_test_results.csv',\n",
       " 'DummyClassifier_ig_top_mentioned_timelines_Texts_test_results.csv',\n",
       " 'DummyClassifier_ig_users_Stance_test_results.csv',\n",
       " 'DummyClassifier_ig_users_Timeline_test_results.csv',\n",
       " 'DummyClassifier_lu_top_mentioned_timelines_Texts_test_results.csv',\n",
       " 'DummyClassifier_lu_users_Stance_test_results.csv',\n",
       " 'DummyClassifier_lu_users_Timeline_test_results.csv',\n",
       " 'XGBClassifier_TfidfVectorizer_bo_top_mentioned_timelines_Texts_test_results.csv',\n",
       " 'XGBClassifier_TfidfVectorizer_bo_users_Stance_test_results.csv',\n",
       " 'XGBClassifier_TfidfVectorizer_bo_users_Timeline_test_results.csv',\n",
       " 'XGBClassifier_TfidfVectorizer_cl_top_mentioned_timelines_Texts_test_results.csv',\n",
       " 'XGBClassifier_TfidfVectorizer_cl_users_Stance_test_results.csv',\n",
       " 'XGBClassifier_TfidfVectorizer_cl_users_Timeline_test_results.csv',\n",
       " 'XGBClassifier_TfidfVectorizer_co_top_mentioned_timelines_Texts_test_results.csv',\n",
       " 'XGBClassifier_TfidfVectorizer_co_users_Stance_test_results.csv',\n",
       " 'XGBClassifier_TfidfVectorizer_co_users_Timeline_test_results.csv',\n",
       " 'XGBClassifier_TfidfVectorizer_gl_top_mentioned_timelines_Texts_test_results.csv',\n",
       " 'XGBClassifier_TfidfVectorizer_gl_users_Stance_test_results.csv',\n",
       " 'XGBClassifier_TfidfVectorizer_gl_users_Timeline_test_results.csv',\n",
       " 'XGBClassifier_TfidfVectorizer_ig_top_mentioned_timelines_Texts_test_results.csv',\n",
       " 'XGBClassifier_TfidfVectorizer_ig_users_Stance_test_results.csv',\n",
       " 'XGBClassifier_TfidfVectorizer_ig_users_Timeline_test_results.csv',\n",
       " 'XGBClassifier_TfidfVectorizer_lu_top_mentioned_timelines_Texts_test_results.csv',\n",
       " 'XGBClassifier_TfidfVectorizer_lu_users_Stance_test_results.csv',\n",
       " 'XGBClassifier_TfidfVectorizer_lu_users_Timeline_test_results.csv',\n",
       " 'belt_filteredTimeline10_pablocosta_bertabaporu-base-uncased_test_results.csv',\n",
       " 'belt_filteredTimeline10_pablocosta_bertabaporu-base-uncased_test_results_part_bo.csv',\n",
       " 'belt_filteredTimeline10_pablocosta_bertabaporu-base-uncased_test_results_part_cl.csv',\n",
       " 'belt_filteredTimeline10_pablocosta_bertabaporu-base-uncased_test_results_part_co.csv',\n",
       " 'belt_filteredTimeline10_pablocosta_bertabaporu-base-uncased_test_results_part_gl.csv',\n",
       " 'belt_filteredTimeline10_pablocosta_bertabaporu-base-uncased_test_results_part_ig.csv',\n",
       " 'belt_filteredTimeline10_pablocosta_bertabaporu-base-uncased_test_results_part_lu.csv',\n",
       " 'belt_filteredTimeline15_pablocosta_bertabaporu-base-uncased_test_results.csv',\n",
       " 'belt_filteredTimeline15_pablocosta_bertabaporu-base-uncased_test_results_part_bo.csv',\n",
       " 'belt_filteredTimeline15_pablocosta_bertabaporu-base-uncased_test_results_part_cl.csv',\n",
       " 'belt_filteredTimeline15_pablocosta_bertabaporu-base-uncased_test_results_part_co.csv',\n",
       " 'belt_filteredTimeline15_pablocosta_bertabaporu-base-uncased_test_results_part_gl.csv',\n",
       " 'belt_filteredTimeline15_pablocosta_bertabaporu-base-uncased_test_results_part_ig.csv',\n",
       " 'belt_filteredTimeline15_pablocosta_bertabaporu-base-uncased_test_results_part_lu.csv',\n",
       " 'belt_filteredTimeline5_pablocosta_bertabaporu-base-uncased_test_results.csv',\n",
       " 'belt_filteredTimeline5_pablocosta_bertabaporu-base-uncased_test_results_part_bo.csv',\n",
       " 'belt_filteredTimeline5_pablocosta_bertabaporu-base-uncased_test_results_part_cl.csv',\n",
       " 'belt_filteredTimeline5_pablocosta_bertabaporu-base-uncased_test_results_part_co.csv',\n",
       " 'belt_filteredTimeline5_pablocosta_bertabaporu-base-uncased_test_results_part_gl.csv',\n",
       " 'belt_filteredTimeline5_pablocosta_bertabaporu-base-uncased_test_results_part_ig.csv',\n",
       " 'belt_filteredTimeline5_pablocosta_bertabaporu-base-uncased_test_results_part_lu.csv',\n",
       " 'belt_filtered_Texts10_pablocosta_bertabaporu-base-uncased_test_results.csv',\n",
       " 'belt_filtered_Texts10_pablocosta_bertabaporu-base-uncased_test_results_part_bo.csv',\n",
       " 'belt_filtered_Texts10_pablocosta_bertabaporu-base-uncased_test_results_part_cl.csv',\n",
       " 'belt_filtered_Texts10_pablocosta_bertabaporu-base-uncased_test_results_part_co.csv',\n",
       " 'belt_filtered_Texts10_pablocosta_bertabaporu-base-uncased_test_results_part_gl.csv',\n",
       " 'belt_filtered_Texts10_pablocosta_bertabaporu-base-uncased_test_results_part_ig.csv',\n",
       " 'belt_filtered_Texts10_pablocosta_bertabaporu-base-uncased_test_results_part_lu.csv',\n",
       " 'belt_filtered_Texts15_pablocosta_bertabaporu-base-uncased_test_results.csv',\n",
       " 'belt_filtered_Texts15_pablocosta_bertabaporu-base-uncased_test_results_part_bo.csv',\n",
       " 'belt_filtered_Texts15_pablocosta_bertabaporu-base-uncased_test_results_part_cl.csv',\n",
       " 'belt_filtered_Texts15_pablocosta_bertabaporu-base-uncased_test_results_part_co.csv',\n",
       " 'belt_filtered_Texts15_pablocosta_bertabaporu-base-uncased_test_results_part_gl.csv',\n",
       " 'belt_filtered_Texts15_pablocosta_bertabaporu-base-uncased_test_results_part_ig.csv',\n",
       " 'belt_filtered_Texts15_pablocosta_bertabaporu-base-uncased_test_results_part_lu.csv',\n",
       " 'belt_filtered_Texts5_pablocosta_bertabaporu-base-uncased_test_results.csv',\n",
       " 'belt_filtered_Texts5_pablocosta_bertabaporu-base-uncased_test_results_part_bo.csv',\n",
       " 'belt_filtered_Texts5_pablocosta_bertabaporu-base-uncased_test_results_part_cl.csv',\n",
       " 'belt_filtered_Texts5_pablocosta_bertabaporu-base-uncased_test_results_part_co.csv',\n",
       " 'belt_filtered_Texts5_pablocosta_bertabaporu-base-uncased_test_results_part_gl.csv',\n",
       " 'belt_filtered_Texts5_pablocosta_bertabaporu-base-uncased_test_results_part_ig.csv',\n",
       " 'belt_filtered_Texts5_pablocosta_bertabaporu-base-uncased_test_results_part_lu.csv',\n",
       " 'bert_classifier_pablocosta_bertabaporu_base_uncased_bo_Stance_test_results.csv',\n",
       " 'bert_classifier_pablocosta_bertabaporu_base_uncased_cl_Stance_test_results.csv',\n",
       " 'bert_classifier_pablocosta_bertabaporu_base_uncased_co_Stance_test_results.csv',\n",
       " 'bert_classifier_pablocosta_bertabaporu_base_uncased_gl_Stance_test_results.csv',\n",
       " 'bert_classifier_pablocosta_bertabaporu_base_uncased_ig_Stance_test_results.csv',\n",
       " 'bert_classifier_pablocosta_bertabaporu_base_uncased_lu_Stance_test_results.csv',\n",
       " 'bertimbau_xgb_bo_top_mentioned_timelines_emb_Texts_test_results.csv',\n",
       " 'bertimbau_xgb_bo_users_emb_Stance_test_results.csv',\n",
       " 'bertimbau_xgb_bo_users_emb_Timeline_test_results.csv',\n",
       " 'bertimbau_xgb_cl_top_mentioned_timelines_emb_Texts_test_results.csv',\n",
       " 'bertimbau_xgb_cl_users_emb_Stance_test_results.csv',\n",
       " 'bertimbau_xgb_cl_users_emb_Timeline_test_results.csv',\n",
       " 'bertimbau_xgb_co_top_mentioned_timelines_emb_Texts_test_results.csv',\n",
       " 'bertimbau_xgb_co_users_emb_Stance_test_results.csv',\n",
       " 'bertimbau_xgb_co_users_emb_Timeline_test_results.csv',\n",
       " 'bertimbau_xgb_gl_top_mentioned_timelines_emb_Texts_test_results.csv',\n",
       " 'bertimbau_xgb_gl_users_emb_Stance_test_results.csv',\n",
       " 'bertimbau_xgb_gl_users_emb_Timeline_test_results.csv',\n",
       " 'bertimbau_xgb_ig_top_mentioned_timelines_emb_Texts_test_results.csv',\n",
       " 'bertimbau_xgb_ig_users_emb_Stance_test_results.csv',\n",
       " 'bertimbau_xgb_ig_users_emb_Timeline_test_results.csv',\n",
       " 'bertimbau_xgb_lu_top_mentioned_timelines_emb_Texts_test_results.csv',\n",
       " 'bertimbau_xgb_lu_users_emb_Stance_test_results.csv',\n",
       " 'bertimbau_xgb_lu_users_emb_Timeline_test_results.csv',\n",
       " 'llama3_bo_Stance_prompt2_Stance_test_results.csv',\n",
       " 'llama3_cl_Stance_prompt2_Stance_test_results.csv',\n",
       " 'llama3_co_Stance_prompt2_Stance_test_results.csv',\n",
       " 'llama3_gl_Stance_prompt2_Stance_test_results.csv',\n",
       " 'llama3_ig_Stance_prompt2_Stance_test_results.csv',\n",
       " 'llama3_ig_filtered_Texts5_prompt2_Texts_test_results.csv',\n",
       " 'llama3_lu_Stance_prompt2_Stance_test_results.csv',\n",
       " 'old']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_results_path = '../reports/test_results/'\n",
    "\n",
    "list_df_t = os.listdir(test_results_path)\n",
    "list_df_t.sort()\n",
    "list_df_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hydrox.', 'Lula', 'Sinovac', 'Church', 'Globo TV', 'Bolsonaro']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Target list\n",
    "target_list = [\n",
    "    'ig',\n",
    "    'bo', \n",
    "    'cl', \n",
    "    'co', \n",
    "    'gl', \n",
    "    'lu'\n",
    "]\n",
    "\n",
    "dict_cp = {\n",
    "    'cl':'Hydrox.',\n",
    "    'lu':'Lula',\n",
    "    'co':'Sinovac',\n",
    "    'ig':'Church',\n",
    "    'gl':'Globo TV',\n",
    "    'bo':'Bolsonaro',\n",
    "}\n",
    "\n",
    "names = list(dict_cp.values())\n",
    "names"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create complete table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (vectorizer,estimator, path_sring) \n",
    "results_tuples_stance = [\n",
    "    # Stance\n",
    "    (\"Stance\", \"-\" ,\"dummy\", \"DummyClassifier_{target}_users_Stance_test_results.csv\"),\n",
    "    (\"Stance\", \"tf-idf\" ,\"xgb\", \"XGBClassifier_TfidfVectorizer_{target}_users_Stance_test_results.csv\"),\n",
    "    (\"Stance\", \"bertabaporu-base\" ,\"xgb\", \"bertimbau_xgb_{target}_users_emb_Stance_test_results.csv\"),\n",
    "    (\"Stance\", \"-\" ,\"bertabaporu-base\", \"bert_classifier_pablocosta_bertabaporu_base_uncased_{target}_Stance_test_results.csv\"),\n",
    "    (\"Stance\", \"-\",  \"llama3:7b\", \"llama3_{target}_Stance_prompt2_Stance_test_results.csv\"),\n",
    "    \n",
    "    # Texts\n",
    "    (\"Texts\", \"-\" ,\"dummy\", \"DummyClassifier_{target}_top_mentioned_timelines_Texts_test_results.csv\"),\n",
    "    (\"Texts\", \"tf-idf\" ,\"xgb\", \"XGBClassifier_TfidfVectorizer_{target}_top_mentioned_timelines_Texts_test_results.csv\"),\n",
    "    (\"Texts\", \"bertabaporu-base\" ,\"xgb\", \"bertimbau_xgb_{target}_top_mentioned_timelines_emb_Texts_test_results.csv\"),\n",
    "    \n",
    "    # Timeline\n",
    "    (\"Timeline\", \"-\" ,\"dummy\", \"DummyClassifier_{target}_users_Timeline_test_results.csv\"),\n",
    "    (\"Timeline\", \"tf-idf\" ,\"xgb\", \"XGBClassifier_TfidfVectorizer_{target}_users_Timeline_test_results.csv\"),\n",
    "    (\"Timeline\", \"bertabaporu-base\" ,\"xgb\", \"bertimbau_xgb_{target}_users_emb_Timeline_test_results.csv\")\n",
    "    \n",
    "]\n",
    "\n",
    "list_results = []\n",
    "for text_col, vectorizer, estimator, path_results in results_tuples_stance:\n",
    "    \n",
    "    list_cr = []\n",
    "    \n",
    "    for target in target_list:\n",
    "        \n",
    "        \n",
    "        path = test_results_path + path_results.format(target = target)\n",
    "        df_results = pd.read_csv(path)\n",
    "        df_results_or = df_results.copy()\n",
    "        \n",
    "        # get classification report df\n",
    "        df_classification_report = get_classification_report(df_results.test, df_results.pred, cr_args = {})\n",
    "        \n",
    "        # create multindex\n",
    "        column_indexes = [(metric,dict_cp[target]) for metric in df_classification_report.columns]\n",
    "        multi_index_cols = pd.MultiIndex.from_tuples(column_indexes, names=['metric', 'target'])\n",
    "        rows_indexes = [(text_col, vectorizer, estimator, cl) for cl in df_classification_report.index]\n",
    "        multi_index_rows = pd.MultiIndex.from_tuples(rows_indexes, names=['text_col','vectorizer', 'estimator', 'class'])\n",
    "        df_classification_report.columns = multi_index_cols\n",
    "        df_classification_report.index = multi_index_rows\n",
    "        \n",
    "        # print(text_col, vectorizer, estimator,target)\n",
    "        # print(path)\n",
    "        # display(df_classification_report)\n",
    "        \n",
    "        list_cr.append(df_classification_report)\n",
    "        \n",
    "    df_results = pd.concat(list_cr, axis = 1)\n",
    "    \n",
    "    list_results.append(df_results)\n",
    "    \n",
    "df_results_final = pd.concat(list_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>metric</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>...</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>Church</th>\n",
       "      <th>Church</th>\n",
       "      <th>Church</th>\n",
       "      <th>Church</th>\n",
       "      <th>Bolsonaro</th>\n",
       "      <th>Bolsonaro</th>\n",
       "      <th>Bolsonaro</th>\n",
       "      <th>Bolsonaro</th>\n",
       "      <th>Hydrox.</th>\n",
       "      <th>Hydrox.</th>\n",
       "      <th>...</th>\n",
       "      <th>Sinovac</th>\n",
       "      <th>Sinovac</th>\n",
       "      <th>Globo TV</th>\n",
       "      <th>Globo TV</th>\n",
       "      <th>Globo TV</th>\n",
       "      <th>Globo TV</th>\n",
       "      <th>Lula</th>\n",
       "      <th>Lula</th>\n",
       "      <th>Lula</th>\n",
       "      <th>Lula</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text_col</th>\n",
       "      <th>vectorizer</th>\n",
       "      <th>estimator</th>\n",
       "      <th>class</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"25\" valign=\"top\">Stance</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">-</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">dummy</th>\n",
       "      <th>against</th>\n",
       "      <td>0.565943</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.722814</td>\n",
       "      <td>339.000000</td>\n",
       "      <td>0.861702</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.925714</td>\n",
       "      <td>162.000000</td>\n",
       "      <td>0.503484</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>354.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>167.000000</td>\n",
       "      <td>0.525735</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.689157</td>\n",
       "      <td>143.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.565943</td>\n",
       "      <td>0.565943</td>\n",
       "      <td>0.565943</td>\n",
       "      <td>0.565943</td>\n",
       "      <td>0.861702</td>\n",
       "      <td>0.861702</td>\n",
       "      <td>0.861702</td>\n",
       "      <td>0.861702</td>\n",
       "      <td>0.503484</td>\n",
       "      <td>0.503484</td>\n",
       "      <td>...</td>\n",
       "      <td>0.542636</td>\n",
       "      <td>0.542636</td>\n",
       "      <td>0.593674</td>\n",
       "      <td>0.593674</td>\n",
       "      <td>0.593674</td>\n",
       "      <td>0.593674</td>\n",
       "      <td>0.525735</td>\n",
       "      <td>0.525735</td>\n",
       "      <td>0.525735</td>\n",
       "      <td>0.525735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.320292</td>\n",
       "      <td>0.565943</td>\n",
       "      <td>0.409072</td>\n",
       "      <td>599.000000</td>\n",
       "      <td>0.742531</td>\n",
       "      <td>0.861702</td>\n",
       "      <td>0.797690</td>\n",
       "      <td>188.000000</td>\n",
       "      <td>0.253496</td>\n",
       "      <td>0.503484</td>\n",
       "      <td>...</td>\n",
       "      <td>0.381754</td>\n",
       "      <td>774.000000</td>\n",
       "      <td>0.352449</td>\n",
       "      <td>0.593674</td>\n",
       "      <td>0.442310</td>\n",
       "      <td>411.000000</td>\n",
       "      <td>0.276398</td>\n",
       "      <td>0.525735</td>\n",
       "      <td>0.362314</td>\n",
       "      <td>272.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.282972</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.361407</td>\n",
       "      <td>599.000000</td>\n",
       "      <td>0.430851</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.462857</td>\n",
       "      <td>188.000000</td>\n",
       "      <td>0.251742</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.351759</td>\n",
       "      <td>774.000000</td>\n",
       "      <td>0.296837</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.372519</td>\n",
       "      <td>411.000000</td>\n",
       "      <td>0.262868</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.344578</td>\n",
       "      <td>272.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>for</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>260.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.703518</td>\n",
       "      <td>420.000000</td>\n",
       "      <td>0.593674</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.745038</td>\n",
       "      <td>244.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>129.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">tf-idf</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">xgb</th>\n",
       "      <th>against</th>\n",
       "      <td>0.732394</td>\n",
       "      <td>0.766962</td>\n",
       "      <td>0.749280</td>\n",
       "      <td>339.000000</td>\n",
       "      <td>0.881356</td>\n",
       "      <td>0.962963</td>\n",
       "      <td>0.920354</td>\n",
       "      <td>162.000000</td>\n",
       "      <td>0.716088</td>\n",
       "      <td>0.785467</td>\n",
       "      <td>...</td>\n",
       "      <td>0.719403</td>\n",
       "      <td>354.000000</td>\n",
       "      <td>0.653846</td>\n",
       "      <td>0.508982</td>\n",
       "      <td>0.572391</td>\n",
       "      <td>167.000000</td>\n",
       "      <td>0.689922</td>\n",
       "      <td>0.622378</td>\n",
       "      <td>0.654412</td>\n",
       "      <td>143.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.709516</td>\n",
       "      <td>0.709516</td>\n",
       "      <td>0.709516</td>\n",
       "      <td>0.709516</td>\n",
       "      <td>0.856383</td>\n",
       "      <td>0.856383</td>\n",
       "      <td>0.856383</td>\n",
       "      <td>0.856383</td>\n",
       "      <td>0.735192</td>\n",
       "      <td>0.735192</td>\n",
       "      <td>...</td>\n",
       "      <td>0.757106</td>\n",
       "      <td>0.757106</td>\n",
       "      <td>0.690998</td>\n",
       "      <td>0.690998</td>\n",
       "      <td>0.690998</td>\n",
       "      <td>0.690998</td>\n",
       "      <td>0.654412</td>\n",
       "      <td>0.654412</td>\n",
       "      <td>0.654412</td>\n",
       "      <td>0.654412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.708016</td>\n",
       "      <td>0.709516</td>\n",
       "      <td>0.708254</td>\n",
       "      <td>599.000000</td>\n",
       "      <td>0.822329</td>\n",
       "      <td>0.856383</td>\n",
       "      <td>0.830449</td>\n",
       "      <td>188.000000</td>\n",
       "      <td>0.737273</td>\n",
       "      <td>0.735192</td>\n",
       "      <td>...</td>\n",
       "      <td>0.755474</td>\n",
       "      <td>774.000000</td>\n",
       "      <td>0.686106</td>\n",
       "      <td>0.690998</td>\n",
       "      <td>0.682639</td>\n",
       "      <td>411.000000</td>\n",
       "      <td>0.657888</td>\n",
       "      <td>0.654412</td>\n",
       "      <td>0.654412</td>\n",
       "      <td>272.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.704312</td>\n",
       "      <td>0.700789</td>\n",
       "      <td>0.702021</td>\n",
       "      <td>599.000000</td>\n",
       "      <td>0.667951</td>\n",
       "      <td>0.577635</td>\n",
       "      <td>0.595312</td>\n",
       "      <td>188.000000</td>\n",
       "      <td>0.737422</td>\n",
       "      <td>0.734839</td>\n",
       "      <td>...</td>\n",
       "      <td>0.752640</td>\n",
       "      <td>774.000000</td>\n",
       "      <td>0.681016</td>\n",
       "      <td>0.662278</td>\n",
       "      <td>0.665243</td>\n",
       "      <td>411.000000</td>\n",
       "      <td>0.656150</td>\n",
       "      <td>0.656150</td>\n",
       "      <td>0.654412</td>\n",
       "      <td>272.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>for</th>\n",
       "      <td>0.676230</td>\n",
       "      <td>0.634615</td>\n",
       "      <td>0.654762</td>\n",
       "      <td>260.000000</td>\n",
       "      <td>0.454545</td>\n",
       "      <td>0.192308</td>\n",
       "      <td>0.270270</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>0.758755</td>\n",
       "      <td>0.684211</td>\n",
       "      <td>...</td>\n",
       "      <td>0.785877</td>\n",
       "      <td>420.000000</td>\n",
       "      <td>0.708185</td>\n",
       "      <td>0.815574</td>\n",
       "      <td>0.758095</td>\n",
       "      <td>244.000000</td>\n",
       "      <td>0.622378</td>\n",
       "      <td>0.689922</td>\n",
       "      <td>0.654412</td>\n",
       "      <td>129.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">bertabaporu-base</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">xgb</th>\n",
       "      <th>against</th>\n",
       "      <td>0.834646</td>\n",
       "      <td>0.938053</td>\n",
       "      <td>0.883333</td>\n",
       "      <td>339.000000</td>\n",
       "      <td>0.887006</td>\n",
       "      <td>0.969136</td>\n",
       "      <td>0.926254</td>\n",
       "      <td>162.000000</td>\n",
       "      <td>0.824324</td>\n",
       "      <td>0.844291</td>\n",
       "      <td>...</td>\n",
       "      <td>0.782738</td>\n",
       "      <td>354.000000</td>\n",
       "      <td>0.751553</td>\n",
       "      <td>0.724551</td>\n",
       "      <td>0.737805</td>\n",
       "      <td>167.000000</td>\n",
       "      <td>0.766667</td>\n",
       "      <td>0.804196</td>\n",
       "      <td>0.784983</td>\n",
       "      <td>143.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.859766</td>\n",
       "      <td>0.859766</td>\n",
       "      <td>0.859766</td>\n",
       "      <td>0.859766</td>\n",
       "      <td>0.867021</td>\n",
       "      <td>0.867021</td>\n",
       "      <td>0.867021</td>\n",
       "      <td>0.867021</td>\n",
       "      <td>0.831010</td>\n",
       "      <td>0.831010</td>\n",
       "      <td>...</td>\n",
       "      <td>0.811370</td>\n",
       "      <td>0.811370</td>\n",
       "      <td>0.790754</td>\n",
       "      <td>0.790754</td>\n",
       "      <td>0.790754</td>\n",
       "      <td>0.790754</td>\n",
       "      <td>0.768382</td>\n",
       "      <td>0.768382</td>\n",
       "      <td>0.768382</td>\n",
       "      <td>0.768382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.864606</td>\n",
       "      <td>0.859766</td>\n",
       "      <td>0.857696</td>\n",
       "      <td>599.000000</td>\n",
       "      <td>0.839770</td>\n",
       "      <td>0.867021</td>\n",
       "      <td>0.843008</td>\n",
       "      <td>188.000000</td>\n",
       "      <td>0.831179</td>\n",
       "      <td>0.831010</td>\n",
       "      <td>...</td>\n",
       "      <td>0.810193</td>\n",
       "      <td>774.000000</td>\n",
       "      <td>0.789813</td>\n",
       "      <td>0.790754</td>\n",
       "      <td>0.790111</td>\n",
       "      <td>411.000000</td>\n",
       "      <td>0.768481</td>\n",
       "      <td>0.768382</td>\n",
       "      <td>0.767919</td>\n",
       "      <td>272.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.869158</td>\n",
       "      <td>0.847873</td>\n",
       "      <td>0.853801</td>\n",
       "      <td>599.000000</td>\n",
       "      <td>0.716230</td>\n",
       "      <td>0.599953</td>\n",
       "      <td>0.625289</td>\n",
       "      <td>188.000000</td>\n",
       "      <td>0.831227</td>\n",
       "      <td>0.830917</td>\n",
       "      <td>...</td>\n",
       "      <td>0.808036</td>\n",
       "      <td>774.000000</td>\n",
       "      <td>0.783776</td>\n",
       "      <td>0.780308</td>\n",
       "      <td>0.781858</td>\n",
       "      <td>411.000000</td>\n",
       "      <td>0.768579</td>\n",
       "      <td>0.766439</td>\n",
       "      <td>0.766993</td>\n",
       "      <td>272.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>for</th>\n",
       "      <td>0.903670</td>\n",
       "      <td>0.757692</td>\n",
       "      <td>0.824268</td>\n",
       "      <td>260.000000</td>\n",
       "      <td>0.545455</td>\n",
       "      <td>0.230769</td>\n",
       "      <td>0.324324</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>0.838129</td>\n",
       "      <td>0.817544</td>\n",
       "      <td>...</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>420.000000</td>\n",
       "      <td>0.816000</td>\n",
       "      <td>0.836066</td>\n",
       "      <td>0.825911</td>\n",
       "      <td>244.000000</td>\n",
       "      <td>0.770492</td>\n",
       "      <td>0.728682</td>\n",
       "      <td>0.749004</td>\n",
       "      <td>129.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"10\" valign=\"top\">-</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">bertabaporu-base</th>\n",
       "      <th>against</th>\n",
       "      <td>0.850267</td>\n",
       "      <td>0.938053</td>\n",
       "      <td>0.892006</td>\n",
       "      <td>339.000000</td>\n",
       "      <td>0.926380</td>\n",
       "      <td>0.932099</td>\n",
       "      <td>0.929231</td>\n",
       "      <td>162.000000</td>\n",
       "      <td>0.875940</td>\n",
       "      <td>0.806228</td>\n",
       "      <td>...</td>\n",
       "      <td>0.823188</td>\n",
       "      <td>354.000000</td>\n",
       "      <td>0.814607</td>\n",
       "      <td>0.868263</td>\n",
       "      <td>0.840580</td>\n",
       "      <td>167.000000</td>\n",
       "      <td>0.789474</td>\n",
       "      <td>0.839161</td>\n",
       "      <td>0.813559</td>\n",
       "      <td>143.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.871452</td>\n",
       "      <td>0.871452</td>\n",
       "      <td>0.871452</td>\n",
       "      <td>0.871452</td>\n",
       "      <td>0.877660</td>\n",
       "      <td>0.877660</td>\n",
       "      <td>0.877660</td>\n",
       "      <td>0.877660</td>\n",
       "      <td>0.844948</td>\n",
       "      <td>0.844948</td>\n",
       "      <td>...</td>\n",
       "      <td>0.842377</td>\n",
       "      <td>0.842377</td>\n",
       "      <td>0.866180</td>\n",
       "      <td>0.866180</td>\n",
       "      <td>0.866180</td>\n",
       "      <td>0.866180</td>\n",
       "      <td>0.797794</td>\n",
       "      <td>0.797794</td>\n",
       "      <td>0.797794</td>\n",
       "      <td>0.797794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.874748</td>\n",
       "      <td>0.871452</td>\n",
       "      <td>0.869969</td>\n",
       "      <td>599.000000</td>\n",
       "      <td>0.875711</td>\n",
       "      <td>0.877660</td>\n",
       "      <td>0.876648</td>\n",
       "      <td>188.000000</td>\n",
       "      <td>0.847262</td>\n",
       "      <td>0.844948</td>\n",
       "      <td>...</td>\n",
       "      <td>0.841975</td>\n",
       "      <td>774.000000</td>\n",
       "      <td>0.868615</td>\n",
       "      <td>0.866180</td>\n",
       "      <td>0.866770</td>\n",
       "      <td>411.000000</td>\n",
       "      <td>0.798418</td>\n",
       "      <td>0.797794</td>\n",
       "      <td>0.797224</td>\n",
       "      <td>272.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.878467</td>\n",
       "      <td>0.861334</td>\n",
       "      <td>0.866621</td>\n",
       "      <td>599.000000</td>\n",
       "      <td>0.743190</td>\n",
       "      <td>0.735280</td>\n",
       "      <td>0.739125</td>\n",
       "      <td>188.000000</td>\n",
       "      <td>0.847061</td>\n",
       "      <td>0.845219</td>\n",
       "      <td>...</td>\n",
       "      <td>0.840499</td>\n",
       "      <td>774.000000</td>\n",
       "      <td>0.860093</td>\n",
       "      <td>0.866509</td>\n",
       "      <td>0.862638</td>\n",
       "      <td>411.000000</td>\n",
       "      <td>0.798904</td>\n",
       "      <td>0.795549</td>\n",
       "      <td>0.796338</td>\n",
       "      <td>272.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>for</th>\n",
       "      <td>0.906667</td>\n",
       "      <td>0.784615</td>\n",
       "      <td>0.841237</td>\n",
       "      <td>260.000000</td>\n",
       "      <td>0.560000</td>\n",
       "      <td>0.538462</td>\n",
       "      <td>0.549020</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.884211</td>\n",
       "      <td>...</td>\n",
       "      <td>0.857809</td>\n",
       "      <td>420.000000</td>\n",
       "      <td>0.905579</td>\n",
       "      <td>0.864754</td>\n",
       "      <td>0.884696</td>\n",
       "      <td>244.000000</td>\n",
       "      <td>0.808333</td>\n",
       "      <td>0.751938</td>\n",
       "      <td>0.779116</td>\n",
       "      <td>129.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">llama3:7b</th>\n",
       "      <th>for</th>\n",
       "      <td>0.640000</td>\n",
       "      <td>0.861538</td>\n",
       "      <td>0.734426</td>\n",
       "      <td>260.000000</td>\n",
       "      <td>0.180000</td>\n",
       "      <td>0.692308</td>\n",
       "      <td>0.285714</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>0.625806</td>\n",
       "      <td>0.680702</td>\n",
       "      <td>...</td>\n",
       "      <td>0.625581</td>\n",
       "      <td>420.000000</td>\n",
       "      <td>0.779359</td>\n",
       "      <td>0.897541</td>\n",
       "      <td>0.834286</td>\n",
       "      <td>244.000000</td>\n",
       "      <td>0.633880</td>\n",
       "      <td>0.899225</td>\n",
       "      <td>0.743590</td>\n",
       "      <td>129.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.729549</td>\n",
       "      <td>0.729549</td>\n",
       "      <td>0.729549</td>\n",
       "      <td>0.729549</td>\n",
       "      <td>0.521277</td>\n",
       "      <td>0.521277</td>\n",
       "      <td>0.521277</td>\n",
       "      <td>0.521277</td>\n",
       "      <td>0.639373</td>\n",
       "      <td>0.639373</td>\n",
       "      <td>...</td>\n",
       "      <td>0.583979</td>\n",
       "      <td>0.583979</td>\n",
       "      <td>0.788321</td>\n",
       "      <td>0.788321</td>\n",
       "      <td>0.788321</td>\n",
       "      <td>0.788321</td>\n",
       "      <td>0.705882</td>\n",
       "      <td>0.705882</td>\n",
       "      <td>0.705882</td>\n",
       "      <td>0.705882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.747711</td>\n",
       "      <td>0.744929</td>\n",
       "      <td>0.729458</td>\n",
       "      <td>599.000000</td>\n",
       "      <td>0.544545</td>\n",
       "      <td>0.593067</td>\n",
       "      <td>0.462857</td>\n",
       "      <td>188.000000</td>\n",
       "      <td>0.640555</td>\n",
       "      <td>0.639659</td>\n",
       "      <td>...</td>\n",
       "      <td>0.578779</td>\n",
       "      <td>774.000000</td>\n",
       "      <td>0.793526</td>\n",
       "      <td>0.763142</td>\n",
       "      <td>0.770678</td>\n",
       "      <td>411.000000</td>\n",
       "      <td>0.743906</td>\n",
       "      <td>0.715347</td>\n",
       "      <td>0.699381</td>\n",
       "      <td>272.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.761916</td>\n",
       "      <td>0.729549</td>\n",
       "      <td>0.728803</td>\n",
       "      <td>599.000000</td>\n",
       "      <td>0.808259</td>\n",
       "      <td>0.521277</td>\n",
       "      <td>0.591003</td>\n",
       "      <td>188.000000</td>\n",
       "      <td>0.640658</td>\n",
       "      <td>0.639373</td>\n",
       "      <td>...</td>\n",
       "      <td>0.582770</td>\n",
       "      <td>774.000000</td>\n",
       "      <td>0.790872</td>\n",
       "      <td>0.788321</td>\n",
       "      <td>0.782595</td>\n",
       "      <td>411.000000</td>\n",
       "      <td>0.749569</td>\n",
       "      <td>0.705882</td>\n",
       "      <td>0.697106</td>\n",
       "      <td>272.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>against</th>\n",
       "      <td>0.855422</td>\n",
       "      <td>0.628319</td>\n",
       "      <td>0.724490</td>\n",
       "      <td>339.000000</td>\n",
       "      <td>0.909091</td>\n",
       "      <td>0.493827</td>\n",
       "      <td>0.640000</td>\n",
       "      <td>162.000000</td>\n",
       "      <td>0.655303</td>\n",
       "      <td>0.598616</td>\n",
       "      <td>...</td>\n",
       "      <td>0.531977</td>\n",
       "      <td>354.000000</td>\n",
       "      <td>0.807692</td>\n",
       "      <td>0.628743</td>\n",
       "      <td>0.707071</td>\n",
       "      <td>167.000000</td>\n",
       "      <td>0.853933</td>\n",
       "      <td>0.531469</td>\n",
       "      <td>0.655172</td>\n",
       "      <td>143.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"15\" valign=\"top\">Texts</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">-</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">dummy</th>\n",
       "      <th>against</th>\n",
       "      <td>0.565943</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.722814</td>\n",
       "      <td>339.000000</td>\n",
       "      <td>0.861702</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.925714</td>\n",
       "      <td>162.000000</td>\n",
       "      <td>0.503484</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>354.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>167.000000</td>\n",
       "      <td>0.525735</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.689157</td>\n",
       "      <td>143.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.565943</td>\n",
       "      <td>0.565943</td>\n",
       "      <td>0.565943</td>\n",
       "      <td>0.565943</td>\n",
       "      <td>0.861702</td>\n",
       "      <td>0.861702</td>\n",
       "      <td>0.861702</td>\n",
       "      <td>0.861702</td>\n",
       "      <td>0.503484</td>\n",
       "      <td>0.503484</td>\n",
       "      <td>...</td>\n",
       "      <td>0.542636</td>\n",
       "      <td>0.542636</td>\n",
       "      <td>0.593674</td>\n",
       "      <td>0.593674</td>\n",
       "      <td>0.593674</td>\n",
       "      <td>0.593674</td>\n",
       "      <td>0.525735</td>\n",
       "      <td>0.525735</td>\n",
       "      <td>0.525735</td>\n",
       "      <td>0.525735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.320292</td>\n",
       "      <td>0.565943</td>\n",
       "      <td>0.409072</td>\n",
       "      <td>599.000000</td>\n",
       "      <td>0.742531</td>\n",
       "      <td>0.861702</td>\n",
       "      <td>0.797690</td>\n",
       "      <td>188.000000</td>\n",
       "      <td>0.253496</td>\n",
       "      <td>0.503484</td>\n",
       "      <td>...</td>\n",
       "      <td>0.381754</td>\n",
       "      <td>774.000000</td>\n",
       "      <td>0.352449</td>\n",
       "      <td>0.593674</td>\n",
       "      <td>0.442310</td>\n",
       "      <td>411.000000</td>\n",
       "      <td>0.276398</td>\n",
       "      <td>0.525735</td>\n",
       "      <td>0.362314</td>\n",
       "      <td>272.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.282972</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.361407</td>\n",
       "      <td>599.000000</td>\n",
       "      <td>0.430851</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.462857</td>\n",
       "      <td>188.000000</td>\n",
       "      <td>0.251742</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.351759</td>\n",
       "      <td>774.000000</td>\n",
       "      <td>0.296837</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.372519</td>\n",
       "      <td>411.000000</td>\n",
       "      <td>0.262868</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.344578</td>\n",
       "      <td>272.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>for</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>260.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.703518</td>\n",
       "      <td>420.000000</td>\n",
       "      <td>0.593674</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.745038</td>\n",
       "      <td>244.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>129.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">tf-idf</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">xgb</th>\n",
       "      <th>against</th>\n",
       "      <td>0.638677</td>\n",
       "      <td>0.740413</td>\n",
       "      <td>0.685792</td>\n",
       "      <td>339.000000</td>\n",
       "      <td>0.866310</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.928367</td>\n",
       "      <td>162.000000</td>\n",
       "      <td>0.595166</td>\n",
       "      <td>0.681661</td>\n",
       "      <td>...</td>\n",
       "      <td>0.643159</td>\n",
       "      <td>354.000000</td>\n",
       "      <td>0.504673</td>\n",
       "      <td>0.323353</td>\n",
       "      <td>0.394161</td>\n",
       "      <td>167.000000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.608392</td>\n",
       "      <td>0.604167</td>\n",
       "      <td>143.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.616027</td>\n",
       "      <td>0.616027</td>\n",
       "      <td>0.616027</td>\n",
       "      <td>0.616027</td>\n",
       "      <td>0.867021</td>\n",
       "      <td>0.867021</td>\n",
       "      <td>0.867021</td>\n",
       "      <td>0.867021</td>\n",
       "      <td>0.606272</td>\n",
       "      <td>0.606272</td>\n",
       "      <td>...</td>\n",
       "      <td>0.673127</td>\n",
       "      <td>0.673127</td>\n",
       "      <td>0.596107</td>\n",
       "      <td>0.596107</td>\n",
       "      <td>0.596107</td>\n",
       "      <td>0.596107</td>\n",
       "      <td>0.580882</td>\n",
       "      <td>0.580882</td>\n",
       "      <td>0.580882</td>\n",
       "      <td>0.580882</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.610089</td>\n",
       "      <td>0.616027</td>\n",
       "      <td>0.607942</td>\n",
       "      <td>599.000000</td>\n",
       "      <td>0.884799</td>\n",
       "      <td>0.867021</td>\n",
       "      <td>0.810220</td>\n",
       "      <td>188.000000</td>\n",
       "      <td>0.608191</td>\n",
       "      <td>0.606272</td>\n",
       "      <td>...</td>\n",
       "      <td>0.673162</td>\n",
       "      <td>774.000000</td>\n",
       "      <td>0.578061</td>\n",
       "      <td>0.596107</td>\n",
       "      <td>0.573996</td>\n",
       "      <td>411.000000</td>\n",
       "      <td>0.580581</td>\n",
       "      <td>0.580882</td>\n",
       "      <td>0.580700</td>\n",
       "      <td>272.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.605746</td>\n",
       "      <td>0.597130</td>\n",
       "      <td>0.596115</td>\n",
       "      <td>599.000000</td>\n",
       "      <td>0.933155</td>\n",
       "      <td>0.519231</td>\n",
       "      <td>0.501220</td>\n",
       "      <td>188.000000</td>\n",
       "      <td>0.608283</td>\n",
       "      <td>0.605743</td>\n",
       "      <td>...</td>\n",
       "      <td>0.670805</td>\n",
       "      <td>774.000000</td>\n",
       "      <td>0.566481</td>\n",
       "      <td>0.553070</td>\n",
       "      <td>0.545620</td>\n",
       "      <td>411.000000</td>\n",
       "      <td>0.579528</td>\n",
       "      <td>0.579390</td>\n",
       "      <td>0.579427</td>\n",
       "      <td>272.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>for</th>\n",
       "      <td>0.572816</td>\n",
       "      <td>0.453846</td>\n",
       "      <td>0.506438</td>\n",
       "      <td>260.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.074074</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>0.621399</td>\n",
       "      <td>0.529825</td>\n",
       "      <td>...</td>\n",
       "      <td>0.698451</td>\n",
       "      <td>420.000000</td>\n",
       "      <td>0.628289</td>\n",
       "      <td>0.782787</td>\n",
       "      <td>0.697080</td>\n",
       "      <td>244.000000</td>\n",
       "      <td>0.559055</td>\n",
       "      <td>0.550388</td>\n",
       "      <td>0.554688</td>\n",
       "      <td>129.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">bertabaporu-base</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">xgb</th>\n",
       "      <th>against</th>\n",
       "      <td>0.639474</td>\n",
       "      <td>0.716814</td>\n",
       "      <td>0.675939</td>\n",
       "      <td>339.000000</td>\n",
       "      <td>0.864865</td>\n",
       "      <td>0.987654</td>\n",
       "      <td>0.922190</td>\n",
       "      <td>162.000000</td>\n",
       "      <td>0.598240</td>\n",
       "      <td>0.705882</td>\n",
       "      <td>...</td>\n",
       "      <td>0.632911</td>\n",
       "      <td>354.000000</td>\n",
       "      <td>0.481818</td>\n",
       "      <td>0.317365</td>\n",
       "      <td>0.382671</td>\n",
       "      <td>167.000000</td>\n",
       "      <td>0.587097</td>\n",
       "      <td>0.636364</td>\n",
       "      <td>0.610738</td>\n",
       "      <td>143.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.611018</td>\n",
       "      <td>0.611018</td>\n",
       "      <td>0.611018</td>\n",
       "      <td>0.611018</td>\n",
       "      <td>0.856383</td>\n",
       "      <td>0.856383</td>\n",
       "      <td>0.856383</td>\n",
       "      <td>0.856383</td>\n",
       "      <td>0.613240</td>\n",
       "      <td>0.613240</td>\n",
       "      <td>...</td>\n",
       "      <td>0.662791</td>\n",
       "      <td>0.662791</td>\n",
       "      <td>0.583942</td>\n",
       "      <td>0.583942</td>\n",
       "      <td>0.583942</td>\n",
       "      <td>0.583942</td>\n",
       "      <td>0.573529</td>\n",
       "      <td>0.573529</td>\n",
       "      <td>0.573529</td>\n",
       "      <td>0.573529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.605691</td>\n",
       "      <td>0.611018</td>\n",
       "      <td>0.605461</td>\n",
       "      <td>599.000000</td>\n",
       "      <td>0.791355</td>\n",
       "      <td>0.856383</td>\n",
       "      <td>0.804191</td>\n",
       "      <td>188.000000</td>\n",
       "      <td>0.616588</td>\n",
       "      <td>0.613240</td>\n",
       "      <td>...</td>\n",
       "      <td>0.662898</td>\n",
       "      <td>774.000000</td>\n",
       "      <td>0.564603</td>\n",
       "      <td>0.583942</td>\n",
       "      <td>0.562891</td>\n",
       "      <td>411.000000</td>\n",
       "      <td>0.572138</td>\n",
       "      <td>0.573529</td>\n",
       "      <td>0.571714</td>\n",
       "      <td>272.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.600559</td>\n",
       "      <td>0.594946</td>\n",
       "      <td>0.594754</td>\n",
       "      <td>599.000000</td>\n",
       "      <td>0.599099</td>\n",
       "      <td>0.513058</td>\n",
       "      <td>0.495578</td>\n",
       "      <td>188.000000</td>\n",
       "      <td>0.616717</td>\n",
       "      <td>0.612590</td>\n",
       "      <td>...</td>\n",
       "      <td>0.660542</td>\n",
       "      <td>774.000000</td>\n",
       "      <td>0.551540</td>\n",
       "      <td>0.541879</td>\n",
       "      <td>0.534455</td>\n",
       "      <td>411.000000</td>\n",
       "      <td>0.571326</td>\n",
       "      <td>0.570120</td>\n",
       "      <td>0.569597</td>\n",
       "      <td>272.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>for</th>\n",
       "      <td>0.561644</td>\n",
       "      <td>0.473077</td>\n",
       "      <td>0.513570</td>\n",
       "      <td>260.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.038462</td>\n",
       "      <td>0.068966</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>0.635193</td>\n",
       "      <td>0.519298</td>\n",
       "      <td>...</td>\n",
       "      <td>0.688172</td>\n",
       "      <td>420.000000</td>\n",
       "      <td>0.621262</td>\n",
       "      <td>0.766393</td>\n",
       "      <td>0.686239</td>\n",
       "      <td>244.000000</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.503876</td>\n",
       "      <td>0.528455</td>\n",
       "      <td>129.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"15\" valign=\"top\">Timeline</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">-</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">dummy</th>\n",
       "      <th>against</th>\n",
       "      <td>0.565943</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.722814</td>\n",
       "      <td>339.000000</td>\n",
       "      <td>0.861702</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.925714</td>\n",
       "      <td>162.000000</td>\n",
       "      <td>0.503484</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>354.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>167.000000</td>\n",
       "      <td>0.525735</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.689157</td>\n",
       "      <td>143.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.565943</td>\n",
       "      <td>0.565943</td>\n",
       "      <td>0.565943</td>\n",
       "      <td>0.565943</td>\n",
       "      <td>0.861702</td>\n",
       "      <td>0.861702</td>\n",
       "      <td>0.861702</td>\n",
       "      <td>0.861702</td>\n",
       "      <td>0.503484</td>\n",
       "      <td>0.503484</td>\n",
       "      <td>...</td>\n",
       "      <td>0.542636</td>\n",
       "      <td>0.542636</td>\n",
       "      <td>0.593674</td>\n",
       "      <td>0.593674</td>\n",
       "      <td>0.593674</td>\n",
       "      <td>0.593674</td>\n",
       "      <td>0.525735</td>\n",
       "      <td>0.525735</td>\n",
       "      <td>0.525735</td>\n",
       "      <td>0.525735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.320292</td>\n",
       "      <td>0.565943</td>\n",
       "      <td>0.409072</td>\n",
       "      <td>599.000000</td>\n",
       "      <td>0.742531</td>\n",
       "      <td>0.861702</td>\n",
       "      <td>0.797690</td>\n",
       "      <td>188.000000</td>\n",
       "      <td>0.253496</td>\n",
       "      <td>0.503484</td>\n",
       "      <td>...</td>\n",
       "      <td>0.381754</td>\n",
       "      <td>774.000000</td>\n",
       "      <td>0.352449</td>\n",
       "      <td>0.593674</td>\n",
       "      <td>0.442310</td>\n",
       "      <td>411.000000</td>\n",
       "      <td>0.276398</td>\n",
       "      <td>0.525735</td>\n",
       "      <td>0.362314</td>\n",
       "      <td>272.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.282972</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.361407</td>\n",
       "      <td>599.000000</td>\n",
       "      <td>0.430851</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.462857</td>\n",
       "      <td>188.000000</td>\n",
       "      <td>0.251742</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.351759</td>\n",
       "      <td>774.000000</td>\n",
       "      <td>0.296837</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.372519</td>\n",
       "      <td>411.000000</td>\n",
       "      <td>0.262868</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.344578</td>\n",
       "      <td>272.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>for</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>260.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.703518</td>\n",
       "      <td>420.000000</td>\n",
       "      <td>0.593674</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.745038</td>\n",
       "      <td>244.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>129.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">tf-idf</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">xgb</th>\n",
       "      <th>against</th>\n",
       "      <td>0.726519</td>\n",
       "      <td>0.775811</td>\n",
       "      <td>0.750357</td>\n",
       "      <td>339.000000</td>\n",
       "      <td>0.908571</td>\n",
       "      <td>0.981481</td>\n",
       "      <td>0.943620</td>\n",
       "      <td>162.000000</td>\n",
       "      <td>0.896907</td>\n",
       "      <td>0.903114</td>\n",
       "      <td>...</td>\n",
       "      <td>0.843227</td>\n",
       "      <td>354.000000</td>\n",
       "      <td>0.592593</td>\n",
       "      <td>0.383234</td>\n",
       "      <td>0.465455</td>\n",
       "      <td>167.000000</td>\n",
       "      <td>0.760274</td>\n",
       "      <td>0.776224</td>\n",
       "      <td>0.768166</td>\n",
       "      <td>143.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.707846</td>\n",
       "      <td>0.707846</td>\n",
       "      <td>0.707846</td>\n",
       "      <td>0.707846</td>\n",
       "      <td>0.898936</td>\n",
       "      <td>0.898936</td>\n",
       "      <td>0.898936</td>\n",
       "      <td>0.898936</td>\n",
       "      <td>0.898955</td>\n",
       "      <td>0.898955</td>\n",
       "      <td>...</td>\n",
       "      <td>0.866925</td>\n",
       "      <td>0.866925</td>\n",
       "      <td>0.642336</td>\n",
       "      <td>0.642336</td>\n",
       "      <td>0.642336</td>\n",
       "      <td>0.642336</td>\n",
       "      <td>0.753676</td>\n",
       "      <td>0.753676</td>\n",
       "      <td>0.753676</td>\n",
       "      <td>0.753676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.706034</td>\n",
       "      <td>0.707846</td>\n",
       "      <td>0.705879</td>\n",
       "      <td>599.000000</td>\n",
       "      <td>0.889301</td>\n",
       "      <td>0.898936</td>\n",
       "      <td>0.884042</td>\n",
       "      <td>188.000000</td>\n",
       "      <td>0.898969</td>\n",
       "      <td>0.898955</td>\n",
       "      <td>...</td>\n",
       "      <td>0.865569</td>\n",
       "      <td>774.000000</td>\n",
       "      <td>0.632650</td>\n",
       "      <td>0.642336</td>\n",
       "      <td>0.623257</td>\n",
       "      <td>411.000000</td>\n",
       "      <td>0.753519</td>\n",
       "      <td>0.753676</td>\n",
       "      <td>0.753506</td>\n",
       "      <td>272.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.702922</td>\n",
       "      <td>0.697521</td>\n",
       "      <td>0.699122</td>\n",
       "      <td>599.000000</td>\n",
       "      <td>0.838901</td>\n",
       "      <td>0.683048</td>\n",
       "      <td>0.728220</td>\n",
       "      <td>188.000000</td>\n",
       "      <td>0.898984</td>\n",
       "      <td>0.898926</td>\n",
       "      <td>...</td>\n",
       "      <td>0.863813</td>\n",
       "      <td>774.000000</td>\n",
       "      <td>0.626329</td>\n",
       "      <td>0.601453</td>\n",
       "      <td>0.598358</td>\n",
       "      <td>411.000000</td>\n",
       "      <td>0.753153</td>\n",
       "      <td>0.752453</td>\n",
       "      <td>0.752710</td>\n",
       "      <td>272.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>for</th>\n",
       "      <td>0.679325</td>\n",
       "      <td>0.619231</td>\n",
       "      <td>0.647887</td>\n",
       "      <td>260.000000</td>\n",
       "      <td>0.769231</td>\n",
       "      <td>0.384615</td>\n",
       "      <td>0.512821</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>0.901060</td>\n",
       "      <td>0.894737</td>\n",
       "      <td>...</td>\n",
       "      <td>0.884400</td>\n",
       "      <td>420.000000</td>\n",
       "      <td>0.660066</td>\n",
       "      <td>0.819672</td>\n",
       "      <td>0.731261</td>\n",
       "      <td>244.000000</td>\n",
       "      <td>0.746032</td>\n",
       "      <td>0.728682</td>\n",
       "      <td>0.737255</td>\n",
       "      <td>129.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">bertabaporu-base</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">xgb</th>\n",
       "      <th>against</th>\n",
       "      <td>0.691489</td>\n",
       "      <td>0.766962</td>\n",
       "      <td>0.727273</td>\n",
       "      <td>339.000000</td>\n",
       "      <td>0.902299</td>\n",
       "      <td>0.969136</td>\n",
       "      <td>0.934524</td>\n",
       "      <td>162.000000</td>\n",
       "      <td>0.788530</td>\n",
       "      <td>0.761246</td>\n",
       "      <td>...</td>\n",
       "      <td>0.746988</td>\n",
       "      <td>354.000000</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>0.395210</td>\n",
       "      <td>0.459930</td>\n",
       "      <td>167.000000</td>\n",
       "      <td>0.648148</td>\n",
       "      <td>0.734266</td>\n",
       "      <td>0.688525</td>\n",
       "      <td>143.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.674457</td>\n",
       "      <td>0.674457</td>\n",
       "      <td>0.674457</td>\n",
       "      <td>0.674457</td>\n",
       "      <td>0.882979</td>\n",
       "      <td>0.882979</td>\n",
       "      <td>0.882979</td>\n",
       "      <td>0.882979</td>\n",
       "      <td>0.777003</td>\n",
       "      <td>0.777003</td>\n",
       "      <td>...</td>\n",
       "      <td>0.782946</td>\n",
       "      <td>0.782946</td>\n",
       "      <td>0.622871</td>\n",
       "      <td>0.622871</td>\n",
       "      <td>0.622871</td>\n",
       "      <td>0.622871</td>\n",
       "      <td>0.650735</td>\n",
       "      <td>0.650735</td>\n",
       "      <td>0.650735</td>\n",
       "      <td>0.650735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.671632</td>\n",
       "      <td>0.674457</td>\n",
       "      <td>0.670412</td>\n",
       "      <td>599.000000</td>\n",
       "      <td>0.866419</td>\n",
       "      <td>0.882979</td>\n",
       "      <td>0.867515</td>\n",
       "      <td>188.000000</td>\n",
       "      <td>0.777394</td>\n",
       "      <td>0.777003</td>\n",
       "      <td>...</td>\n",
       "      <td>0.781156</td>\n",
       "      <td>774.000000</td>\n",
       "      <td>0.611101</td>\n",
       "      <td>0.622871</td>\n",
       "      <td>0.608557</td>\n",
       "      <td>411.000000</td>\n",
       "      <td>0.651182</td>\n",
       "      <td>0.650735</td>\n",
       "      <td>0.647731</td>\n",
       "      <td>272.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.668615</td>\n",
       "      <td>0.660404</td>\n",
       "      <td>0.661773</td>\n",
       "      <td>599.000000</td>\n",
       "      <td>0.772578</td>\n",
       "      <td>0.657645</td>\n",
       "      <td>0.692262</td>\n",
       "      <td>188.000000</td>\n",
       "      <td>0.777316</td>\n",
       "      <td>0.777114</td>\n",
       "      <td>...</td>\n",
       "      <td>0.778471</td>\n",
       "      <td>774.000000</td>\n",
       "      <td>0.601460</td>\n",
       "      <td>0.586949</td>\n",
       "      <td>0.585105</td>\n",
       "      <td>411.000000</td>\n",
       "      <td>0.651347</td>\n",
       "      <td>0.646203</td>\n",
       "      <td>0.645518</td>\n",
       "      <td>272.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>for</th>\n",
       "      <td>0.645740</td>\n",
       "      <td>0.553846</td>\n",
       "      <td>0.596273</td>\n",
       "      <td>260.000000</td>\n",
       "      <td>0.642857</td>\n",
       "      <td>0.346154</td>\n",
       "      <td>0.450000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>0.766102</td>\n",
       "      <td>0.792982</td>\n",
       "      <td>...</td>\n",
       "      <td>0.809955</td>\n",
       "      <td>420.000000</td>\n",
       "      <td>0.652921</td>\n",
       "      <td>0.778689</td>\n",
       "      <td>0.710280</td>\n",
       "      <td>244.000000</td>\n",
       "      <td>0.654545</td>\n",
       "      <td>0.558140</td>\n",
       "      <td>0.602510</td>\n",
       "      <td>129.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>55 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "metric                                                  precision    recall  \\\n",
       "target                                                     Church    Church   \n",
       "text_col vectorizer       estimator        class                              \n",
       "Stance   -                dummy            against       0.565943  1.000000   \n",
       "                                           accuracy      0.565943  0.565943   \n",
       "                                           weighted avg  0.320292  0.565943   \n",
       "                                           macro avg     0.282972  0.500000   \n",
       "                                           for           0.000000  0.000000   \n",
       "         tf-idf           xgb              against       0.732394  0.766962   \n",
       "                                           accuracy      0.709516  0.709516   \n",
       "                                           weighted avg  0.708016  0.709516   \n",
       "                                           macro avg     0.704312  0.700789   \n",
       "                                           for           0.676230  0.634615   \n",
       "         bertabaporu-base xgb              against       0.834646  0.938053   \n",
       "                                           accuracy      0.859766  0.859766   \n",
       "                                           weighted avg  0.864606  0.859766   \n",
       "                                           macro avg     0.869158  0.847873   \n",
       "                                           for           0.903670  0.757692   \n",
       "         -                bertabaporu-base against       0.850267  0.938053   \n",
       "                                           accuracy      0.871452  0.871452   \n",
       "                                           weighted avg  0.874748  0.871452   \n",
       "                                           macro avg     0.878467  0.861334   \n",
       "                                           for           0.906667  0.784615   \n",
       "                          llama3:7b        for           0.640000  0.861538   \n",
       "                                           accuracy      0.729549  0.729549   \n",
       "                                           macro avg     0.747711  0.744929   \n",
       "                                           weighted avg  0.761916  0.729549   \n",
       "                                           against       0.855422  0.628319   \n",
       "Texts    -                dummy            against       0.565943  1.000000   \n",
       "                                           accuracy      0.565943  0.565943   \n",
       "                                           weighted avg  0.320292  0.565943   \n",
       "                                           macro avg     0.282972  0.500000   \n",
       "                                           for           0.000000  0.000000   \n",
       "         tf-idf           xgb              against       0.638677  0.740413   \n",
       "                                           accuracy      0.616027  0.616027   \n",
       "                                           weighted avg  0.610089  0.616027   \n",
       "                                           macro avg     0.605746  0.597130   \n",
       "                                           for           0.572816  0.453846   \n",
       "         bertabaporu-base xgb              against       0.639474  0.716814   \n",
       "                                           accuracy      0.611018  0.611018   \n",
       "                                           weighted avg  0.605691  0.611018   \n",
       "                                           macro avg     0.600559  0.594946   \n",
       "                                           for           0.561644  0.473077   \n",
       "Timeline -                dummy            against       0.565943  1.000000   \n",
       "                                           accuracy      0.565943  0.565943   \n",
       "                                           weighted avg  0.320292  0.565943   \n",
       "                                           macro avg     0.282972  0.500000   \n",
       "                                           for           0.000000  0.000000   \n",
       "         tf-idf           xgb              against       0.726519  0.775811   \n",
       "                                           accuracy      0.707846  0.707846   \n",
       "                                           weighted avg  0.706034  0.707846   \n",
       "                                           macro avg     0.702922  0.697521   \n",
       "                                           for           0.679325  0.619231   \n",
       "         bertabaporu-base xgb              against       0.691489  0.766962   \n",
       "                                           accuracy      0.674457  0.674457   \n",
       "                                           weighted avg  0.671632  0.674457   \n",
       "                                           macro avg     0.668615  0.660404   \n",
       "                                           for           0.645740  0.553846   \n",
       "\n",
       "metric                                                   f1-score     support  \\\n",
       "target                                                     Church      Church   \n",
       "text_col vectorizer       estimator        class                                \n",
       "Stance   -                dummy            against       0.722814  339.000000   \n",
       "                                           accuracy      0.565943    0.565943   \n",
       "                                           weighted avg  0.409072  599.000000   \n",
       "                                           macro avg     0.361407  599.000000   \n",
       "                                           for           0.000000  260.000000   \n",
       "         tf-idf           xgb              against       0.749280  339.000000   \n",
       "                                           accuracy      0.709516    0.709516   \n",
       "                                           weighted avg  0.708254  599.000000   \n",
       "                                           macro avg     0.702021  599.000000   \n",
       "                                           for           0.654762  260.000000   \n",
       "         bertabaporu-base xgb              against       0.883333  339.000000   \n",
       "                                           accuracy      0.859766    0.859766   \n",
       "                                           weighted avg  0.857696  599.000000   \n",
       "                                           macro avg     0.853801  599.000000   \n",
       "                                           for           0.824268  260.000000   \n",
       "         -                bertabaporu-base against       0.892006  339.000000   \n",
       "                                           accuracy      0.871452    0.871452   \n",
       "                                           weighted avg  0.869969  599.000000   \n",
       "                                           macro avg     0.866621  599.000000   \n",
       "                                           for           0.841237  260.000000   \n",
       "                          llama3:7b        for           0.734426  260.000000   \n",
       "                                           accuracy      0.729549    0.729549   \n",
       "                                           macro avg     0.729458  599.000000   \n",
       "                                           weighted avg  0.728803  599.000000   \n",
       "                                           against       0.724490  339.000000   \n",
       "Texts    -                dummy            against       0.722814  339.000000   \n",
       "                                           accuracy      0.565943    0.565943   \n",
       "                                           weighted avg  0.409072  599.000000   \n",
       "                                           macro avg     0.361407  599.000000   \n",
       "                                           for           0.000000  260.000000   \n",
       "         tf-idf           xgb              against       0.685792  339.000000   \n",
       "                                           accuracy      0.616027    0.616027   \n",
       "                                           weighted avg  0.607942  599.000000   \n",
       "                                           macro avg     0.596115  599.000000   \n",
       "                                           for           0.506438  260.000000   \n",
       "         bertabaporu-base xgb              against       0.675939  339.000000   \n",
       "                                           accuracy      0.611018    0.611018   \n",
       "                                           weighted avg  0.605461  599.000000   \n",
       "                                           macro avg     0.594754  599.000000   \n",
       "                                           for           0.513570  260.000000   \n",
       "Timeline -                dummy            against       0.722814  339.000000   \n",
       "                                           accuracy      0.565943    0.565943   \n",
       "                                           weighted avg  0.409072  599.000000   \n",
       "                                           macro avg     0.361407  599.000000   \n",
       "                                           for           0.000000  260.000000   \n",
       "         tf-idf           xgb              against       0.750357  339.000000   \n",
       "                                           accuracy      0.707846    0.707846   \n",
       "                                           weighted avg  0.705879  599.000000   \n",
       "                                           macro avg     0.699122  599.000000   \n",
       "                                           for           0.647887  260.000000   \n",
       "         bertabaporu-base xgb              against       0.727273  339.000000   \n",
       "                                           accuracy      0.674457    0.674457   \n",
       "                                           weighted avg  0.670412  599.000000   \n",
       "                                           macro avg     0.661773  599.000000   \n",
       "                                           for           0.596273  260.000000   \n",
       "\n",
       "metric                                                  precision    recall  \\\n",
       "target                                                  Bolsonaro Bolsonaro   \n",
       "text_col vectorizer       estimator        class                              \n",
       "Stance   -                dummy            against       0.861702  1.000000   \n",
       "                                           accuracy      0.861702  0.861702   \n",
       "                                           weighted avg  0.742531  0.861702   \n",
       "                                           macro avg     0.430851  0.500000   \n",
       "                                           for           0.000000  0.000000   \n",
       "         tf-idf           xgb              against       0.881356  0.962963   \n",
       "                                           accuracy      0.856383  0.856383   \n",
       "                                           weighted avg  0.822329  0.856383   \n",
       "                                           macro avg     0.667951  0.577635   \n",
       "                                           for           0.454545  0.192308   \n",
       "         bertabaporu-base xgb              against       0.887006  0.969136   \n",
       "                                           accuracy      0.867021  0.867021   \n",
       "                                           weighted avg  0.839770  0.867021   \n",
       "                                           macro avg     0.716230  0.599953   \n",
       "                                           for           0.545455  0.230769   \n",
       "         -                bertabaporu-base against       0.926380  0.932099   \n",
       "                                           accuracy      0.877660  0.877660   \n",
       "                                           weighted avg  0.875711  0.877660   \n",
       "                                           macro avg     0.743190  0.735280   \n",
       "                                           for           0.560000  0.538462   \n",
       "                          llama3:7b        for           0.180000  0.692308   \n",
       "                                           accuracy      0.521277  0.521277   \n",
       "                                           macro avg     0.544545  0.593067   \n",
       "                                           weighted avg  0.808259  0.521277   \n",
       "                                           against       0.909091  0.493827   \n",
       "Texts    -                dummy            against       0.861702  1.000000   \n",
       "                                           accuracy      0.861702  0.861702   \n",
       "                                           weighted avg  0.742531  0.861702   \n",
       "                                           macro avg     0.430851  0.500000   \n",
       "                                           for           0.000000  0.000000   \n",
       "         tf-idf           xgb              against       0.866310  1.000000   \n",
       "                                           accuracy      0.867021  0.867021   \n",
       "                                           weighted avg  0.884799  0.867021   \n",
       "                                           macro avg     0.933155  0.519231   \n",
       "                                           for           1.000000  0.038462   \n",
       "         bertabaporu-base xgb              against       0.864865  0.987654   \n",
       "                                           accuracy      0.856383  0.856383   \n",
       "                                           weighted avg  0.791355  0.856383   \n",
       "                                           macro avg     0.599099  0.513058   \n",
       "                                           for           0.333333  0.038462   \n",
       "Timeline -                dummy            against       0.861702  1.000000   \n",
       "                                           accuracy      0.861702  0.861702   \n",
       "                                           weighted avg  0.742531  0.861702   \n",
       "                                           macro avg     0.430851  0.500000   \n",
       "                                           for           0.000000  0.000000   \n",
       "         tf-idf           xgb              against       0.908571  0.981481   \n",
       "                                           accuracy      0.898936  0.898936   \n",
       "                                           weighted avg  0.889301  0.898936   \n",
       "                                           macro avg     0.838901  0.683048   \n",
       "                                           for           0.769231  0.384615   \n",
       "         bertabaporu-base xgb              against       0.902299  0.969136   \n",
       "                                           accuracy      0.882979  0.882979   \n",
       "                                           weighted avg  0.866419  0.882979   \n",
       "                                           macro avg     0.772578  0.657645   \n",
       "                                           for           0.642857  0.346154   \n",
       "\n",
       "metric                                                   f1-score     support  \\\n",
       "target                                                  Bolsonaro   Bolsonaro   \n",
       "text_col vectorizer       estimator        class                                \n",
       "Stance   -                dummy            against       0.925714  162.000000   \n",
       "                                           accuracy      0.861702    0.861702   \n",
       "                                           weighted avg  0.797690  188.000000   \n",
       "                                           macro avg     0.462857  188.000000   \n",
       "                                           for           0.000000   26.000000   \n",
       "         tf-idf           xgb              against       0.920354  162.000000   \n",
       "                                           accuracy      0.856383    0.856383   \n",
       "                                           weighted avg  0.830449  188.000000   \n",
       "                                           macro avg     0.595312  188.000000   \n",
       "                                           for           0.270270   26.000000   \n",
       "         bertabaporu-base xgb              against       0.926254  162.000000   \n",
       "                                           accuracy      0.867021    0.867021   \n",
       "                                           weighted avg  0.843008  188.000000   \n",
       "                                           macro avg     0.625289  188.000000   \n",
       "                                           for           0.324324   26.000000   \n",
       "         -                bertabaporu-base against       0.929231  162.000000   \n",
       "                                           accuracy      0.877660    0.877660   \n",
       "                                           weighted avg  0.876648  188.000000   \n",
       "                                           macro avg     0.739125  188.000000   \n",
       "                                           for           0.549020   26.000000   \n",
       "                          llama3:7b        for           0.285714   26.000000   \n",
       "                                           accuracy      0.521277    0.521277   \n",
       "                                           macro avg     0.462857  188.000000   \n",
       "                                           weighted avg  0.591003  188.000000   \n",
       "                                           against       0.640000  162.000000   \n",
       "Texts    -                dummy            against       0.925714  162.000000   \n",
       "                                           accuracy      0.861702    0.861702   \n",
       "                                           weighted avg  0.797690  188.000000   \n",
       "                                           macro avg     0.462857  188.000000   \n",
       "                                           for           0.000000   26.000000   \n",
       "         tf-idf           xgb              against       0.928367  162.000000   \n",
       "                                           accuracy      0.867021    0.867021   \n",
       "                                           weighted avg  0.810220  188.000000   \n",
       "                                           macro avg     0.501220  188.000000   \n",
       "                                           for           0.074074   26.000000   \n",
       "         bertabaporu-base xgb              against       0.922190  162.000000   \n",
       "                                           accuracy      0.856383    0.856383   \n",
       "                                           weighted avg  0.804191  188.000000   \n",
       "                                           macro avg     0.495578  188.000000   \n",
       "                                           for           0.068966   26.000000   \n",
       "Timeline -                dummy            against       0.925714  162.000000   \n",
       "                                           accuracy      0.861702    0.861702   \n",
       "                                           weighted avg  0.797690  188.000000   \n",
       "                                           macro avg     0.462857  188.000000   \n",
       "                                           for           0.000000   26.000000   \n",
       "         tf-idf           xgb              against       0.943620  162.000000   \n",
       "                                           accuracy      0.898936    0.898936   \n",
       "                                           weighted avg  0.884042  188.000000   \n",
       "                                           macro avg     0.728220  188.000000   \n",
       "                                           for           0.512821   26.000000   \n",
       "         bertabaporu-base xgb              against       0.934524  162.000000   \n",
       "                                           accuracy      0.882979    0.882979   \n",
       "                                           weighted avg  0.867515  188.000000   \n",
       "                                           macro avg     0.692262  188.000000   \n",
       "                                           for           0.450000   26.000000   \n",
       "\n",
       "metric                                                  precision    recall  \\\n",
       "target                                                    Hydrox.   Hydrox.   \n",
       "text_col vectorizer       estimator        class                              \n",
       "Stance   -                dummy            against       0.503484  1.000000   \n",
       "                                           accuracy      0.503484  0.503484   \n",
       "                                           weighted avg  0.253496  0.503484   \n",
       "                                           macro avg     0.251742  0.500000   \n",
       "                                           for           0.000000  0.000000   \n",
       "         tf-idf           xgb              against       0.716088  0.785467   \n",
       "                                           accuracy      0.735192  0.735192   \n",
       "                                           weighted avg  0.737273  0.735192   \n",
       "                                           macro avg     0.737422  0.734839   \n",
       "                                           for           0.758755  0.684211   \n",
       "         bertabaporu-base xgb              against       0.824324  0.844291   \n",
       "                                           accuracy      0.831010  0.831010   \n",
       "                                           weighted avg  0.831179  0.831010   \n",
       "                                           macro avg     0.831227  0.830917   \n",
       "                                           for           0.838129  0.817544   \n",
       "         -                bertabaporu-base against       0.875940  0.806228   \n",
       "                                           accuracy      0.844948  0.844948   \n",
       "                                           weighted avg  0.847262  0.844948   \n",
       "                                           macro avg     0.847061  0.845219   \n",
       "                                           for           0.818182  0.884211   \n",
       "                          llama3:7b        for           0.625806  0.680702   \n",
       "                                           accuracy      0.639373  0.639373   \n",
       "                                           macro avg     0.640555  0.639659   \n",
       "                                           weighted avg  0.640658  0.639373   \n",
       "                                           against       0.655303  0.598616   \n",
       "Texts    -                dummy            against       0.503484  1.000000   \n",
       "                                           accuracy      0.503484  0.503484   \n",
       "                                           weighted avg  0.253496  0.503484   \n",
       "                                           macro avg     0.251742  0.500000   \n",
       "                                           for           0.000000  0.000000   \n",
       "         tf-idf           xgb              against       0.595166  0.681661   \n",
       "                                           accuracy      0.606272  0.606272   \n",
       "                                           weighted avg  0.608191  0.606272   \n",
       "                                           macro avg     0.608283  0.605743   \n",
       "                                           for           0.621399  0.529825   \n",
       "         bertabaporu-base xgb              against       0.598240  0.705882   \n",
       "                                           accuracy      0.613240  0.613240   \n",
       "                                           weighted avg  0.616588  0.613240   \n",
       "                                           macro avg     0.616717  0.612590   \n",
       "                                           for           0.635193  0.519298   \n",
       "Timeline -                dummy            against       0.503484  1.000000   \n",
       "                                           accuracy      0.503484  0.503484   \n",
       "                                           weighted avg  0.253496  0.503484   \n",
       "                                           macro avg     0.251742  0.500000   \n",
       "                                           for           0.000000  0.000000   \n",
       "         tf-idf           xgb              against       0.896907  0.903114   \n",
       "                                           accuracy      0.898955  0.898955   \n",
       "                                           weighted avg  0.898969  0.898955   \n",
       "                                           macro avg     0.898984  0.898926   \n",
       "                                           for           0.901060  0.894737   \n",
       "         bertabaporu-base xgb              against       0.788530  0.761246   \n",
       "                                           accuracy      0.777003  0.777003   \n",
       "                                           weighted avg  0.777394  0.777003   \n",
       "                                           macro avg     0.777316  0.777114   \n",
       "                                           for           0.766102  0.792982   \n",
       "\n",
       "metric                                                   ...  f1-score  \\\n",
       "target                                                   ...   Sinovac   \n",
       "text_col vectorizer       estimator        class         ...             \n",
       "Stance   -                dummy            against       ...  0.000000   \n",
       "                                           accuracy      ...  0.542636   \n",
       "                                           weighted avg  ...  0.381754   \n",
       "                                           macro avg     ...  0.351759   \n",
       "                                           for           ...  0.703518   \n",
       "         tf-idf           xgb              against       ...  0.719403   \n",
       "                                           accuracy      ...  0.757106   \n",
       "                                           weighted avg  ...  0.755474   \n",
       "                                           macro avg     ...  0.752640   \n",
       "                                           for           ...  0.785877   \n",
       "         bertabaporu-base xgb              against       ...  0.782738   \n",
       "                                           accuracy      ...  0.811370   \n",
       "                                           weighted avg  ...  0.810193   \n",
       "                                           macro avg     ...  0.808036   \n",
       "                                           for           ...  0.833333   \n",
       "         -                bertabaporu-base against       ...  0.823188   \n",
       "                                           accuracy      ...  0.842377   \n",
       "                                           weighted avg  ...  0.841975   \n",
       "                                           macro avg     ...  0.840499   \n",
       "                                           for           ...  0.857809   \n",
       "                          llama3:7b        for           ...  0.625581   \n",
       "                                           accuracy      ...  0.583979   \n",
       "                                           macro avg     ...  0.578779   \n",
       "                                           weighted avg  ...  0.582770   \n",
       "                                           against       ...  0.531977   \n",
       "Texts    -                dummy            against       ...  0.000000   \n",
       "                                           accuracy      ...  0.542636   \n",
       "                                           weighted avg  ...  0.381754   \n",
       "                                           macro avg     ...  0.351759   \n",
       "                                           for           ...  0.703518   \n",
       "         tf-idf           xgb              against       ...  0.643159   \n",
       "                                           accuracy      ...  0.673127   \n",
       "                                           weighted avg  ...  0.673162   \n",
       "                                           macro avg     ...  0.670805   \n",
       "                                           for           ...  0.698451   \n",
       "         bertabaporu-base xgb              against       ...  0.632911   \n",
       "                                           accuracy      ...  0.662791   \n",
       "                                           weighted avg  ...  0.662898   \n",
       "                                           macro avg     ...  0.660542   \n",
       "                                           for           ...  0.688172   \n",
       "Timeline -                dummy            against       ...  0.000000   \n",
       "                                           accuracy      ...  0.542636   \n",
       "                                           weighted avg  ...  0.381754   \n",
       "                                           macro avg     ...  0.351759   \n",
       "                                           for           ...  0.703518   \n",
       "         tf-idf           xgb              against       ...  0.843227   \n",
       "                                           accuracy      ...  0.866925   \n",
       "                                           weighted avg  ...  0.865569   \n",
       "                                           macro avg     ...  0.863813   \n",
       "                                           for           ...  0.884400   \n",
       "         bertabaporu-base xgb              against       ...  0.746988   \n",
       "                                           accuracy      ...  0.782946   \n",
       "                                           weighted avg  ...  0.781156   \n",
       "                                           macro avg     ...  0.778471   \n",
       "                                           for           ...  0.809955   \n",
       "\n",
       "metric                                                      support precision  \\\n",
       "target                                                      Sinovac  Globo TV   \n",
       "text_col vectorizer       estimator        class                                \n",
       "Stance   -                dummy            against       354.000000  0.000000   \n",
       "                                           accuracy        0.542636  0.593674   \n",
       "                                           weighted avg  774.000000  0.352449   \n",
       "                                           macro avg     774.000000  0.296837   \n",
       "                                           for           420.000000  0.593674   \n",
       "         tf-idf           xgb              against       354.000000  0.653846   \n",
       "                                           accuracy        0.757106  0.690998   \n",
       "                                           weighted avg  774.000000  0.686106   \n",
       "                                           macro avg     774.000000  0.681016   \n",
       "                                           for           420.000000  0.708185   \n",
       "         bertabaporu-base xgb              against       354.000000  0.751553   \n",
       "                                           accuracy        0.811370  0.790754   \n",
       "                                           weighted avg  774.000000  0.789813   \n",
       "                                           macro avg     774.000000  0.783776   \n",
       "                                           for           420.000000  0.816000   \n",
       "         -                bertabaporu-base against       354.000000  0.814607   \n",
       "                                           accuracy        0.842377  0.866180   \n",
       "                                           weighted avg  774.000000  0.868615   \n",
       "                                           macro avg     774.000000  0.860093   \n",
       "                                           for           420.000000  0.905579   \n",
       "                          llama3:7b        for           420.000000  0.779359   \n",
       "                                           accuracy        0.583979  0.788321   \n",
       "                                           macro avg     774.000000  0.793526   \n",
       "                                           weighted avg  774.000000  0.790872   \n",
       "                                           against       354.000000  0.807692   \n",
       "Texts    -                dummy            against       354.000000  0.000000   \n",
       "                                           accuracy        0.542636  0.593674   \n",
       "                                           weighted avg  774.000000  0.352449   \n",
       "                                           macro avg     774.000000  0.296837   \n",
       "                                           for           420.000000  0.593674   \n",
       "         tf-idf           xgb              against       354.000000  0.504673   \n",
       "                                           accuracy        0.673127  0.596107   \n",
       "                                           weighted avg  774.000000  0.578061   \n",
       "                                           macro avg     774.000000  0.566481   \n",
       "                                           for           420.000000  0.628289   \n",
       "         bertabaporu-base xgb              against       354.000000  0.481818   \n",
       "                                           accuracy        0.662791  0.583942   \n",
       "                                           weighted avg  774.000000  0.564603   \n",
       "                                           macro avg     774.000000  0.551540   \n",
       "                                           for           420.000000  0.621262   \n",
       "Timeline -                dummy            against       354.000000  0.000000   \n",
       "                                           accuracy        0.542636  0.593674   \n",
       "                                           weighted avg  774.000000  0.352449   \n",
       "                                           macro avg     774.000000  0.296837   \n",
       "                                           for           420.000000  0.593674   \n",
       "         tf-idf           xgb              against       354.000000  0.592593   \n",
       "                                           accuracy        0.866925  0.642336   \n",
       "                                           weighted avg  774.000000  0.632650   \n",
       "                                           macro avg     774.000000  0.626329   \n",
       "                                           for           420.000000  0.660066   \n",
       "         bertabaporu-base xgb              against       354.000000  0.550000   \n",
       "                                           accuracy        0.782946  0.622871   \n",
       "                                           weighted avg  774.000000  0.611101   \n",
       "                                           macro avg     774.000000  0.601460   \n",
       "                                           for           420.000000  0.652921   \n",
       "\n",
       "metric                                                     recall  f1-score  \\\n",
       "target                                                   Globo TV  Globo TV   \n",
       "text_col vectorizer       estimator        class                              \n",
       "Stance   -                dummy            against       0.000000  0.000000   \n",
       "                                           accuracy      0.593674  0.593674   \n",
       "                                           weighted avg  0.593674  0.442310   \n",
       "                                           macro avg     0.500000  0.372519   \n",
       "                                           for           1.000000  0.745038   \n",
       "         tf-idf           xgb              against       0.508982  0.572391   \n",
       "                                           accuracy      0.690998  0.690998   \n",
       "                                           weighted avg  0.690998  0.682639   \n",
       "                                           macro avg     0.662278  0.665243   \n",
       "                                           for           0.815574  0.758095   \n",
       "         bertabaporu-base xgb              against       0.724551  0.737805   \n",
       "                                           accuracy      0.790754  0.790754   \n",
       "                                           weighted avg  0.790754  0.790111   \n",
       "                                           macro avg     0.780308  0.781858   \n",
       "                                           for           0.836066  0.825911   \n",
       "         -                bertabaporu-base against       0.868263  0.840580   \n",
       "                                           accuracy      0.866180  0.866180   \n",
       "                                           weighted avg  0.866180  0.866770   \n",
       "                                           macro avg     0.866509  0.862638   \n",
       "                                           for           0.864754  0.884696   \n",
       "                          llama3:7b        for           0.897541  0.834286   \n",
       "                                           accuracy      0.788321  0.788321   \n",
       "                                           macro avg     0.763142  0.770678   \n",
       "                                           weighted avg  0.788321  0.782595   \n",
       "                                           against       0.628743  0.707071   \n",
       "Texts    -                dummy            against       0.000000  0.000000   \n",
       "                                           accuracy      0.593674  0.593674   \n",
       "                                           weighted avg  0.593674  0.442310   \n",
       "                                           macro avg     0.500000  0.372519   \n",
       "                                           for           1.000000  0.745038   \n",
       "         tf-idf           xgb              against       0.323353  0.394161   \n",
       "                                           accuracy      0.596107  0.596107   \n",
       "                                           weighted avg  0.596107  0.573996   \n",
       "                                           macro avg     0.553070  0.545620   \n",
       "                                           for           0.782787  0.697080   \n",
       "         bertabaporu-base xgb              against       0.317365  0.382671   \n",
       "                                           accuracy      0.583942  0.583942   \n",
       "                                           weighted avg  0.583942  0.562891   \n",
       "                                           macro avg     0.541879  0.534455   \n",
       "                                           for           0.766393  0.686239   \n",
       "Timeline -                dummy            against       0.000000  0.000000   \n",
       "                                           accuracy      0.593674  0.593674   \n",
       "                                           weighted avg  0.593674  0.442310   \n",
       "                                           macro avg     0.500000  0.372519   \n",
       "                                           for           1.000000  0.745038   \n",
       "         tf-idf           xgb              against       0.383234  0.465455   \n",
       "                                           accuracy      0.642336  0.642336   \n",
       "                                           weighted avg  0.642336  0.623257   \n",
       "                                           macro avg     0.601453  0.598358   \n",
       "                                           for           0.819672  0.731261   \n",
       "         bertabaporu-base xgb              against       0.395210  0.459930   \n",
       "                                           accuracy      0.622871  0.622871   \n",
       "                                           weighted avg  0.622871  0.608557   \n",
       "                                           macro avg     0.586949  0.585105   \n",
       "                                           for           0.778689  0.710280   \n",
       "\n",
       "metric                                                      support precision  \\\n",
       "target                                                     Globo TV      Lula   \n",
       "text_col vectorizer       estimator        class                                \n",
       "Stance   -                dummy            against       167.000000  0.525735   \n",
       "                                           accuracy        0.593674  0.525735   \n",
       "                                           weighted avg  411.000000  0.276398   \n",
       "                                           macro avg     411.000000  0.262868   \n",
       "                                           for           244.000000  0.000000   \n",
       "         tf-idf           xgb              against       167.000000  0.689922   \n",
       "                                           accuracy        0.690998  0.654412   \n",
       "                                           weighted avg  411.000000  0.657888   \n",
       "                                           macro avg     411.000000  0.656150   \n",
       "                                           for           244.000000  0.622378   \n",
       "         bertabaporu-base xgb              against       167.000000  0.766667   \n",
       "                                           accuracy        0.790754  0.768382   \n",
       "                                           weighted avg  411.000000  0.768481   \n",
       "                                           macro avg     411.000000  0.768579   \n",
       "                                           for           244.000000  0.770492   \n",
       "         -                bertabaporu-base against       167.000000  0.789474   \n",
       "                                           accuracy        0.866180  0.797794   \n",
       "                                           weighted avg  411.000000  0.798418   \n",
       "                                           macro avg     411.000000  0.798904   \n",
       "                                           for           244.000000  0.808333   \n",
       "                          llama3:7b        for           244.000000  0.633880   \n",
       "                                           accuracy        0.788321  0.705882   \n",
       "                                           macro avg     411.000000  0.743906   \n",
       "                                           weighted avg  411.000000  0.749569   \n",
       "                                           against       167.000000  0.853933   \n",
       "Texts    -                dummy            against       167.000000  0.525735   \n",
       "                                           accuracy        0.593674  0.525735   \n",
       "                                           weighted avg  411.000000  0.276398   \n",
       "                                           macro avg     411.000000  0.262868   \n",
       "                                           for           244.000000  0.000000   \n",
       "         tf-idf           xgb              against       167.000000  0.600000   \n",
       "                                           accuracy        0.596107  0.580882   \n",
       "                                           weighted avg  411.000000  0.580581   \n",
       "                                           macro avg     411.000000  0.579528   \n",
       "                                           for           244.000000  0.559055   \n",
       "         bertabaporu-base xgb              against       167.000000  0.587097   \n",
       "                                           accuracy        0.583942  0.573529   \n",
       "                                           weighted avg  411.000000  0.572138   \n",
       "                                           macro avg     411.000000  0.571326   \n",
       "                                           for           244.000000  0.555556   \n",
       "Timeline -                dummy            against       167.000000  0.525735   \n",
       "                                           accuracy        0.593674  0.525735   \n",
       "                                           weighted avg  411.000000  0.276398   \n",
       "                                           macro avg     411.000000  0.262868   \n",
       "                                           for           244.000000  0.000000   \n",
       "         tf-idf           xgb              against       167.000000  0.760274   \n",
       "                                           accuracy        0.642336  0.753676   \n",
       "                                           weighted avg  411.000000  0.753519   \n",
       "                                           macro avg     411.000000  0.753153   \n",
       "                                           for           244.000000  0.746032   \n",
       "         bertabaporu-base xgb              against       167.000000  0.648148   \n",
       "                                           accuracy        0.622871  0.650735   \n",
       "                                           weighted avg  411.000000  0.651182   \n",
       "                                           macro avg     411.000000  0.651347   \n",
       "                                           for           244.000000  0.654545   \n",
       "\n",
       "metric                                                     recall  f1-score  \\\n",
       "target                                                       Lula      Lula   \n",
       "text_col vectorizer       estimator        class                              \n",
       "Stance   -                dummy            against       1.000000  0.689157   \n",
       "                                           accuracy      0.525735  0.525735   \n",
       "                                           weighted avg  0.525735  0.362314   \n",
       "                                           macro avg     0.500000  0.344578   \n",
       "                                           for           0.000000  0.000000   \n",
       "         tf-idf           xgb              against       0.622378  0.654412   \n",
       "                                           accuracy      0.654412  0.654412   \n",
       "                                           weighted avg  0.654412  0.654412   \n",
       "                                           macro avg     0.656150  0.654412   \n",
       "                                           for           0.689922  0.654412   \n",
       "         bertabaporu-base xgb              against       0.804196  0.784983   \n",
       "                                           accuracy      0.768382  0.768382   \n",
       "                                           weighted avg  0.768382  0.767919   \n",
       "                                           macro avg     0.766439  0.766993   \n",
       "                                           for           0.728682  0.749004   \n",
       "         -                bertabaporu-base against       0.839161  0.813559   \n",
       "                                           accuracy      0.797794  0.797794   \n",
       "                                           weighted avg  0.797794  0.797224   \n",
       "                                           macro avg     0.795549  0.796338   \n",
       "                                           for           0.751938  0.779116   \n",
       "                          llama3:7b        for           0.899225  0.743590   \n",
       "                                           accuracy      0.705882  0.705882   \n",
       "                                           macro avg     0.715347  0.699381   \n",
       "                                           weighted avg  0.705882  0.697106   \n",
       "                                           against       0.531469  0.655172   \n",
       "Texts    -                dummy            against       1.000000  0.689157   \n",
       "                                           accuracy      0.525735  0.525735   \n",
       "                                           weighted avg  0.525735  0.362314   \n",
       "                                           macro avg     0.500000  0.344578   \n",
       "                                           for           0.000000  0.000000   \n",
       "         tf-idf           xgb              against       0.608392  0.604167   \n",
       "                                           accuracy      0.580882  0.580882   \n",
       "                                           weighted avg  0.580882  0.580700   \n",
       "                                           macro avg     0.579390  0.579427   \n",
       "                                           for           0.550388  0.554688   \n",
       "         bertabaporu-base xgb              against       0.636364  0.610738   \n",
       "                                           accuracy      0.573529  0.573529   \n",
       "                                           weighted avg  0.573529  0.571714   \n",
       "                                           macro avg     0.570120  0.569597   \n",
       "                                           for           0.503876  0.528455   \n",
       "Timeline -                dummy            against       1.000000  0.689157   \n",
       "                                           accuracy      0.525735  0.525735   \n",
       "                                           weighted avg  0.525735  0.362314   \n",
       "                                           macro avg     0.500000  0.344578   \n",
       "                                           for           0.000000  0.000000   \n",
       "         tf-idf           xgb              against       0.776224  0.768166   \n",
       "                                           accuracy      0.753676  0.753676   \n",
       "                                           weighted avg  0.753676  0.753506   \n",
       "                                           macro avg     0.752453  0.752710   \n",
       "                                           for           0.728682  0.737255   \n",
       "         bertabaporu-base xgb              against       0.734266  0.688525   \n",
       "                                           accuracy      0.650735  0.650735   \n",
       "                                           weighted avg  0.650735  0.647731   \n",
       "                                           macro avg     0.646203  0.645518   \n",
       "                                           for           0.558140  0.602510   \n",
       "\n",
       "metric                                                      support  \n",
       "target                                                         Lula  \n",
       "text_col vectorizer       estimator        class                     \n",
       "Stance   -                dummy            against       143.000000  \n",
       "                                           accuracy        0.525735  \n",
       "                                           weighted avg  272.000000  \n",
       "                                           macro avg     272.000000  \n",
       "                                           for           129.000000  \n",
       "         tf-idf           xgb              against       143.000000  \n",
       "                                           accuracy        0.654412  \n",
       "                                           weighted avg  272.000000  \n",
       "                                           macro avg     272.000000  \n",
       "                                           for           129.000000  \n",
       "         bertabaporu-base xgb              against       143.000000  \n",
       "                                           accuracy        0.768382  \n",
       "                                           weighted avg  272.000000  \n",
       "                                           macro avg     272.000000  \n",
       "                                           for           129.000000  \n",
       "         -                bertabaporu-base against       143.000000  \n",
       "                                           accuracy        0.797794  \n",
       "                                           weighted avg  272.000000  \n",
       "                                           macro avg     272.000000  \n",
       "                                           for           129.000000  \n",
       "                          llama3:7b        for           129.000000  \n",
       "                                           accuracy        0.705882  \n",
       "                                           macro avg     272.000000  \n",
       "                                           weighted avg  272.000000  \n",
       "                                           against       143.000000  \n",
       "Texts    -                dummy            against       143.000000  \n",
       "                                           accuracy        0.525735  \n",
       "                                           weighted avg  272.000000  \n",
       "                                           macro avg     272.000000  \n",
       "                                           for           129.000000  \n",
       "         tf-idf           xgb              against       143.000000  \n",
       "                                           accuracy        0.580882  \n",
       "                                           weighted avg  272.000000  \n",
       "                                           macro avg     272.000000  \n",
       "                                           for           129.000000  \n",
       "         bertabaporu-base xgb              against       143.000000  \n",
       "                                           accuracy        0.573529  \n",
       "                                           weighted avg  272.000000  \n",
       "                                           macro avg     272.000000  \n",
       "                                           for           129.000000  \n",
       "Timeline -                dummy            against       143.000000  \n",
       "                                           accuracy        0.525735  \n",
       "                                           weighted avg  272.000000  \n",
       "                                           macro avg     272.000000  \n",
       "                                           for           129.000000  \n",
       "         tf-idf           xgb              against       143.000000  \n",
       "                                           accuracy        0.753676  \n",
       "                                           weighted avg  272.000000  \n",
       "                                           macro avg     272.000000  \n",
       "                                           for           129.000000  \n",
       "         bertabaporu-base xgb              against       143.000000  \n",
       "                                           accuracy        0.650735  \n",
       "                                           weighted avg  272.000000  \n",
       "                                           macro avg     272.000000  \n",
       "                                           for           129.000000  \n",
       "\n",
       "[55 rows x 24 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_results_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_results_final.to_excel(\"../reports/table_complete_results.xlsx\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create table f1 macro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>metric</th>\n",
       "      <th colspan=\"7\" halign=\"left\">f1-score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>Church</th>\n",
       "      <th>Bolsonaro</th>\n",
       "      <th>Hydrox.</th>\n",
       "      <th>Sinovac</th>\n",
       "      <th>Globo TV</th>\n",
       "      <th>Lula</th>\n",
       "      <th>overall</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text_col</th>\n",
       "      <th>vectorizer</th>\n",
       "      <th>estimator</th>\n",
       "      <th>class</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">Stance</th>\n",
       "      <th>-</th>\n",
       "      <th>dummy</th>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.361407</td>\n",
       "      <td>0.462857</td>\n",
       "      <td>0.334878</td>\n",
       "      <td>0.351759</td>\n",
       "      <td>0.372519</td>\n",
       "      <td>0.344578</td>\n",
       "      <td>0.371333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tf-idf</th>\n",
       "      <th>xgb</th>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.702021</td>\n",
       "      <td>0.595312</td>\n",
       "      <td>0.734366</td>\n",
       "      <td>0.752640</td>\n",
       "      <td>0.665243</td>\n",
       "      <td>0.654412</td>\n",
       "      <td>0.683999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bertabaporu-base</th>\n",
       "      <th>xgb</th>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.853801</td>\n",
       "      <td>0.625289</td>\n",
       "      <td>0.830948</td>\n",
       "      <td>0.808036</td>\n",
       "      <td>0.781858</td>\n",
       "      <td>0.766993</td>\n",
       "      <td>0.777821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">-</th>\n",
       "      <th>bertabaporu-base</th>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.866621</td>\n",
       "      <td>0.739125</td>\n",
       "      <td>0.844778</td>\n",
       "      <td>0.840499</td>\n",
       "      <td>0.862638</td>\n",
       "      <td>0.796338</td>\n",
       "      <td>0.825000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>llama3:7b</th>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.729458</td>\n",
       "      <td>0.462857</td>\n",
       "      <td>0.638889</td>\n",
       "      <td>0.578779</td>\n",
       "      <td>0.770678</td>\n",
       "      <td>0.699381</td>\n",
       "      <td>0.646674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">Texts</th>\n",
       "      <th>-</th>\n",
       "      <th>dummy</th>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.361407</td>\n",
       "      <td>0.462857</td>\n",
       "      <td>0.334878</td>\n",
       "      <td>0.351759</td>\n",
       "      <td>0.372519</td>\n",
       "      <td>0.344578</td>\n",
       "      <td>0.371333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tf-idf</th>\n",
       "      <th>xgb</th>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.596115</td>\n",
       "      <td>0.501220</td>\n",
       "      <td>0.603727</td>\n",
       "      <td>0.670805</td>\n",
       "      <td>0.545620</td>\n",
       "      <td>0.579427</td>\n",
       "      <td>0.582819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bertabaporu-base</th>\n",
       "      <th>xgb</th>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.594754</td>\n",
       "      <td>0.495578</td>\n",
       "      <td>0.609524</td>\n",
       "      <td>0.660542</td>\n",
       "      <td>0.534455</td>\n",
       "      <td>0.569597</td>\n",
       "      <td>0.577408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">Timeline</th>\n",
       "      <th>-</th>\n",
       "      <th>dummy</th>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.361407</td>\n",
       "      <td>0.462857</td>\n",
       "      <td>0.334878</td>\n",
       "      <td>0.351759</td>\n",
       "      <td>0.372519</td>\n",
       "      <td>0.344578</td>\n",
       "      <td>0.371333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tf-idf</th>\n",
       "      <th>xgb</th>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.699122</td>\n",
       "      <td>0.728220</td>\n",
       "      <td>0.898944</td>\n",
       "      <td>0.863813</td>\n",
       "      <td>0.598358</td>\n",
       "      <td>0.752710</td>\n",
       "      <td>0.756861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bertabaporu-base</th>\n",
       "      <th>xgb</th>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.661773</td>\n",
       "      <td>0.692262</td>\n",
       "      <td>0.776979</td>\n",
       "      <td>0.778471</td>\n",
       "      <td>0.585105</td>\n",
       "      <td>0.645518</td>\n",
       "      <td>0.690018</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "metric                                                f1-score            \\\n",
       "target                                                  Church Bolsonaro   \n",
       "text_col vectorizer       estimator        class                           \n",
       "Stance   -                dummy            macro avg  0.361407  0.462857   \n",
       "         tf-idf           xgb              macro avg  0.702021  0.595312   \n",
       "         bertabaporu-base xgb              macro avg  0.853801  0.625289   \n",
       "         -                bertabaporu-base macro avg  0.866621  0.739125   \n",
       "                          llama3:7b        macro avg  0.729458  0.462857   \n",
       "Texts    -                dummy            macro avg  0.361407  0.462857   \n",
       "         tf-idf           xgb              macro avg  0.596115  0.501220   \n",
       "         bertabaporu-base xgb              macro avg  0.594754  0.495578   \n",
       "Timeline -                dummy            macro avg  0.361407  0.462857   \n",
       "         tf-idf           xgb              macro avg  0.699122  0.728220   \n",
       "         bertabaporu-base xgb              macro avg  0.661773  0.692262   \n",
       "\n",
       "metric                                                                    \\\n",
       "target                                                 Hydrox.   Sinovac   \n",
       "text_col vectorizer       estimator        class                           \n",
       "Stance   -                dummy            macro avg  0.334878  0.351759   \n",
       "         tf-idf           xgb              macro avg  0.734366  0.752640   \n",
       "         bertabaporu-base xgb              macro avg  0.830948  0.808036   \n",
       "         -                bertabaporu-base macro avg  0.844778  0.840499   \n",
       "                          llama3:7b        macro avg  0.638889  0.578779   \n",
       "Texts    -                dummy            macro avg  0.334878  0.351759   \n",
       "         tf-idf           xgb              macro avg  0.603727  0.670805   \n",
       "         bertabaporu-base xgb              macro avg  0.609524  0.660542   \n",
       "Timeline -                dummy            macro avg  0.334878  0.351759   \n",
       "         tf-idf           xgb              macro avg  0.898944  0.863813   \n",
       "         bertabaporu-base xgb              macro avg  0.776979  0.778471   \n",
       "\n",
       "metric                                                                    \\\n",
       "target                                                Globo TV      Lula   \n",
       "text_col vectorizer       estimator        class                           \n",
       "Stance   -                dummy            macro avg  0.372519  0.344578   \n",
       "         tf-idf           xgb              macro avg  0.665243  0.654412   \n",
       "         bertabaporu-base xgb              macro avg  0.781858  0.766993   \n",
       "         -                bertabaporu-base macro avg  0.862638  0.796338   \n",
       "                          llama3:7b        macro avg  0.770678  0.699381   \n",
       "Texts    -                dummy            macro avg  0.372519  0.344578   \n",
       "         tf-idf           xgb              macro avg  0.545620  0.579427   \n",
       "         bertabaporu-base xgb              macro avg  0.534455  0.569597   \n",
       "Timeline -                dummy            macro avg  0.372519  0.344578   \n",
       "         tf-idf           xgb              macro avg  0.598358  0.752710   \n",
       "         bertabaporu-base xgb              macro avg  0.585105  0.645518   \n",
       "\n",
       "metric                                                          \n",
       "target                                                 overall  \n",
       "text_col vectorizer       estimator        class                \n",
       "Stance   -                dummy            macro avg  0.371333  \n",
       "         tf-idf           xgb              macro avg  0.683999  \n",
       "         bertabaporu-base xgb              macro avg  0.777821  \n",
       "         -                bertabaporu-base macro avg  0.825000  \n",
       "                          llama3:7b        macro avg  0.646674  \n",
       "Texts    -                dummy            macro avg  0.371333  \n",
       "         tf-idf           xgb              macro avg  0.582819  \n",
       "         bertabaporu-base xgb              macro avg  0.577408  \n",
       "Timeline -                dummy            macro avg  0.371333  \n",
       "         tf-idf           xgb              macro avg  0.756861  \n",
       "         bertabaporu-base xgb              macro avg  0.690018  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask_f1 = [True if  \"f1-score\" in col else False for col in df_results_final.columns]\n",
    "mask_macro = [True if  \"macro avg\" in col else False for col in df_results_final.index]\n",
    "\n",
    "f1_macro_df = df_results_final.loc[mask_macro,mask_f1]\n",
    "f1_macro_df[('f1-score','overall')] = f1_macro_df.mean(axis=1)\n",
    "\n",
    "f1_macro_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Table for docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>metric</th>\n",
       "      <th colspan=\"7\" halign=\"left\">f1-score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>Church</th>\n",
       "      <th>Bolsonaro</th>\n",
       "      <th>Hydrox.</th>\n",
       "      <th>Sinovac</th>\n",
       "      <th>Globo TV</th>\n",
       "      <th>Lula</th>\n",
       "      <th>overall</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>text_col</th>\n",
       "      <th>vectorizer</th>\n",
       "      <th>estimator</th>\n",
       "      <th>class</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">Stance</th>\n",
       "      <th>-</th>\n",
       "      <th>dummy</th>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.361407</td>\n",
       "      <td>0.462857</td>\n",
       "      <td>0.334878</td>\n",
       "      <td>0.351759</td>\n",
       "      <td>0.372519</td>\n",
       "      <td>0.344578</td>\n",
       "      <td>0.371333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tf-idf</th>\n",
       "      <th>xgb</th>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.702021</td>\n",
       "      <td>0.595312</td>\n",
       "      <td>0.734366</td>\n",
       "      <td>0.752640</td>\n",
       "      <td>0.665243</td>\n",
       "      <td>0.654412</td>\n",
       "      <td>0.683999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bertabaporu-base</th>\n",
       "      <th>xgb</th>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.853801</td>\n",
       "      <td>0.625289</td>\n",
       "      <td>0.830948</td>\n",
       "      <td>0.808036</td>\n",
       "      <td>0.781858</td>\n",
       "      <td>0.766993</td>\n",
       "      <td>0.777821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">-</th>\n",
       "      <th>bertabaporu-base</th>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.866621</td>\n",
       "      <td>0.739125</td>\n",
       "      <td>0.844778</td>\n",
       "      <td>0.840499</td>\n",
       "      <td>0.862638</td>\n",
       "      <td>0.796338</td>\n",
       "      <td>0.825000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>llama3:7b</th>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.729458</td>\n",
       "      <td>0.462857</td>\n",
       "      <td>0.638889</td>\n",
       "      <td>0.578779</td>\n",
       "      <td>0.770678</td>\n",
       "      <td>0.699381</td>\n",
       "      <td>0.646674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">Texts</th>\n",
       "      <th>-</th>\n",
       "      <th>dummy</th>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.361407</td>\n",
       "      <td>0.462857</td>\n",
       "      <td>0.334878</td>\n",
       "      <td>0.351759</td>\n",
       "      <td>0.372519</td>\n",
       "      <td>0.344578</td>\n",
       "      <td>0.371333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tf-idf</th>\n",
       "      <th>xgb</th>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.596115</td>\n",
       "      <td>0.501220</td>\n",
       "      <td>0.603727</td>\n",
       "      <td>0.670805</td>\n",
       "      <td>0.545620</td>\n",
       "      <td>0.579427</td>\n",
       "      <td>0.582819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bertabaporu-base</th>\n",
       "      <th>xgb</th>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.594754</td>\n",
       "      <td>0.495578</td>\n",
       "      <td>0.609524</td>\n",
       "      <td>0.660542</td>\n",
       "      <td>0.534455</td>\n",
       "      <td>0.569597</td>\n",
       "      <td>0.577408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">Timeline</th>\n",
       "      <th>-</th>\n",
       "      <th>dummy</th>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.361407</td>\n",
       "      <td>0.462857</td>\n",
       "      <td>0.334878</td>\n",
       "      <td>0.351759</td>\n",
       "      <td>0.372519</td>\n",
       "      <td>0.344578</td>\n",
       "      <td>0.371333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tf-idf</th>\n",
       "      <th>xgb</th>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.699122</td>\n",
       "      <td>0.728220</td>\n",
       "      <td>0.898944</td>\n",
       "      <td>0.863813</td>\n",
       "      <td>0.598358</td>\n",
       "      <td>0.752710</td>\n",
       "      <td>0.756861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bertabaporu-base</th>\n",
       "      <th>xgb</th>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.661773</td>\n",
       "      <td>0.692262</td>\n",
       "      <td>0.776979</td>\n",
       "      <td>0.778471</td>\n",
       "      <td>0.585105</td>\n",
       "      <td>0.645518</td>\n",
       "      <td>0.690018</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "metric                                                f1-score            \\\n",
       "target                                                  Church Bolsonaro   \n",
       "text_col vectorizer       estimator        class                           \n",
       "Stance   -                dummy            macro avg  0.361407  0.462857   \n",
       "         tf-idf           xgb              macro avg  0.702021  0.595312   \n",
       "         bertabaporu-base xgb              macro avg  0.853801  0.625289   \n",
       "         -                bertabaporu-base macro avg  0.866621  0.739125   \n",
       "                          llama3:7b        macro avg  0.729458  0.462857   \n",
       "Texts    -                dummy            macro avg  0.361407  0.462857   \n",
       "         tf-idf           xgb              macro avg  0.596115  0.501220   \n",
       "         bertabaporu-base xgb              macro avg  0.594754  0.495578   \n",
       "Timeline -                dummy            macro avg  0.361407  0.462857   \n",
       "         tf-idf           xgb              macro avg  0.699122  0.728220   \n",
       "         bertabaporu-base xgb              macro avg  0.661773  0.692262   \n",
       "\n",
       "metric                                                                    \\\n",
       "target                                                 Hydrox.   Sinovac   \n",
       "text_col vectorizer       estimator        class                           \n",
       "Stance   -                dummy            macro avg  0.334878  0.351759   \n",
       "         tf-idf           xgb              macro avg  0.734366  0.752640   \n",
       "         bertabaporu-base xgb              macro avg  0.830948  0.808036   \n",
       "         -                bertabaporu-base macro avg  0.844778  0.840499   \n",
       "                          llama3:7b        macro avg  0.638889  0.578779   \n",
       "Texts    -                dummy            macro avg  0.334878  0.351759   \n",
       "         tf-idf           xgb              macro avg  0.603727  0.670805   \n",
       "         bertabaporu-base xgb              macro avg  0.609524  0.660542   \n",
       "Timeline -                dummy            macro avg  0.334878  0.351759   \n",
       "         tf-idf           xgb              macro avg  0.898944  0.863813   \n",
       "         bertabaporu-base xgb              macro avg  0.776979  0.778471   \n",
       "\n",
       "metric                                                                    \\\n",
       "target                                                Globo TV      Lula   \n",
       "text_col vectorizer       estimator        class                           \n",
       "Stance   -                dummy            macro avg  0.372519  0.344578   \n",
       "         tf-idf           xgb              macro avg  0.665243  0.654412   \n",
       "         bertabaporu-base xgb              macro avg  0.781858  0.766993   \n",
       "         -                bertabaporu-base macro avg  0.862638  0.796338   \n",
       "                          llama3:7b        macro avg  0.770678  0.699381   \n",
       "Texts    -                dummy            macro avg  0.372519  0.344578   \n",
       "         tf-idf           xgb              macro avg  0.545620  0.579427   \n",
       "         bertabaporu-base xgb              macro avg  0.534455  0.569597   \n",
       "Timeline -                dummy            macro avg  0.372519  0.344578   \n",
       "         tf-idf           xgb              macro avg  0.598358  0.752710   \n",
       "         bertabaporu-base xgb              macro avg  0.585105  0.645518   \n",
       "\n",
       "metric                                                          \n",
       "target                                                 overall  \n",
       "text_col vectorizer       estimator        class                \n",
       "Stance   -                dummy            macro avg  0.371333  \n",
       "         tf-idf           xgb              macro avg  0.683999  \n",
       "         bertabaporu-base xgb              macro avg  0.777821  \n",
       "         -                bertabaporu-base macro avg  0.825000  \n",
       "                          llama3:7b        macro avg  0.646674  \n",
       "Texts    -                dummy            macro avg  0.371333  \n",
       "         tf-idf           xgb              macro avg  0.582819  \n",
       "         bertabaporu-base xgb              macro avg  0.577408  \n",
       "Timeline -                dummy            macro avg  0.371333  \n",
       "         tf-idf           xgb              macro avg  0.756861  \n",
       "         bertabaporu-base xgb              macro avg  0.690018  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_report = f1_macro_df.copy()\n",
    "f1_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>metric</th>\n",
       "      <th>text_col</th>\n",
       "      <th>vectorizer</th>\n",
       "      <th>estimator</th>\n",
       "      <th>class</th>\n",
       "      <th colspan=\"7\" halign=\"left\">f1-score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>target</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Church</th>\n",
       "      <th>Bolsonaro</th>\n",
       "      <th>Hydrox.</th>\n",
       "      <th>Sinovac</th>\n",
       "      <th>Globo TV</th>\n",
       "      <th>Lula</th>\n",
       "      <th>overall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Stance</td>\n",
       "      <td>-</td>\n",
       "      <td>dummy</td>\n",
       "      <td>macro avg</td>\n",
       "      <td>0.361407</td>\n",
       "      <td>0.462857</td>\n",
       "      <td>0.334878</td>\n",
       "      <td>0.351759</td>\n",
       "      <td>0.372519</td>\n",
       "      <td>0.344578</td>\n",
       "      <td>0.371333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Stance</td>\n",
       "      <td>tf-idf</td>\n",
       "      <td>xgb</td>\n",
       "      <td>macro avg</td>\n",
       "      <td>0.702021</td>\n",
       "      <td>0.595312</td>\n",
       "      <td>0.734366</td>\n",
       "      <td>0.752640</td>\n",
       "      <td>0.665243</td>\n",
       "      <td>0.654412</td>\n",
       "      <td>0.683999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Stance</td>\n",
       "      <td>bertabaporu-base</td>\n",
       "      <td>xgb</td>\n",
       "      <td>macro avg</td>\n",
       "      <td>0.853801</td>\n",
       "      <td>0.625289</td>\n",
       "      <td>0.830948</td>\n",
       "      <td>0.808036</td>\n",
       "      <td>0.781858</td>\n",
       "      <td>0.766993</td>\n",
       "      <td>0.777821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Stance</td>\n",
       "      <td>-</td>\n",
       "      <td>bertabaporu-base</td>\n",
       "      <td>macro avg</td>\n",
       "      <td>0.866621</td>\n",
       "      <td>0.739125</td>\n",
       "      <td>0.844778</td>\n",
       "      <td>0.840499</td>\n",
       "      <td>0.862638</td>\n",
       "      <td>0.796338</td>\n",
       "      <td>0.825000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Stance</td>\n",
       "      <td>-</td>\n",
       "      <td>llama3:7b</td>\n",
       "      <td>macro avg</td>\n",
       "      <td>0.729458</td>\n",
       "      <td>0.462857</td>\n",
       "      <td>0.638889</td>\n",
       "      <td>0.578779</td>\n",
       "      <td>0.770678</td>\n",
       "      <td>0.699381</td>\n",
       "      <td>0.646674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Texts</td>\n",
       "      <td>-</td>\n",
       "      <td>dummy</td>\n",
       "      <td>macro avg</td>\n",
       "      <td>0.361407</td>\n",
       "      <td>0.462857</td>\n",
       "      <td>0.334878</td>\n",
       "      <td>0.351759</td>\n",
       "      <td>0.372519</td>\n",
       "      <td>0.344578</td>\n",
       "      <td>0.371333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Texts</td>\n",
       "      <td>tf-idf</td>\n",
       "      <td>xgb</td>\n",
       "      <td>macro avg</td>\n",
       "      <td>0.596115</td>\n",
       "      <td>0.501220</td>\n",
       "      <td>0.603727</td>\n",
       "      <td>0.670805</td>\n",
       "      <td>0.545620</td>\n",
       "      <td>0.579427</td>\n",
       "      <td>0.582819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Texts</td>\n",
       "      <td>bertabaporu-base</td>\n",
       "      <td>xgb</td>\n",
       "      <td>macro avg</td>\n",
       "      <td>0.594754</td>\n",
       "      <td>0.495578</td>\n",
       "      <td>0.609524</td>\n",
       "      <td>0.660542</td>\n",
       "      <td>0.534455</td>\n",
       "      <td>0.569597</td>\n",
       "      <td>0.577408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Timeline</td>\n",
       "      <td>-</td>\n",
       "      <td>dummy</td>\n",
       "      <td>macro avg</td>\n",
       "      <td>0.361407</td>\n",
       "      <td>0.462857</td>\n",
       "      <td>0.334878</td>\n",
       "      <td>0.351759</td>\n",
       "      <td>0.372519</td>\n",
       "      <td>0.344578</td>\n",
       "      <td>0.371333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Timeline</td>\n",
       "      <td>tf-idf</td>\n",
       "      <td>xgb</td>\n",
       "      <td>macro avg</td>\n",
       "      <td>0.699122</td>\n",
       "      <td>0.728220</td>\n",
       "      <td>0.898944</td>\n",
       "      <td>0.863813</td>\n",
       "      <td>0.598358</td>\n",
       "      <td>0.752710</td>\n",
       "      <td>0.756861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Timeline</td>\n",
       "      <td>bertabaporu-base</td>\n",
       "      <td>xgb</td>\n",
       "      <td>macro avg</td>\n",
       "      <td>0.661773</td>\n",
       "      <td>0.692262</td>\n",
       "      <td>0.776979</td>\n",
       "      <td>0.778471</td>\n",
       "      <td>0.585105</td>\n",
       "      <td>0.645518</td>\n",
       "      <td>0.690018</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "metric  text_col        vectorizer         estimator      class  f1-score  \\\n",
       "target                                                             Church   \n",
       "0         Stance                 -             dummy  macro avg  0.361407   \n",
       "1         Stance            tf-idf               xgb  macro avg  0.702021   \n",
       "2         Stance  bertabaporu-base               xgb  macro avg  0.853801   \n",
       "3         Stance                 -  bertabaporu-base  macro avg  0.866621   \n",
       "4         Stance                 -         llama3:7b  macro avg  0.729458   \n",
       "5          Texts                 -             dummy  macro avg  0.361407   \n",
       "6          Texts            tf-idf               xgb  macro avg  0.596115   \n",
       "7          Texts  bertabaporu-base               xgb  macro avg  0.594754   \n",
       "8       Timeline                 -             dummy  macro avg  0.361407   \n",
       "9       Timeline            tf-idf               xgb  macro avg  0.699122   \n",
       "10      Timeline  bertabaporu-base               xgb  macro avg  0.661773   \n",
       "\n",
       "metric                                                              \n",
       "target Bolsonaro   Hydrox.   Sinovac  Globo TV      Lula   overall  \n",
       "0       0.462857  0.334878  0.351759  0.372519  0.344578  0.371333  \n",
       "1       0.595312  0.734366  0.752640  0.665243  0.654412  0.683999  \n",
       "2       0.625289  0.830948  0.808036  0.781858  0.766993  0.777821  \n",
       "3       0.739125  0.844778  0.840499  0.862638  0.796338  0.825000  \n",
       "4       0.462857  0.638889  0.578779  0.770678  0.699381  0.646674  \n",
       "5       0.462857  0.334878  0.351759  0.372519  0.344578  0.371333  \n",
       "6       0.501220  0.603727  0.670805  0.545620  0.579427  0.582819  \n",
       "7       0.495578  0.609524  0.660542  0.534455  0.569597  0.577408  \n",
       "8       0.462857  0.334878  0.351759  0.372519  0.344578  0.371333  \n",
       "9       0.728220  0.898944  0.863813  0.598358  0.752710  0.756861  \n",
       "10      0.692262  0.776979  0.778471  0.585105  0.645518  0.690018  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_report.reset_index(drop=False, inplace=True)\n",
    "f1_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultiIndex([(  'text_col',          ''),\n",
       "            ('vectorizer',          ''),\n",
       "            ( 'estimator',          ''),\n",
       "            (     'class',          ''),\n",
       "            (  'f1-score',    'Church'),\n",
       "            (  'f1-score', 'Bolsonaro'),\n",
       "            (  'f1-score',   'Hydrox.'),\n",
       "            (  'f1-score',   'Sinovac'),\n",
       "            (  'f1-score',  'Globo TV'),\n",
       "            (  'f1-score',      'Lula'),\n",
       "            (  'f1-score',   'overall')],\n",
       "           names=['metric', 'target'])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_report.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['text_col',\n",
       " 'vectorizer',\n",
       " 'estimator',\n",
       " 'class',\n",
       " 'Church',\n",
       " 'Bolsonaro',\n",
       " 'Hydrox.',\n",
       " 'Sinovac',\n",
       " 'Globo TV',\n",
       " 'Lula',\n",
       " 'overall']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_columns = [col[0] if col[1] == '' else col[1] for col in f1_report.columns]\n",
    "new_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_col</th>\n",
       "      <th>vectorizer</th>\n",
       "      <th>estimator</th>\n",
       "      <th>class</th>\n",
       "      <th>Church</th>\n",
       "      <th>Bolsonaro</th>\n",
       "      <th>Hydrox.</th>\n",
       "      <th>Sinovac</th>\n",
       "      <th>Globo TV</th>\n",
       "      <th>Lula</th>\n",
       "      <th>overall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Stance</td>\n",
       "      <td>-</td>\n",
       "      <td>dummy</td>\n",
       "      <td>macro avg</td>\n",
       "      <td>0.361407</td>\n",
       "      <td>0.462857</td>\n",
       "      <td>0.334878</td>\n",
       "      <td>0.351759</td>\n",
       "      <td>0.372519</td>\n",
       "      <td>0.344578</td>\n",
       "      <td>0.371333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Stance</td>\n",
       "      <td>tf-idf</td>\n",
       "      <td>xgb</td>\n",
       "      <td>macro avg</td>\n",
       "      <td>0.702021</td>\n",
       "      <td>0.595312</td>\n",
       "      <td>0.734366</td>\n",
       "      <td>0.752640</td>\n",
       "      <td>0.665243</td>\n",
       "      <td>0.654412</td>\n",
       "      <td>0.683999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Stance</td>\n",
       "      <td>bertabaporu-base</td>\n",
       "      <td>xgb</td>\n",
       "      <td>macro avg</td>\n",
       "      <td>0.853801</td>\n",
       "      <td>0.625289</td>\n",
       "      <td>0.830948</td>\n",
       "      <td>0.808036</td>\n",
       "      <td>0.781858</td>\n",
       "      <td>0.766993</td>\n",
       "      <td>0.777821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Stance</td>\n",
       "      <td>-</td>\n",
       "      <td>bertabaporu-base</td>\n",
       "      <td>macro avg</td>\n",
       "      <td>0.866621</td>\n",
       "      <td>0.739125</td>\n",
       "      <td>0.844778</td>\n",
       "      <td>0.840499</td>\n",
       "      <td>0.862638</td>\n",
       "      <td>0.796338</td>\n",
       "      <td>0.825000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Stance</td>\n",
       "      <td>-</td>\n",
       "      <td>llama3:7b</td>\n",
       "      <td>macro avg</td>\n",
       "      <td>0.729458</td>\n",
       "      <td>0.462857</td>\n",
       "      <td>0.638889</td>\n",
       "      <td>0.578779</td>\n",
       "      <td>0.770678</td>\n",
       "      <td>0.699381</td>\n",
       "      <td>0.646674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Texts</td>\n",
       "      <td>-</td>\n",
       "      <td>dummy</td>\n",
       "      <td>macro avg</td>\n",
       "      <td>0.361407</td>\n",
       "      <td>0.462857</td>\n",
       "      <td>0.334878</td>\n",
       "      <td>0.351759</td>\n",
       "      <td>0.372519</td>\n",
       "      <td>0.344578</td>\n",
       "      <td>0.371333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Texts</td>\n",
       "      <td>tf-idf</td>\n",
       "      <td>xgb</td>\n",
       "      <td>macro avg</td>\n",
       "      <td>0.596115</td>\n",
       "      <td>0.501220</td>\n",
       "      <td>0.603727</td>\n",
       "      <td>0.670805</td>\n",
       "      <td>0.545620</td>\n",
       "      <td>0.579427</td>\n",
       "      <td>0.582819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Texts</td>\n",
       "      <td>bertabaporu-base</td>\n",
       "      <td>xgb</td>\n",
       "      <td>macro avg</td>\n",
       "      <td>0.594754</td>\n",
       "      <td>0.495578</td>\n",
       "      <td>0.609524</td>\n",
       "      <td>0.660542</td>\n",
       "      <td>0.534455</td>\n",
       "      <td>0.569597</td>\n",
       "      <td>0.577408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Timeline</td>\n",
       "      <td>-</td>\n",
       "      <td>dummy</td>\n",
       "      <td>macro avg</td>\n",
       "      <td>0.361407</td>\n",
       "      <td>0.462857</td>\n",
       "      <td>0.334878</td>\n",
       "      <td>0.351759</td>\n",
       "      <td>0.372519</td>\n",
       "      <td>0.344578</td>\n",
       "      <td>0.371333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Timeline</td>\n",
       "      <td>tf-idf</td>\n",
       "      <td>xgb</td>\n",
       "      <td>macro avg</td>\n",
       "      <td>0.699122</td>\n",
       "      <td>0.728220</td>\n",
       "      <td>0.898944</td>\n",
       "      <td>0.863813</td>\n",
       "      <td>0.598358</td>\n",
       "      <td>0.752710</td>\n",
       "      <td>0.756861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Timeline</td>\n",
       "      <td>bertabaporu-base</td>\n",
       "      <td>xgb</td>\n",
       "      <td>macro avg</td>\n",
       "      <td>0.661773</td>\n",
       "      <td>0.692262</td>\n",
       "      <td>0.776979</td>\n",
       "      <td>0.778471</td>\n",
       "      <td>0.585105</td>\n",
       "      <td>0.645518</td>\n",
       "      <td>0.690018</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    text_col        vectorizer         estimator      class    Church  \\\n",
       "0     Stance                 -             dummy  macro avg  0.361407   \n",
       "1     Stance            tf-idf               xgb  macro avg  0.702021   \n",
       "2     Stance  bertabaporu-base               xgb  macro avg  0.853801   \n",
       "3     Stance                 -  bertabaporu-base  macro avg  0.866621   \n",
       "4     Stance                 -         llama3:7b  macro avg  0.729458   \n",
       "5      Texts                 -             dummy  macro avg  0.361407   \n",
       "6      Texts            tf-idf               xgb  macro avg  0.596115   \n",
       "7      Texts  bertabaporu-base               xgb  macro avg  0.594754   \n",
       "8   Timeline                 -             dummy  macro avg  0.361407   \n",
       "9   Timeline            tf-idf               xgb  macro avg  0.699122   \n",
       "10  Timeline  bertabaporu-base               xgb  macro avg  0.661773   \n",
       "\n",
       "    Bolsonaro   Hydrox.   Sinovac  Globo TV      Lula   overall  \n",
       "0    0.462857  0.334878  0.351759  0.372519  0.344578  0.371333  \n",
       "1    0.595312  0.734366  0.752640  0.665243  0.654412  0.683999  \n",
       "2    0.625289  0.830948  0.808036  0.781858  0.766993  0.777821  \n",
       "3    0.739125  0.844778  0.840499  0.862638  0.796338  0.825000  \n",
       "4    0.462857  0.638889  0.578779  0.770678  0.699381  0.646674  \n",
       "5    0.462857  0.334878  0.351759  0.372519  0.344578  0.371333  \n",
       "6    0.501220  0.603727  0.670805  0.545620  0.579427  0.582819  \n",
       "7    0.495578  0.609524  0.660542  0.534455  0.569597  0.577408  \n",
       "8    0.462857  0.334878  0.351759  0.372519  0.344578  0.371333  \n",
       "9    0.728220  0.898944  0.863813  0.598358  0.752710  0.756861  \n",
       "10   0.692262  0.776979  0.778471  0.585105  0.645518  0.690018  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_report.columns = new_columns\n",
    "f1_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_col</th>\n",
       "      <th>vectorizer</th>\n",
       "      <th>estimator</th>\n",
       "      <th>Church</th>\n",
       "      <th>Bolsonaro</th>\n",
       "      <th>Hydrox.</th>\n",
       "      <th>Sinovac</th>\n",
       "      <th>Globo TV</th>\n",
       "      <th>Lula</th>\n",
       "      <th>overall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Stance</td>\n",
       "      <td>-</td>\n",
       "      <td>dummy</td>\n",
       "      <td>0.361407</td>\n",
       "      <td>0.462857</td>\n",
       "      <td>0.334878</td>\n",
       "      <td>0.351759</td>\n",
       "      <td>0.372519</td>\n",
       "      <td>0.344578</td>\n",
       "      <td>0.371333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Stance</td>\n",
       "      <td>tf-idf</td>\n",
       "      <td>xgb</td>\n",
       "      <td>0.702021</td>\n",
       "      <td>0.595312</td>\n",
       "      <td>0.734366</td>\n",
       "      <td>0.752640</td>\n",
       "      <td>0.665243</td>\n",
       "      <td>0.654412</td>\n",
       "      <td>0.683999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Stance</td>\n",
       "      <td>bertabaporu-base</td>\n",
       "      <td>xgb</td>\n",
       "      <td>0.853801</td>\n",
       "      <td>0.625289</td>\n",
       "      <td>0.830948</td>\n",
       "      <td>0.808036</td>\n",
       "      <td>0.781858</td>\n",
       "      <td>0.766993</td>\n",
       "      <td>0.777821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Stance</td>\n",
       "      <td>-</td>\n",
       "      <td>bertabaporu-base</td>\n",
       "      <td>0.866621</td>\n",
       "      <td>0.739125</td>\n",
       "      <td>0.844778</td>\n",
       "      <td>0.840499</td>\n",
       "      <td>0.862638</td>\n",
       "      <td>0.796338</td>\n",
       "      <td>0.825000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Stance</td>\n",
       "      <td>-</td>\n",
       "      <td>llama3:7b</td>\n",
       "      <td>0.729458</td>\n",
       "      <td>0.462857</td>\n",
       "      <td>0.638889</td>\n",
       "      <td>0.578779</td>\n",
       "      <td>0.770678</td>\n",
       "      <td>0.699381</td>\n",
       "      <td>0.646674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Texts</td>\n",
       "      <td>-</td>\n",
       "      <td>dummy</td>\n",
       "      <td>0.361407</td>\n",
       "      <td>0.462857</td>\n",
       "      <td>0.334878</td>\n",
       "      <td>0.351759</td>\n",
       "      <td>0.372519</td>\n",
       "      <td>0.344578</td>\n",
       "      <td>0.371333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Texts</td>\n",
       "      <td>tf-idf</td>\n",
       "      <td>xgb</td>\n",
       "      <td>0.596115</td>\n",
       "      <td>0.501220</td>\n",
       "      <td>0.603727</td>\n",
       "      <td>0.670805</td>\n",
       "      <td>0.545620</td>\n",
       "      <td>0.579427</td>\n",
       "      <td>0.582819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Texts</td>\n",
       "      <td>bertabaporu-base</td>\n",
       "      <td>xgb</td>\n",
       "      <td>0.594754</td>\n",
       "      <td>0.495578</td>\n",
       "      <td>0.609524</td>\n",
       "      <td>0.660542</td>\n",
       "      <td>0.534455</td>\n",
       "      <td>0.569597</td>\n",
       "      <td>0.577408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Timeline</td>\n",
       "      <td>-</td>\n",
       "      <td>dummy</td>\n",
       "      <td>0.361407</td>\n",
       "      <td>0.462857</td>\n",
       "      <td>0.334878</td>\n",
       "      <td>0.351759</td>\n",
       "      <td>0.372519</td>\n",
       "      <td>0.344578</td>\n",
       "      <td>0.371333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Timeline</td>\n",
       "      <td>tf-idf</td>\n",
       "      <td>xgb</td>\n",
       "      <td>0.699122</td>\n",
       "      <td>0.728220</td>\n",
       "      <td>0.898944</td>\n",
       "      <td>0.863813</td>\n",
       "      <td>0.598358</td>\n",
       "      <td>0.752710</td>\n",
       "      <td>0.756861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Timeline</td>\n",
       "      <td>bertabaporu-base</td>\n",
       "      <td>xgb</td>\n",
       "      <td>0.661773</td>\n",
       "      <td>0.692262</td>\n",
       "      <td>0.776979</td>\n",
       "      <td>0.778471</td>\n",
       "      <td>0.585105</td>\n",
       "      <td>0.645518</td>\n",
       "      <td>0.690018</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    text_col        vectorizer         estimator    Church  Bolsonaro  \\\n",
       "0     Stance                 -             dummy  0.361407   0.462857   \n",
       "1     Stance            tf-idf               xgb  0.702021   0.595312   \n",
       "2     Stance  bertabaporu-base               xgb  0.853801   0.625289   \n",
       "3     Stance                 -  bertabaporu-base  0.866621   0.739125   \n",
       "4     Stance                 -         llama3:7b  0.729458   0.462857   \n",
       "5      Texts                 -             dummy  0.361407   0.462857   \n",
       "6      Texts            tf-idf               xgb  0.596115   0.501220   \n",
       "7      Texts  bertabaporu-base               xgb  0.594754   0.495578   \n",
       "8   Timeline                 -             dummy  0.361407   0.462857   \n",
       "9   Timeline            tf-idf               xgb  0.699122   0.728220   \n",
       "10  Timeline  bertabaporu-base               xgb  0.661773   0.692262   \n",
       "\n",
       "     Hydrox.   Sinovac  Globo TV      Lula   overall  \n",
       "0   0.334878  0.351759  0.372519  0.344578  0.371333  \n",
       "1   0.734366  0.752640  0.665243  0.654412  0.683999  \n",
       "2   0.830948  0.808036  0.781858  0.766993  0.777821  \n",
       "3   0.844778  0.840499  0.862638  0.796338  0.825000  \n",
       "4   0.638889  0.578779  0.770678  0.699381  0.646674  \n",
       "5   0.334878  0.351759  0.372519  0.344578  0.371333  \n",
       "6   0.603727  0.670805  0.545620  0.579427  0.582819  \n",
       "7   0.609524  0.660542  0.534455  0.569597  0.577408  \n",
       "8   0.334878  0.351759  0.372519  0.344578  0.371333  \n",
       "9   0.898944  0.863813  0.598358  0.752710  0.756861  \n",
       "10  0.776979  0.778471  0.585105  0.645518  0.690018  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_report.drop(['class'],axis = 1, inplace=True)\n",
    "f1_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text_col</th>\n",
       "      <th>classifier</th>\n",
       "      <th>Church</th>\n",
       "      <th>Bolsonaro</th>\n",
       "      <th>Hydrox.</th>\n",
       "      <th>Sinovac</th>\n",
       "      <th>Globo TV</th>\n",
       "      <th>Lula</th>\n",
       "      <th>overall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Stance</td>\n",
       "      <td>dummy</td>\n",
       "      <td>0.361407</td>\n",
       "      <td>0.462857</td>\n",
       "      <td>0.334878</td>\n",
       "      <td>0.351759</td>\n",
       "      <td>0.372519</td>\n",
       "      <td>0.344578</td>\n",
       "      <td>0.371333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Stance</td>\n",
       "      <td>tf-idf + xgb</td>\n",
       "      <td>0.702021</td>\n",
       "      <td>0.595312</td>\n",
       "      <td>0.734366</td>\n",
       "      <td>0.752640</td>\n",
       "      <td>0.665243</td>\n",
       "      <td>0.654412</td>\n",
       "      <td>0.683999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Stance</td>\n",
       "      <td>bertabaporu-base + xgb</td>\n",
       "      <td>0.853801</td>\n",
       "      <td>0.625289</td>\n",
       "      <td>0.830948</td>\n",
       "      <td>0.808036</td>\n",
       "      <td>0.781858</td>\n",
       "      <td>0.766993</td>\n",
       "      <td>0.777821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Stance</td>\n",
       "      <td>bertabaporu-base</td>\n",
       "      <td>0.866621</td>\n",
       "      <td>0.739125</td>\n",
       "      <td>0.844778</td>\n",
       "      <td>0.840499</td>\n",
       "      <td>0.862638</td>\n",
       "      <td>0.796338</td>\n",
       "      <td>0.825000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Stance</td>\n",
       "      <td>llama3:7b</td>\n",
       "      <td>0.729458</td>\n",
       "      <td>0.462857</td>\n",
       "      <td>0.638889</td>\n",
       "      <td>0.578779</td>\n",
       "      <td>0.770678</td>\n",
       "      <td>0.699381</td>\n",
       "      <td>0.646674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Texts</td>\n",
       "      <td>dummy</td>\n",
       "      <td>0.361407</td>\n",
       "      <td>0.462857</td>\n",
       "      <td>0.334878</td>\n",
       "      <td>0.351759</td>\n",
       "      <td>0.372519</td>\n",
       "      <td>0.344578</td>\n",
       "      <td>0.371333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Texts</td>\n",
       "      <td>tf-idf + xgb</td>\n",
       "      <td>0.596115</td>\n",
       "      <td>0.501220</td>\n",
       "      <td>0.603727</td>\n",
       "      <td>0.670805</td>\n",
       "      <td>0.545620</td>\n",
       "      <td>0.579427</td>\n",
       "      <td>0.582819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Texts</td>\n",
       "      <td>bertabaporu-base + xgb</td>\n",
       "      <td>0.594754</td>\n",
       "      <td>0.495578</td>\n",
       "      <td>0.609524</td>\n",
       "      <td>0.660542</td>\n",
       "      <td>0.534455</td>\n",
       "      <td>0.569597</td>\n",
       "      <td>0.577408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Timeline</td>\n",
       "      <td>dummy</td>\n",
       "      <td>0.361407</td>\n",
       "      <td>0.462857</td>\n",
       "      <td>0.334878</td>\n",
       "      <td>0.351759</td>\n",
       "      <td>0.372519</td>\n",
       "      <td>0.344578</td>\n",
       "      <td>0.371333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Timeline</td>\n",
       "      <td>tf-idf + xgb</td>\n",
       "      <td>0.699122</td>\n",
       "      <td>0.728220</td>\n",
       "      <td>0.898944</td>\n",
       "      <td>0.863813</td>\n",
       "      <td>0.598358</td>\n",
       "      <td>0.752710</td>\n",
       "      <td>0.756861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Timeline</td>\n",
       "      <td>bertabaporu-base + xgb</td>\n",
       "      <td>0.661773</td>\n",
       "      <td>0.692262</td>\n",
       "      <td>0.776979</td>\n",
       "      <td>0.778471</td>\n",
       "      <td>0.585105</td>\n",
       "      <td>0.645518</td>\n",
       "      <td>0.690018</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    text_col              classifier    Church  Bolsonaro   Hydrox.   Sinovac  \\\n",
       "0     Stance                   dummy  0.361407   0.462857  0.334878  0.351759   \n",
       "1     Stance            tf-idf + xgb  0.702021   0.595312  0.734366  0.752640   \n",
       "2     Stance  bertabaporu-base + xgb  0.853801   0.625289  0.830948  0.808036   \n",
       "3     Stance        bertabaporu-base  0.866621   0.739125  0.844778  0.840499   \n",
       "4     Stance               llama3:7b  0.729458   0.462857  0.638889  0.578779   \n",
       "5      Texts                   dummy  0.361407   0.462857  0.334878  0.351759   \n",
       "6      Texts            tf-idf + xgb  0.596115   0.501220  0.603727  0.670805   \n",
       "7      Texts  bertabaporu-base + xgb  0.594754   0.495578  0.609524  0.660542   \n",
       "8   Timeline                   dummy  0.361407   0.462857  0.334878  0.351759   \n",
       "9   Timeline            tf-idf + xgb  0.699122   0.728220  0.898944  0.863813   \n",
       "10  Timeline  bertabaporu-base + xgb  0.661773   0.692262  0.776979  0.778471   \n",
       "\n",
       "    Globo TV      Lula   overall  \n",
       "0   0.372519  0.344578  0.371333  \n",
       "1   0.665243  0.654412  0.683999  \n",
       "2   0.781858  0.766993  0.777821  \n",
       "3   0.862638  0.796338  0.825000  \n",
       "4   0.770678  0.699381  0.646674  \n",
       "5   0.372519  0.344578  0.371333  \n",
       "6   0.545620  0.579427  0.582819  \n",
       "7   0.534455  0.569597  0.577408  \n",
       "8   0.372519  0.344578  0.371333  \n",
       "9   0.598358  0.752710  0.756861  \n",
       "10  0.585105  0.645518  0.690018  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_report.insert(\n",
    "    1, \n",
    "    \"classifier\", \n",
    "    f1_report.apply(\n",
    "        lambda x: f\"{x['vectorizer']} + {x['estimator']}\" if x['vectorizer'] != '-' else x['estimator'],\n",
    "        axis = 1\n",
    "        ).to_list()\n",
    "\n",
    ")\n",
    "f1_report.drop(['estimator', 'vectorizer'],axis =1, inplace = True)\n",
    "f1_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input</th>\n",
       "      <th>classifier</th>\n",
       "      <th>Church</th>\n",
       "      <th>Bolsonaro</th>\n",
       "      <th>Hydrox.</th>\n",
       "      <th>Sinovac</th>\n",
       "      <th>Globo TV</th>\n",
       "      <th>Lula</th>\n",
       "      <th>overall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Stance</td>\n",
       "      <td>dummy</td>\n",
       "      <td>0.361407</td>\n",
       "      <td>0.462857</td>\n",
       "      <td>0.334878</td>\n",
       "      <td>0.351759</td>\n",
       "      <td>0.372519</td>\n",
       "      <td>0.344578</td>\n",
       "      <td>0.371333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Stance</td>\n",
       "      <td>tf-idf + xgb</td>\n",
       "      <td>0.702021</td>\n",
       "      <td>0.595312</td>\n",
       "      <td>0.734366</td>\n",
       "      <td>0.752640</td>\n",
       "      <td>0.665243</td>\n",
       "      <td>0.654412</td>\n",
       "      <td>0.683999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Stance</td>\n",
       "      <td>bertabaporu-base + xgb</td>\n",
       "      <td>0.853801</td>\n",
       "      <td>0.625289</td>\n",
       "      <td>0.830948</td>\n",
       "      <td>0.808036</td>\n",
       "      <td>0.781858</td>\n",
       "      <td>0.766993</td>\n",
       "      <td>0.777821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Stance</td>\n",
       "      <td>bertabaporu-base</td>\n",
       "      <td>0.866621</td>\n",
       "      <td>0.739125</td>\n",
       "      <td>0.844778</td>\n",
       "      <td>0.840499</td>\n",
       "      <td>0.862638</td>\n",
       "      <td>0.796338</td>\n",
       "      <td>0.825000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Stance</td>\n",
       "      <td>llama3:7b</td>\n",
       "      <td>0.729458</td>\n",
       "      <td>0.462857</td>\n",
       "      <td>0.638889</td>\n",
       "      <td>0.578779</td>\n",
       "      <td>0.770678</td>\n",
       "      <td>0.699381</td>\n",
       "      <td>0.646674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Texts</td>\n",
       "      <td>dummy</td>\n",
       "      <td>0.361407</td>\n",
       "      <td>0.462857</td>\n",
       "      <td>0.334878</td>\n",
       "      <td>0.351759</td>\n",
       "      <td>0.372519</td>\n",
       "      <td>0.344578</td>\n",
       "      <td>0.371333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Texts</td>\n",
       "      <td>tf-idf + xgb</td>\n",
       "      <td>0.596115</td>\n",
       "      <td>0.501220</td>\n",
       "      <td>0.603727</td>\n",
       "      <td>0.670805</td>\n",
       "      <td>0.545620</td>\n",
       "      <td>0.579427</td>\n",
       "      <td>0.582819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Texts</td>\n",
       "      <td>bertabaporu-base + xgb</td>\n",
       "      <td>0.594754</td>\n",
       "      <td>0.495578</td>\n",
       "      <td>0.609524</td>\n",
       "      <td>0.660542</td>\n",
       "      <td>0.534455</td>\n",
       "      <td>0.569597</td>\n",
       "      <td>0.577408</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Timeline</td>\n",
       "      <td>dummy</td>\n",
       "      <td>0.361407</td>\n",
       "      <td>0.462857</td>\n",
       "      <td>0.334878</td>\n",
       "      <td>0.351759</td>\n",
       "      <td>0.372519</td>\n",
       "      <td>0.344578</td>\n",
       "      <td>0.371333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Timeline</td>\n",
       "      <td>tf-idf + xgb</td>\n",
       "      <td>0.699122</td>\n",
       "      <td>0.728220</td>\n",
       "      <td>0.898944</td>\n",
       "      <td>0.863813</td>\n",
       "      <td>0.598358</td>\n",
       "      <td>0.752710</td>\n",
       "      <td>0.756861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Timeline</td>\n",
       "      <td>bertabaporu-base + xgb</td>\n",
       "      <td>0.661773</td>\n",
       "      <td>0.692262</td>\n",
       "      <td>0.776979</td>\n",
       "      <td>0.778471</td>\n",
       "      <td>0.585105</td>\n",
       "      <td>0.645518</td>\n",
       "      <td>0.690018</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       input              classifier    Church  Bolsonaro   Hydrox.   Sinovac  \\\n",
       "0     Stance                   dummy  0.361407   0.462857  0.334878  0.351759   \n",
       "1     Stance            tf-idf + xgb  0.702021   0.595312  0.734366  0.752640   \n",
       "2     Stance  bertabaporu-base + xgb  0.853801   0.625289  0.830948  0.808036   \n",
       "3     Stance        bertabaporu-base  0.866621   0.739125  0.844778  0.840499   \n",
       "4     Stance               llama3:7b  0.729458   0.462857  0.638889  0.578779   \n",
       "5      Texts                   dummy  0.361407   0.462857  0.334878  0.351759   \n",
       "6      Texts            tf-idf + xgb  0.596115   0.501220  0.603727  0.670805   \n",
       "7      Texts  bertabaporu-base + xgb  0.594754   0.495578  0.609524  0.660542   \n",
       "8   Timeline                   dummy  0.361407   0.462857  0.334878  0.351759   \n",
       "9   Timeline            tf-idf + xgb  0.699122   0.728220  0.898944  0.863813   \n",
       "10  Timeline  bertabaporu-base + xgb  0.661773   0.692262  0.776979  0.778471   \n",
       "\n",
       "    Globo TV      Lula   overall  \n",
       "0   0.372519  0.344578  0.371333  \n",
       "1   0.665243  0.654412  0.683999  \n",
       "2   0.781858  0.766993  0.777821  \n",
       "3   0.862638  0.796338  0.825000  \n",
       "4   0.770678  0.699381  0.646674  \n",
       "5   0.372519  0.344578  0.371333  \n",
       "6   0.545620  0.579427  0.582819  \n",
       "7   0.534455  0.569597  0.577408  \n",
       "8   0.372519  0.344578  0.371333  \n",
       "9   0.598358  0.752710  0.756861  \n",
       "10  0.585105  0.645518  0.690018  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_report.rename({\"text_col\":\"input\"}, axis = 1, inplace=True)\n",
    "f1_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#f1_report.set_index(['input'],inplace=True)\n",
    "#f1_report.drop('input', axis = 1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_latex_with_multirow_and_bold(df):\n",
    "    latex_code = ''\n",
    "    latex_code += '\\\\begin{table}[H]'\n",
    "    latex_code += \"\\\\begin{tabular}{ll|rrrrrrr}\\n\\\\toprule\\n\"\n",
    "    latex_code += \"input & classifier & Church & Bolsonaro & Hydrox. & Sinovac & Globo TV & Lula & overall \\\\\\\\ \\n\\\\midrule\\n\"\n",
    "\n",
    "    last_input = None\n",
    "    multirow_count = 0\n",
    "\n",
    "    for input_value in df['input'].unique():\n",
    "        subset = df[df['input'] == input_value]\n",
    "        max_overall_idx = subset['overall'].idxmax()\n",
    "\n",
    "        for i, row in subset.iterrows():\n",
    "            if row['input'] == last_input:\n",
    "                latex_code += \"& \"\n",
    "                multirow_count += 1\n",
    "            else:\n",
    "                if multirow_count > 0:\n",
    "                    latex_code = latex_code.replace(f\"multirow{{{multirow_count}}}\", f\"multirow{{{multirow_count + 1}}}\", 1)\n",
    "                if last_input is not None:\n",
    "                    latex_code += \"\\\\cmidrule(lr){1-9}\\n\"\n",
    "                latex_code += f\"\\\\multirow{{{1}}}{{*}}{{{row['input']}}} & \"\n",
    "                multirow_count = 1\n",
    "\n",
    "            if i == max_overall_idx:\n",
    "                row_data = [f\"\\\\textbf{{{row[col]:.2f}}}\" if col not in ['input', 'classifier'] else f\"\\\\textbf{{{row[col]}}}\" for col in df.columns[1:]]\n",
    "                latex_code += \" & \".join(row_data) + \" \\\\\\\\ \\n\"\n",
    "            else:\n",
    "                latex_code += \" & \".join([f\"{row[col]:.2f}\" if isinstance(row[col], float) else str(row[col]) for col in df.columns[1:]]) + \" \\\\\\\\ \\n\"\n",
    "            \n",
    "            last_input = row['input']\n",
    "\n",
    "    if multirow_count > 0:\n",
    "        latex_code = latex_code.replace(f\"multirow{{{multirow_count}}}\", f\"multirow{{{multirow_count + 1}}}\", 1)\n",
    "\n",
    "    latex_code += \"\\\\cmidrule(lr){1-9}\\n\"\n",
    "    latex_code += \"\\\\bottomrule\\n\\\\end{tabular}\"\n",
    "    latex_code += \"\\caption{F1 macro results}\"\n",
    "    latex_code += '\\label{table:results_f1_macro}\\n'\n",
    "    latex_code += '\\end{table}'\n",
    "\n",
    "    return latex_code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_report.input = f1_report.input.map({\n",
    "    \"Stance\": \"S\",\n",
    "    \"Timeline\": 'UT',\n",
    "    \"Texts\": 'UFT'\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "str_latex = generate_latex_with_multirow_and_bold(f1_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\begin{table}[H]\\begin{tabular}{ll|rrrrrrr}\n",
      "\\toprule\n",
      "input & classifier & Church & Bolsonaro & Hydrox. & Sinovac & Globo TV & Lula & overall \\\\ \n",
      "\\midrule\n",
      "\\multirow{1}{*}{S} & dummy & 0.36 & 0.46 & 0.33 & 0.35 & 0.37 & 0.34 & 0.37 \\\\ \n",
      "& tf-idf + xgb & 0.70 & 0.60 & 0.73 & 0.75 & 0.67 & 0.65 & 0.68 \\\\ \n",
      "& bertabaporu-base + xgb & 0.85 & 0.63 & 0.83 & 0.81 & 0.78 & 0.77 & 0.78 \\\\ \n",
      "& \\textbf{bertabaporu-base} & \\textbf{0.87} & \\textbf{0.74} & \\textbf{0.84} & \\textbf{0.84} & \\textbf{0.86} & \\textbf{0.80} & \\textbf{0.82} \\\\ \n",
      "& llama3:7b & 0.73 & 0.46 & 0.64 & 0.58 & 0.77 & 0.70 & 0.65 \\\\ \n",
      "\\cmidrule(lr){1-9}\n",
      "\\multirow{1}{*}{UFT} & dummy & 0.36 & 0.46 & 0.33 & 0.35 & 0.37 & 0.34 & 0.37 \\\\ \n",
      "& \\textbf{tf-idf + xgb} & \\textbf{0.60} & \\textbf{0.50} & \\textbf{0.60} & \\textbf{0.67} & \\textbf{0.55} & \\textbf{0.58} & \\textbf{0.58} \\\\ \n",
      "& bertabaporu-base + xgb & 0.59 & 0.50 & 0.61 & 0.66 & 0.53 & 0.57 & 0.58 \\\\ \n",
      "\\cmidrule(lr){1-9}\n",
      "\\multirow{1}{*}{UT} & dummy & 0.36 & 0.46 & 0.33 & 0.35 & 0.37 & 0.34 & 0.37 \\\\ \n",
      "& \\textbf{tf-idf + xgb} & \\textbf{0.70} & \\textbf{0.73} & \\textbf{0.90} & \\textbf{0.86} & \\textbf{0.60} & \\textbf{0.75} & \\textbf{0.76} \\\\ \n",
      "& bertabaporu-base + xgb & 0.66 & 0.69 & 0.78 & 0.78 & 0.59 & 0.65 & 0.69 \\\\ \n",
      "\\cmidrule(lr){1-9}\n",
      "\\bottomrule\n",
      "\\end{tabular}\\caption{F1 macro results}\\label{table:results_f1_macro}\n",
      "\\end{table}\n"
     ]
    }
   ],
   "source": [
    "print(str_latex)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env-stance-pred",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
