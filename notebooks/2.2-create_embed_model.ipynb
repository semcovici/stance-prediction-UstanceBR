{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import LabelEncoder, MaxAbsScaler\n",
    "import numpy as np\n",
    "from imblearn.over_sampling import RandomOverSampler, SMOTE\n",
    "from imblearn.pipeline import Pipeline as IMBPipeline\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from nltk.corpus import stopwords\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.feature_selection import RFE\n",
    "from tsfresh.feature_extraction import MinimalFCParameters\n",
    "from tsfresh.feature_extraction import extract_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/semcovici/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../src/')\n",
    "from models.classification_methods import process_classification "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_raw_data = '../data/raw/'\n",
    "path_processed_data = '../data/processed/'\n",
    "path_results_cr = '../reports/classification_reports/'\n",
    "path_test_results = '../reports/test_results/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_target = ['ig','bo', 'cl', 'co', 'gl', 'lu']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = 'ig'\n",
    "model_name = 'facebook/fasttext-pt-vectors'\n",
    "model_name = 'neuralmind/bert-base-portuguese-cased'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top mentioned timelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:13<00:00,  2.30s/it]\n"
     ]
    }
   ],
   "source": [
    "# create a list of tuples with (data_train, data_test, target)\n",
    "\n",
    "list_tuples_top_ment = []\n",
    "\n",
    "for target in tqdm(list_target):\n",
    "    \n",
    "    path_data_train = path_processed_data + f'train_r3_{target}_top_mentioned_timelines_{model_name.replace(\"/\", \"_\")}.parquet'\n",
    "    path_data_test = path_processed_data + f'test_r3_{target}_top_mentioned_timelines_{model_name.replace(\"/\", \"_\")}.parquet'\n",
    "\n",
    "    data_train = pd.read_parquet(path_data_train)\n",
    "    data_test = pd.read_parquet(path_data_test)\n",
    "    \n",
    "    list_tuples_top_ment.append((data_train, data_test, target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_cols = [col for col in data_test.columns if 'emb' in col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Texts_emb_1',\n",
       " 'Texts_emb_2',\n",
       " 'Texts_emb_3',\n",
       " 'Texts_emb_4',\n",
       " 'Texts_emb_5',\n",
       " 'Texts_emb_6',\n",
       " 'Texts_emb_7',\n",
       " 'Texts_emb_8',\n",
       " 'Texts_emb_9',\n",
       " 'Texts_emb_10',\n",
       " 'Texts_emb_11',\n",
       " 'Texts_emb_12',\n",
       " 'Texts_emb_13',\n",
       " 'Texts_emb_14',\n",
       " 'Texts_emb_15',\n",
       " 'Texts_emb_16',\n",
       " 'Texts_emb_17',\n",
       " 'Texts_emb_18',\n",
       " 'Texts_emb_19',\n",
       " 'Texts_emb_20',\n",
       " 'Texts_emb_21',\n",
       " 'Texts_emb_22',\n",
       " 'Texts_emb_23',\n",
       " 'Texts_emb_24',\n",
       " 'Texts_emb_25',\n",
       " 'Texts_emb_26',\n",
       " 'Texts_emb_27',\n",
       " 'Texts_emb_28',\n",
       " 'Texts_emb_29',\n",
       " 'Texts_emb_30',\n",
       " 'Texts_emb_31',\n",
       " 'Texts_emb_32',\n",
       " 'Texts_emb_33',\n",
       " 'Texts_emb_34',\n",
       " 'Texts_emb_35',\n",
       " 'Texts_emb_36',\n",
       " 'Texts_emb_37',\n",
       " 'Texts_emb_38',\n",
       " 'Texts_emb_39',\n",
       " 'Texts_emb_40',\n",
       " 'Texts_emb_41',\n",
       " 'Texts_emb_42',\n",
       " 'Texts_emb_43',\n",
       " 'Texts_emb_44',\n",
       " 'Texts_emb_45',\n",
       " 'Texts_emb_46',\n",
       " 'Texts_emb_47',\n",
       " 'Texts_emb_48',\n",
       " 'Texts_emb_49',\n",
       " 'Texts_emb_50',\n",
       " 'Texts_emb_51',\n",
       " 'Texts_emb_52',\n",
       " 'Texts_emb_53',\n",
       " 'Texts_emb_54',\n",
       " 'Texts_emb_55',\n",
       " 'Texts_emb_56',\n",
       " 'Texts_emb_57',\n",
       " 'Texts_emb_58',\n",
       " 'Texts_emb_59',\n",
       " 'Texts_emb_60',\n",
       " 'Texts_emb_61',\n",
       " 'Texts_emb_62',\n",
       " 'Texts_emb_63',\n",
       " 'Texts_emb_64',\n",
       " 'Texts_emb_65',\n",
       " 'Texts_emb_66',\n",
       " 'Texts_emb_67',\n",
       " 'Texts_emb_68',\n",
       " 'Texts_emb_69',\n",
       " 'Texts_emb_70',\n",
       " 'Texts_emb_71',\n",
       " 'Texts_emb_72',\n",
       " 'Texts_emb_73',\n",
       " 'Texts_emb_74',\n",
       " 'Texts_emb_75',\n",
       " 'Texts_emb_76',\n",
       " 'Texts_emb_77',\n",
       " 'Texts_emb_78',\n",
       " 'Texts_emb_79',\n",
       " 'Texts_emb_80',\n",
       " 'Texts_emb_81',\n",
       " 'Texts_emb_82',\n",
       " 'Texts_emb_83',\n",
       " 'Texts_emb_84',\n",
       " 'Texts_emb_85',\n",
       " 'Texts_emb_86',\n",
       " 'Texts_emb_87',\n",
       " 'Texts_emb_88',\n",
       " 'Texts_emb_89',\n",
       " 'Texts_emb_90',\n",
       " 'Texts_emb_91',\n",
       " 'Texts_emb_92',\n",
       " 'Texts_emb_93',\n",
       " 'Texts_emb_94',\n",
       " 'Texts_emb_95',\n",
       " 'Texts_emb_96',\n",
       " 'Texts_emb_97',\n",
       " 'Texts_emb_98',\n",
       " 'Texts_emb_99',\n",
       " 'Texts_emb_100',\n",
       " 'Texts_emb_101',\n",
       " 'Texts_emb_102',\n",
       " 'Texts_emb_103',\n",
       " 'Texts_emb_104',\n",
       " 'Texts_emb_105',\n",
       " 'Texts_emb_106',\n",
       " 'Texts_emb_107',\n",
       " 'Texts_emb_108',\n",
       " 'Texts_emb_109',\n",
       " 'Texts_emb_110',\n",
       " 'Texts_emb_111',\n",
       " 'Texts_emb_112',\n",
       " 'Texts_emb_113',\n",
       " 'Texts_emb_114',\n",
       " 'Texts_emb_115',\n",
       " 'Texts_emb_116',\n",
       " 'Texts_emb_117',\n",
       " 'Texts_emb_118',\n",
       " 'Texts_emb_119',\n",
       " 'Texts_emb_120',\n",
       " 'Texts_emb_121',\n",
       " 'Texts_emb_122',\n",
       " 'Texts_emb_123',\n",
       " 'Texts_emb_124',\n",
       " 'Texts_emb_125',\n",
       " 'Texts_emb_126',\n",
       " 'Texts_emb_127',\n",
       " 'Texts_emb_128',\n",
       " 'Texts_emb_129',\n",
       " 'Texts_emb_130',\n",
       " 'Texts_emb_131',\n",
       " 'Texts_emb_132',\n",
       " 'Texts_emb_133',\n",
       " 'Texts_emb_134',\n",
       " 'Texts_emb_135',\n",
       " 'Texts_emb_136',\n",
       " 'Texts_emb_137',\n",
       " 'Texts_emb_138',\n",
       " 'Texts_emb_139',\n",
       " 'Texts_emb_140',\n",
       " 'Texts_emb_141',\n",
       " 'Texts_emb_142',\n",
       " 'Texts_emb_143',\n",
       " 'Texts_emb_144',\n",
       " 'Texts_emb_145',\n",
       " 'Texts_emb_146',\n",
       " 'Texts_emb_147',\n",
       " 'Texts_emb_148',\n",
       " 'Texts_emb_149',\n",
       " 'Texts_emb_150',\n",
       " 'Texts_emb_151',\n",
       " 'Texts_emb_152',\n",
       " 'Texts_emb_153',\n",
       " 'Texts_emb_154',\n",
       " 'Texts_emb_155',\n",
       " 'Texts_emb_156',\n",
       " 'Texts_emb_157',\n",
       " 'Texts_emb_158',\n",
       " 'Texts_emb_159',\n",
       " 'Texts_emb_160',\n",
       " 'Texts_emb_161',\n",
       " 'Texts_emb_162',\n",
       " 'Texts_emb_163',\n",
       " 'Texts_emb_164',\n",
       " 'Texts_emb_165',\n",
       " 'Texts_emb_166',\n",
       " 'Texts_emb_167',\n",
       " 'Texts_emb_168',\n",
       " 'Texts_emb_169',\n",
       " 'Texts_emb_170',\n",
       " 'Texts_emb_171',\n",
       " 'Texts_emb_172',\n",
       " 'Texts_emb_173',\n",
       " 'Texts_emb_174',\n",
       " 'Texts_emb_175',\n",
       " 'Texts_emb_176',\n",
       " 'Texts_emb_177',\n",
       " 'Texts_emb_178',\n",
       " 'Texts_emb_179',\n",
       " 'Texts_emb_180',\n",
       " 'Texts_emb_181',\n",
       " 'Texts_emb_182',\n",
       " 'Texts_emb_183',\n",
       " 'Texts_emb_184',\n",
       " 'Texts_emb_185',\n",
       " 'Texts_emb_186',\n",
       " 'Texts_emb_187',\n",
       " 'Texts_emb_188',\n",
       " 'Texts_emb_189',\n",
       " 'Texts_emb_190',\n",
       " 'Texts_emb_191',\n",
       " 'Texts_emb_192',\n",
       " 'Texts_emb_193',\n",
       " 'Texts_emb_194',\n",
       " 'Texts_emb_195',\n",
       " 'Texts_emb_196',\n",
       " 'Texts_emb_197',\n",
       " 'Texts_emb_198',\n",
       " 'Texts_emb_199',\n",
       " 'Texts_emb_200',\n",
       " 'Texts_emb_201',\n",
       " 'Texts_emb_202',\n",
       " 'Texts_emb_203',\n",
       " 'Texts_emb_204',\n",
       " 'Texts_emb_205',\n",
       " 'Texts_emb_206',\n",
       " 'Texts_emb_207',\n",
       " 'Texts_emb_208',\n",
       " 'Texts_emb_209',\n",
       " 'Texts_emb_210',\n",
       " 'Texts_emb_211',\n",
       " 'Texts_emb_212',\n",
       " 'Texts_emb_213',\n",
       " 'Texts_emb_214',\n",
       " 'Texts_emb_215',\n",
       " 'Texts_emb_216',\n",
       " 'Texts_emb_217',\n",
       " 'Texts_emb_218',\n",
       " 'Texts_emb_219',\n",
       " 'Texts_emb_220',\n",
       " 'Texts_emb_221',\n",
       " 'Texts_emb_222',\n",
       " 'Texts_emb_223',\n",
       " 'Texts_emb_224',\n",
       " 'Texts_emb_225',\n",
       " 'Texts_emb_226',\n",
       " 'Texts_emb_227',\n",
       " 'Texts_emb_228',\n",
       " 'Texts_emb_229',\n",
       " 'Texts_emb_230',\n",
       " 'Texts_emb_231',\n",
       " 'Texts_emb_232',\n",
       " 'Texts_emb_233',\n",
       " 'Texts_emb_234',\n",
       " 'Texts_emb_235',\n",
       " 'Texts_emb_236',\n",
       " 'Texts_emb_237',\n",
       " 'Texts_emb_238',\n",
       " 'Texts_emb_239',\n",
       " 'Texts_emb_240',\n",
       " 'Texts_emb_241',\n",
       " 'Texts_emb_242',\n",
       " 'Texts_emb_243',\n",
       " 'Texts_emb_244',\n",
       " 'Texts_emb_245',\n",
       " 'Texts_emb_246',\n",
       " 'Texts_emb_247',\n",
       " 'Texts_emb_248',\n",
       " 'Texts_emb_249',\n",
       " 'Texts_emb_250',\n",
       " 'Texts_emb_251',\n",
       " 'Texts_emb_252',\n",
       " 'Texts_emb_253',\n",
       " 'Texts_emb_254',\n",
       " 'Texts_emb_255',\n",
       " 'Texts_emb_256',\n",
       " 'Texts_emb_257',\n",
       " 'Texts_emb_258',\n",
       " 'Texts_emb_259',\n",
       " 'Texts_emb_260',\n",
       " 'Texts_emb_261',\n",
       " 'Texts_emb_262',\n",
       " 'Texts_emb_263',\n",
       " 'Texts_emb_264',\n",
       " 'Texts_emb_265',\n",
       " 'Texts_emb_266',\n",
       " 'Texts_emb_267',\n",
       " 'Texts_emb_268',\n",
       " 'Texts_emb_269',\n",
       " 'Texts_emb_270',\n",
       " 'Texts_emb_271',\n",
       " 'Texts_emb_272',\n",
       " 'Texts_emb_273',\n",
       " 'Texts_emb_274',\n",
       " 'Texts_emb_275',\n",
       " 'Texts_emb_276',\n",
       " 'Texts_emb_277',\n",
       " 'Texts_emb_278',\n",
       " 'Texts_emb_279',\n",
       " 'Texts_emb_280',\n",
       " 'Texts_emb_281',\n",
       " 'Texts_emb_282',\n",
       " 'Texts_emb_283',\n",
       " 'Texts_emb_284',\n",
       " 'Texts_emb_285',\n",
       " 'Texts_emb_286',\n",
       " 'Texts_emb_287',\n",
       " 'Texts_emb_288',\n",
       " 'Texts_emb_289',\n",
       " 'Texts_emb_290',\n",
       " 'Texts_emb_291',\n",
       " 'Texts_emb_292',\n",
       " 'Texts_emb_293',\n",
       " 'Texts_emb_294',\n",
       " 'Texts_emb_295',\n",
       " 'Texts_emb_296',\n",
       " 'Texts_emb_297',\n",
       " 'Texts_emb_298',\n",
       " 'Texts_emb_299',\n",
       " 'Texts_emb_300',\n",
       " 'Texts_emb_301',\n",
       " 'Texts_emb_302',\n",
       " 'Texts_emb_303',\n",
       " 'Texts_emb_304',\n",
       " 'Texts_emb_305',\n",
       " 'Texts_emb_306',\n",
       " 'Texts_emb_307',\n",
       " 'Texts_emb_308',\n",
       " 'Texts_emb_309',\n",
       " 'Texts_emb_310',\n",
       " 'Texts_emb_311',\n",
       " 'Texts_emb_312',\n",
       " 'Texts_emb_313',\n",
       " 'Texts_emb_314',\n",
       " 'Texts_emb_315',\n",
       " 'Texts_emb_316',\n",
       " 'Texts_emb_317',\n",
       " 'Texts_emb_318',\n",
       " 'Texts_emb_319',\n",
       " 'Texts_emb_320',\n",
       " 'Texts_emb_321',\n",
       " 'Texts_emb_322',\n",
       " 'Texts_emb_323',\n",
       " 'Texts_emb_324',\n",
       " 'Texts_emb_325',\n",
       " 'Texts_emb_326',\n",
       " 'Texts_emb_327',\n",
       " 'Texts_emb_328',\n",
       " 'Texts_emb_329',\n",
       " 'Texts_emb_330',\n",
       " 'Texts_emb_331',\n",
       " 'Texts_emb_332',\n",
       " 'Texts_emb_333',\n",
       " 'Texts_emb_334',\n",
       " 'Texts_emb_335',\n",
       " 'Texts_emb_336',\n",
       " 'Texts_emb_337',\n",
       " 'Texts_emb_338',\n",
       " 'Texts_emb_339',\n",
       " 'Texts_emb_340',\n",
       " 'Texts_emb_341',\n",
       " 'Texts_emb_342',\n",
       " 'Texts_emb_343',\n",
       " 'Texts_emb_344',\n",
       " 'Texts_emb_345',\n",
       " 'Texts_emb_346',\n",
       " 'Texts_emb_347',\n",
       " 'Texts_emb_348',\n",
       " 'Texts_emb_349',\n",
       " 'Texts_emb_350',\n",
       " 'Texts_emb_351',\n",
       " 'Texts_emb_352',\n",
       " 'Texts_emb_353',\n",
       " 'Texts_emb_354',\n",
       " 'Texts_emb_355',\n",
       " 'Texts_emb_356',\n",
       " 'Texts_emb_357',\n",
       " 'Texts_emb_358',\n",
       " 'Texts_emb_359',\n",
       " 'Texts_emb_360',\n",
       " 'Texts_emb_361',\n",
       " 'Texts_emb_362',\n",
       " 'Texts_emb_363',\n",
       " 'Texts_emb_364',\n",
       " 'Texts_emb_365',\n",
       " 'Texts_emb_366',\n",
       " 'Texts_emb_367',\n",
       " 'Texts_emb_368',\n",
       " 'Texts_emb_369',\n",
       " 'Texts_emb_370',\n",
       " 'Texts_emb_371',\n",
       " 'Texts_emb_372',\n",
       " 'Texts_emb_373',\n",
       " 'Texts_emb_374',\n",
       " 'Texts_emb_375',\n",
       " 'Texts_emb_376',\n",
       " 'Texts_emb_377',\n",
       " 'Texts_emb_378',\n",
       " 'Texts_emb_379',\n",
       " 'Texts_emb_380',\n",
       " 'Texts_emb_381',\n",
       " 'Texts_emb_382',\n",
       " 'Texts_emb_383',\n",
       " 'Texts_emb_384',\n",
       " 'Texts_emb_385',\n",
       " 'Texts_emb_386',\n",
       " 'Texts_emb_387',\n",
       " 'Texts_emb_388',\n",
       " 'Texts_emb_389',\n",
       " 'Texts_emb_390',\n",
       " 'Texts_emb_391',\n",
       " 'Texts_emb_392',\n",
       " 'Texts_emb_393',\n",
       " 'Texts_emb_394',\n",
       " 'Texts_emb_395',\n",
       " 'Texts_emb_396',\n",
       " 'Texts_emb_397',\n",
       " 'Texts_emb_398',\n",
       " 'Texts_emb_399',\n",
       " 'Texts_emb_400',\n",
       " 'Texts_emb_401',\n",
       " 'Texts_emb_402',\n",
       " 'Texts_emb_403',\n",
       " 'Texts_emb_404',\n",
       " 'Texts_emb_405',\n",
       " 'Texts_emb_406',\n",
       " 'Texts_emb_407',\n",
       " 'Texts_emb_408',\n",
       " 'Texts_emb_409',\n",
       " 'Texts_emb_410',\n",
       " 'Texts_emb_411',\n",
       " 'Texts_emb_412',\n",
       " 'Texts_emb_413',\n",
       " 'Texts_emb_414',\n",
       " 'Texts_emb_415',\n",
       " 'Texts_emb_416',\n",
       " 'Texts_emb_417',\n",
       " 'Texts_emb_418',\n",
       " 'Texts_emb_419',\n",
       " 'Texts_emb_420',\n",
       " 'Texts_emb_421',\n",
       " 'Texts_emb_422',\n",
       " 'Texts_emb_423',\n",
       " 'Texts_emb_424',\n",
       " 'Texts_emb_425',\n",
       " 'Texts_emb_426',\n",
       " 'Texts_emb_427',\n",
       " 'Texts_emb_428',\n",
       " 'Texts_emb_429',\n",
       " 'Texts_emb_430',\n",
       " 'Texts_emb_431',\n",
       " 'Texts_emb_432',\n",
       " 'Texts_emb_433',\n",
       " 'Texts_emb_434',\n",
       " 'Texts_emb_435',\n",
       " 'Texts_emb_436',\n",
       " 'Texts_emb_437',\n",
       " 'Texts_emb_438',\n",
       " 'Texts_emb_439',\n",
       " 'Texts_emb_440',\n",
       " 'Texts_emb_441',\n",
       " 'Texts_emb_442',\n",
       " 'Texts_emb_443',\n",
       " 'Texts_emb_444',\n",
       " 'Texts_emb_445',\n",
       " 'Texts_emb_446',\n",
       " 'Texts_emb_447',\n",
       " 'Texts_emb_448',\n",
       " 'Texts_emb_449',\n",
       " 'Texts_emb_450',\n",
       " 'Texts_emb_451',\n",
       " 'Texts_emb_452',\n",
       " 'Texts_emb_453',\n",
       " 'Texts_emb_454',\n",
       " 'Texts_emb_455',\n",
       " 'Texts_emb_456',\n",
       " 'Texts_emb_457',\n",
       " 'Texts_emb_458',\n",
       " 'Texts_emb_459',\n",
       " 'Texts_emb_460',\n",
       " 'Texts_emb_461',\n",
       " 'Texts_emb_462',\n",
       " 'Texts_emb_463',\n",
       " 'Texts_emb_464',\n",
       " 'Texts_emb_465',\n",
       " 'Texts_emb_466',\n",
       " 'Texts_emb_467',\n",
       " 'Texts_emb_468',\n",
       " 'Texts_emb_469',\n",
       " 'Texts_emb_470',\n",
       " 'Texts_emb_471',\n",
       " 'Texts_emb_472',\n",
       " 'Texts_emb_473',\n",
       " 'Texts_emb_474',\n",
       " 'Texts_emb_475',\n",
       " 'Texts_emb_476',\n",
       " 'Texts_emb_477',\n",
       " 'Texts_emb_478',\n",
       " 'Texts_emb_479',\n",
       " 'Texts_emb_480',\n",
       " 'Texts_emb_481',\n",
       " 'Texts_emb_482',\n",
       " 'Texts_emb_483',\n",
       " 'Texts_emb_484',\n",
       " 'Texts_emb_485',\n",
       " 'Texts_emb_486',\n",
       " 'Texts_emb_487',\n",
       " 'Texts_emb_488',\n",
       " 'Texts_emb_489',\n",
       " 'Texts_emb_490',\n",
       " 'Texts_emb_491',\n",
       " 'Texts_emb_492',\n",
       " 'Texts_emb_493',\n",
       " 'Texts_emb_494',\n",
       " 'Texts_emb_495',\n",
       " 'Texts_emb_496',\n",
       " 'Texts_emb_497',\n",
       " 'Texts_emb_498',\n",
       " 'Texts_emb_499',\n",
       " 'Texts_emb_500',\n",
       " 'Texts_emb_501',\n",
       " 'Texts_emb_502',\n",
       " 'Texts_emb_503',\n",
       " 'Texts_emb_504',\n",
       " 'Texts_emb_505',\n",
       " 'Texts_emb_506',\n",
       " 'Texts_emb_507',\n",
       " 'Texts_emb_508',\n",
       " 'Texts_emb_509',\n",
       " 'Texts_emb_510',\n",
       " 'Texts_emb_511',\n",
       " 'Texts_emb_512',\n",
       " 'Texts_emb_513',\n",
       " 'Texts_emb_514',\n",
       " 'Texts_emb_515',\n",
       " 'Texts_emb_516',\n",
       " 'Texts_emb_517',\n",
       " 'Texts_emb_518',\n",
       " 'Texts_emb_519',\n",
       " 'Texts_emb_520',\n",
       " 'Texts_emb_521',\n",
       " 'Texts_emb_522',\n",
       " 'Texts_emb_523',\n",
       " 'Texts_emb_524',\n",
       " 'Texts_emb_525',\n",
       " 'Texts_emb_526',\n",
       " 'Texts_emb_527',\n",
       " 'Texts_emb_528',\n",
       " 'Texts_emb_529',\n",
       " 'Texts_emb_530',\n",
       " 'Texts_emb_531',\n",
       " 'Texts_emb_532',\n",
       " 'Texts_emb_533',\n",
       " 'Texts_emb_534',\n",
       " 'Texts_emb_535',\n",
       " 'Texts_emb_536',\n",
       " 'Texts_emb_537',\n",
       " 'Texts_emb_538',\n",
       " 'Texts_emb_539',\n",
       " 'Texts_emb_540',\n",
       " 'Texts_emb_541',\n",
       " 'Texts_emb_542',\n",
       " 'Texts_emb_543',\n",
       " 'Texts_emb_544',\n",
       " 'Texts_emb_545',\n",
       " 'Texts_emb_546',\n",
       " 'Texts_emb_547',\n",
       " 'Texts_emb_548',\n",
       " 'Texts_emb_549',\n",
       " 'Texts_emb_550',\n",
       " 'Texts_emb_551',\n",
       " 'Texts_emb_552',\n",
       " 'Texts_emb_553',\n",
       " 'Texts_emb_554',\n",
       " 'Texts_emb_555',\n",
       " 'Texts_emb_556',\n",
       " 'Texts_emb_557',\n",
       " 'Texts_emb_558',\n",
       " 'Texts_emb_559',\n",
       " 'Texts_emb_560',\n",
       " 'Texts_emb_561',\n",
       " 'Texts_emb_562',\n",
       " 'Texts_emb_563',\n",
       " 'Texts_emb_564',\n",
       " 'Texts_emb_565',\n",
       " 'Texts_emb_566',\n",
       " 'Texts_emb_567',\n",
       " 'Texts_emb_568',\n",
       " 'Texts_emb_569',\n",
       " 'Texts_emb_570',\n",
       " 'Texts_emb_571',\n",
       " 'Texts_emb_572',\n",
       " 'Texts_emb_573',\n",
       " 'Texts_emb_574',\n",
       " 'Texts_emb_575',\n",
       " 'Texts_emb_576',\n",
       " 'Texts_emb_577',\n",
       " 'Texts_emb_578',\n",
       " 'Texts_emb_579',\n",
       " 'Texts_emb_580',\n",
       " 'Texts_emb_581',\n",
       " 'Texts_emb_582',\n",
       " 'Texts_emb_583',\n",
       " 'Texts_emb_584',\n",
       " 'Texts_emb_585',\n",
       " 'Texts_emb_586',\n",
       " 'Texts_emb_587',\n",
       " 'Texts_emb_588',\n",
       " 'Texts_emb_589',\n",
       " 'Texts_emb_590',\n",
       " 'Texts_emb_591',\n",
       " 'Texts_emb_592',\n",
       " 'Texts_emb_593',\n",
       " 'Texts_emb_594',\n",
       " 'Texts_emb_595',\n",
       " 'Texts_emb_596',\n",
       " 'Texts_emb_597',\n",
       " 'Texts_emb_598',\n",
       " 'Texts_emb_599',\n",
       " 'Texts_emb_600',\n",
       " 'Texts_emb_601',\n",
       " 'Texts_emb_602',\n",
       " 'Texts_emb_603',\n",
       " 'Texts_emb_604',\n",
       " 'Texts_emb_605',\n",
       " 'Texts_emb_606',\n",
       " 'Texts_emb_607',\n",
       " 'Texts_emb_608',\n",
       " 'Texts_emb_609',\n",
       " 'Texts_emb_610',\n",
       " 'Texts_emb_611',\n",
       " 'Texts_emb_612',\n",
       " 'Texts_emb_613',\n",
       " 'Texts_emb_614',\n",
       " 'Texts_emb_615',\n",
       " 'Texts_emb_616',\n",
       " 'Texts_emb_617',\n",
       " 'Texts_emb_618',\n",
       " 'Texts_emb_619',\n",
       " 'Texts_emb_620',\n",
       " 'Texts_emb_621',\n",
       " 'Texts_emb_622',\n",
       " 'Texts_emb_623',\n",
       " 'Texts_emb_624',\n",
       " 'Texts_emb_625',\n",
       " 'Texts_emb_626',\n",
       " 'Texts_emb_627',\n",
       " 'Texts_emb_628',\n",
       " 'Texts_emb_629',\n",
       " 'Texts_emb_630',\n",
       " 'Texts_emb_631',\n",
       " 'Texts_emb_632',\n",
       " 'Texts_emb_633',\n",
       " 'Texts_emb_634',\n",
       " 'Texts_emb_635',\n",
       " 'Texts_emb_636',\n",
       " 'Texts_emb_637',\n",
       " 'Texts_emb_638',\n",
       " 'Texts_emb_639',\n",
       " 'Texts_emb_640',\n",
       " 'Texts_emb_641',\n",
       " 'Texts_emb_642',\n",
       " 'Texts_emb_643',\n",
       " 'Texts_emb_644',\n",
       " 'Texts_emb_645',\n",
       " 'Texts_emb_646',\n",
       " 'Texts_emb_647',\n",
       " 'Texts_emb_648',\n",
       " 'Texts_emb_649',\n",
       " 'Texts_emb_650',\n",
       " 'Texts_emb_651',\n",
       " 'Texts_emb_652',\n",
       " 'Texts_emb_653',\n",
       " 'Texts_emb_654',\n",
       " 'Texts_emb_655',\n",
       " 'Texts_emb_656',\n",
       " 'Texts_emb_657',\n",
       " 'Texts_emb_658',\n",
       " 'Texts_emb_659',\n",
       " 'Texts_emb_660',\n",
       " 'Texts_emb_661',\n",
       " 'Texts_emb_662',\n",
       " 'Texts_emb_663',\n",
       " 'Texts_emb_664',\n",
       " 'Texts_emb_665',\n",
       " 'Texts_emb_666',\n",
       " 'Texts_emb_667',\n",
       " 'Texts_emb_668',\n",
       " 'Texts_emb_669',\n",
       " 'Texts_emb_670',\n",
       " 'Texts_emb_671',\n",
       " 'Texts_emb_672',\n",
       " 'Texts_emb_673',\n",
       " 'Texts_emb_674',\n",
       " 'Texts_emb_675',\n",
       " 'Texts_emb_676',\n",
       " 'Texts_emb_677',\n",
       " 'Texts_emb_678',\n",
       " 'Texts_emb_679',\n",
       " 'Texts_emb_680',\n",
       " 'Texts_emb_681',\n",
       " 'Texts_emb_682',\n",
       " 'Texts_emb_683',\n",
       " 'Texts_emb_684',\n",
       " 'Texts_emb_685',\n",
       " 'Texts_emb_686',\n",
       " 'Texts_emb_687',\n",
       " 'Texts_emb_688',\n",
       " 'Texts_emb_689',\n",
       " 'Texts_emb_690',\n",
       " 'Texts_emb_691',\n",
       " 'Texts_emb_692',\n",
       " 'Texts_emb_693',\n",
       " 'Texts_emb_694',\n",
       " 'Texts_emb_695',\n",
       " 'Texts_emb_696',\n",
       " 'Texts_emb_697',\n",
       " 'Texts_emb_698',\n",
       " 'Texts_emb_699',\n",
       " 'Texts_emb_700',\n",
       " 'Texts_emb_701',\n",
       " 'Texts_emb_702',\n",
       " 'Texts_emb_703',\n",
       " 'Texts_emb_704',\n",
       " 'Texts_emb_705',\n",
       " 'Texts_emb_706',\n",
       " 'Texts_emb_707',\n",
       " 'Texts_emb_708',\n",
       " 'Texts_emb_709',\n",
       " 'Texts_emb_710',\n",
       " 'Texts_emb_711',\n",
       " 'Texts_emb_712',\n",
       " 'Texts_emb_713',\n",
       " 'Texts_emb_714',\n",
       " 'Texts_emb_715',\n",
       " 'Texts_emb_716',\n",
       " 'Texts_emb_717',\n",
       " 'Texts_emb_718',\n",
       " 'Texts_emb_719',\n",
       " 'Texts_emb_720',\n",
       " 'Texts_emb_721',\n",
       " 'Texts_emb_722',\n",
       " 'Texts_emb_723',\n",
       " 'Texts_emb_724',\n",
       " 'Texts_emb_725',\n",
       " 'Texts_emb_726',\n",
       " 'Texts_emb_727',\n",
       " 'Texts_emb_728',\n",
       " 'Texts_emb_729',\n",
       " 'Texts_emb_730',\n",
       " 'Texts_emb_731',\n",
       " 'Texts_emb_732',\n",
       " 'Texts_emb_733',\n",
       " 'Texts_emb_734',\n",
       " 'Texts_emb_735',\n",
       " 'Texts_emb_736',\n",
       " 'Texts_emb_737',\n",
       " 'Texts_emb_738',\n",
       " 'Texts_emb_739',\n",
       " 'Texts_emb_740',\n",
       " 'Texts_emb_741',\n",
       " 'Texts_emb_742',\n",
       " 'Texts_emb_743',\n",
       " 'Texts_emb_744',\n",
       " 'Texts_emb_745',\n",
       " 'Texts_emb_746',\n",
       " 'Texts_emb_747',\n",
       " 'Texts_emb_748',\n",
       " 'Texts_emb_749',\n",
       " 'Texts_emb_750',\n",
       " 'Texts_emb_751',\n",
       " 'Texts_emb_752',\n",
       " 'Texts_emb_753',\n",
       " 'Texts_emb_754',\n",
       " 'Texts_emb_755',\n",
       " 'Texts_emb_756',\n",
       " 'Texts_emb_757',\n",
       " 'Texts_emb_758',\n",
       " 'Texts_emb_759',\n",
       " 'Texts_emb_760',\n",
       " 'Texts_emb_761',\n",
       " 'Texts_emb_762',\n",
       " 'Texts_emb_763',\n",
       " 'Texts_emb_764',\n",
       " 'Texts_emb_765',\n",
       " 'Texts_emb_766',\n",
       " 'Texts_emb_767',\n",
       " 'Texts_emb_768']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Texts_emb_1',\n",
       " 'Texts_emb_2',\n",
       " 'Texts_emb_3',\n",
       " 'Texts_emb_4',\n",
       " 'Texts_emb_5',\n",
       " 'Texts_emb_6',\n",
       " 'Texts_emb_7',\n",
       " 'Texts_emb_8',\n",
       " 'Texts_emb_9',\n",
       " 'Texts_emb_10',\n",
       " 'Texts_emb_11',\n",
       " 'Texts_emb_12',\n",
       " 'Texts_emb_13',\n",
       " 'Texts_emb_14',\n",
       " 'Texts_emb_15',\n",
       " 'Texts_emb_16',\n",
       " 'Texts_emb_17',\n",
       " 'Texts_emb_18',\n",
       " 'Texts_emb_19',\n",
       " 'Texts_emb_20',\n",
       " 'Texts_emb_21',\n",
       " 'Texts_emb_22',\n",
       " 'Texts_emb_23',\n",
       " 'Texts_emb_24',\n",
       " 'Texts_emb_25',\n",
       " 'Texts_emb_26',\n",
       " 'Texts_emb_27',\n",
       " 'Texts_emb_28',\n",
       " 'Texts_emb_29',\n",
       " 'Texts_emb_30',\n",
       " 'Texts_emb_31',\n",
       " 'Texts_emb_32',\n",
       " 'Texts_emb_33',\n",
       " 'Texts_emb_34',\n",
       " 'Texts_emb_35',\n",
       " 'Texts_emb_36',\n",
       " 'Texts_emb_37',\n",
       " 'Texts_emb_38',\n",
       " 'Texts_emb_39',\n",
       " 'Texts_emb_40',\n",
       " 'Texts_emb_41',\n",
       " 'Texts_emb_42',\n",
       " 'Texts_emb_43',\n",
       " 'Texts_emb_44',\n",
       " 'Texts_emb_45',\n",
       " 'Texts_emb_46',\n",
       " 'Texts_emb_47',\n",
       " 'Texts_emb_48',\n",
       " 'Texts_emb_49',\n",
       " 'Texts_emb_50',\n",
       " 'Texts_emb_51',\n",
       " 'Texts_emb_52',\n",
       " 'Texts_emb_53',\n",
       " 'Texts_emb_54',\n",
       " 'Texts_emb_55',\n",
       " 'Texts_emb_56',\n",
       " 'Texts_emb_57',\n",
       " 'Texts_emb_58',\n",
       " 'Texts_emb_59',\n",
       " 'Texts_emb_60',\n",
       " 'Texts_emb_61',\n",
       " 'Texts_emb_62',\n",
       " 'Texts_emb_63',\n",
       " 'Texts_emb_64',\n",
       " 'Texts_emb_65',\n",
       " 'Texts_emb_66',\n",
       " 'Texts_emb_67',\n",
       " 'Texts_emb_68',\n",
       " 'Texts_emb_69',\n",
       " 'Texts_emb_70',\n",
       " 'Texts_emb_71',\n",
       " 'Texts_emb_72',\n",
       " 'Texts_emb_73',\n",
       " 'Texts_emb_74',\n",
       " 'Texts_emb_75',\n",
       " 'Texts_emb_76',\n",
       " 'Texts_emb_77',\n",
       " 'Texts_emb_78',\n",
       " 'Texts_emb_79',\n",
       " 'Texts_emb_80',\n",
       " 'Texts_emb_81',\n",
       " 'Texts_emb_82',\n",
       " 'Texts_emb_83',\n",
       " 'Texts_emb_84',\n",
       " 'Texts_emb_85',\n",
       " 'Texts_emb_86',\n",
       " 'Texts_emb_87',\n",
       " 'Texts_emb_88',\n",
       " 'Texts_emb_89',\n",
       " 'Texts_emb_90',\n",
       " 'Texts_emb_91',\n",
       " 'Texts_emb_92',\n",
       " 'Texts_emb_93',\n",
       " 'Texts_emb_94',\n",
       " 'Texts_emb_95',\n",
       " 'Texts_emb_96',\n",
       " 'Texts_emb_97',\n",
       " 'Texts_emb_98',\n",
       " 'Texts_emb_99',\n",
       " 'Texts_emb_100',\n",
       " 'Texts_emb_101',\n",
       " 'Texts_emb_102',\n",
       " 'Texts_emb_103',\n",
       " 'Texts_emb_104',\n",
       " 'Texts_emb_105',\n",
       " 'Texts_emb_106',\n",
       " 'Texts_emb_107',\n",
       " 'Texts_emb_108',\n",
       " 'Texts_emb_109',\n",
       " 'Texts_emb_110',\n",
       " 'Texts_emb_111',\n",
       " 'Texts_emb_112',\n",
       " 'Texts_emb_113',\n",
       " 'Texts_emb_114',\n",
       " 'Texts_emb_115',\n",
       " 'Texts_emb_116',\n",
       " 'Texts_emb_117',\n",
       " 'Texts_emb_118',\n",
       " 'Texts_emb_119',\n",
       " 'Texts_emb_120',\n",
       " 'Texts_emb_121',\n",
       " 'Texts_emb_122',\n",
       " 'Texts_emb_123',\n",
       " 'Texts_emb_124',\n",
       " 'Texts_emb_125',\n",
       " 'Texts_emb_126',\n",
       " 'Texts_emb_127',\n",
       " 'Texts_emb_128',\n",
       " 'Texts_emb_129',\n",
       " 'Texts_emb_130',\n",
       " 'Texts_emb_131',\n",
       " 'Texts_emb_132',\n",
       " 'Texts_emb_133',\n",
       " 'Texts_emb_134',\n",
       " 'Texts_emb_135',\n",
       " 'Texts_emb_136',\n",
       " 'Texts_emb_137',\n",
       " 'Texts_emb_138',\n",
       " 'Texts_emb_139',\n",
       " 'Texts_emb_140',\n",
       " 'Texts_emb_141',\n",
       " 'Texts_emb_142',\n",
       " 'Texts_emb_143',\n",
       " 'Texts_emb_144',\n",
       " 'Texts_emb_145',\n",
       " 'Texts_emb_146',\n",
       " 'Texts_emb_147',\n",
       " 'Texts_emb_148',\n",
       " 'Texts_emb_149',\n",
       " 'Texts_emb_150',\n",
       " 'Texts_emb_151',\n",
       " 'Texts_emb_152',\n",
       " 'Texts_emb_153',\n",
       " 'Texts_emb_154',\n",
       " 'Texts_emb_155',\n",
       " 'Texts_emb_156',\n",
       " 'Texts_emb_157',\n",
       " 'Texts_emb_158',\n",
       " 'Texts_emb_159',\n",
       " 'Texts_emb_160',\n",
       " 'Texts_emb_161',\n",
       " 'Texts_emb_162',\n",
       " 'Texts_emb_163',\n",
       " 'Texts_emb_164',\n",
       " 'Texts_emb_165',\n",
       " 'Texts_emb_166',\n",
       " 'Texts_emb_167',\n",
       " 'Texts_emb_168',\n",
       " 'Texts_emb_169',\n",
       " 'Texts_emb_170',\n",
       " 'Texts_emb_171',\n",
       " 'Texts_emb_172',\n",
       " 'Texts_emb_173',\n",
       " 'Texts_emb_174',\n",
       " 'Texts_emb_175',\n",
       " 'Texts_emb_176',\n",
       " 'Texts_emb_177',\n",
       " 'Texts_emb_178',\n",
       " 'Texts_emb_179',\n",
       " 'Texts_emb_180',\n",
       " 'Texts_emb_181',\n",
       " 'Texts_emb_182',\n",
       " 'Texts_emb_183',\n",
       " 'Texts_emb_184',\n",
       " 'Texts_emb_185',\n",
       " 'Texts_emb_186',\n",
       " 'Texts_emb_187',\n",
       " 'Texts_emb_188',\n",
       " 'Texts_emb_189',\n",
       " 'Texts_emb_190',\n",
       " 'Texts_emb_191',\n",
       " 'Texts_emb_192',\n",
       " 'Texts_emb_193',\n",
       " 'Texts_emb_194',\n",
       " 'Texts_emb_195',\n",
       " 'Texts_emb_196',\n",
       " 'Texts_emb_197',\n",
       " 'Texts_emb_198',\n",
       " 'Texts_emb_199',\n",
       " 'Texts_emb_200',\n",
       " 'Texts_emb_201',\n",
       " 'Texts_emb_202',\n",
       " 'Texts_emb_203',\n",
       " 'Texts_emb_204',\n",
       " 'Texts_emb_205',\n",
       " 'Texts_emb_206',\n",
       " 'Texts_emb_207',\n",
       " 'Texts_emb_208',\n",
       " 'Texts_emb_209',\n",
       " 'Texts_emb_210',\n",
       " 'Texts_emb_211',\n",
       " 'Texts_emb_212',\n",
       " 'Texts_emb_213',\n",
       " 'Texts_emb_214',\n",
       " 'Texts_emb_215',\n",
       " 'Texts_emb_216',\n",
       " 'Texts_emb_217',\n",
       " 'Texts_emb_218',\n",
       " 'Texts_emb_219',\n",
       " 'Texts_emb_220',\n",
       " 'Texts_emb_221',\n",
       " 'Texts_emb_222',\n",
       " 'Texts_emb_223',\n",
       " 'Texts_emb_224',\n",
       " 'Texts_emb_225',\n",
       " 'Texts_emb_226',\n",
       " 'Texts_emb_227',\n",
       " 'Texts_emb_228',\n",
       " 'Texts_emb_229',\n",
       " 'Texts_emb_230',\n",
       " 'Texts_emb_231',\n",
       " 'Texts_emb_232',\n",
       " 'Texts_emb_233',\n",
       " 'Texts_emb_234',\n",
       " 'Texts_emb_235',\n",
       " 'Texts_emb_236',\n",
       " 'Texts_emb_237',\n",
       " 'Texts_emb_238',\n",
       " 'Texts_emb_239',\n",
       " 'Texts_emb_240',\n",
       " 'Texts_emb_241',\n",
       " 'Texts_emb_242',\n",
       " 'Texts_emb_243',\n",
       " 'Texts_emb_244',\n",
       " 'Texts_emb_245',\n",
       " 'Texts_emb_246',\n",
       " 'Texts_emb_247',\n",
       " 'Texts_emb_248',\n",
       " 'Texts_emb_249',\n",
       " 'Texts_emb_250',\n",
       " 'Texts_emb_251',\n",
       " 'Texts_emb_252',\n",
       " 'Texts_emb_253',\n",
       " 'Texts_emb_254',\n",
       " 'Texts_emb_255',\n",
       " 'Texts_emb_256',\n",
       " 'Texts_emb_257',\n",
       " 'Texts_emb_258',\n",
       " 'Texts_emb_259',\n",
       " 'Texts_emb_260',\n",
       " 'Texts_emb_261',\n",
       " 'Texts_emb_262',\n",
       " 'Texts_emb_263',\n",
       " 'Texts_emb_264',\n",
       " 'Texts_emb_265',\n",
       " 'Texts_emb_266',\n",
       " 'Texts_emb_267',\n",
       " 'Texts_emb_268',\n",
       " 'Texts_emb_269',\n",
       " 'Texts_emb_270',\n",
       " 'Texts_emb_271',\n",
       " 'Texts_emb_272',\n",
       " 'Texts_emb_273',\n",
       " 'Texts_emb_274',\n",
       " 'Texts_emb_275',\n",
       " 'Texts_emb_276',\n",
       " 'Texts_emb_277',\n",
       " 'Texts_emb_278',\n",
       " 'Texts_emb_279',\n",
       " 'Texts_emb_280',\n",
       " 'Texts_emb_281',\n",
       " 'Texts_emb_282',\n",
       " 'Texts_emb_283',\n",
       " 'Texts_emb_284',\n",
       " 'Texts_emb_285',\n",
       " 'Texts_emb_286',\n",
       " 'Texts_emb_287',\n",
       " 'Texts_emb_288',\n",
       " 'Texts_emb_289',\n",
       " 'Texts_emb_290',\n",
       " 'Texts_emb_291',\n",
       " 'Texts_emb_292',\n",
       " 'Texts_emb_293',\n",
       " 'Texts_emb_294',\n",
       " 'Texts_emb_295',\n",
       " 'Texts_emb_296',\n",
       " 'Texts_emb_297',\n",
       " 'Texts_emb_298',\n",
       " 'Texts_emb_299',\n",
       " 'Texts_emb_300',\n",
       " 'Texts_emb_301',\n",
       " 'Texts_emb_302',\n",
       " 'Texts_emb_303',\n",
       " 'Texts_emb_304',\n",
       " 'Texts_emb_305',\n",
       " 'Texts_emb_306',\n",
       " 'Texts_emb_307',\n",
       " 'Texts_emb_308',\n",
       " 'Texts_emb_309',\n",
       " 'Texts_emb_310',\n",
       " 'Texts_emb_311',\n",
       " 'Texts_emb_312',\n",
       " 'Texts_emb_313',\n",
       " 'Texts_emb_314',\n",
       " 'Texts_emb_315',\n",
       " 'Texts_emb_316',\n",
       " 'Texts_emb_317',\n",
       " 'Texts_emb_318',\n",
       " 'Texts_emb_319',\n",
       " 'Texts_emb_320',\n",
       " 'Texts_emb_321',\n",
       " 'Texts_emb_322',\n",
       " 'Texts_emb_323',\n",
       " 'Texts_emb_324',\n",
       " 'Texts_emb_325',\n",
       " 'Texts_emb_326',\n",
       " 'Texts_emb_327',\n",
       " 'Texts_emb_328',\n",
       " 'Texts_emb_329',\n",
       " 'Texts_emb_330',\n",
       " 'Texts_emb_331',\n",
       " 'Texts_emb_332',\n",
       " 'Texts_emb_333',\n",
       " 'Texts_emb_334',\n",
       " 'Texts_emb_335',\n",
       " 'Texts_emb_336',\n",
       " 'Texts_emb_337',\n",
       " 'Texts_emb_338',\n",
       " 'Texts_emb_339',\n",
       " 'Texts_emb_340',\n",
       " 'Texts_emb_341',\n",
       " 'Texts_emb_342',\n",
       " 'Texts_emb_343',\n",
       " 'Texts_emb_344',\n",
       " 'Texts_emb_345',\n",
       " 'Texts_emb_346',\n",
       " 'Texts_emb_347',\n",
       " 'Texts_emb_348',\n",
       " 'Texts_emb_349',\n",
       " 'Texts_emb_350',\n",
       " 'Texts_emb_351',\n",
       " 'Texts_emb_352',\n",
       " 'Texts_emb_353',\n",
       " 'Texts_emb_354',\n",
       " 'Texts_emb_355',\n",
       " 'Texts_emb_356',\n",
       " 'Texts_emb_357',\n",
       " 'Texts_emb_358',\n",
       " 'Texts_emb_359',\n",
       " 'Texts_emb_360',\n",
       " 'Texts_emb_361',\n",
       " 'Texts_emb_362',\n",
       " 'Texts_emb_363',\n",
       " 'Texts_emb_364',\n",
       " 'Texts_emb_365',\n",
       " 'Texts_emb_366',\n",
       " 'Texts_emb_367',\n",
       " 'Texts_emb_368',\n",
       " 'Texts_emb_369',\n",
       " 'Texts_emb_370',\n",
       " 'Texts_emb_371',\n",
       " 'Texts_emb_372',\n",
       " 'Texts_emb_373',\n",
       " 'Texts_emb_374',\n",
       " 'Texts_emb_375',\n",
       " 'Texts_emb_376',\n",
       " 'Texts_emb_377',\n",
       " 'Texts_emb_378',\n",
       " 'Texts_emb_379',\n",
       " 'Texts_emb_380',\n",
       " 'Texts_emb_381',\n",
       " 'Texts_emb_382',\n",
       " 'Texts_emb_383',\n",
       " 'Texts_emb_384',\n",
       " 'Texts_emb_385',\n",
       " 'Texts_emb_386',\n",
       " 'Texts_emb_387',\n",
       " 'Texts_emb_388',\n",
       " 'Texts_emb_389',\n",
       " 'Texts_emb_390',\n",
       " 'Texts_emb_391',\n",
       " 'Texts_emb_392',\n",
       " 'Texts_emb_393',\n",
       " 'Texts_emb_394',\n",
       " 'Texts_emb_395',\n",
       " 'Texts_emb_396',\n",
       " 'Texts_emb_397',\n",
       " 'Texts_emb_398',\n",
       " 'Texts_emb_399',\n",
       " 'Texts_emb_400',\n",
       " 'Texts_emb_401',\n",
       " 'Texts_emb_402',\n",
       " 'Texts_emb_403',\n",
       " 'Texts_emb_404',\n",
       " 'Texts_emb_405',\n",
       " 'Texts_emb_406',\n",
       " 'Texts_emb_407',\n",
       " 'Texts_emb_408',\n",
       " 'Texts_emb_409',\n",
       " 'Texts_emb_410',\n",
       " 'Texts_emb_411',\n",
       " 'Texts_emb_412',\n",
       " 'Texts_emb_413',\n",
       " 'Texts_emb_414',\n",
       " 'Texts_emb_415',\n",
       " 'Texts_emb_416',\n",
       " 'Texts_emb_417',\n",
       " 'Texts_emb_418',\n",
       " 'Texts_emb_419',\n",
       " 'Texts_emb_420',\n",
       " 'Texts_emb_421',\n",
       " 'Texts_emb_422',\n",
       " 'Texts_emb_423',\n",
       " 'Texts_emb_424',\n",
       " 'Texts_emb_425',\n",
       " 'Texts_emb_426',\n",
       " 'Texts_emb_427',\n",
       " 'Texts_emb_428',\n",
       " 'Texts_emb_429',\n",
       " 'Texts_emb_430',\n",
       " 'Texts_emb_431',\n",
       " 'Texts_emb_432',\n",
       " 'Texts_emb_433',\n",
       " 'Texts_emb_434',\n",
       " 'Texts_emb_435',\n",
       " 'Texts_emb_436',\n",
       " 'Texts_emb_437',\n",
       " 'Texts_emb_438',\n",
       " 'Texts_emb_439',\n",
       " 'Texts_emb_440',\n",
       " 'Texts_emb_441',\n",
       " 'Texts_emb_442',\n",
       " 'Texts_emb_443',\n",
       " 'Texts_emb_444',\n",
       " 'Texts_emb_445',\n",
       " 'Texts_emb_446',\n",
       " 'Texts_emb_447',\n",
       " 'Texts_emb_448',\n",
       " 'Texts_emb_449',\n",
       " 'Texts_emb_450',\n",
       " 'Texts_emb_451',\n",
       " 'Texts_emb_452',\n",
       " 'Texts_emb_453',\n",
       " 'Texts_emb_454',\n",
       " 'Texts_emb_455',\n",
       " 'Texts_emb_456',\n",
       " 'Texts_emb_457',\n",
       " 'Texts_emb_458',\n",
       " 'Texts_emb_459',\n",
       " 'Texts_emb_460',\n",
       " 'Texts_emb_461',\n",
       " 'Texts_emb_462',\n",
       " 'Texts_emb_463',\n",
       " 'Texts_emb_464',\n",
       " 'Texts_emb_465',\n",
       " 'Texts_emb_466',\n",
       " 'Texts_emb_467',\n",
       " 'Texts_emb_468',\n",
       " 'Texts_emb_469',\n",
       " 'Texts_emb_470',\n",
       " 'Texts_emb_471',\n",
       " 'Texts_emb_472',\n",
       " 'Texts_emb_473',\n",
       " 'Texts_emb_474',\n",
       " 'Texts_emb_475',\n",
       " 'Texts_emb_476',\n",
       " 'Texts_emb_477',\n",
       " 'Texts_emb_478',\n",
       " 'Texts_emb_479',\n",
       " 'Texts_emb_480',\n",
       " 'Texts_emb_481',\n",
       " 'Texts_emb_482',\n",
       " 'Texts_emb_483',\n",
       " 'Texts_emb_484',\n",
       " 'Texts_emb_485',\n",
       " 'Texts_emb_486',\n",
       " 'Texts_emb_487',\n",
       " 'Texts_emb_488',\n",
       " 'Texts_emb_489',\n",
       " 'Texts_emb_490',\n",
       " 'Texts_emb_491',\n",
       " 'Texts_emb_492',\n",
       " 'Texts_emb_493',\n",
       " 'Texts_emb_494',\n",
       " 'Texts_emb_495',\n",
       " 'Texts_emb_496',\n",
       " 'Texts_emb_497',\n",
       " 'Texts_emb_498',\n",
       " 'Texts_emb_499',\n",
       " 'Texts_emb_500',\n",
       " 'Texts_emb_501',\n",
       " 'Texts_emb_502',\n",
       " 'Texts_emb_503',\n",
       " 'Texts_emb_504',\n",
       " 'Texts_emb_505',\n",
       " 'Texts_emb_506',\n",
       " 'Texts_emb_507',\n",
       " 'Texts_emb_508',\n",
       " 'Texts_emb_509',\n",
       " 'Texts_emb_510',\n",
       " 'Texts_emb_511',\n",
       " 'Texts_emb_512',\n",
       " 'Texts_emb_513',\n",
       " 'Texts_emb_514',\n",
       " 'Texts_emb_515',\n",
       " 'Texts_emb_516',\n",
       " 'Texts_emb_517',\n",
       " 'Texts_emb_518',\n",
       " 'Texts_emb_519',\n",
       " 'Texts_emb_520',\n",
       " 'Texts_emb_521',\n",
       " 'Texts_emb_522',\n",
       " 'Texts_emb_523',\n",
       " 'Texts_emb_524',\n",
       " 'Texts_emb_525',\n",
       " 'Texts_emb_526',\n",
       " 'Texts_emb_527',\n",
       " 'Texts_emb_528',\n",
       " 'Texts_emb_529',\n",
       " 'Texts_emb_530',\n",
       " 'Texts_emb_531',\n",
       " 'Texts_emb_532',\n",
       " 'Texts_emb_533',\n",
       " 'Texts_emb_534',\n",
       " 'Texts_emb_535',\n",
       " 'Texts_emb_536',\n",
       " 'Texts_emb_537',\n",
       " 'Texts_emb_538',\n",
       " 'Texts_emb_539',\n",
       " 'Texts_emb_540',\n",
       " 'Texts_emb_541',\n",
       " 'Texts_emb_542',\n",
       " 'Texts_emb_543',\n",
       " 'Texts_emb_544',\n",
       " 'Texts_emb_545',\n",
       " 'Texts_emb_546',\n",
       " 'Texts_emb_547',\n",
       " 'Texts_emb_548',\n",
       " 'Texts_emb_549',\n",
       " 'Texts_emb_550',\n",
       " 'Texts_emb_551',\n",
       " 'Texts_emb_552',\n",
       " 'Texts_emb_553',\n",
       " 'Texts_emb_554',\n",
       " 'Texts_emb_555',\n",
       " 'Texts_emb_556',\n",
       " 'Texts_emb_557',\n",
       " 'Texts_emb_558',\n",
       " 'Texts_emb_559',\n",
       " 'Texts_emb_560',\n",
       " 'Texts_emb_561',\n",
       " 'Texts_emb_562',\n",
       " 'Texts_emb_563',\n",
       " 'Texts_emb_564',\n",
       " 'Texts_emb_565',\n",
       " 'Texts_emb_566',\n",
       " 'Texts_emb_567',\n",
       " 'Texts_emb_568',\n",
       " 'Texts_emb_569',\n",
       " 'Texts_emb_570',\n",
       " 'Texts_emb_571',\n",
       " 'Texts_emb_572',\n",
       " 'Texts_emb_573',\n",
       " 'Texts_emb_574',\n",
       " 'Texts_emb_575',\n",
       " 'Texts_emb_576',\n",
       " 'Texts_emb_577',\n",
       " 'Texts_emb_578',\n",
       " 'Texts_emb_579',\n",
       " 'Texts_emb_580',\n",
       " 'Texts_emb_581',\n",
       " 'Texts_emb_582',\n",
       " 'Texts_emb_583',\n",
       " 'Texts_emb_584',\n",
       " 'Texts_emb_585',\n",
       " 'Texts_emb_586',\n",
       " 'Texts_emb_587',\n",
       " 'Texts_emb_588',\n",
       " 'Texts_emb_589',\n",
       " 'Texts_emb_590',\n",
       " 'Texts_emb_591',\n",
       " 'Texts_emb_592',\n",
       " 'Texts_emb_593',\n",
       " 'Texts_emb_594',\n",
       " 'Texts_emb_595',\n",
       " 'Texts_emb_596',\n",
       " 'Texts_emb_597',\n",
       " 'Texts_emb_598',\n",
       " 'Texts_emb_599',\n",
       " 'Texts_emb_600',\n",
       " 'Texts_emb_601',\n",
       " 'Texts_emb_602',\n",
       " 'Texts_emb_603',\n",
       " 'Texts_emb_604',\n",
       " 'Texts_emb_605',\n",
       " 'Texts_emb_606',\n",
       " 'Texts_emb_607',\n",
       " 'Texts_emb_608',\n",
       " 'Texts_emb_609',\n",
       " 'Texts_emb_610',\n",
       " 'Texts_emb_611',\n",
       " 'Texts_emb_612',\n",
       " 'Texts_emb_613',\n",
       " 'Texts_emb_614',\n",
       " 'Texts_emb_615',\n",
       " 'Texts_emb_616',\n",
       " 'Texts_emb_617',\n",
       " 'Texts_emb_618',\n",
       " 'Texts_emb_619',\n",
       " 'Texts_emb_620',\n",
       " 'Texts_emb_621',\n",
       " 'Texts_emb_622',\n",
       " 'Texts_emb_623',\n",
       " 'Texts_emb_624',\n",
       " 'Texts_emb_625',\n",
       " 'Texts_emb_626',\n",
       " 'Texts_emb_627',\n",
       " 'Texts_emb_628',\n",
       " 'Texts_emb_629',\n",
       " 'Texts_emb_630',\n",
       " 'Texts_emb_631',\n",
       " 'Texts_emb_632',\n",
       " 'Texts_emb_633',\n",
       " 'Texts_emb_634',\n",
       " 'Texts_emb_635',\n",
       " 'Texts_emb_636',\n",
       " 'Texts_emb_637',\n",
       " 'Texts_emb_638',\n",
       " 'Texts_emb_639',\n",
       " 'Texts_emb_640',\n",
       " 'Texts_emb_641',\n",
       " 'Texts_emb_642',\n",
       " 'Texts_emb_643',\n",
       " 'Texts_emb_644',\n",
       " 'Texts_emb_645',\n",
       " 'Texts_emb_646',\n",
       " 'Texts_emb_647',\n",
       " 'Texts_emb_648',\n",
       " 'Texts_emb_649',\n",
       " 'Texts_emb_650',\n",
       " 'Texts_emb_651',\n",
       " 'Texts_emb_652',\n",
       " 'Texts_emb_653',\n",
       " 'Texts_emb_654',\n",
       " 'Texts_emb_655',\n",
       " 'Texts_emb_656',\n",
       " 'Texts_emb_657',\n",
       " 'Texts_emb_658',\n",
       " 'Texts_emb_659',\n",
       " 'Texts_emb_660',\n",
       " 'Texts_emb_661',\n",
       " 'Texts_emb_662',\n",
       " 'Texts_emb_663',\n",
       " 'Texts_emb_664',\n",
       " 'Texts_emb_665',\n",
       " 'Texts_emb_666',\n",
       " 'Texts_emb_667',\n",
       " 'Texts_emb_668',\n",
       " 'Texts_emb_669',\n",
       " 'Texts_emb_670',\n",
       " 'Texts_emb_671',\n",
       " 'Texts_emb_672',\n",
       " 'Texts_emb_673',\n",
       " 'Texts_emb_674',\n",
       " 'Texts_emb_675',\n",
       " 'Texts_emb_676',\n",
       " 'Texts_emb_677',\n",
       " 'Texts_emb_678',\n",
       " 'Texts_emb_679',\n",
       " 'Texts_emb_680',\n",
       " 'Texts_emb_681',\n",
       " 'Texts_emb_682',\n",
       " 'Texts_emb_683',\n",
       " 'Texts_emb_684',\n",
       " 'Texts_emb_685',\n",
       " 'Texts_emb_686',\n",
       " 'Texts_emb_687',\n",
       " 'Texts_emb_688',\n",
       " 'Texts_emb_689',\n",
       " 'Texts_emb_690',\n",
       " 'Texts_emb_691',\n",
       " 'Texts_emb_692',\n",
       " 'Texts_emb_693',\n",
       " 'Texts_emb_694',\n",
       " 'Texts_emb_695',\n",
       " 'Texts_emb_696',\n",
       " 'Texts_emb_697',\n",
       " 'Texts_emb_698',\n",
       " 'Texts_emb_699',\n",
       " 'Texts_emb_700',\n",
       " 'Texts_emb_701',\n",
       " 'Texts_emb_702',\n",
       " 'Texts_emb_703',\n",
       " 'Texts_emb_704',\n",
       " 'Texts_emb_705',\n",
       " 'Texts_emb_706',\n",
       " 'Texts_emb_707',\n",
       " 'Texts_emb_708',\n",
       " 'Texts_emb_709',\n",
       " 'Texts_emb_710',\n",
       " 'Texts_emb_711',\n",
       " 'Texts_emb_712',\n",
       " 'Texts_emb_713',\n",
       " 'Texts_emb_714',\n",
       " 'Texts_emb_715',\n",
       " 'Texts_emb_716',\n",
       " 'Texts_emb_717',\n",
       " 'Texts_emb_718',\n",
       " 'Texts_emb_719',\n",
       " 'Texts_emb_720',\n",
       " 'Texts_emb_721',\n",
       " 'Texts_emb_722',\n",
       " 'Texts_emb_723',\n",
       " 'Texts_emb_724',\n",
       " 'Texts_emb_725',\n",
       " 'Texts_emb_726',\n",
       " 'Texts_emb_727',\n",
       " 'Texts_emb_728',\n",
       " 'Texts_emb_729',\n",
       " 'Texts_emb_730',\n",
       " 'Texts_emb_731',\n",
       " 'Texts_emb_732',\n",
       " 'Texts_emb_733',\n",
       " 'Texts_emb_734',\n",
       " 'Texts_emb_735',\n",
       " 'Texts_emb_736',\n",
       " 'Texts_emb_737',\n",
       " 'Texts_emb_738',\n",
       " 'Texts_emb_739',\n",
       " 'Texts_emb_740',\n",
       " 'Texts_emb_741',\n",
       " 'Texts_emb_742',\n",
       " 'Texts_emb_743',\n",
       " 'Texts_emb_744',\n",
       " 'Texts_emb_745',\n",
       " 'Texts_emb_746',\n",
       " 'Texts_emb_747',\n",
       " 'Texts_emb_748',\n",
       " 'Texts_emb_749',\n",
       " 'Texts_emb_750',\n",
       " 'Texts_emb_751',\n",
       " 'Texts_emb_752',\n",
       " 'Texts_emb_753',\n",
       " 'Texts_emb_754',\n",
       " 'Texts_emb_755',\n",
       " 'Texts_emb_756',\n",
       " 'Texts_emb_757',\n",
       " 'Texts_emb_758',\n",
       " 'Texts_emb_759',\n",
       " 'Texts_emb_760',\n",
       " 'Texts_emb_761',\n",
       " 'Texts_emb_762',\n",
       " 'Texts_emb_763',\n",
       " 'Texts_emb_764',\n",
       " 'Texts_emb_765',\n",
       " 'Texts_emb_766',\n",
       " 'Texts_emb_767',\n",
       " 'Texts_emb_768']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ...\n",
      "[Pipeline] ........ (step 1 of 5) Processing vectorizer, total=   0.0s\n",
      "[Pipeline] .......... (step 2 of 5) Processing sampling, total=   0.0s\n",
      "[Pipeline] ........... (step 3 of 5) Processing scaling, total=   0.0s\n",
      "[Pipeline] ......... (step 4 of 5) Processing selection, total=   0.0s\n",
      "[16:54:36] ======== Monitor (0): HostSketchContainer ========\n",
      "[16:54:36] AllReduce: 0.023712s, 1 calls @ 23712us\n",
      "\n",
      "[16:54:36] MakeCuts: 0.035969s, 1 calls @ 35969us\n",
      "\n",
      "[16:54:36] DEBUG: /workspace/src/gbm/gbtree.cc:130: Using tree method: 3\n",
      "[16:54:36] DEBUG: /workspace/src/tree/updater_gpu_hist.cu:744: [GPU Hist]: Configure\n",
      "[16:54:36] ======== Monitor (0):  ========\n",
      "[16:54:36] InitCompressedData: 0.001512s, 1 calls @ 1512us\n",
      "\n",
      "[16:54:38] ======== Monitor (0): Learner ========\n",
      "[16:54:38] Configure: 0.009921s, 1 calls @ 9921us\n",
      "\n",
      "[16:54:38] EvalOneIter: 0.000848s, 100 calls @ 848us\n",
      "\n",
      "[16:54:38] GetGradient: 0.006654s, 100 calls @ 6654us\n",
      "\n",
      "[16:54:38] PredictRaw: 0.000132s, 100 calls @ 132us\n",
      "\n",
      "[16:54:38] UpdateOneIter: 1.72563s, 100 calls @ 1725634us\n",
      "\n",
      "[16:54:38] ======== Monitor (0): GBTree ========\n",
      "[16:54:38] BoostNewTrees: 1.706s, 100 calls @ 1705997us\n",
      "\n",
      "[16:54:38] CommitModel: 5.8e-05s, 100 calls @ 58us\n",
      "\n",
      "[16:54:38] ======== Device 0 Memory Allocations:  ========\n",
      "[16:54:38] Peak memory usage: 687MiB\n",
      "[16:54:38] Number of allocations: 86185\n",
      "[16:54:38] ======== Monitor (0): updater_gpu_hist ========\n",
      "[16:54:38] InitData: 0.002206s, 100 calls @ 2206us\n",
      "\n",
      "[16:54:38] InitDataOnce: 0.002191s, 1 calls @ 2191us\n",
      "\n",
      "[16:54:38] Update: 1.69582s, 100 calls @ 1695820us\n",
      "\n",
      "[16:54:38] UpdatePredictionCache: 0.009405s, 100 calls @ 9405us\n",
      "\n",
      "[16:54:38] ======== Monitor (0): gradient_based_sampler ========\n",
      "[16:54:38] Sample: 0.003562s, 100 calls @ 3562us\n",
      "\n",
      "[16:54:38] ======== Monitor (0): GPUHistMakerDevice0 ========\n",
      "[16:54:38] AllReduce: 0.000373s, 600 calls @ 373us\n",
      "\n",
      "[16:54:38] BuildHist: 0.015537s, 600 calls @ 15537us\n",
      "\n",
      "[16:54:38] EvaluateSplits: 1.39285s, 600 calls @ 1392850us\n",
      "\n",
      "[16:54:38] FinalisePosition: 0.01641s, 100 calls @ 16410us\n",
      "\n",
      "[16:54:38] InitRoot: 0.153035s, 100 calls @ 153035us\n",
      "\n",
      "[16:54:38] Reset: 0.018865s, 100 calls @ 18865us\n",
      "\n",
      "[16:54:38] UpdatePosition: 0.093106s, 600 calls @ 93106us\n",
      "\n",
      "[Pipeline] ......... (step 5 of 5) Processing estimator, total=   1.9s\n",
      "[16:54:38] DEBUG: /workspace/src/gbm/gbtree.cc:130: Using tree method: 3\n",
      "[16:54:38] DEBUG: /workspace/src/tree/updater_gpu_hist.cu:744: [GPU Hist]: Configure\n",
      "Training ...\n",
      "[Pipeline] ........ (step 1 of 5) Processing vectorizer, total=   0.0s\n",
      "[Pipeline] .......... (step 2 of 5) Processing sampling, total=   0.0s\n",
      "[Pipeline] ........... (step 3 of 5) Processing scaling, total=   0.0s\n",
      "[Pipeline] ......... (step 4 of 5) Processing selection, total=   0.0s\n",
      "[16:54:38] ======== Monitor (0): HostSketchContainer ========\n",
      "[16:54:38] AllReduce: 0.001757s, 1 calls @ 1757us\n",
      "\n",
      "[16:54:38] MakeCuts: 0.00257s, 1 calls @ 2570us\n",
      "\n",
      "[16:54:38] DEBUG: /workspace/src/gbm/gbtree.cc:130: Using tree method: 3\n",
      "[16:54:38] DEBUG: /workspace/src/tree/updater_gpu_hist.cu:744: [GPU Hist]: Configure\n",
      "[16:54:38] ======== Monitor (0):  ========\n",
      "[16:54:38] InitCompressedData: 0.000101s, 1 calls @ 101us\n",
      "\n",
      "[16:54:38] ======== Monitor (0): Learner ========\n",
      "[16:54:38] Configure: 0.000647s, 1 calls @ 647us\n",
      "\n",
      "[16:54:38] EvalOneIter: 0.000544s, 100 calls @ 544us\n",
      "\n",
      "[16:54:38] GetGradient: 0.005151s, 100 calls @ 5151us\n",
      "\n",
      "[16:54:38] PredictRaw: 9.7e-05s, 100 calls @ 97us\n",
      "\n",
      "[16:54:38] UpdateOneIter: 0.592948s, 100 calls @ 592948us\n",
      "\n",
      "[16:54:38] ======== Monitor (0): GBTree ========\n",
      "[16:54:38] BoostNewTrees: 0.585754s, 100 calls @ 585754us\n",
      "\n",
      "[16:54:38] CommitModel: 3.6e-05s, 100 calls @ 36us\n",
      "\n",
      "[16:54:38] ======== Device 0 Memory Allocations:  ========\n",
      "[16:54:38] Peak memory usage: 689MiB\n",
      "[16:54:38] Number of allocations: 91178\n",
      "[16:54:38] ======== Monitor (0): updater_gpu_hist ========\n",
      "[16:54:38] InitData: 0.000483s, 100 calls @ 483us\n",
      "\n",
      "[16:54:38] InitDataOnce: 0.000469s, 1 calls @ 469us\n",
      "\n",
      "[16:54:38] Update: 0.581718s, 100 calls @ 581718us\n",
      "\n",
      "[16:54:38] UpdatePredictionCache: 0.003498s, 100 calls @ 3498us\n",
      "\n",
      "[16:54:38] ======== Monitor (0): gradient_based_sampler ========\n",
      "[16:54:38] Sample: 0.000749s, 100 calls @ 749us\n",
      "\n",
      "[16:54:38] ======== Monitor (0): GPUHistMakerDevice0 ========\n",
      "[16:54:38] AllReduce: 0.000264s, 530 calls @ 264us\n",
      "\n",
      "[16:54:38] BuildHist: 0.006547s, 454 calls @ 6547us\n",
      "\n",
      "[16:54:38] EvaluateSplits: 0.388255s, 454 calls @ 388255us\n",
      "\n",
      "[16:54:38] FinalisePosition: 0.009061s, 100 calls @ 9061us\n",
      "\n",
      "[16:54:38] InitRoot: 0.107854s, 100 calls @ 107854us\n",
      "\n",
      "[16:54:38] Reset: 0.013084s, 100 calls @ 13084us\n",
      "\n",
      "[16:54:38] UpdatePosition: 0.054691s, 454 calls @ 54691us\n",
      "\n",
      "[16:54:38] ======== Monitor (0): Learner ========\n",
      "[16:54:38] Configure: 0.000554s, 1 calls @ 554us\n",
      "\n",
      "[16:54:38] ======== Monitor (0): GBTree ========\n",
      "[16:54:38] ======== Device 0 Memory Allocations:  ========\n",
      "[16:54:38] Peak memory usage: 689MiB\n",
      "[16:54:38] Number of allocations: 91178\n",
      "[16:54:38] ======== Monitor (0): updater_gpu_hist ========\n",
      "[Pipeline] ......... (step 5 of 5) Processing estimator, total=   0.6s\n",
      "[16:54:38] DEBUG: /workspace/src/gbm/gbtree.cc:130: Using tree method: 3\n",
      "[16:54:38] DEBUG: /workspace/src/tree/updater_gpu_hist.cu:744: [GPU Hist]: Configure\n",
      "Training ...\n",
      "[Pipeline] ........ (step 1 of 5) Processing vectorizer, total=   0.0s\n",
      "[Pipeline] .......... (step 2 of 5) Processing sampling, total=   0.0s\n",
      "[Pipeline] ........... (step 3 of 5) Processing scaling, total=   0.0s\n",
      "[Pipeline] ......... (step 4 of 5) Processing selection, total=   0.0s\n",
      "[16:54:38] ======== Monitor (0): HostSketchContainer ========\n",
      "[16:54:38] AllReduce: 0.010546s, 1 calls @ 10546us\n",
      "\n",
      "[16:54:38] MakeCuts: 0.011821s, 1 calls @ 11821us\n",
      "\n",
      "[16:54:38] DEBUG: /workspace/src/gbm/gbtree.cc:130: Using tree method: 3\n",
      "[16:54:38] DEBUG: /workspace/src/tree/updater_gpu_hist.cu:744: [GPU Hist]: Configure\n",
      "[16:54:38] ======== Monitor (0):  ========\n",
      "[16:54:38] InitCompressedData: 0.000116s, 1 calls @ 116us\n",
      "\n",
      "[16:54:39] ======== Monitor (0): Learner ========\n",
      "[16:54:39] Configure: 0.000669s, 1 calls @ 669us\n",
      "\n",
      "[16:54:39] EvalOneIter: 0.00087s, 100 calls @ 870us\n",
      "\n",
      "[16:54:39] GetGradient: 0.006519s, 100 calls @ 6519us\n",
      "\n",
      "[16:54:39] PredictRaw: 0.000128s, 100 calls @ 128us\n",
      "\n",
      "[16:54:39] UpdateOneIter: 1.08726s, 100 calls @ 1087256us\n",
      "\n",
      "[16:54:39] ======== Monitor (0): GBTree ========\n",
      "[16:54:39] BoostNewTrees: 1.07828s, 100 calls @ 1078282us\n",
      "\n",
      "[16:54:39] CommitModel: 5.3e-05s, 100 calls @ 53us\n",
      "\n",
      "[16:54:39] ======== Device 0 Memory Allocations:  ========\n",
      "[16:54:39] Peak memory usage: 692MiB\n",
      "[16:54:39] Number of allocations: 96731\n",
      "[16:54:39] ======== Monitor (0): updater_gpu_hist ========\n",
      "[16:54:39] InitData: 0.000248s, 100 calls @ 248us\n",
      "\n",
      "[16:54:39] InitDataOnce: 0.000233s, 1 calls @ 233us\n",
      "\n",
      "[16:54:39] Update: 1.06976s, 100 calls @ 1069764us\n",
      "\n",
      "[16:54:39] UpdatePredictionCache: 0.007742s, 100 calls @ 7742us\n",
      "\n",
      "[16:54:39] ======== Monitor (0): gradient_based_sampler ========\n",
      "[16:54:39] Sample: 0.001091s, 100 calls @ 1091us\n",
      "\n",
      "[16:54:39] ======== Monitor (0): GPUHistMakerDevice0 ========\n",
      "[16:54:39] AllReduce: 0.000389s, 600 calls @ 389us\n",
      "\n",
      "[16:54:39] BuildHist: 0.012115s, 600 calls @ 12115us\n",
      "\n",
      "[16:54:39] EvaluateSplits: 0.815922s, 600 calls @ 815922us\n",
      "\n",
      "[16:54:39] FinalisePosition: 0.014796s, 100 calls @ 14796us\n",
      "\n",
      "[16:54:39] InitRoot: 0.12237s, 100 calls @ 122370us\n",
      "\n",
      "[16:54:39] Reset: 0.015343s, 100 calls @ 15343us\n",
      "\n",
      "[16:54:39] UpdatePosition: 0.085561s, 600 calls @ 85561us\n",
      "\n",
      "[16:54:39] ======== Monitor (0): Learner ========\n",
      "[16:54:39] Configure: 0.000541s, 1 calls @ 541us\n",
      "\n",
      "[16:54:39] ======== Monitor (0): GBTree ========\n",
      "[16:54:39] ======== Device 0 Memory Allocations:  ========\n",
      "[16:54:39] Peak memory usage: 692MiB\n",
      "[16:54:39] Number of allocations: 96731\n",
      "[16:54:39] ======== Monitor (0): updater_gpu_hist ========\n",
      "[Pipeline] ......... (step 5 of 5) Processing estimator, total=   1.2s\n",
      "[16:54:39] DEBUG: /workspace/src/gbm/gbtree.cc:130: Using tree method: 3\n",
      "[16:54:39] DEBUG: /workspace/src/tree/updater_gpu_hist.cu:744: [GPU Hist]: Configure\n",
      "Training ...\n",
      "[Pipeline] ........ (step 1 of 5) Processing vectorizer, total=   0.0s\n",
      "[Pipeline] .......... (step 2 of 5) Processing sampling, total=   0.0s\n",
      "[Pipeline] ........... (step 3 of 5) Processing scaling, total=   0.0s\n",
      "[Pipeline] ......... (step 4 of 5) Processing selection, total=   0.0s\n",
      "[16:54:40] ======== Monitor (0): HostSketchContainer ========\n",
      "[16:54:40] AllReduce: 0.015161s, 1 calls @ 15161us\n",
      "\n",
      "[16:54:40] MakeCuts: 0.017423s, 1 calls @ 17423us\n",
      "\n",
      "[16:54:40] DEBUG: /workspace/src/gbm/gbtree.cc:130: Using tree method: 3\n",
      "[16:54:40] DEBUG: /workspace/src/tree/updater_gpu_hist.cu:744: [GPU Hist]: Configure\n",
      "[16:54:40] ======== Monitor (0):  ========\n",
      "[16:54:40] InitCompressedData: 0.000126s, 1 calls @ 126us\n",
      "\n",
      "[16:54:41] ======== Monitor (0): Learner ========\n",
      "[16:54:41] Configure: 0.000677s, 1 calls @ 677us\n",
      "\n",
      "[16:54:41] EvalOneIter: 0.00086s, 100 calls @ 860us\n",
      "\n",
      "[16:54:41] GetGradient: 0.005271s, 100 calls @ 5271us\n",
      "\n",
      "[16:54:41] PredictRaw: 0.000122s, 100 calls @ 122us\n",
      "\n",
      "[16:54:41] UpdateOneIter: 1.23759s, 100 calls @ 1237589us\n",
      "\n",
      "[16:54:41] ======== Monitor (0): GBTree ========\n",
      "[16:54:41] BoostNewTrees: 1.22976s, 100 calls @ 1229764us\n",
      "\n",
      "[16:54:41] CommitModel: 5e-05s, 100 calls @ 50us\n",
      "\n",
      "[16:54:41] ======== Device 0 Memory Allocations:  ========\n",
      "[16:54:41] Peak memory usage: 697MiB\n",
      "[16:54:41] Number of allocations: 102284\n",
      "[16:54:41] ======== Monitor (0): updater_gpu_hist ========\n",
      "[16:54:41] InitData: 0.00021s, 100 calls @ 210us\n",
      "\n",
      "[16:54:41] InitDataOnce: 0.000195s, 1 calls @ 195us\n",
      "\n",
      "[16:54:41] Update: 1.21992s, 100 calls @ 1219925us\n",
      "\n",
      "[16:54:41] UpdatePredictionCache: 0.009075s, 100 calls @ 9075us\n",
      "\n",
      "[16:54:41] ======== Monitor (0): gradient_based_sampler ========\n",
      "[16:54:41] Sample: 0.001395s, 100 calls @ 1395us\n",
      "\n",
      "[16:54:41] ======== Monitor (0): GPUHistMakerDevice0 ========\n",
      "[16:54:41] AllReduce: 0.000364s, 600 calls @ 364us\n",
      "\n",
      "[16:54:41] BuildHist: 0.012085s, 600 calls @ 12085us\n",
      "\n",
      "[16:54:41] EvaluateSplits: 0.9462s, 600 calls @ 946200us\n",
      "\n",
      "[16:54:41] FinalisePosition: 0.017523s, 100 calls @ 17523us\n",
      "\n",
      "[16:54:41] InitRoot: 0.134508s, 100 calls @ 134508us\n",
      "\n",
      "[16:54:41] Reset: 0.01405s, 100 calls @ 14050us\n",
      "\n",
      "[16:54:41] UpdatePosition: 0.091836s, 600 calls @ 91836us\n",
      "\n",
      "[16:54:41] ======== Monitor (0): Learner ========\n",
      "[16:54:41] Configure: 0.000926s, 1 calls @ 926us\n",
      "\n",
      "[16:54:41] ======== Monitor (0): GBTree ========\n",
      "[16:54:41] ======== Device 0 Memory Allocations:  ========\n",
      "[16:54:41] Peak memory usage: 697MiB\n",
      "[16:54:41] Number of allocations: 102284\n",
      "[16:54:41] ======== Monitor (0): updater_gpu_hist ========\n",
      "[Pipeline] ......... (step 5 of 5) Processing estimator, total=   1.3s\n",
      "[16:54:41] DEBUG: /workspace/src/gbm/gbtree.cc:130: Using tree method: 3\n",
      "[16:54:41] DEBUG: /workspace/src/tree/updater_gpu_hist.cu:744: [GPU Hist]: Configure\n",
      "Training ...\n",
      "[Pipeline] ........ (step 1 of 5) Processing vectorizer, total=   0.0s\n",
      "[Pipeline] .......... (step 2 of 5) Processing sampling, total=   0.0s\n",
      "[Pipeline] ........... (step 3 of 5) Processing scaling, total=   0.0s\n",
      "[Pipeline] ......... (step 4 of 5) Processing selection, total=   0.0s\n",
      "[16:54:41] ======== Monitor (0): HostSketchContainer ========\n",
      "[16:54:41] AllReduce: 0.011489s, 1 calls @ 11489us\n",
      "\n",
      "[16:54:41] MakeCuts: 0.017765s, 1 calls @ 17765us\n",
      "\n",
      "[16:54:41] DEBUG: /workspace/src/gbm/gbtree.cc:130: Using tree method: 3\n",
      "[16:54:41] DEBUG: /workspace/src/tree/updater_gpu_hist.cu:744: [GPU Hist]: Configure\n",
      "[16:54:41] ======== Monitor (0):  ========\n",
      "[16:54:41] InitCompressedData: 0.00011s, 1 calls @ 110us\n",
      "\n",
      "[16:54:42] ======== Monitor (0): Learner ========\n",
      "[16:54:42] Configure: 0.000728s, 1 calls @ 728us\n",
      "\n",
      "[16:54:42] EvalOneIter: 0.00088s, 100 calls @ 880us\n",
      "\n",
      "[16:54:42] GetGradient: 0.005965s, 100 calls @ 5965us\n",
      "\n",
      "[16:54:42] PredictRaw: 0.000122s, 100 calls @ 122us\n",
      "\n",
      "[16:54:42] UpdateOneIter: 1.19683s, 100 calls @ 1196830us\n",
      "\n",
      "[16:54:42] ======== Monitor (0): GBTree ========\n",
      "[16:54:42] BoostNewTrees: 1.18831s, 100 calls @ 1188311us\n",
      "\n",
      "[16:54:42] CommitModel: 5.2e-05s, 100 calls @ 52us\n",
      "\n",
      "[16:54:42] ======== Device 0 Memory Allocations:  ========\n",
      "[16:54:42] Peak memory usage: 699MiB\n",
      "[16:54:42] Number of allocations: 107837\n",
      "[16:54:42] ======== Monitor (0): updater_gpu_hist ========\n",
      "[16:54:42] InitData: 0.000222s, 100 calls @ 222us\n",
      "\n",
      "[16:54:42] InitDataOnce: 0.000207s, 1 calls @ 207us\n",
      "\n",
      "[16:54:42] Update: 1.18091s, 100 calls @ 1180909us\n",
      "\n",
      "[16:54:42] UpdatePredictionCache: 0.006609s, 100 calls @ 6609us\n",
      "\n",
      "[16:54:42] ======== Monitor (0): gradient_based_sampler ========\n",
      "[16:54:42] Sample: 0.001042s, 100 calls @ 1042us\n",
      "\n",
      "[16:54:42] ======== Monitor (0): GPUHistMakerDevice0 ========\n",
      "[16:54:42] AllReduce: 0.000403s, 600 calls @ 403us\n",
      "\n",
      "[16:54:42] BuildHist: 0.012187s, 600 calls @ 12187us\n",
      "\n",
      "[16:54:42] EvaluateSplits: 0.911494s, 600 calls @ 911494us\n",
      "\n",
      "[16:54:42] FinalisePosition: 0.016611s, 100 calls @ 16611us\n",
      "\n",
      "[16:54:42] InitRoot: 0.132106s, 100 calls @ 132106us\n",
      "\n",
      "[16:54:42] Reset: 0.01862s, 100 calls @ 18620us\n",
      "\n",
      "[16:54:42] UpdatePosition: 0.086102s, 600 calls @ 86102us\n",
      "\n",
      "[16:54:42] ======== Monitor (0): Learner ========\n",
      "[16:54:42] Configure: 0.004761s, 1 calls @ 4761us\n",
      "\n",
      "[16:54:42] ======== Monitor (0): GBTree ========\n",
      "[16:54:42] ======== Device 0 Memory Allocations:  ========\n",
      "[16:54:42] Peak memory usage: 699MiB\n",
      "[16:54:42] Number of allocations: 107837\n",
      "[16:54:42] ======== Monitor (0): updater_gpu_hist ========\n",
      "[Pipeline] ......... (step 5 of 5) Processing estimator, total=   1.4s\n",
      "[16:54:42] DEBUG: /workspace/src/gbm/gbtree.cc:130: Using tree method: 3\n",
      "[16:54:42] DEBUG: /workspace/src/tree/updater_gpu_hist.cu:744: [GPU Hist]: Configure\n",
      "Training ...\n",
      "[Pipeline] ........ (step 1 of 5) Processing vectorizer, total=   0.0s\n",
      "[Pipeline] .......... (step 2 of 5) Processing sampling, total=   0.0s\n",
      "[Pipeline] ........... (step 3 of 5) Processing scaling, total=   0.0s\n",
      "[Pipeline] ......... (step 4 of 5) Processing selection, total=   0.0s\n",
      "[16:54:42] ======== Monitor (0): HostSketchContainer ========\n",
      "[16:54:42] AllReduce: 0.00511s, 1 calls @ 5110us\n",
      "\n",
      "[16:54:42] MakeCuts: 0.008512s, 1 calls @ 8512us\n",
      "\n",
      "[16:54:42] DEBUG: /workspace/src/gbm/gbtree.cc:130: Using tree method: 3\n",
      "[16:54:42] DEBUG: /workspace/src/tree/updater_gpu_hist.cu:744: [GPU Hist]: Configure\n",
      "[16:54:42] ======== Monitor (0):  ========\n",
      "[16:54:42] InitCompressedData: 0.000165s, 1 calls @ 165us\n",
      "\n",
      "[16:54:43] ======== Monitor (0): Learner ========\n",
      "[16:54:43] Configure: 0.000628s, 1 calls @ 628us\n",
      "\n",
      "[16:54:43] EvalOneIter: 0.000833s, 100 calls @ 833us\n",
      "\n",
      "[16:54:43] GetGradient: 0.004603s, 100 calls @ 4603us\n",
      "\n",
      "[16:54:43] PredictRaw: 0.000123s, 100 calls @ 123us\n",
      "\n",
      "[16:54:43] UpdateOneIter: 1.00695s, 100 calls @ 1006953us\n",
      "\n",
      "[16:54:43] ======== Monitor (0): GBTree ========\n",
      "[16:54:43] BoostNewTrees: 0.999887s, 100 calls @ 999887us\n",
      "\n",
      "[16:54:43] CommitModel: 5.1e-05s, 100 calls @ 51us\n",
      "\n",
      "[16:54:43] ======== Device 0 Memory Allocations:  ========\n",
      "[16:54:43] Peak memory usage: 701MiB\n",
      "[16:54:43] Number of allocations: 113390\n",
      "[16:54:43] ======== Monitor (0): updater_gpu_hist ========\n",
      "[16:54:43] InitData: 0.000235s, 100 calls @ 235us\n",
      "\n",
      "[16:54:43] InitDataOnce: 0.00022s, 1 calls @ 220us\n",
      "\n",
      "[16:54:43] Update: 0.994224s, 100 calls @ 994224us\n",
      "\n",
      "[16:54:43] UpdatePredictionCache: 0.00489s, 100 calls @ 4890us\n",
      "\n",
      "[16:54:43] ======== Monitor (0): gradient_based_sampler ========\n",
      "[16:54:43] Sample: 0.001864s, 100 calls @ 1864us\n",
      "\n",
      "[16:54:43] ======== Monitor (0): GPUHistMakerDevice0 ========\n",
      "[16:54:43] AllReduce: 0.000379s, 600 calls @ 379us\n",
      "\n",
      "[16:54:43] BuildHist: 0.010421s, 600 calls @ 10421us\n",
      "\n",
      "[16:54:43] EvaluateSplits: 0.742607s, 600 calls @ 742607us\n",
      "\n",
      "[16:54:43] FinalisePosition: 0.015464s, 100 calls @ 15464us\n",
      "\n",
      "[16:54:43] InitRoot: 0.123383s, 100 calls @ 123383us\n",
      "\n",
      "[16:54:43] Reset: 0.015639s, 100 calls @ 15639us\n",
      "\n",
      "[16:54:43] UpdatePosition: 0.083349s, 600 calls @ 83349us\n",
      "\n",
      "[16:54:43] ======== Monitor (0): Learner ========\n",
      "[16:54:43] Configure: 0.000564s, 1 calls @ 564us\n",
      "\n",
      "[16:54:43] ======== Monitor (0): GBTree ========\n",
      "[16:54:43] ======== Device 0 Memory Allocations:  ========\n",
      "[16:54:43] Peak memory usage: 701MiB\n",
      "[16:54:43] Number of allocations: 113390\n",
      "[16:54:43] ======== Monitor (0): updater_gpu_hist ========\n",
      "[Pipeline] ......... (step 5 of 5) Processing estimator, total=   1.1s\n",
      "[16:54:43] DEBUG: /workspace/src/gbm/gbtree.cc:130: Using tree method: 3\n",
      "[16:54:43] DEBUG: /workspace/src/tree/updater_gpu_hist.cu:744: [GPU Hist]: Configure\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "      <th>corpus</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>macro avg</td>\n",
       "      <td>0.682796</td>\n",
       "      <td>0.516144</td>\n",
       "      <td>0.498358</td>\n",
       "      <td>188.0</td>\n",
       "      <td>bo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>macro avg</td>\n",
       "      <td>0.566350</td>\n",
       "      <td>0.544726</td>\n",
       "      <td>0.526831</td>\n",
       "      <td>411.0</td>\n",
       "      <td>gl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>macro avg</td>\n",
       "      <td>0.582660</td>\n",
       "      <td>0.579850</td>\n",
       "      <td>0.578352</td>\n",
       "      <td>272.0</td>\n",
       "      <td>lu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>macro avg</td>\n",
       "      <td>0.584290</td>\n",
       "      <td>0.579430</td>\n",
       "      <td>0.578806</td>\n",
       "      <td>599.0</td>\n",
       "      <td>ig</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>macro avg</td>\n",
       "      <td>0.604328</td>\n",
       "      <td>0.602307</td>\n",
       "      <td>0.600649</td>\n",
       "      <td>574.0</td>\n",
       "      <td>cl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>macro avg</td>\n",
       "      <td>0.654220</td>\n",
       "      <td>0.654701</td>\n",
       "      <td>0.654390</td>\n",
       "      <td>774.0</td>\n",
       "      <td>co</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       class  precision    recall  f1-score  support corpus\n",
       "3  macro avg   0.682796  0.516144  0.498358    188.0     bo\n",
       "3  macro avg   0.566350  0.544726  0.526831    411.0     gl\n",
       "3  macro avg   0.582660  0.579850  0.578352    272.0     lu\n",
       "3  macro avg   0.584290  0.579430  0.578806    599.0     ig\n",
       "3  macro avg   0.604328  0.602307  0.600649    574.0     cl\n",
       "3  macro avg   0.654220  0.654701  0.654390    774.0     co"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define pipeline steps \n",
    "scaling = MaxAbsScaler()\n",
    "selection = None\n",
    "estimator = XGBClassifier(\n",
    "                random_state = 42,\n",
    "                verbosity = 3,\n",
    "                device = 'cuda',\n",
    "                tree_method = 'hist'\n",
    "                )\n",
    "\n",
    "\n",
    "# get results\n",
    "df_cr, df_test_results = process_classification(\n",
    "        estimator = estimator,\n",
    "        scaling = scaling,\n",
    "        selection= selection,\n",
    "        data_tuples = list_tuples_top_ment,\n",
    "        X_cols = X_cols\n",
    ")\n",
    "df_cr.to_csv(path_results_cr + 'dummy_classifier_users_timeline_classification_report.csv')\n",
    "df_cr[df_cr['class'] == 'macro avg'].sort_values('f1-score')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:23<00:00,  3.98s/it]\n"
     ]
    }
   ],
   "source": [
    "# create a list of tuples with (data_train, data_test, target)\n",
    "\n",
    "list_tuples_users = []\n",
    "\n",
    "for target in tqdm(list_target):\n",
    "\n",
    "    path_data_train = path_processed_data + f'r3_{target}_train_users_{model_name.replace(\"/\", \"_\")}.parquet'\n",
    "    path_data_test = path_processed_data + f'r3_{target}_test_users_{model_name.replace(\"/\", \"_\")}.parquet'\n",
    "\n",
    "    data_train = pd.read_parquet(path_data_train)\n",
    "    data_test = pd.read_parquet(path_data_test)\n",
    "    \n",
    "    list_tuples_users.append((data_train, data_test, target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User_ID</th>\n",
       "      <th>Polarity</th>\n",
       "      <th>Texts</th>\n",
       "      <th>Texts_emb_1</th>\n",
       "      <th>Texts_emb_2</th>\n",
       "      <th>Texts_emb_3</th>\n",
       "      <th>Texts_emb_4</th>\n",
       "      <th>Texts_emb_5</th>\n",
       "      <th>Texts_emb_6</th>\n",
       "      <th>Texts_emb_7</th>\n",
       "      <th>...</th>\n",
       "      <th>Texts_emb_759</th>\n",
       "      <th>Texts_emb_760</th>\n",
       "      <th>Texts_emb_761</th>\n",
       "      <th>Texts_emb_762</th>\n",
       "      <th>Texts_emb_763</th>\n",
       "      <th>Texts_emb_764</th>\n",
       "      <th>Texts_emb_765</th>\n",
       "      <th>Texts_emb_766</th>\n",
       "      <th>Texts_emb_767</th>\n",
       "      <th>Texts_emb_768</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>r2_lu_1</td>\n",
       "      <td>for</td>\n",
       "      <td>Bastidores do Logo mais novas palestras e cont...</td>\n",
       "      <td>-0.228853</td>\n",
       "      <td>-0.202725</td>\n",
       "      <td>0.508440</td>\n",
       "      <td>-0.006737</td>\n",
       "      <td>0.586556</td>\n",
       "      <td>0.266518</td>\n",
       "      <td>-0.067279</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.078371</td>\n",
       "      <td>-0.204703</td>\n",
       "      <td>-0.780542</td>\n",
       "      <td>-0.497446</td>\n",
       "      <td>0.385078</td>\n",
       "      <td>-0.414355</td>\n",
       "      <td>0.050656</td>\n",
       "      <td>0.012453</td>\n",
       "      <td>-0.067538</td>\n",
       "      <td>-0.350661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>r2_lu_2</td>\n",
       "      <td>for</td>\n",
       "      <td>PQP ESSE DORAMA É MUITO FOADA(Sassy GoGo(Cheer...</td>\n",
       "      <td>-0.107667</td>\n",
       "      <td>-0.151855</td>\n",
       "      <td>0.441127</td>\n",
       "      <td>0.037583</td>\n",
       "      <td>0.520407</td>\n",
       "      <td>0.679378</td>\n",
       "      <td>-0.029682</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006313</td>\n",
       "      <td>0.026672</td>\n",
       "      <td>-0.765249</td>\n",
       "      <td>-0.240724</td>\n",
       "      <td>0.398015</td>\n",
       "      <td>-0.335633</td>\n",
       "      <td>0.090770</td>\n",
       "      <td>0.056602</td>\n",
       "      <td>0.063500</td>\n",
       "      <td>-0.374083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>r2_lu_3</td>\n",
       "      <td>against</td>\n",
       "      <td>@Gremio E que domínio, hein campeão? # @Analis...</td>\n",
       "      <td>-0.159751</td>\n",
       "      <td>-0.175113</td>\n",
       "      <td>0.287834</td>\n",
       "      <td>-0.063407</td>\n",
       "      <td>0.524479</td>\n",
       "      <td>0.426202</td>\n",
       "      <td>0.115893</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.037945</td>\n",
       "      <td>-0.006513</td>\n",
       "      <td>-0.776340</td>\n",
       "      <td>-0.320336</td>\n",
       "      <td>0.408296</td>\n",
       "      <td>-0.454143</td>\n",
       "      <td>0.057517</td>\n",
       "      <td>-0.155906</td>\n",
       "      <td>-0.106136</td>\n",
       "      <td>-0.307476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>r2_lu_5</td>\n",
       "      <td>for</td>\n",
       "      <td>a vontade de cortar o cabelo curtinho não pass...</td>\n",
       "      <td>-0.204866</td>\n",
       "      <td>-0.195960</td>\n",
       "      <td>0.342440</td>\n",
       "      <td>-0.008330</td>\n",
       "      <td>0.581180</td>\n",
       "      <td>0.559819</td>\n",
       "      <td>-0.025620</td>\n",
       "      <td>...</td>\n",
       "      <td>0.018827</td>\n",
       "      <td>0.013892</td>\n",
       "      <td>-0.643602</td>\n",
       "      <td>-0.244813</td>\n",
       "      <td>0.475716</td>\n",
       "      <td>-0.391150</td>\n",
       "      <td>0.268533</td>\n",
       "      <td>0.040979</td>\n",
       "      <td>-0.040325</td>\n",
       "      <td>-0.285664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>r2_lu_9</td>\n",
       "      <td>for</td>\n",
       "      <td>Para mais informações sigam os perfil do @govb...</td>\n",
       "      <td>-0.161962</td>\n",
       "      <td>-0.293159</td>\n",
       "      <td>0.410162</td>\n",
       "      <td>-0.022136</td>\n",
       "      <td>0.492353</td>\n",
       "      <td>0.250965</td>\n",
       "      <td>0.029293</td>\n",
       "      <td>...</td>\n",
       "      <td>0.133500</td>\n",
       "      <td>-0.203925</td>\n",
       "      <td>-0.487742</td>\n",
       "      <td>-0.325804</td>\n",
       "      <td>0.384087</td>\n",
       "      <td>-0.418149</td>\n",
       "      <td>0.102530</td>\n",
       "      <td>-0.095404</td>\n",
       "      <td>-0.091220</td>\n",
       "      <td>-0.275685</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>811</th>\n",
       "      <td>r2_lu_1089</td>\n",
       "      <td>for</td>\n",
       "      <td>.@GuilhermeBoulos convida. É domingo, dia 13. ...</td>\n",
       "      <td>-0.195680</td>\n",
       "      <td>-0.102688</td>\n",
       "      <td>0.375545</td>\n",
       "      <td>0.028601</td>\n",
       "      <td>0.552920</td>\n",
       "      <td>0.321834</td>\n",
       "      <td>0.033052</td>\n",
       "      <td>...</td>\n",
       "      <td>0.120257</td>\n",
       "      <td>-0.086251</td>\n",
       "      <td>-0.673046</td>\n",
       "      <td>-0.309781</td>\n",
       "      <td>0.414674</td>\n",
       "      <td>-0.438636</td>\n",
       "      <td>0.014682</td>\n",
       "      <td>-0.075526</td>\n",
       "      <td>-0.013378</td>\n",
       "      <td>-0.408907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>812</th>\n",
       "      <td>r2_lu_1092</td>\n",
       "      <td>for</td>\n",
       "      <td>(...) p/ conscientizar e explicar como elimina...</td>\n",
       "      <td>-0.094237</td>\n",
       "      <td>-0.217138</td>\n",
       "      <td>0.524669</td>\n",
       "      <td>0.005611</td>\n",
       "      <td>0.488059</td>\n",
       "      <td>0.370081</td>\n",
       "      <td>-0.089034</td>\n",
       "      <td>...</td>\n",
       "      <td>0.114370</td>\n",
       "      <td>-0.112064</td>\n",
       "      <td>-0.733496</td>\n",
       "      <td>-0.348119</td>\n",
       "      <td>0.266663</td>\n",
       "      <td>-0.431373</td>\n",
       "      <td>0.149339</td>\n",
       "      <td>-0.134464</td>\n",
       "      <td>-0.057407</td>\n",
       "      <td>-0.331929</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>813</th>\n",
       "      <td>r2_lu_1095</td>\n",
       "      <td>for</td>\n",
       "      <td>@TVJustica @RadioJustica O min. Marco Aurélio,...</td>\n",
       "      <td>-0.198064</td>\n",
       "      <td>-0.166758</td>\n",
       "      <td>0.530498</td>\n",
       "      <td>0.133116</td>\n",
       "      <td>0.373059</td>\n",
       "      <td>0.479163</td>\n",
       "      <td>-0.018344</td>\n",
       "      <td>...</td>\n",
       "      <td>0.113587</td>\n",
       "      <td>-0.043571</td>\n",
       "      <td>-0.714946</td>\n",
       "      <td>-0.401168</td>\n",
       "      <td>0.422786</td>\n",
       "      <td>-0.384292</td>\n",
       "      <td>-0.050555</td>\n",
       "      <td>0.076332</td>\n",
       "      <td>-0.154675</td>\n",
       "      <td>-0.129023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>814</th>\n",
       "      <td>r2_lu_1096</td>\n",
       "      <td>for</td>\n",
       "      <td>IBGE sugere vacinar equipes para Censo e discu...</td>\n",
       "      <td>-0.137815</td>\n",
       "      <td>-0.194538</td>\n",
       "      <td>0.517122</td>\n",
       "      <td>-0.037006</td>\n",
       "      <td>0.614969</td>\n",
       "      <td>0.288686</td>\n",
       "      <td>0.126937</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.030401</td>\n",
       "      <td>-0.216349</td>\n",
       "      <td>-0.628359</td>\n",
       "      <td>-0.308201</td>\n",
       "      <td>0.408606</td>\n",
       "      <td>-0.290563</td>\n",
       "      <td>-0.011164</td>\n",
       "      <td>-0.139985</td>\n",
       "      <td>-0.089073</td>\n",
       "      <td>-0.112610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>815</th>\n",
       "      <td>r2_lu_1097</td>\n",
       "      <td>for</td>\n",
       "      <td>Lula nos braços do povo. Lembrança nos prédios...</td>\n",
       "      <td>-0.142768</td>\n",
       "      <td>-0.149502</td>\n",
       "      <td>0.382769</td>\n",
       "      <td>0.151034</td>\n",
       "      <td>0.476296</td>\n",
       "      <td>0.463054</td>\n",
       "      <td>0.003500</td>\n",
       "      <td>...</td>\n",
       "      <td>0.226564</td>\n",
       "      <td>-0.105888</td>\n",
       "      <td>-0.665892</td>\n",
       "      <td>-0.271048</td>\n",
       "      <td>0.455163</td>\n",
       "      <td>-0.466204</td>\n",
       "      <td>-0.022646</td>\n",
       "      <td>-0.119793</td>\n",
       "      <td>-0.214250</td>\n",
       "      <td>-0.191938</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>816 rows × 771 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        User_ID Polarity                                              Texts  \\\n",
       "0       r2_lu_1      for  Bastidores do Logo mais novas palestras e cont...   \n",
       "1       r2_lu_2      for  PQP ESSE DORAMA É MUITO FOADA(Sassy GoGo(Cheer...   \n",
       "2       r2_lu_3  against  @Gremio E que domínio, hein campeão? # @Analis...   \n",
       "3       r2_lu_5      for  a vontade de cortar o cabelo curtinho não pass...   \n",
       "4       r2_lu_9      for  Para mais informações sigam os perfil do @govb...   \n",
       "..          ...      ...                                                ...   \n",
       "811  r2_lu_1089      for  .@GuilhermeBoulos convida. É domingo, dia 13. ...   \n",
       "812  r2_lu_1092      for  (...) p/ conscientizar e explicar como elimina...   \n",
       "813  r2_lu_1095      for  @TVJustica @RadioJustica O min. Marco Aurélio,...   \n",
       "814  r2_lu_1096      for  IBGE sugere vacinar equipes para Censo e discu...   \n",
       "815  r2_lu_1097      for  Lula nos braços do povo. Lembrança nos prédios...   \n",
       "\n",
       "     Texts_emb_1  Texts_emb_2  Texts_emb_3  Texts_emb_4  Texts_emb_5  \\\n",
       "0      -0.228853    -0.202725     0.508440    -0.006737     0.586556   \n",
       "1      -0.107667    -0.151855     0.441127     0.037583     0.520407   \n",
       "2      -0.159751    -0.175113     0.287834    -0.063407     0.524479   \n",
       "3      -0.204866    -0.195960     0.342440    -0.008330     0.581180   \n",
       "4      -0.161962    -0.293159     0.410162    -0.022136     0.492353   \n",
       "..           ...          ...          ...          ...          ...   \n",
       "811    -0.195680    -0.102688     0.375545     0.028601     0.552920   \n",
       "812    -0.094237    -0.217138     0.524669     0.005611     0.488059   \n",
       "813    -0.198064    -0.166758     0.530498     0.133116     0.373059   \n",
       "814    -0.137815    -0.194538     0.517122    -0.037006     0.614969   \n",
       "815    -0.142768    -0.149502     0.382769     0.151034     0.476296   \n",
       "\n",
       "     Texts_emb_6  Texts_emb_7  ...  Texts_emb_759  Texts_emb_760  \\\n",
       "0       0.266518    -0.067279  ...      -0.078371      -0.204703   \n",
       "1       0.679378    -0.029682  ...       0.006313       0.026672   \n",
       "2       0.426202     0.115893  ...      -0.037945      -0.006513   \n",
       "3       0.559819    -0.025620  ...       0.018827       0.013892   \n",
       "4       0.250965     0.029293  ...       0.133500      -0.203925   \n",
       "..           ...          ...  ...            ...            ...   \n",
       "811     0.321834     0.033052  ...       0.120257      -0.086251   \n",
       "812     0.370081    -0.089034  ...       0.114370      -0.112064   \n",
       "813     0.479163    -0.018344  ...       0.113587      -0.043571   \n",
       "814     0.288686     0.126937  ...      -0.030401      -0.216349   \n",
       "815     0.463054     0.003500  ...       0.226564      -0.105888   \n",
       "\n",
       "     Texts_emb_761  Texts_emb_762  Texts_emb_763  Texts_emb_764  \\\n",
       "0        -0.780542      -0.497446       0.385078      -0.414355   \n",
       "1        -0.765249      -0.240724       0.398015      -0.335633   \n",
       "2        -0.776340      -0.320336       0.408296      -0.454143   \n",
       "3        -0.643602      -0.244813       0.475716      -0.391150   \n",
       "4        -0.487742      -0.325804       0.384087      -0.418149   \n",
       "..             ...            ...            ...            ...   \n",
       "811      -0.673046      -0.309781       0.414674      -0.438636   \n",
       "812      -0.733496      -0.348119       0.266663      -0.431373   \n",
       "813      -0.714946      -0.401168       0.422786      -0.384292   \n",
       "814      -0.628359      -0.308201       0.408606      -0.290563   \n",
       "815      -0.665892      -0.271048       0.455163      -0.466204   \n",
       "\n",
       "     Texts_emb_765  Texts_emb_766  Texts_emb_767  Texts_emb_768  \n",
       "0         0.050656       0.012453      -0.067538      -0.350661  \n",
       "1         0.090770       0.056602       0.063500      -0.374083  \n",
       "2         0.057517      -0.155906      -0.106136      -0.307476  \n",
       "3         0.268533       0.040979      -0.040325      -0.285664  \n",
       "4         0.102530      -0.095404      -0.091220      -0.275685  \n",
       "..             ...            ...            ...            ...  \n",
       "811       0.014682      -0.075526      -0.013378      -0.408907  \n",
       "812       0.149339      -0.134464      -0.057407      -0.331929  \n",
       "813      -0.050555       0.076332      -0.154675      -0.129023  \n",
       "814      -0.011164      -0.139985      -0.089073      -0.112610  \n",
       "815      -0.022646      -0.119793      -0.214250      -0.191938  \n",
       "\n",
       "[816 rows x 771 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_parquet(path_data_train, **{})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Timelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_cols = [col for col in data_test.columns if 'emb' in col and 'Timeline' in col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ...\n",
      "[Pipeline] ........ (step 1 of 5) Processing vectorizer, total=   0.0s\n",
      "[Pipeline] .......... (step 2 of 5) Processing sampling, total=   0.0s\n",
      "[Pipeline] ........... (step 3 of 5) Processing scaling, total=   0.0s\n",
      "[Pipeline] ......... (step 4 of 5) Processing selection, total=   0.0s\n",
      "[17:00:41] ======== Monitor (0): HostSketchContainer ========\n",
      "[17:00:41] AllReduce: 0.029834s, 1 calls @ 29834us\n",
      "\n",
      "[17:00:41] MakeCuts: 0.035246s, 1 calls @ 35246us\n",
      "\n",
      "[17:00:41] DEBUG: /workspace/src/gbm/gbtree.cc:130: Using tree method: 3\n",
      "[17:00:41] DEBUG: /workspace/src/tree/updater_gpu_hist.cu:744: [GPU Hist]: Configure\n",
      "[17:00:41] ======== Monitor (0):  ========\n",
      "[17:00:41] InitCompressedData: 0.000158s, 1 calls @ 158us\n",
      "\n",
      "[17:00:43] ======== Monitor (0): Learner ========\n",
      "[17:00:43] Configure: 0.018689s, 1 calls @ 18689us\n",
      "\n",
      "[17:00:43] EvalOneIter: 0.001097s, 100 calls @ 1097us\n",
      "\n",
      "[17:00:43] GetGradient: 0.006715s, 100 calls @ 6715us\n",
      "\n",
      "[17:00:43] PredictRaw: 0.000138s, 100 calls @ 138us\n",
      "\n",
      "[17:00:43] UpdateOneIter: 1.65281s, 100 calls @ 1652807us\n",
      "\n",
      "[17:00:43] ======== Monitor (0): GBTree ========\n",
      "[17:00:43] BoostNewTrees: 1.62354s, 100 calls @ 1623543us\n",
      "\n",
      "[17:00:43] CommitModel: 5.2e-05s, 100 calls @ 52us\n",
      "\n",
      "[17:00:43] ======== Device 0 Memory Allocations:  ========\n",
      "[17:00:43] Peak memory usage: 705MiB\n",
      "[17:00:43] Number of allocations: 118911\n",
      "[17:00:43] ======== Monitor (0): updater_gpu_hist ========\n",
      "[17:00:43] InitData: 0.000466s, 100 calls @ 466us\n",
      "\n",
      "[17:00:43] InitDataOnce: 0.000452s, 1 calls @ 452us\n",
      "\n",
      "[17:00:43] Update: 1.61412s, 100 calls @ 1614119us\n",
      "\n",
      "[17:00:43] UpdatePredictionCache: 0.008639s, 100 calls @ 8639us\n",
      "\n",
      "[17:00:43] ======== Monitor (0): gradient_based_sampler ========\n",
      "[17:00:43] Sample: 0.002226s, 100 calls @ 2226us\n",
      "\n",
      "[17:00:43] ======== Monitor (0): GPUHistMakerDevice0 ========\n",
      "[17:00:43] AllReduce: 0.000386s, 596 calls @ 386us\n",
      "\n",
      "[17:00:43] BuildHist: 0.013674s, 588 calls @ 13674us\n",
      "\n",
      "[17:00:43] EvaluateSplits: 1.30239s, 588 calls @ 1302392us\n",
      "\n",
      "[17:00:43] FinalisePosition: 0.018775s, 100 calls @ 18775us\n",
      "\n",
      "[17:00:43] InitRoot: 0.156374s, 100 calls @ 156374us\n",
      "\n",
      "[17:00:43] Reset: 0.01635s, 100 calls @ 16350us\n",
      "\n",
      "[17:00:43] UpdatePosition: 0.101197s, 588 calls @ 101197us\n",
      "\n",
      "[Pipeline] ......... (step 5 of 5) Processing estimator, total=   1.8s\n",
      "[17:00:43] DEBUG: /workspace/src/gbm/gbtree.cc:130: Using tree method: 3\n",
      "[17:00:43] DEBUG: /workspace/src/tree/updater_gpu_hist.cu:744: [GPU Hist]: Configure\n",
      "Training ...\n",
      "[Pipeline] ........ (step 1 of 5) Processing vectorizer, total=   0.0s\n",
      "[Pipeline] .......... (step 2 of 5) Processing sampling, total=   0.0s\n",
      "[Pipeline] ........... (step 3 of 5) Processing scaling, total=   0.0s\n",
      "[Pipeline] ......... (step 4 of 5) Processing selection, total=   0.0s\n",
      "[17:00:43] ======== Monitor (0): HostSketchContainer ========\n",
      "[17:00:43] AllReduce: 0.003124s, 1 calls @ 3124us\n",
      "\n",
      "[17:00:43] MakeCuts: 0.004138s, 1 calls @ 4138us\n",
      "\n",
      "[17:00:43] DEBUG: /workspace/src/gbm/gbtree.cc:130: Using tree method: 3\n",
      "[17:00:43] DEBUG: /workspace/src/tree/updater_gpu_hist.cu:744: [GPU Hist]: Configure\n",
      "[17:00:43] ======== Monitor (0):  ========\n",
      "[17:00:43] InitCompressedData: 3.1e-05s, 1 calls @ 31us\n",
      "\n",
      "[17:00:43] ======== Monitor (0): Learner ========\n",
      "[17:00:43] Configure: 0.000632s, 1 calls @ 632us\n",
      "\n",
      "[17:00:43] EvalOneIter: 0.000494s, 100 calls @ 494us\n",
      "\n",
      "[17:00:43] GetGradient: 0.003626s, 100 calls @ 3626us\n",
      "\n",
      "[17:00:43] PredictRaw: 9.4e-05s, 100 calls @ 94us\n",
      "\n",
      "[17:00:43] UpdateOneIter: 0.489741s, 100 calls @ 489741us\n",
      "\n",
      "[17:00:43] ======== Monitor (0): GBTree ========\n",
      "[17:00:43] BoostNewTrees: 0.484075s, 100 calls @ 484075us\n",
      "\n",
      "[17:00:43] CommitModel: 3.7e-05s, 100 calls @ 37us\n",
      "\n",
      "[17:00:43] ======== Device 0 Memory Allocations:  ========\n",
      "[17:00:43] Peak memory usage: 707MiB\n",
      "[17:00:43] Number of allocations: 122424\n",
      "[17:00:43] ======== Monitor (0): updater_gpu_hist ========\n",
      "[17:00:43] InitData: 0.000203s, 100 calls @ 203us\n",
      "\n",
      "[17:00:43] InitDataOnce: 0.000189s, 1 calls @ 189us\n",
      "\n",
      "[17:00:43] Update: 0.478892s, 100 calls @ 478892us\n",
      "\n",
      "[17:00:43] UpdatePredictionCache: 0.004684s, 100 calls @ 4684us\n",
      "\n",
      "[17:00:43] ======== Monitor (0): gradient_based_sampler ========\n",
      "[17:00:43] Sample: 0.001284s, 100 calls @ 1284us\n",
      "\n",
      "[17:00:43] ======== Monitor (0): GPUHistMakerDevice0 ========\n",
      "[17:00:43] AllReduce: 0.000191s, 345 calls @ 191us\n",
      "\n",
      "[17:00:43] BuildHist: 0.00591s, 253 calls @ 5910us\n",
      "\n",
      "[17:00:43] EvaluateSplits: 0.28627s, 253 calls @ 286270us\n",
      "\n",
      "[17:00:43] FinalisePosition: 0.010613s, 100 calls @ 10613us\n",
      "\n",
      "[17:00:43] InitRoot: 0.129782s, 100 calls @ 129782us\n",
      "\n",
      "[17:00:43] Reset: 0.013384s, 100 calls @ 13384us\n",
      "\n",
      "[17:00:43] UpdatePosition: 0.030552s, 253 calls @ 30552us\n",
      "\n",
      "[17:00:43] ======== Monitor (0): Learner ========\n",
      "[17:00:43] Configure: 0.000608s, 1 calls @ 608us\n",
      "\n",
      "[17:00:43] ======== Monitor (0): GBTree ========\n",
      "[17:00:43] ======== Device 0 Memory Allocations:  ========\n",
      "[17:00:43] Peak memory usage: 707MiB\n",
      "[17:00:43] Number of allocations: 122424\n",
      "[17:00:43] ======== Monitor (0): updater_gpu_hist ========\n",
      "[Pipeline] ......... (step 5 of 5) Processing estimator, total=   0.5s\n",
      "[17:00:43] DEBUG: /workspace/src/gbm/gbtree.cc:130: Using tree method: 3\n",
      "[17:00:43] DEBUG: /workspace/src/tree/updater_gpu_hist.cu:744: [GPU Hist]: Configure\n",
      "Training ...\n",
      "[Pipeline] ........ (step 1 of 5) Processing vectorizer, total=   0.0s\n",
      "[Pipeline] .......... (step 2 of 5) Processing sampling, total=   0.0s\n",
      "[Pipeline] ........... (step 3 of 5) Processing scaling, total=   0.0s\n",
      "[Pipeline] ......... (step 4 of 5) Processing selection, total=   0.0s\n",
      "[17:00:43] ======== Monitor (0): HostSketchContainer ========\n",
      "[17:00:43] AllReduce: 0.008025s, 1 calls @ 8025us\n",
      "\n",
      "[17:00:43] MakeCuts: 0.014644s, 1 calls @ 14644us\n",
      "\n",
      "[17:00:43] DEBUG: /workspace/src/gbm/gbtree.cc:130: Using tree method: 3\n",
      "[17:00:43] DEBUG: /workspace/src/tree/updater_gpu_hist.cu:744: [GPU Hist]: Configure\n",
      "[17:00:43] ======== Monitor (0):  ========\n",
      "[17:00:43] InitCompressedData: 0.000132s, 1 calls @ 132us\n",
      "\n",
      "[17:00:45] ======== Monitor (0): Learner ========\n",
      "[17:00:45] Configure: 0.000668s, 1 calls @ 668us\n",
      "\n",
      "[17:00:45] EvalOneIter: 0.000819s, 100 calls @ 819us\n",
      "\n",
      "[17:00:45] GetGradient: 0.006706s, 100 calls @ 6706us\n",
      "\n",
      "[17:00:45] PredictRaw: 0.000118s, 100 calls @ 118us\n",
      "\n",
      "[17:00:45] UpdateOneIter: 1.53057s, 100 calls @ 1530571us\n",
      "\n",
      "[17:00:45] ======== Monitor (0): GBTree ========\n",
      "[17:00:45] BoostNewTrees: 1.52149s, 100 calls @ 1521487us\n",
      "\n",
      "[17:00:45] CommitModel: 5e-05s, 100 calls @ 50us\n",
      "\n",
      "[17:00:45] ======== Device 0 Memory Allocations:  ========\n",
      "[17:00:45] Peak memory usage: 710MiB\n",
      "[17:00:45] Number of allocations: 127913\n",
      "[17:00:45] ======== Monitor (0): updater_gpu_hist ========\n",
      "[17:00:45] InitData: 0.001931s, 100 calls @ 1931us\n",
      "\n",
      "[17:00:45] InitDataOnce: 0.001917s, 1 calls @ 1917us\n",
      "\n",
      "[17:00:45] Update: 1.5164s, 100 calls @ 1516398us\n",
      "\n",
      "[17:00:45] UpdatePredictionCache: 0.004363s, 100 calls @ 4363us\n",
      "\n",
      "[17:00:45] ======== Monitor (0): gradient_based_sampler ========\n",
      "[17:00:45] Sample: 0.00137s, 100 calls @ 1370us\n",
      "\n",
      "[17:00:45] ======== Monitor (0): GPUHistMakerDevice0 ========\n",
      "[17:00:45] AllReduce: 0.000361s, 592 calls @ 361us\n",
      "\n",
      "[17:00:45] BuildHist: 0.012937s, 569 calls @ 12937us\n",
      "\n",
      "[17:00:45] EvaluateSplits: 1.21842s, 569 calls @ 1218415us\n",
      "\n",
      "[17:00:45] FinalisePosition: 0.020274s, 100 calls @ 20274us\n",
      "\n",
      "[17:00:45] InitRoot: 0.151318s, 100 calls @ 151318us\n",
      "\n",
      "[17:00:45] Reset: 0.017657s, 100 calls @ 17657us\n",
      "\n",
      "[17:00:45] UpdatePosition: 0.089541s, 569 calls @ 89541us\n",
      "\n",
      "[17:00:45] ======== Monitor (0): Learner ========\n",
      "[17:00:45] Configure: 0.000544s, 1 calls @ 544us\n",
      "\n",
      "[17:00:45] ======== Monitor (0): GBTree ========\n",
      "[17:00:45] ======== Device 0 Memory Allocations:  ========\n",
      "[17:00:45] Peak memory usage: 710MiB\n",
      "[17:00:45] Number of allocations: 127913\n",
      "[17:00:45] ======== Monitor (0): updater_gpu_hist ========\n",
      "[Pipeline] ......... (step 5 of 5) Processing estimator, total=   1.6s\n",
      "[17:00:45] DEBUG: /workspace/src/gbm/gbtree.cc:130: Using tree method: 3\n",
      "[17:00:45] DEBUG: /workspace/src/tree/updater_gpu_hist.cu:744: [GPU Hist]: Configure\n",
      "Training ...\n",
      "[Pipeline] ........ (step 1 of 5) Processing vectorizer, total=   0.0s\n",
      "[Pipeline] .......... (step 2 of 5) Processing sampling, total=   0.0s\n",
      "[Pipeline] ........... (step 3 of 5) Processing scaling, total=   0.0s\n",
      "[Pipeline] ......... (step 4 of 5) Processing selection, total=   0.0s\n",
      "[17:00:45] ======== Monitor (0): HostSketchContainer ========\n",
      "[17:00:45] AllReduce: 0.019922s, 1 calls @ 19922us\n",
      "\n",
      "[17:00:45] MakeCuts: 0.022683s, 1 calls @ 22683us\n",
      "\n",
      "[17:00:45] DEBUG: /workspace/src/gbm/gbtree.cc:130: Using tree method: 3\n",
      "[17:00:45] DEBUG: /workspace/src/tree/updater_gpu_hist.cu:744: [GPU Hist]: Configure\n",
      "[17:00:45] ======== Monitor (0):  ========\n",
      "[17:00:45] InitCompressedData: 0.000123s, 1 calls @ 123us\n",
      "\n",
      "[17:00:47] ======== Monitor (0): Learner ========\n",
      "[17:00:47] Configure: 0.00103s, 1 calls @ 1030us\n",
      "\n",
      "[17:00:47] EvalOneIter: 0.000965s, 100 calls @ 965us\n",
      "\n",
      "[17:00:47] GetGradient: 0.005507s, 100 calls @ 5507us\n",
      "\n",
      "[17:00:47] PredictRaw: 0.000137s, 100 calls @ 137us\n",
      "\n",
      "[17:00:47] UpdateOneIter: 1.79251s, 100 calls @ 1792512us\n",
      "\n",
      "[17:00:47] ======== Monitor (0): GBTree ========\n",
      "[17:00:47] BoostNewTrees: 1.78402s, 100 calls @ 1784025us\n",
      "\n",
      "[17:00:47] CommitModel: 5.4e-05s, 100 calls @ 54us\n",
      "\n",
      "[17:00:47] ======== Device 0 Memory Allocations:  ========\n",
      "[17:00:47] Peak memory usage: 1099MiB\n",
      "[17:00:47] Number of allocations: 133459\n",
      "[17:00:47] ======== Monitor (0): updater_gpu_hist ========\n",
      "[17:00:47] InitData: 0.000227s, 100 calls @ 227us\n",
      "\n",
      "[17:00:47] InitDataOnce: 0.000212s, 1 calls @ 212us\n",
      "\n",
      "[17:00:47] Update: 1.77787s, 100 calls @ 1777870us\n",
      "\n",
      "[17:00:47] UpdatePredictionCache: 0.005298s, 100 calls @ 5298us\n",
      "\n",
      "[17:00:47] ======== Monitor (0): gradient_based_sampler ========\n",
      "[17:00:47] Sample: 0.001415s, 100 calls @ 1415us\n",
      "\n",
      "[17:00:47] ======== Monitor (0): GPUHistMakerDevice0 ========\n",
      "[17:00:47] AllReduce: 0.000421s, 599 calls @ 421us\n",
      "\n",
      "[17:00:47] BuildHist: 0.016965s, 590 calls @ 16965us\n",
      "\n",
      "[17:00:47] EvaluateSplits: 1.39031s, 590 calls @ 1390311us\n",
      "\n",
      "[17:00:47] FinalisePosition: 0.02031s, 100 calls @ 20310us\n",
      "\n",
      "[17:00:47] InitRoot: 0.231397s, 100 calls @ 231397us\n",
      "\n",
      "[17:00:47] Reset: 0.017052s, 100 calls @ 17052us\n",
      "\n",
      "[17:00:47] UpdatePosition: 0.096435s, 590 calls @ 96435us\n",
      "\n",
      "[17:00:47] ======== Monitor (0): Learner ========\n",
      "[17:00:47] Configure: 0.000525s, 1 calls @ 525us\n",
      "\n",
      "[17:00:47] ======== Monitor (0): GBTree ========\n",
      "[17:00:47] ======== Device 0 Memory Allocations:  ========\n",
      "[17:00:47] Peak memory usage: 1099MiB\n",
      "[17:00:47] Number of allocations: 133459\n",
      "[17:00:47] ======== Monitor (0): updater_gpu_hist ========\n",
      "[Pipeline] ......... (step 5 of 5) Processing estimator, total=   1.9s\n",
      "[17:00:47] DEBUG: /workspace/src/gbm/gbtree.cc:130: Using tree method: 3\n",
      "[17:00:47] DEBUG: /workspace/src/tree/updater_gpu_hist.cu:744: [GPU Hist]: Configure\n",
      "Training ...\n",
      "[Pipeline] ........ (step 1 of 5) Processing vectorizer, total=   0.0s\n",
      "[Pipeline] .......... (step 2 of 5) Processing sampling, total=   0.0s\n",
      "[Pipeline] ........... (step 3 of 5) Processing scaling, total=   0.0s\n",
      "[Pipeline] ......... (step 4 of 5) Processing selection, total=   0.0s\n",
      "[17:00:47] ======== Monitor (0): HostSketchContainer ========\n",
      "[17:00:47] AllReduce: 0.006379s, 1 calls @ 6379us\n",
      "\n",
      "[17:00:47] MakeCuts: 0.007807s, 1 calls @ 7807us\n",
      "\n",
      "[17:00:47] DEBUG: /workspace/src/gbm/gbtree.cc:130: Using tree method: 3\n",
      "[17:00:47] DEBUG: /workspace/src/tree/updater_gpu_hist.cu:744: [GPU Hist]: Configure\n",
      "[17:00:47] ======== Monitor (0):  ========\n",
      "[17:00:47] InitCompressedData: 0.000109s, 1 calls @ 109us\n",
      "\n",
      "[17:00:48] ======== Monitor (0): Learner ========\n",
      "[17:00:48] Configure: 0.000707s, 1 calls @ 707us\n",
      "\n",
      "[17:00:48] EvalOneIter: 0.000841s, 100 calls @ 841us\n",
      "\n",
      "[17:00:48] GetGradient: 0.006319s, 100 calls @ 6319us\n",
      "\n",
      "[17:00:48] PredictRaw: 0.000124s, 100 calls @ 124us\n",
      "\n",
      "[17:00:48] UpdateOneIter: 1.30737s, 100 calls @ 1307367us\n",
      "\n",
      "[17:00:48] ======== Monitor (0): GBTree ========\n",
      "[17:00:48] BoostNewTrees: 1.29851s, 100 calls @ 1298511us\n",
      "\n",
      "[17:00:48] CommitModel: 5.2e-05s, 100 calls @ 52us\n",
      "\n",
      "[17:00:48] ======== Device 0 Memory Allocations:  ========\n",
      "[17:00:48] Peak memory usage: 1099MiB\n",
      "[17:00:48] Number of allocations: 138940\n",
      "[17:00:48] ======== Monitor (0): updater_gpu_hist ========\n",
      "[17:00:48] InitData: 0.000222s, 100 calls @ 222us\n",
      "\n",
      "[17:00:48] InitDataOnce: 0.000206s, 1 calls @ 206us\n",
      "\n",
      "[17:00:48] Update: 1.29278s, 100 calls @ 1292780us\n",
      "\n",
      "[17:00:48] UpdatePredictionCache: 0.004961s, 100 calls @ 4961us\n",
      "\n",
      "[17:00:48] ======== Monitor (0): gradient_based_sampler ========\n",
      "[17:00:48] Sample: 0.001185s, 100 calls @ 1185us\n",
      "\n",
      "[17:00:48] ======== Monitor (0): GPUHistMakerDevice0 ========\n",
      "[17:00:48] AllReduce: 0.000394s, 591 calls @ 394us\n",
      "\n",
      "[17:00:48] BuildHist: 0.012156s, 558 calls @ 12156us\n",
      "\n",
      "[17:00:48] EvaluateSplits: 1.00838s, 558 calls @ 1008377us\n",
      "\n",
      "[17:00:48] FinalisePosition: 0.015229s, 100 calls @ 15229us\n",
      "\n",
      "[17:00:48] InitRoot: 0.149067s, 100 calls @ 149067us\n",
      "\n",
      "[17:00:48] Reset: 0.014744s, 100 calls @ 14744us\n",
      "\n",
      "[17:00:48] UpdatePosition: 0.088492s, 558 calls @ 88492us\n",
      "\n",
      "[17:00:48] ======== Monitor (0): Learner ========\n",
      "[17:00:48] Configure: 0.000548s, 1 calls @ 548us\n",
      "\n",
      "[17:00:48] ======== Monitor (0): GBTree ========\n",
      "[17:00:48] ======== Device 0 Memory Allocations:  ========\n",
      "[17:00:48] Peak memory usage: 1099MiB\n",
      "[17:00:48] Number of allocations: 138940\n",
      "[17:00:48] ======== Monitor (0): updater_gpu_hist ========\n",
      "[Pipeline] ......... (step 5 of 5) Processing estimator, total=   1.4s\n",
      "[17:00:48] DEBUG: /workspace/src/gbm/gbtree.cc:130: Using tree method: 3\n",
      "[17:00:48] DEBUG: /workspace/src/tree/updater_gpu_hist.cu:744: [GPU Hist]: Configure\n",
      "Training ...\n",
      "[Pipeline] ........ (step 1 of 5) Processing vectorizer, total=   0.0s\n",
      "[Pipeline] .......... (step 2 of 5) Processing sampling, total=   0.0s\n",
      "[Pipeline] ........... (step 3 of 5) Processing scaling, total=   0.0s\n",
      "[Pipeline] ......... (step 4 of 5) Processing selection, total=   0.0s\n",
      "[17:00:48] ======== Monitor (0): HostSketchContainer ========\n",
      "[17:00:48] AllReduce: 0.002897s, 1 calls @ 2897us\n",
      "\n",
      "[17:00:48] MakeCuts: 0.00394s, 1 calls @ 3940us\n",
      "\n",
      "[17:00:48] DEBUG: /workspace/src/gbm/gbtree.cc:130: Using tree method: 3\n",
      "[17:00:48] DEBUG: /workspace/src/tree/updater_gpu_hist.cu:744: [GPU Hist]: Configure\n",
      "[17:00:48] ======== Monitor (0):  ========\n",
      "[17:00:48] InitCompressedData: 0.000214s, 1 calls @ 214us\n",
      "\n",
      "[17:00:49] ======== Monitor (0): Learner ========\n",
      "[17:00:49] Configure: 0.00069s, 1 calls @ 690us\n",
      "\n",
      "[17:00:49] EvalOneIter: 0.000773s, 100 calls @ 773us\n",
      "\n",
      "[17:00:49] GetGradient: 0.006688s, 100 calls @ 6688us\n",
      "\n",
      "[17:00:49] PredictRaw: 0.000129s, 100 calls @ 129us\n",
      "\n",
      "[17:00:49] UpdateOneIter: 1.05171s, 100 calls @ 1051715us\n",
      "\n",
      "[17:00:49] ======== Monitor (0): GBTree ========\n",
      "[17:00:49] BoostNewTrees: 1.04266s, 100 calls @ 1042660us\n",
      "\n",
      "[17:00:49] CommitModel: 4.6e-05s, 100 calls @ 46us\n",
      "\n",
      "[17:00:49] ======== Device 0 Memory Allocations:  ========\n",
      "[17:00:49] Peak memory usage: 1099MiB\n",
      "[17:00:49] Number of allocations: 143997\n",
      "[17:00:49] ======== Monitor (0): updater_gpu_hist ========\n",
      "[17:00:49] InitData: 0.000661s, 100 calls @ 661us\n",
      "\n",
      "[17:00:49] InitDataOnce: 0.000648s, 1 calls @ 648us\n",
      "\n",
      "[17:00:49] Update: 1.03757s, 100 calls @ 1037569us\n",
      "\n",
      "[17:00:49] UpdatePredictionCache: 0.004381s, 100 calls @ 4381us\n",
      "\n",
      "[17:00:49] ======== Monitor (0): gradient_based_sampler ========\n",
      "[17:00:49] Sample: 0.005208s, 100 calls @ 5208us\n",
      "\n",
      "[17:00:49] ======== Monitor (0): GPUHistMakerDevice0 ========\n",
      "[17:00:49] AllReduce: 0.000294s, 538 calls @ 294us\n",
      "\n",
      "[17:00:49] BuildHist: 0.009131s, 481 calls @ 9131us\n",
      "\n",
      "[17:00:49] EvaluateSplits: 0.788968s, 481 calls @ 788968us\n",
      "\n",
      "[17:00:49] FinalisePosition: 0.013421s, 100 calls @ 13421us\n",
      "\n",
      "[17:00:49] InitRoot: 0.141333s, 100 calls @ 141333us\n",
      "\n",
      "[17:00:49] Reset: 0.018725s, 100 calls @ 18725us\n",
      "\n",
      "[17:00:49] UpdatePosition: 0.061888s, 481 calls @ 61888us\n",
      "\n",
      "[17:00:49] ======== Monitor (0): Learner ========\n",
      "[17:00:49] Configure: 0.000616s, 1 calls @ 616us\n",
      "\n",
      "[17:00:49] ======== Monitor (0): GBTree ========\n",
      "[17:00:49] ======== Device 0 Memory Allocations:  ========\n",
      "[17:00:49] Peak memory usage: 1099MiB\n",
      "[17:00:49] Number of allocations: 143997\n",
      "[17:00:49] ======== Monitor (0): updater_gpu_hist ========\n",
      "[Pipeline] ......... (step 5 of 5) Processing estimator, total=   1.1s\n",
      "[17:00:49] DEBUG: /workspace/src/gbm/gbtree.cc:130: Using tree method: 3\n",
      "[17:00:49] DEBUG: /workspace/src/tree/updater_gpu_hist.cu:744: [GPU Hist]: Configure\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "      <th>corpus</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>macro avg</td>\n",
       "      <td>0.613325</td>\n",
       "      <td>0.599870</td>\n",
       "      <td>0.599599</td>\n",
       "      <td>411.0</td>\n",
       "      <td>gl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>macro avg</td>\n",
       "      <td>0.620309</td>\n",
       "      <td>0.617472</td>\n",
       "      <td>0.616969</td>\n",
       "      <td>272.0</td>\n",
       "      <td>lu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>macro avg</td>\n",
       "      <td>0.629701</td>\n",
       "      <td>0.626611</td>\n",
       "      <td>0.627343</td>\n",
       "      <td>599.0</td>\n",
       "      <td>ig</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>macro avg</td>\n",
       "      <td>0.682637</td>\n",
       "      <td>0.681473</td>\n",
       "      <td>0.680757</td>\n",
       "      <td>574.0</td>\n",
       "      <td>cl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>macro avg</td>\n",
       "      <td>0.712332</td>\n",
       "      <td>0.711602</td>\n",
       "      <td>0.711908</td>\n",
       "      <td>774.0</td>\n",
       "      <td>co</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>macro avg</td>\n",
       "      <td>0.853595</td>\n",
       "      <td>0.756885</td>\n",
       "      <td>0.794085</td>\n",
       "      <td>188.0</td>\n",
       "      <td>bo</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       class  precision    recall  f1-score  support corpus\n",
       "3  macro avg   0.613325  0.599870  0.599599    411.0     gl\n",
       "3  macro avg   0.620309  0.617472  0.616969    272.0     lu\n",
       "3  macro avg   0.629701  0.626611  0.627343    599.0     ig\n",
       "2  macro avg   0.682637  0.681473  0.680757    574.0     cl\n",
       "3  macro avg   0.712332  0.711602  0.711908    774.0     co\n",
       "3  macro avg   0.853595  0.756885  0.794085    188.0     bo"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define pipeline steps \n",
    "scaling = MaxAbsScaler()\n",
    "selection = None\n",
    "estimator = XGBClassifier(\n",
    "                random_state = 42,\n",
    "                verbosity = 3,\n",
    "                device = 'cuda',\n",
    "                tree_method = 'hist'\n",
    "                )\n",
    "\n",
    "\n",
    "# get results\n",
    "df_cr, df_test_results = process_classification(\n",
    "        estimator = estimator,\n",
    "        scaling = scaling,\n",
    "        selection= selection,\n",
    "        data_tuples = list_tuples_users,\n",
    "        X_cols = X_cols\n",
    ")\n",
    "\n",
    "df_cr.to_csv(path_results_cr + 'dummy_classifier_users_timeline_classification_report.csv')\n",
    "df_cr[df_cr['class'] == 'macro avg'].sort_values('f1-score')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_cols = [col for col in data_test.columns if 'emb' in col and 'Stance' in col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ...\n",
      "[Pipeline] ........ (step 1 of 5) Processing vectorizer, total=   0.0s\n",
      "[Pipeline] .......... (step 2 of 5) Processing sampling, total=   0.0s\n",
      "[Pipeline] ........... (step 3 of 5) Processing scaling, total=   0.0s\n",
      "[Pipeline] ......... (step 4 of 5) Processing selection, total=   0.0s\n",
      "[17:01:52] ======== Monitor (0): HostSketchContainer ========\n",
      "[17:01:52] AllReduce: 0.016668s, 1 calls @ 16668us\n",
      "\n",
      "[17:01:52] MakeCuts: 0.024559s, 1 calls @ 24559us\n",
      "\n",
      "[17:01:52] DEBUG: /workspace/src/gbm/gbtree.cc:130: Using tree method: 3\n",
      "[17:01:52] DEBUG: /workspace/src/tree/updater_gpu_hist.cu:744: [GPU Hist]: Configure\n",
      "[17:01:52] ======== Monitor (0):  ========\n",
      "[17:01:52] InitCompressedData: 0.000219s, 1 calls @ 219us\n",
      "\n",
      "[17:01:54] ======== Monitor (0): Learner ========\n",
      "[17:01:54] Configure: 0.01335s, 1 calls @ 13350us\n",
      "\n",
      "[17:01:54] EvalOneIter: 0.000814s, 100 calls @ 814us\n",
      "\n",
      "[17:01:54] GetGradient: 0.005933s, 100 calls @ 5933us\n",
      "\n",
      "[17:01:54] PredictRaw: 0.000124s, 100 calls @ 124us\n",
      "\n",
      "[17:01:54] UpdateOneIter: 1.40831s, 100 calls @ 1408313us\n",
      "\n",
      "[17:01:54] ======== Monitor (0): GBTree ========\n",
      "[17:01:54] BoostNewTrees: 1.38688s, 100 calls @ 1386876us\n",
      "\n",
      "[17:01:54] CommitModel: 5e-05s, 100 calls @ 50us\n",
      "\n",
      "[17:01:54] ======== Device 0 Memory Allocations:  ========\n",
      "[17:01:54] Peak memory usage: 1099MiB\n",
      "[17:01:54] Number of allocations: 149350\n",
      "[17:01:54] ======== Monitor (0): updater_gpu_hist ========\n",
      "[17:01:54] InitData: 0.00087s, 100 calls @ 870us\n",
      "\n",
      "[17:01:54] InitDataOnce: 0.000855s, 1 calls @ 855us\n",
      "\n",
      "[17:01:54] Update: 1.37894s, 100 calls @ 1378935us\n",
      "\n",
      "[17:01:54] UpdatePredictionCache: 0.007152s, 100 calls @ 7152us\n",
      "\n",
      "[17:01:54] ======== Monitor (0): gradient_based_sampler ========\n",
      "[17:01:54] Sample: 0.00258s, 100 calls @ 2580us\n",
      "\n",
      "[17:01:54] ======== Monitor (0): GPUHistMakerDevice0 ========\n",
      "[17:01:54] AllReduce: 0.000357s, 575 calls @ 357us\n",
      "\n",
      "[17:01:54] BuildHist: 0.011849s, 534 calls @ 11849us\n",
      "\n",
      "[17:01:54] EvaluateSplits: 1.09595s, 534 calls @ 1095951us\n",
      "\n",
      "[17:01:54] FinalisePosition: 0.014479s, 100 calls @ 14479us\n",
      "\n",
      "[17:01:54] InitRoot: 0.153798s, 100 calls @ 153798us\n",
      "\n",
      "[17:01:54] Reset: 0.017065s, 100 calls @ 17065us\n",
      "\n",
      "[17:01:54] UpdatePosition: 0.080732s, 534 calls @ 80732us\n",
      "\n",
      "[Pipeline] ......... (step 5 of 5) Processing estimator, total=   1.6s\n",
      "[17:01:54] DEBUG: /workspace/src/gbm/gbtree.cc:130: Using tree method: 3\n",
      "[17:01:54] DEBUG: /workspace/src/tree/updater_gpu_hist.cu:744: [GPU Hist]: Configure\n",
      "Training ...\n",
      "[Pipeline] ........ (step 1 of 5) Processing vectorizer, total=   0.0s\n",
      "[Pipeline] .......... (step 2 of 5) Processing sampling, total=   0.0s\n",
      "[Pipeline] ........... (step 3 of 5) Processing scaling, total=   0.0s\n",
      "[Pipeline] ......... (step 4 of 5) Processing selection, total=   0.0s\n",
      "[17:01:54] ======== Monitor (0): HostSketchContainer ========\n",
      "[17:01:54] AllReduce: 0.003405s, 1 calls @ 3405us\n",
      "\n",
      "[17:01:54] MakeCuts: 0.006118s, 1 calls @ 6118us\n",
      "\n",
      "[17:01:54] DEBUG: /workspace/src/gbm/gbtree.cc:130: Using tree method: 3\n",
      "[17:01:54] DEBUG: /workspace/src/tree/updater_gpu_hist.cu:744: [GPU Hist]: Configure\n",
      "[17:01:54] ======== Monitor (0):  ========\n",
      "[17:01:54] InitCompressedData: 2.4e-05s, 1 calls @ 24us\n",
      "\n",
      "[17:01:54] ======== Monitor (0): Learner ========\n",
      "[17:01:54] Configure: 0.000648s, 1 calls @ 648us\n",
      "\n",
      "[17:01:54] EvalOneIter: 0.000491s, 100 calls @ 491us\n",
      "\n",
      "[17:01:54] GetGradient: 0.005971s, 100 calls @ 5971us\n",
      "\n",
      "[17:01:54] PredictRaw: 8.8e-05s, 100 calls @ 88us\n",
      "\n",
      "[17:01:54] UpdateOneIter: 0.54522s, 100 calls @ 545220us\n",
      "\n",
      "[17:01:54] ======== Monitor (0): GBTree ========\n",
      "[17:01:54] BoostNewTrees: 0.536577s, 100 calls @ 536577us\n",
      "\n",
      "[17:01:54] CommitModel: 3.5e-05s, 100 calls @ 35us\n",
      "\n",
      "[17:01:54] ======== Device 0 Memory Allocations:  ========\n",
      "[17:01:54] Peak memory usage: 1099MiB\n",
      "[17:01:54] Number of allocations: 153079\n",
      "[17:01:54] ======== Monitor (0): updater_gpu_hist ========\n",
      "[17:01:54] InitData: 0.000317s, 100 calls @ 317us\n",
      "\n",
      "[17:01:54] InitDataOnce: 0.000303s, 1 calls @ 303us\n",
      "\n",
      "[17:01:54] Update: 0.531041s, 100 calls @ 531041us\n",
      "\n",
      "[17:01:54] UpdatePredictionCache: 0.00504s, 100 calls @ 5040us\n",
      "\n",
      "[17:01:54] ======== Monitor (0): gradient_based_sampler ========\n",
      "[17:01:54] Sample: 0.00152s, 100 calls @ 1520us\n",
      "\n",
      "[17:01:54] ======== Monitor (0): GPUHistMakerDevice0 ========\n",
      "[17:01:54] AllReduce: 0.000201s, 372 calls @ 201us\n",
      "\n",
      "[17:01:54] BuildHist: 0.006004s, 285 calls @ 6004us\n",
      "\n",
      "[17:01:54] EvaluateSplits: 0.334802s, 285 calls @ 334802us\n",
      "\n",
      "[17:01:54] FinalisePosition: 0.010446s, 100 calls @ 10446us\n",
      "\n",
      "[17:01:54] InitRoot: 0.127875s, 100 calls @ 127875us\n",
      "\n",
      "[17:01:54] Reset: 0.014535s, 100 calls @ 14535us\n",
      "\n",
      "[17:01:54] UpdatePosition: 0.034736s, 285 calls @ 34736us\n",
      "\n",
      "[17:01:54] ======== Monitor (0): Learner ========\n",
      "[17:01:54] Configure: 0.000558s, 1 calls @ 558us\n",
      "\n",
      "[17:01:54] ======== Monitor (0): GBTree ========\n",
      "[17:01:54] ======== Device 0 Memory Allocations:  ========\n",
      "[17:01:54] Peak memory usage: 1099MiB\n",
      "[17:01:54] Number of allocations: 153079\n",
      "[17:01:54] ======== Monitor (0): updater_gpu_hist ========\n",
      "[Pipeline] ......... (step 5 of 5) Processing estimator, total=   0.6s\n",
      "[17:01:54] DEBUG: /workspace/src/gbm/gbtree.cc:130: Using tree method: 3\n",
      "[17:01:54] DEBUG: /workspace/src/tree/updater_gpu_hist.cu:744: [GPU Hist]: Configure\n",
      "Training ...\n",
      "[Pipeline] ........ (step 1 of 5) Processing vectorizer, total=   0.0s\n",
      "[Pipeline] .......... (step 2 of 5) Processing sampling, total=   0.0s\n",
      "[Pipeline] ........... (step 3 of 5) Processing scaling, total=   0.0s\n",
      "[Pipeline] ......... (step 4 of 5) Processing selection, total=   0.0s\n",
      "[17:01:54] ======== Monitor (0): HostSketchContainer ========\n",
      "[17:01:54] AllReduce: 0.015243s, 1 calls @ 15243us\n",
      "\n",
      "[17:01:54] MakeCuts: 0.019291s, 1 calls @ 19291us\n",
      "\n",
      "[17:01:54] DEBUG: /workspace/src/gbm/gbtree.cc:130: Using tree method: 3\n",
      "[17:01:54] DEBUG: /workspace/src/tree/updater_gpu_hist.cu:744: [GPU Hist]: Configure\n",
      "[17:01:54] ======== Monitor (0):  ========\n",
      "[17:01:54] InitCompressedData: 0.001034s, 1 calls @ 1034us\n",
      "\n",
      "[17:01:56] ======== Monitor (0): Learner ========\n",
      "[17:01:56] Configure: 0.000682s, 1 calls @ 682us\n",
      "\n",
      "[17:01:56] EvalOneIter: 0.000822s, 100 calls @ 822us\n",
      "\n",
      "[17:01:56] GetGradient: 0.005765s, 100 calls @ 5765us\n",
      "\n",
      "[17:01:56] PredictRaw: 0.000115s, 100 calls @ 115us\n",
      "\n",
      "[17:01:56] UpdateOneIter: 1.60153s, 100 calls @ 1601526us\n",
      "\n",
      "[17:01:56] ======== Monitor (0): GBTree ========\n",
      "[17:01:56] BoostNewTrees: 1.59338s, 100 calls @ 1593376us\n",
      "\n",
      "[17:01:56] CommitModel: 5.2e-05s, 100 calls @ 52us\n",
      "\n",
      "[17:01:56] ======== Device 0 Memory Allocations:  ========\n",
      "[17:01:56] Peak memory usage: 1113MiB\n",
      "[17:01:56] Number of allocations: 158553\n",
      "[17:01:56] ======== Monitor (0): updater_gpu_hist ========\n",
      "[17:01:56] InitData: 0.000378s, 100 calls @ 378us\n",
      "\n",
      "[17:01:56] InitDataOnce: 0.000364s, 1 calls @ 364us\n",
      "\n",
      "[17:01:56] Update: 1.58774s, 100 calls @ 1587742us\n",
      "\n",
      "[17:01:56] UpdatePredictionCache: 0.004912s, 100 calls @ 4912us\n",
      "\n",
      "[17:01:56] ======== Monitor (0): gradient_based_sampler ========\n",
      "[17:01:56] Sample: 0.002254s, 100 calls @ 2254us\n",
      "\n",
      "[17:01:56] ======== Monitor (0): GPUHistMakerDevice0 ========\n",
      "[17:01:56] AllReduce: 0.000357s, 590 calls @ 357us\n",
      "\n",
      "[17:01:56] BuildHist: 0.015023s, 564 calls @ 15023us\n",
      "\n",
      "[17:01:56] EvaluateSplits: 1.21327s, 564 calls @ 1213267us\n",
      "\n",
      "[17:01:56] FinalisePosition: 0.015158s, 100 calls @ 15158us\n",
      "\n",
      "[17:01:56] InitRoot: 0.234787s, 100 calls @ 234787us\n",
      "\n",
      "[17:01:56] Reset: 0.017206s, 100 calls @ 17206us\n",
      "\n",
      "[17:01:56] UpdatePosition: 0.087795s, 564 calls @ 87795us\n",
      "\n",
      "[17:01:56] ======== Monitor (0): Learner ========\n",
      "[17:01:56] Configure: 0.000586s, 1 calls @ 586us\n",
      "\n",
      "[17:01:56] ======== Monitor (0): GBTree ========\n",
      "[17:01:56] ======== Device 0 Memory Allocations:  ========\n",
      "[17:01:56] Peak memory usage: 1113MiB\n",
      "[17:01:56] Number of allocations: 158553\n",
      "[17:01:56] ======== Monitor (0): updater_gpu_hist ========\n",
      "[Pipeline] ......... (step 5 of 5) Processing estimator, total=   1.7s\n",
      "[17:01:56] DEBUG: /workspace/src/gbm/gbtree.cc:130: Using tree method: 3\n",
      "[17:01:56] DEBUG: /workspace/src/tree/updater_gpu_hist.cu:744: [GPU Hist]: Configure\n",
      "Training ...\n",
      "[Pipeline] ........ (step 1 of 5) Processing vectorizer, total=   0.0s\n",
      "[Pipeline] .......... (step 2 of 5) Processing sampling, total=   0.0s\n",
      "[Pipeline] ........... (step 3 of 5) Processing scaling, total=   0.0s\n",
      "[Pipeline] ......... (step 4 of 5) Processing selection, total=   0.0s\n",
      "[17:01:56] ======== Monitor (0): HostSketchContainer ========\n",
      "[17:01:56] AllReduce: 0.016271s, 1 calls @ 16271us\n",
      "\n",
      "[17:01:56] MakeCuts: 0.018976s, 1 calls @ 18976us\n",
      "\n",
      "[17:01:56] DEBUG: /workspace/src/gbm/gbtree.cc:130: Using tree method: 3\n",
      "[17:01:56] DEBUG: /workspace/src/tree/updater_gpu_hist.cu:744: [GPU Hist]: Configure\n",
      "[17:01:56] ======== Monitor (0):  ========\n",
      "[17:01:56] InitCompressedData: 0.000117s, 1 calls @ 117us\n",
      "\n",
      "[17:01:58] ======== Monitor (0): Learner ========\n",
      "[17:01:58] Configure: 0.000668s, 1 calls @ 668us\n",
      "\n",
      "[17:01:58] EvalOneIter: 0.000846s, 100 calls @ 846us\n",
      "\n",
      "[17:01:58] GetGradient: 0.005568s, 100 calls @ 5568us\n",
      "\n",
      "[17:01:58] PredictRaw: 0.000119s, 100 calls @ 119us\n",
      "\n",
      "[17:01:58] UpdateOneIter: 1.77647s, 100 calls @ 1776467us\n",
      "\n",
      "[17:01:58] ======== Monitor (0): GBTree ========\n",
      "[17:01:58] BoostNewTrees: 1.76846s, 100 calls @ 1768464us\n",
      "\n",
      "[17:01:58] CommitModel: 5.4e-05s, 100 calls @ 54us\n",
      "\n",
      "[17:01:58] ======== Device 0 Memory Allocations:  ========\n",
      "[17:01:58] Peak memory usage: 1113MiB\n",
      "[17:01:58] Number of allocations: 164106\n",
      "[17:01:58] ======== Monitor (0): updater_gpu_hist ========\n",
      "[17:01:58] InitData: 0.000225s, 100 calls @ 225us\n",
      "\n",
      "[17:01:58] InitDataOnce: 0.000209s, 1 calls @ 209us\n",
      "\n",
      "[17:01:58] Update: 1.76154s, 100 calls @ 1761543us\n",
      "\n",
      "[17:01:58] UpdatePredictionCache: 0.006132s, 100 calls @ 6132us\n",
      "\n",
      "[17:01:58] ======== Monitor (0): gradient_based_sampler ========\n",
      "[17:01:58] Sample: 0.00138s, 100 calls @ 1380us\n",
      "\n",
      "[17:01:58] ======== Monitor (0): GPUHistMakerDevice0 ========\n",
      "[17:01:58] AllReduce: 0.00037s, 600 calls @ 370us\n",
      "\n",
      "[17:01:58] BuildHist: 0.013804s, 594 calls @ 13804us\n",
      "\n",
      "[17:01:58] EvaluateSplits: 1.44925s, 594 calls @ 1449246us\n",
      "\n",
      "[17:01:58] FinalisePosition: 0.018858s, 100 calls @ 18858us\n",
      "\n",
      "[17:01:58] InitRoot: 0.161356s, 100 calls @ 161356us\n",
      "\n",
      "[17:01:58] Reset: 0.014885s, 100 calls @ 14885us\n",
      "\n",
      "[17:01:58] UpdatePosition: 0.098326s, 594 calls @ 98326us\n",
      "\n",
      "[17:01:58] ======== Monitor (0): Learner ========\n",
      "[17:01:58] Configure: 0.00053s, 1 calls @ 530us\n",
      "\n",
      "[17:01:58] ======== Monitor (0): GBTree ========\n",
      "[17:01:58] ======== Device 0 Memory Allocations:  ========\n",
      "[17:01:58] Peak memory usage: 1113MiB\n",
      "[17:01:58] Number of allocations: 164106\n",
      "[17:01:58] ======== Monitor (0): updater_gpu_hist ========\n",
      "[Pipeline] ......... (step 5 of 5) Processing estimator, total=   1.9s\n",
      "[17:01:58] DEBUG: /workspace/src/gbm/gbtree.cc:130: Using tree method: 3\n",
      "[17:01:58] DEBUG: /workspace/src/tree/updater_gpu_hist.cu:744: [GPU Hist]: Configure\n",
      "Training ...\n",
      "[Pipeline] ........ (step 1 of 5) Processing vectorizer, total=   0.0s\n",
      "[Pipeline] .......... (step 2 of 5) Processing sampling, total=   0.0s\n",
      "[Pipeline] ........... (step 3 of 5) Processing scaling, total=   0.0s\n",
      "[Pipeline] ......... (step 4 of 5) Processing selection, total=   0.0s\n",
      "[17:01:58] ======== Monitor (0): HostSketchContainer ========\n",
      "[17:01:58] AllReduce: 0.004709s, 1 calls @ 4709us\n",
      "\n",
      "[17:01:58] MakeCuts: 0.006343s, 1 calls @ 6343us\n",
      "\n",
      "[17:01:58] DEBUG: /workspace/src/gbm/gbtree.cc:130: Using tree method: 3\n",
      "[17:01:58] DEBUG: /workspace/src/tree/updater_gpu_hist.cu:744: [GPU Hist]: Configure\n",
      "[17:01:58] ======== Monitor (0):  ========\n",
      "[17:01:58] InitCompressedData: 0.000107s, 1 calls @ 107us\n",
      "\n",
      "[17:01:59] ======== Monitor (0): Learner ========\n",
      "[17:01:59] Configure: 0.000642s, 1 calls @ 642us\n",
      "\n",
      "[17:01:59] EvalOneIter: 0.000669s, 100 calls @ 669us\n",
      "\n",
      "[17:01:59] GetGradient: 0.005305s, 100 calls @ 5305us\n",
      "\n",
      "[17:01:59] PredictRaw: 0.000102s, 100 calls @ 102us\n",
      "\n",
      "[17:01:59] UpdateOneIter: 1.15073s, 100 calls @ 1150731us\n",
      "\n",
      "[17:01:59] ======== Monitor (0): GBTree ========\n",
      "[17:01:59] BoostNewTrees: 1.14328s, 100 calls @ 1143275us\n",
      "\n",
      "[17:01:59] CommitModel: 4e-05s, 100 calls @ 40us\n",
      "\n",
      "[17:01:59] ======== Device 0 Memory Allocations:  ========\n",
      "[17:01:59] Peak memory usage: 1113MiB\n",
      "[17:01:59] Number of allocations: 169163\n",
      "[17:01:59] ======== Monitor (0): updater_gpu_hist ========\n",
      "[17:01:59] InitData: 0.000226s, 100 calls @ 226us\n",
      "\n",
      "[17:01:59] InitDataOnce: 0.000211s, 1 calls @ 211us\n",
      "\n",
      "[17:01:59] Update: 1.13917s, 100 calls @ 1139168us\n",
      "\n",
      "[17:01:59] UpdatePredictionCache: 0.003462s, 100 calls @ 3462us\n",
      "\n",
      "[17:01:59] ======== Monitor (0): gradient_based_sampler ========\n",
      "[17:01:59] Sample: 0.001126s, 100 calls @ 1126us\n",
      "\n",
      "[17:01:59] ======== Monitor (0): GPUHistMakerDevice0 ========\n",
      "[17:01:59] AllReduce: 0.000294s, 538 calls @ 294us\n",
      "\n",
      "[17:01:59] BuildHist: 0.010356s, 483 calls @ 10356us\n",
      "\n",
      "[17:01:59] EvaluateSplits: 0.878246s, 483 calls @ 878246us\n",
      "\n",
      "[17:01:59] FinalisePosition: 0.014025s, 100 calls @ 14025us\n",
      "\n",
      "[17:01:59] InitRoot: 0.143564s, 100 calls @ 143564us\n",
      "\n",
      "[17:01:59] Reset: 0.015362s, 100 calls @ 15362us\n",
      "\n",
      "[17:01:59] UpdatePosition: 0.073966s, 483 calls @ 73966us\n",
      "\n",
      "[17:01:59] ======== Monitor (0): Learner ========\n",
      "[17:01:59] Configure: 0.000618s, 1 calls @ 618us\n",
      "\n",
      "[17:01:59] ======== Monitor (0): GBTree ========\n",
      "[17:01:59] ======== Device 0 Memory Allocations:  ========\n",
      "[17:01:59] Peak memory usage: 1113MiB\n",
      "[17:01:59] Number of allocations: 169163\n",
      "[17:01:59] ======== Monitor (0): updater_gpu_hist ========\n",
      "[Pipeline] ......... (step 5 of 5) Processing estimator, total=   1.2s\n",
      "[17:01:59] DEBUG: /workspace/src/gbm/gbtree.cc:130: Using tree method: 3\n",
      "[17:01:59] DEBUG: /workspace/src/tree/updater_gpu_hist.cu:744: [GPU Hist]: Configure\n",
      "Training ...\n",
      "[Pipeline] ........ (step 1 of 5) Processing vectorizer, total=   0.0s\n",
      "[Pipeline] .......... (step 2 of 5) Processing sampling, total=   0.0s\n",
      "[Pipeline] ........... (step 3 of 5) Processing scaling, total=   0.0s\n",
      "[Pipeline] ......... (step 4 of 5) Processing selection, total=   0.0s\n",
      "[17:01:59] ======== Monitor (0): HostSketchContainer ========\n",
      "[17:01:59] AllReduce: 0.003832s, 1 calls @ 3832us\n",
      "\n",
      "[17:01:59] MakeCuts: 0.005483s, 1 calls @ 5483us\n",
      "\n",
      "[17:01:59] DEBUG: /workspace/src/gbm/gbtree.cc:130: Using tree method: 3\n",
      "[17:01:59] DEBUG: /workspace/src/tree/updater_gpu_hist.cu:744: [GPU Hist]: Configure\n",
      "[17:01:59] ======== Monitor (0):  ========\n",
      "[17:01:59] InitCompressedData: 9.7e-05s, 1 calls @ 97us\n",
      "\n",
      "[17:02:00] ======== Monitor (0): Learner ========\n",
      "[17:02:00] Configure: 0.000622s, 1 calls @ 622us\n",
      "\n",
      "[17:02:00] EvalOneIter: 0.000635s, 100 calls @ 635us\n",
      "\n",
      "[17:02:00] GetGradient: 0.003879s, 100 calls @ 3879us\n",
      "\n",
      "[17:02:00] PredictRaw: 0.000101s, 100 calls @ 101us\n",
      "\n",
      "[17:02:00] UpdateOneIter: 1.00682s, 100 calls @ 1006816us\n",
      "\n",
      "[17:02:00] ======== Monitor (0): GBTree ========\n",
      "[17:02:00] BoostNewTrees: 1.00082s, 100 calls @ 1000816us\n",
      "\n",
      "[17:02:00] CommitModel: 3.9e-05s, 100 calls @ 39us\n",
      "\n",
      "[17:02:00] ======== Device 0 Memory Allocations:  ========\n",
      "[17:02:00] Peak memory usage: 1113MiB\n",
      "[17:02:00] Number of allocations: 174052\n",
      "[17:02:00] ======== Monitor (0): updater_gpu_hist ========\n",
      "[17:02:00] InitData: 0.00019s, 100 calls @ 190us\n",
      "\n",
      "[17:02:00] InitDataOnce: 0.000176s, 1 calls @ 176us\n",
      "\n",
      "[17:02:00] Update: 0.990095s, 100 calls @ 990095us\n",
      "\n",
      "[17:02:00] UpdatePredictionCache: 0.01012s, 100 calls @ 10120us\n",
      "\n",
      "[17:02:00] ======== Monitor (0): gradient_based_sampler ========\n",
      "[17:02:00] Sample: 0.000897s, 100 calls @ 897us\n",
      "\n",
      "[17:02:00] ======== Monitor (0): GPUHistMakerDevice0 ========\n",
      "[17:02:00] AllReduce: 0.000272s, 517 calls @ 272us\n",
      "\n",
      "[17:02:00] BuildHist: 0.008971s, 454 calls @ 8971us\n",
      "\n",
      "[17:02:00] EvaluateSplits: 0.748295s, 454 calls @ 748295us\n",
      "\n",
      "[17:02:00] FinalisePosition: 0.013538s, 100 calls @ 13538us\n",
      "\n",
      "[17:02:00] InitRoot: 0.141015s, 100 calls @ 141015us\n",
      "\n",
      "[17:02:00] Reset: 0.011147s, 100 calls @ 11147us\n",
      "\n",
      "[17:02:00] UpdatePosition: 0.063712s, 454 calls @ 63712us\n",
      "\n",
      "[17:02:00] ======== Monitor (0): Learner ========\n",
      "[17:02:00] Configure: 0.000562s, 1 calls @ 562us\n",
      "\n",
      "[17:02:00] ======== Monitor (0): GBTree ========\n",
      "[17:02:00] ======== Device 0 Memory Allocations:  ========\n",
      "[17:02:00] Peak memory usage: 1113MiB\n",
      "[17:02:00] Number of allocations: 174052\n",
      "[17:02:00] ======== Monitor (0): updater_gpu_hist ========\n",
      "[Pipeline] ......... (step 5 of 5) Processing estimator, total=   1.1s\n",
      "[17:02:00] DEBUG: /workspace/src/gbm/gbtree.cc:130: Using tree method: 3\n",
      "[17:02:00] DEBUG: /workspace/src/tree/updater_gpu_hist.cu:744: [GPU Hist]: Configure\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "      <th>corpus</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>macro avg</td>\n",
       "      <td>0.933155</td>\n",
       "      <td>0.519231</td>\n",
       "      <td>0.501220</td>\n",
       "      <td>188.0</td>\n",
       "      <td>bo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>macro avg</td>\n",
       "      <td>0.678808</td>\n",
       "      <td>0.674879</td>\n",
       "      <td>0.675571</td>\n",
       "      <td>774.0</td>\n",
       "      <td>co</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>macro avg</td>\n",
       "      <td>0.690307</td>\n",
       "      <td>0.689977</td>\n",
       "      <td>0.690104</td>\n",
       "      <td>272.0</td>\n",
       "      <td>lu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>macro avg</td>\n",
       "      <td>0.716314</td>\n",
       "      <td>0.715881</td>\n",
       "      <td>0.715834</td>\n",
       "      <td>574.0</td>\n",
       "      <td>cl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>macro avg</td>\n",
       "      <td>0.765804</td>\n",
       "      <td>0.763129</td>\n",
       "      <td>0.764342</td>\n",
       "      <td>411.0</td>\n",
       "      <td>gl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>macro avg</td>\n",
       "      <td>0.793490</td>\n",
       "      <td>0.782602</td>\n",
       "      <td>0.785899</td>\n",
       "      <td>599.0</td>\n",
       "      <td>ig</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       class  precision    recall  f1-score  support corpus\n",
       "3  macro avg   0.933155  0.519231  0.501220    188.0     bo\n",
       "3  macro avg   0.678808  0.674879  0.675571    774.0     co\n",
       "3  macro avg   0.690307  0.689977  0.690104    272.0     lu\n",
       "3  macro avg   0.716314  0.715881  0.715834    574.0     cl\n",
       "3  macro avg   0.765804  0.763129  0.764342    411.0     gl\n",
       "3  macro avg   0.793490  0.782602  0.785899    599.0     ig"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define pipeline steps \n",
    "scaling = MaxAbsScaler()\n",
    "selection = None\n",
    "estimator = XGBClassifier(\n",
    "                random_state = 42,\n",
    "                verbosity = 3,\n",
    "                device = 'cuda',\n",
    "                tree_method = 'hist'\n",
    "                )\n",
    "\n",
    "\n",
    "# get results\n",
    "df_cr, df_test_results = process_classification(\n",
    "        estimator = estimator,\n",
    "        scaling = scaling,\n",
    "        selection= selection,\n",
    "        data_tuples = list_tuples_users,\n",
    "        X_cols = X_cols\n",
    ")\n",
    "\n",
    "df_cr.to_csv(path_results_cr + 'dummy_classifier_users_timeline_classification_report.csv')\n",
    "df_cr[df_cr['class'] == 'macro avg'].sort_values('f1-score')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env-stance-pred",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
