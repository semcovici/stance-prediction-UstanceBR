{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import seaborn as sns\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/semcovici/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'neuralmind/bert-base-portuguese-cased'\n",
    "\n",
    "random_seed = 42\n",
    "\n",
    "raw_data_path = '../data/raw/'\n",
    "processed_data_path = '../data/processed/'\n",
    "results_cr_path = '../reports/classification_reports/'\n",
    "test_results_path = '../reports/test_results/'\n",
    "reports_path = '../reports/'\n",
    "\n",
    "target_list = ['ig','bo', 'cl', 'co', 'gl', 'lu']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:21<00:00,  3.59s/it]\n"
     ]
    }
   ],
   "source": [
    "data_list = []\n",
    "\n",
    "for target in tqdm(target_list):\n",
    "    \n",
    "    # read data\n",
    "    data_temp_train = pd.read_csv(\n",
    "        raw_data_path + f'train_r3_{target}_top_mentioned_timelines.csv', \n",
    "        sep = ';', \n",
    "        encoding='utf-8-sig'\n",
    "        )\n",
    "    data_temp_test = pd.read_csv(\n",
    "        raw_data_path + f'test_r3_{target}_top_mentioned_timelines.csv', \n",
    "        sep = ';', \n",
    "        encoding='utf-8-sig'\n",
    "        )\n",
    "    \n",
    "    data_temp_train['target'] = target\n",
    "    data_temp_test['target'] = target\n",
    "    \n",
    "    data_temp_train['split'] = \"train\"\n",
    "    data_temp_test['split'] = \"test\"\n",
    "    \n",
    "    data_list.append(data_temp_train)\n",
    "    data_list.append(data_temp_test)\n",
    "    \n",
    "data_tmt = pd.concat(data_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:30<00:00,  5.15s/it]\n"
     ]
    }
   ],
   "source": [
    "data_list = []\n",
    "\n",
    "for target in tqdm(target_list):\n",
    "    \n",
    "    # read data\n",
    "    data_temp_train = pd.read_csv(\n",
    "        raw_data_path + f'r3_{target}_train_users.csv', \n",
    "        sep = ';', \n",
    "        encoding='utf-8-sig'\n",
    "    )\n",
    "    data_temp_test = pd.read_csv(\n",
    "        raw_data_path + f'r3_{target}_test_users.csv', \n",
    "        sep = ';', \n",
    "        encoding='utf-8-sig'\n",
    "        )\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    data_temp_train['target'] = target\n",
    "    data_temp_test['target'] = target\n",
    "    \n",
    "    data_temp_train['split'] = \"train\"\n",
    "    data_temp_test['split'] = \"test\"\n",
    "    \n",
    "    data_list.append(data_temp_train)\n",
    "    data_list.append(data_temp_test)\n",
    "    \n",
    "data_users = pd.concat(data_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "split\n",
       "train    0.749822\n",
       "test     0.250178\n",
       "Name: count, dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_users.split.value_counts()/len(data_users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "split\n",
       "train    0.749822\n",
       "test     0.250178\n",
       "Name: count, dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "data_tmt.split.value_counts()/len(data_tmt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def separate_comments(\n",
    "    data,\n",
    "    Texts_col = 'Texts',\n",
    "    sep = ' # '\n",
    "):\n",
    "    \n",
    "    # Separates texts into individual lines\n",
    "    df_sep_comments = data.assign(Texts=data[Texts_col].str.split(sep)).explode(Texts_col)\n",
    "    \n",
    "    df_sep_comments.rename({\"Texts\":Texts_col},axis = 1)\n",
    "\n",
    "    # Reindex the resulting DataFrame\n",
    "    df_sep_comments.reset_index(drop=True, inplace = True)\n",
    "\n",
    "    df_sep_comments.ffill(inplace = True)\n",
    "    \n",
    "    return df_sep_comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_cp = {\n",
    "    'cl':'Hydrox.',\n",
    "    'lu':'Lula',\n",
    "    'co':'Sinovac',\n",
    "    'ig':'Church',\n",
    "    'gl':'Globo TV',\n",
    "    'bo':'Bolsonaro',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User_ID</th>\n",
       "      <th>Timeline</th>\n",
       "      <th>Stance</th>\n",
       "      <th>Polarity</th>\n",
       "      <th>Tweet_Seq</th>\n",
       "      <th>target</th>\n",
       "      <th>split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>r2_ig_1</td>\n",
       "      <td>@ posso nem comer meu pãozin de queijo em paz ...</td>\n",
       "      <td>tenho pra mim que grande parte senão todas as ...</td>\n",
       "      <td>against</td>\n",
       "      <td>2953</td>\n",
       "      <td>ig</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>r2_ig_4</td>\n",
       "      <td>Fim de jogo ++ uma vitoria do meu Vascão # Hoj...</td>\n",
       "      <td>Cidade de Deus Alicate: quer saber vou entrar ...</td>\n",
       "      <td>for</td>\n",
       "      <td>4792</td>\n",
       "      <td>ig</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>r2_ig_7</td>\n",
       "      <td>Meu chefe é todo aleatório, do nada chega com ...</td>\n",
       "      <td>Acordei já sendo removida do grupo da igreja</td>\n",
       "      <td>against</td>\n",
       "      <td>248</td>\n",
       "      <td>ig</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>r2_ig_8</td>\n",
       "      <td>veja a receita FILÉ COM MOLHO DE MOSTARDA # Di...</td>\n",
       "      <td>I liked a @ video culto infantil na igreja Ass...</td>\n",
       "      <td>for</td>\n",
       "      <td>45</td>\n",
       "      <td>ig</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>r2_ig_10</td>\n",
       "      <td>Oq tem de gente boa, tem de irritante # Não te...</td>\n",
       "      <td>Essa turma da igreja sao tão amorzinho smp con...</td>\n",
       "      <td>for</td>\n",
       "      <td>3809</td>\n",
       "      <td>ig</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>267</th>\n",
       "      <td>r2_lu_1086</td>\n",
       "      <td>Gostei de um vídeo @ … com Sweet Carol | The N...</td>\n",
       "      <td>Eu deveria me espelhar no Lula e ler 55 página...</td>\n",
       "      <td>for</td>\n",
       "      <td>381</td>\n",
       "      <td>lu</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>268</th>\n",
       "      <td>r2_lu_1090</td>\n",
       "      <td>Show de bola! Que venham outros … # Essa renda...</td>\n",
       "      <td>Pqp quanta merda em um Tweet só! Pare de mistu...</td>\n",
       "      <td>against</td>\n",
       "      <td>899</td>\n",
       "      <td>lu</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>269</th>\n",
       "      <td>r2_lu_1091</td>\n",
       "      <td>FOOOOOOOOOOOOOOGOOOOOOOOOOOOOOO!!!!!!! # \"200 ...</td>\n",
       "      <td>nem a Venezuela respeita mais o Brasil sem o L...</td>\n",
       "      <td>for</td>\n",
       "      <td>294</td>\n",
       "      <td>lu</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270</th>\n",
       "      <td>r2_lu_1093</td>\n",
       "      <td>@ quem prejudica a imagem do Brasil não é o po...</td>\n",
       "      <td>Lula tem uma visão de mundo muito diversa de F...</td>\n",
       "      <td>for</td>\n",
       "      <td>2021</td>\n",
       "      <td>lu</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271</th>\n",
       "      <td>r2_lu_1094</td>\n",
       "      <td>O Globo: Osama bin Ladem está morto, diz CNN #...</td>\n",
       "      <td>gente, o Lula não pode ir de avião não, olha o...</td>\n",
       "      <td>for</td>\n",
       "      <td>2551</td>\n",
       "      <td>lu</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11264 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        User_ID                                           Timeline  \\\n",
       "0       r2_ig_1  @ posso nem comer meu pãozin de queijo em paz ...   \n",
       "1       r2_ig_4  Fim de jogo ++ uma vitoria do meu Vascão # Hoj...   \n",
       "2       r2_ig_7  Meu chefe é todo aleatório, do nada chega com ...   \n",
       "3       r2_ig_8  veja a receita FILÉ COM MOLHO DE MOSTARDA # Di...   \n",
       "4      r2_ig_10  Oq tem de gente boa, tem de irritante # Não te...   \n",
       "..          ...                                                ...   \n",
       "267  r2_lu_1086  Gostei de um vídeo @ … com Sweet Carol | The N...   \n",
       "268  r2_lu_1090  Show de bola! Que venham outros … # Essa renda...   \n",
       "269  r2_lu_1091  FOOOOOOOOOOOOOOGOOOOOOOOOOOOOOO!!!!!!! # \"200 ...   \n",
       "270  r2_lu_1093  @ quem prejudica a imagem do Brasil não é o po...   \n",
       "271  r2_lu_1094  O Globo: Osama bin Ladem está morto, diz CNN #...   \n",
       "\n",
       "                                                Stance Polarity  Tweet_Seq  \\\n",
       "0    tenho pra mim que grande parte senão todas as ...  against       2953   \n",
       "1    Cidade de Deus Alicate: quer saber vou entrar ...      for       4792   \n",
       "2         Acordei já sendo removida do grupo da igreja  against        248   \n",
       "3    I liked a @ video culto infantil na igreja Ass...      for         45   \n",
       "4    Essa turma da igreja sao tão amorzinho smp con...      for       3809   \n",
       "..                                                 ...      ...        ...   \n",
       "267  Eu deveria me espelhar no Lula e ler 55 página...      for        381   \n",
       "268  Pqp quanta merda em um Tweet só! Pare de mistu...  against        899   \n",
       "269  nem a Venezuela respeita mais o Brasil sem o L...      for        294   \n",
       "270  Lula tem uma visão de mundo muito diversa de F...      for       2021   \n",
       "271  gente, o Lula não pode ir de avião não, olha o...      for       2551   \n",
       "\n",
       "    target  split  \n",
       "0       ig  train  \n",
       "1       ig  train  \n",
       "2       ig  train  \n",
       "3       ig  train  \n",
       "4       ig  train  \n",
       "..     ...    ...  \n",
       "267     lu   test  \n",
       "268     lu   test  \n",
       "269     lu   test  \n",
       "270     lu   test  \n",
       "271     lu   test  \n",
       "\n",
       "[11264 rows x 7 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##### Start Running ig (1 of 6) #####\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "dict_config = {\n",
    "    'top_mentioned_timelines':{\n",
    "        'data': data_tmt,\n",
    "        'columns': {\n",
    "            'Texts': 1\n",
    "        }\n",
    "    },\n",
    "    'users':{\n",
    "        'data': data_users,\n",
    "        'columns':{\n",
    "            'Timeline': 1,\n",
    "            'Stance': 0\n",
    "        }\n",
    "    }\n",
    "    \n",
    "}\n",
    "\n",
    "\n",
    "dict_results = {}\n",
    "\n",
    "for name, config in dict_config.items():\n",
    "    \n",
    "    \n",
    "    data = config[\"data\"]\n",
    "    \n",
    "    for column, multiple_comments in config[\"columns\"].items():\n",
    "        \n",
    "        \n",
    "        df_anl = pd.DataFrame({\n",
    "            \"Target\": [],\n",
    "            \"Against\": [],\n",
    "            \"For\": [],\n",
    "            \"All\": [],\n",
    "            \"Words\": [],\n",
    "            \"Comments/User\": [],\n",
    "            \"W/Tweet\": []\n",
    "        })\n",
    "        \n",
    "        for i, target in enumerate(target_list):\n",
    "            \n",
    "            print(f'##### Start Running {target} ({i+1} of {len(target_list)}) #####')\n",
    "            \n",
    "            df_target = data[data.target == target]\n",
    "            \n",
    "            counts_target = df_target.Polarity.value_counts()\n",
    "            \n",
    "            n_against = counts_target['against']\n",
    "            n_for = counts_target['for']\n",
    "            \n",
    "            if multiple_comments:\n",
    "                # separate comments and drop the duplicates (the comments that appears in more the one user)\n",
    "                df_sep_comments = separate_comments(df_target, Texts_col = column).drop_duplicates(subset=[column])\n",
    "            \n",
    "                # create column with tokens\n",
    "                df_sep_comments['tokens'] = df_sep_comments[column].progress_apply(lambda x: word_tokenize(x, language='portuguese'))\n",
    "                # create column with count of tokens\n",
    "                df_sep_comments['tokens_count'] = df_sep_comments.tokens.progress_apply(len)\n",
    "                \n",
    "                gpby_userid = df_sep_comments.groupby('User_ID')\n",
    "                count_users = len(df_sep_comments.User_ID.unique())\n",
    "            \n",
    "                new_row = {\n",
    "                    \"Target\": target,\n",
    "                    \"Against\": n_against,\n",
    "                    \"For\": n_for,\n",
    "                    \"All\": n_against + n_for,\n",
    "                    \"Words\": df_sep_comments.tokens_count.sum(),\n",
    "                    \"Comments/User\": gpby_userid.size().sum() / count_users,\n",
    "                    \"W/Tweet\": df_sep_comments.tokens_count.sum()/len(df_sep_comments)\n",
    "                }\n",
    "                \n",
    "                df_anl.loc[len(df_anl)] = new_row\n",
    "                \n",
    "            else:\n",
    "                \n",
    "                # create column with tokens\n",
    "                df_target['tokens'] = df_target[column].progress_apply(lambda x: word_tokenize(x, language='portuguese'))\n",
    "                # create column with count of tokens\n",
    "                df_target['tokens_count'] = df_target.tokens.progress_apply(len)\n",
    "                \n",
    "                gpby_userid = df_target.groupby('User_ID')\n",
    "                count_users = len(df_target.User_ID.unique())\n",
    "            \n",
    "                new_row = {\n",
    "                    \"Target\": target,\n",
    "                    \"Against\": n_against,\n",
    "                    \"For\": n_for,\n",
    "                    \"All\": n_against + n_for,\n",
    "                    \"Words\": df_target.tokens_count.sum(),\n",
    "                    \"Comments/User\": \"nsa\",\n",
    "                    \"W/Tweet\": df_target.tokens_count.sum()/len(df_target)\n",
    "                }\n",
    "                \n",
    "                df_anl.loc[len(df_anl)] = new_row\n",
    "                \n",
    "            \n",
    "            print(f'##### End Running {target} ({i+1} of {len(target_list)}) #####')\n",
    "            \n",
    "        df_anl.Target = df_anl.Target.map(dict_cp)\n",
    "\n",
    "        \n",
    "        counts_target = data.Polarity.value_counts()\n",
    "\n",
    "        n_against = counts_target['against']\n",
    "        n_for = counts_target['for']\n",
    "\n",
    "\n",
    "        if multiple_comments:\n",
    "            comment_user = df_anl[\"Comments/User\"].sum()/len(df_anl)\n",
    "        else:\n",
    "            comment_user = \"nsa\"\n",
    "            \n",
    "\n",
    "        new_row = {\n",
    "            \"Target\": \"Overall\",\n",
    "            \"Against\": n_against,\n",
    "            \"For\": n_for,\n",
    "            \"All\": n_against + n_for,\n",
    "            \"Words\": df_anl.Words.sum(),\n",
    "            \"Comments/User\": comment_user,\n",
    "            \"W/Tweet\": df_anl[\"W/Tweet\"].sum()/len(df_anl)\n",
    "        }\n",
    "\n",
    "        df_anl.loc[len(df_anl)] = new_row\n",
    "        df_anl = df_anl.round(2)\n",
    "        \n",
    "        \n",
    "        dict_results.update({f\"{name}_{column}\":df_anl})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top_mentioned_timelines_Texts\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Target</th>\n",
       "      <th>Against</th>\n",
       "      <th>For</th>\n",
       "      <th>All</th>\n",
       "      <th>Words</th>\n",
       "      <th>Comments/User</th>\n",
       "      <th>W/Tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Church</td>\n",
       "      <td>1354</td>\n",
       "      <td>1041</td>\n",
       "      <td>2395</td>\n",
       "      <td>56364209</td>\n",
       "      <td>1874.95</td>\n",
       "      <td>14.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bolsonaro</td>\n",
       "      <td>649</td>\n",
       "      <td>102</td>\n",
       "      <td>751</td>\n",
       "      <td>14608017</td>\n",
       "      <td>1908.32</td>\n",
       "      <td>14.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hydrox.</td>\n",
       "      <td>1154</td>\n",
       "      <td>1141</td>\n",
       "      <td>2295</td>\n",
       "      <td>51770007</td>\n",
       "      <td>2172.46</td>\n",
       "      <td>22.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sinovac</td>\n",
       "      <td>1416</td>\n",
       "      <td>1677</td>\n",
       "      <td>3093</td>\n",
       "      <td>69421120</td>\n",
       "      <td>2147.33</td>\n",
       "      <td>20.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Globo TV</td>\n",
       "      <td>668</td>\n",
       "      <td>974</td>\n",
       "      <td>1642</td>\n",
       "      <td>35004176</td>\n",
       "      <td>1932.34</td>\n",
       "      <td>15.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Lula</td>\n",
       "      <td>570</td>\n",
       "      <td>518</td>\n",
       "      <td>1088</td>\n",
       "      <td>25731928</td>\n",
       "      <td>2030.16</td>\n",
       "      <td>18.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Overall</td>\n",
       "      <td>5811</td>\n",
       "      <td>5453</td>\n",
       "      <td>11264</td>\n",
       "      <td>252899457</td>\n",
       "      <td>2010.93</td>\n",
       "      <td>17.61</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Target  Against   For    All      Words  Comments/User  W/Tweet\n",
       "0     Church     1354  1041   2395   56364209        1874.95    14.98\n",
       "1  Bolsonaro      649   102    751   14608017        1908.32    14.58\n",
       "2    Hydrox.     1154  1141   2295   51770007        2172.46    22.17\n",
       "3    Sinovac     1416  1677   3093   69421120        2147.33    20.58\n",
       "4   Globo TV      668   974   1642   35004176        1932.34    15.15\n",
       "5       Lula      570   518   1088   25731928        2030.16    18.24\n",
       "6    Overall     5811  5453  11264  252899457        2010.93    17.61"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "users_Timeline\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Target</th>\n",
       "      <th>Against</th>\n",
       "      <th>For</th>\n",
       "      <th>All</th>\n",
       "      <th>Words</th>\n",
       "      <th>Comments/User</th>\n",
       "      <th>W/Tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Church</td>\n",
       "      <td>1354</td>\n",
       "      <td>1041</td>\n",
       "      <td>2395</td>\n",
       "      <td>140207645</td>\n",
       "      <td>1.0</td>\n",
       "      <td>58541.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bolsonaro</td>\n",
       "      <td>649</td>\n",
       "      <td>102</td>\n",
       "      <td>751</td>\n",
       "      <td>41224425</td>\n",
       "      <td>1.0</td>\n",
       "      <td>54892.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hydrox.</td>\n",
       "      <td>1154</td>\n",
       "      <td>1141</td>\n",
       "      <td>2295</td>\n",
       "      <td>108484625</td>\n",
       "      <td>1.0</td>\n",
       "      <td>47269.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sinovac</td>\n",
       "      <td>1416</td>\n",
       "      <td>1677</td>\n",
       "      <td>3093</td>\n",
       "      <td>137333979</td>\n",
       "      <td>1.0</td>\n",
       "      <td>44401.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Globo TV</td>\n",
       "      <td>668</td>\n",
       "      <td>974</td>\n",
       "      <td>1642</td>\n",
       "      <td>93326479</td>\n",
       "      <td>1.0</td>\n",
       "      <td>56837.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Lula</td>\n",
       "      <td>570</td>\n",
       "      <td>518</td>\n",
       "      <td>1088</td>\n",
       "      <td>67569624</td>\n",
       "      <td>1.0</td>\n",
       "      <td>62104.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Overall</td>\n",
       "      <td>5811</td>\n",
       "      <td>5453</td>\n",
       "      <td>11264</td>\n",
       "      <td>588146777</td>\n",
       "      <td>1.0</td>\n",
       "      <td>54007.93</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Target  Against   For    All      Words  Comments/User   W/Tweet\n",
       "0     Church     1354  1041   2395  140207645            1.0  58541.81\n",
       "1  Bolsonaro      649   102    751   41224425            1.0  54892.71\n",
       "2    Hydrox.     1154  1141   2295  108484625            1.0  47269.99\n",
       "3    Sinovac     1416  1677   3093  137333979            1.0  44401.55\n",
       "4   Globo TV      668   974   1642   93326479            1.0  56837.08\n",
       "5       Lula      570   518   1088   67569624            1.0  62104.43\n",
       "6    Overall     5811  5453  11264  588146777            1.0  54007.93"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "users_Stance\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Target</th>\n",
       "      <th>Against</th>\n",
       "      <th>For</th>\n",
       "      <th>All</th>\n",
       "      <th>Words</th>\n",
       "      <th>Comments/User</th>\n",
       "      <th>W/Tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Church</td>\n",
       "      <td>1354</td>\n",
       "      <td>1041</td>\n",
       "      <td>2395</td>\n",
       "      <td>67569624</td>\n",
       "      <td>nsa</td>\n",
       "      <td>62104.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bolsonaro</td>\n",
       "      <td>649</td>\n",
       "      <td>102</td>\n",
       "      <td>751</td>\n",
       "      <td>67569624</td>\n",
       "      <td>nsa</td>\n",
       "      <td>62104.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hydrox.</td>\n",
       "      <td>1154</td>\n",
       "      <td>1141</td>\n",
       "      <td>2295</td>\n",
       "      <td>67569624</td>\n",
       "      <td>nsa</td>\n",
       "      <td>62104.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sinovac</td>\n",
       "      <td>1416</td>\n",
       "      <td>1677</td>\n",
       "      <td>3093</td>\n",
       "      <td>67569624</td>\n",
       "      <td>nsa</td>\n",
       "      <td>62104.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Globo TV</td>\n",
       "      <td>668</td>\n",
       "      <td>974</td>\n",
       "      <td>1642</td>\n",
       "      <td>67569624</td>\n",
       "      <td>nsa</td>\n",
       "      <td>62104.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Lula</td>\n",
       "      <td>570</td>\n",
       "      <td>518</td>\n",
       "      <td>1088</td>\n",
       "      <td>67569624</td>\n",
       "      <td>nsa</td>\n",
       "      <td>62104.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Overall</td>\n",
       "      <td>5811</td>\n",
       "      <td>5453</td>\n",
       "      <td>11264</td>\n",
       "      <td>405417744</td>\n",
       "      <td>nsa</td>\n",
       "      <td>62104.43</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Target  Against   For    All      Words Comments/User   W/Tweet\n",
       "0     Church     1354  1041   2395   67569624           nsa  62104.43\n",
       "1  Bolsonaro      649   102    751   67569624           nsa  62104.43\n",
       "2    Hydrox.     1154  1141   2295   67569624           nsa  62104.43\n",
       "3    Sinovac     1416  1677   3093   67569624           nsa  62104.43\n",
       "4   Globo TV      668   974   1642   67569624           nsa  62104.43\n",
       "5       Lula      570   518   1088   67569624           nsa  62104.43\n",
       "6    Overall     5811  5453  11264  405417744           nsa  62104.43"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for key, value in dict_results.items():\n",
    "    \n",
    "    print(key)\n",
    "    \n",
    "    display(value)\n",
    "    \n",
    "    value.to_csv(reports_path + f'describe/{key}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env-stance-pred",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
