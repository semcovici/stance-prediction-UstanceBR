{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import seaborn as sns\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/semcovici/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'neuralmind/bert-base-portuguese-cased'\n",
    "\n",
    "random_seed = 42\n",
    "\n",
    "raw_data_path = '../data/raw/'\n",
    "processed_data_path = '../data/processed/'\n",
    "results_cr_path = '../reports/classification_reports/'\n",
    "test_results_path = '../reports/test_results/'\n",
    "reports_path = '../reports/'\n",
    "\n",
    "target_list = ['ig','bo', 'cl', 'co', 'gl', 'lu']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:20<00:00,  3.37s/it]\n"
     ]
    }
   ],
   "source": [
    "data_list = []\n",
    "\n",
    "for target in tqdm(target_list):\n",
    "    \n",
    "    # read data\n",
    "    data_temp_train = pd.read_csv(\n",
    "        raw_data_path + f'train_r3_{target}_top_mentioned_timelines.csv', \n",
    "        sep = ';', \n",
    "        encoding='utf-8-sig'\n",
    "        )\n",
    "    data_temp_test = pd.read_csv(\n",
    "        raw_data_path + f'test_r3_{target}_top_mentioned_timelines.csv', \n",
    "        sep = ';', \n",
    "        encoding='utf-8-sig'\n",
    "        )\n",
    "    \n",
    "    data_temp_train['target'] = target\n",
    "    data_temp_test['target'] = target\n",
    "    \n",
    "    data_temp_train['split'] = \"train\"\n",
    "    data_temp_test['split'] = \"test\"\n",
    "    \n",
    "    data_list.append(data_temp_train)\n",
    "    data_list.append(data_temp_test)\n",
    "    \n",
    "data_tmt = pd.concat(data_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:29<00:00,  4.90s/it]\n"
     ]
    }
   ],
   "source": [
    "data_list = []\n",
    "\n",
    "for target in tqdm(target_list):\n",
    "    \n",
    "    # read data\n",
    "    data_temp_train = pd.read_csv(\n",
    "        raw_data_path + f'r3_{target}_train_users.csv', \n",
    "        sep = ';', \n",
    "        encoding='utf-8-sig'\n",
    "    )\n",
    "    data_temp_test = pd.read_csv(\n",
    "        raw_data_path + f'r3_{target}_test_users.csv', \n",
    "        sep = ';', \n",
    "        encoding='utf-8-sig'\n",
    "        )\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    data_temp_train['target'] = target\n",
    "    data_temp_test['target'] = target\n",
    "    \n",
    "    data_temp_train['split'] = \"train\"\n",
    "    data_temp_test['split'] = \"test\"\n",
    "    \n",
    "    data_list.append(data_temp_train)\n",
    "    data_list.append(data_temp_test)\n",
    "    \n",
    "data_users = pd.concat(data_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "split\n",
       "train    0.749822\n",
       "test     0.250178\n",
       "Name: count, dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_users.split.value_counts()/len(data_users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "split\n",
       "train    0.749822\n",
       "test     0.250178\n",
       "Name: count, dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "data_tmt.split.value_counts()/len(data_tmt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def separate_comments(\n",
    "    data,\n",
    "    Texts_col = 'Texts',\n",
    "    sep = ' # '\n",
    "):\n",
    "    \n",
    "    # Separates texts into individual lines\n",
    "    df_sep_comments = data.assign(Texts=data[Texts_col].str.split(sep)).explode(Texts_col)\n",
    "    \n",
    "    df_sep_comments.rename({\"Texts\":Texts_col},axis = 1)\n",
    "\n",
    "    # Reindex the resulting DataFrame\n",
    "    df_sep_comments.reset_index(drop=True, inplace = True)\n",
    "\n",
    "    df_sep_comments.ffill(inplace = True)\n",
    "    \n",
    "    return df_sep_comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_cp = {\n",
    "    'cl':'Hydrox.',\n",
    "    'lu':'Lula',\n",
    "    'co':'Sinovac',\n",
    "    'ig':'Church',\n",
    "    'gl':'Globo TV',\n",
    "    'bo':'Bolsonaro',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User_ID</th>\n",
       "      <th>Timeline</th>\n",
       "      <th>Stance</th>\n",
       "      <th>Polarity</th>\n",
       "      <th>Tweet_Seq</th>\n",
       "      <th>target</th>\n",
       "      <th>split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>r2_ig_1</td>\n",
       "      <td>@ posso nem comer meu pãozin de queijo em paz ...</td>\n",
       "      <td>tenho pra mim que grande parte senão todas as ...</td>\n",
       "      <td>against</td>\n",
       "      <td>2953</td>\n",
       "      <td>ig</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>r2_ig_4</td>\n",
       "      <td>Fim de jogo ++ uma vitoria do meu Vascão # Hoj...</td>\n",
       "      <td>Cidade de Deus Alicate: quer saber vou entrar ...</td>\n",
       "      <td>for</td>\n",
       "      <td>4792</td>\n",
       "      <td>ig</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>r2_ig_7</td>\n",
       "      <td>Meu chefe é todo aleatório, do nada chega com ...</td>\n",
       "      <td>Acordei já sendo removida do grupo da igreja</td>\n",
       "      <td>against</td>\n",
       "      <td>248</td>\n",
       "      <td>ig</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>r2_ig_8</td>\n",
       "      <td>veja a receita FILÉ COM MOLHO DE MOSTARDA # Di...</td>\n",
       "      <td>I liked a @ video culto infantil na igreja Ass...</td>\n",
       "      <td>for</td>\n",
       "      <td>45</td>\n",
       "      <td>ig</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>r2_ig_10</td>\n",
       "      <td>Oq tem de gente boa, tem de irritante # Não te...</td>\n",
       "      <td>Essa turma da igreja sao tão amorzinho smp con...</td>\n",
       "      <td>for</td>\n",
       "      <td>3809</td>\n",
       "      <td>ig</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>267</th>\n",
       "      <td>r2_lu_1086</td>\n",
       "      <td>Gostei de um vídeo @ … com Sweet Carol | The N...</td>\n",
       "      <td>Eu deveria me espelhar no Lula e ler 55 página...</td>\n",
       "      <td>for</td>\n",
       "      <td>381</td>\n",
       "      <td>lu</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>268</th>\n",
       "      <td>r2_lu_1090</td>\n",
       "      <td>Show de bola! Que venham outros … # Essa renda...</td>\n",
       "      <td>Pqp quanta merda em um Tweet só! Pare de mistu...</td>\n",
       "      <td>against</td>\n",
       "      <td>899</td>\n",
       "      <td>lu</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>269</th>\n",
       "      <td>r2_lu_1091</td>\n",
       "      <td>FOOOOOOOOOOOOOOGOOOOOOOOOOOOOOO!!!!!!! # \"200 ...</td>\n",
       "      <td>nem a Venezuela respeita mais o Brasil sem o L...</td>\n",
       "      <td>for</td>\n",
       "      <td>294</td>\n",
       "      <td>lu</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270</th>\n",
       "      <td>r2_lu_1093</td>\n",
       "      <td>@ quem prejudica a imagem do Brasil não é o po...</td>\n",
       "      <td>Lula tem uma visão de mundo muito diversa de F...</td>\n",
       "      <td>for</td>\n",
       "      <td>2021</td>\n",
       "      <td>lu</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271</th>\n",
       "      <td>r2_lu_1094</td>\n",
       "      <td>O Globo: Osama bin Ladem está morto, diz CNN #...</td>\n",
       "      <td>gente, o Lula não pode ir de avião não, olha o...</td>\n",
       "      <td>for</td>\n",
       "      <td>2551</td>\n",
       "      <td>lu</td>\n",
       "      <td>test</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11264 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        User_ID                                           Timeline  \\\n",
       "0       r2_ig_1  @ posso nem comer meu pãozin de queijo em paz ...   \n",
       "1       r2_ig_4  Fim de jogo ++ uma vitoria do meu Vascão # Hoj...   \n",
       "2       r2_ig_7  Meu chefe é todo aleatório, do nada chega com ...   \n",
       "3       r2_ig_8  veja a receita FILÉ COM MOLHO DE MOSTARDA # Di...   \n",
       "4      r2_ig_10  Oq tem de gente boa, tem de irritante # Não te...   \n",
       "..          ...                                                ...   \n",
       "267  r2_lu_1086  Gostei de um vídeo @ … com Sweet Carol | The N...   \n",
       "268  r2_lu_1090  Show de bola! Que venham outros … # Essa renda...   \n",
       "269  r2_lu_1091  FOOOOOOOOOOOOOOGOOOOOOOOOOOOOOO!!!!!!! # \"200 ...   \n",
       "270  r2_lu_1093  @ quem prejudica a imagem do Brasil não é o po...   \n",
       "271  r2_lu_1094  O Globo: Osama bin Ladem está morto, diz CNN #...   \n",
       "\n",
       "                                                Stance Polarity  Tweet_Seq  \\\n",
       "0    tenho pra mim que grande parte senão todas as ...  against       2953   \n",
       "1    Cidade de Deus Alicate: quer saber vou entrar ...      for       4792   \n",
       "2         Acordei já sendo removida do grupo da igreja  against        248   \n",
       "3    I liked a @ video culto infantil na igreja Ass...      for         45   \n",
       "4    Essa turma da igreja sao tão amorzinho smp con...      for       3809   \n",
       "..                                                 ...      ...        ...   \n",
       "267  Eu deveria me espelhar no Lula e ler 55 página...      for        381   \n",
       "268  Pqp quanta merda em um Tweet só! Pare de mistu...  against        899   \n",
       "269  nem a Venezuela respeita mais o Brasil sem o L...      for        294   \n",
       "270  Lula tem uma visão de mundo muito diversa de F...      for       2021   \n",
       "271  gente, o Lula não pode ir de avião não, olha o...      for       2551   \n",
       "\n",
       "    target  split  \n",
       "0       ig  train  \n",
       "1       ig  train  \n",
       "2       ig  train  \n",
       "3       ig  train  \n",
       "4       ig  train  \n",
       "..     ...    ...  \n",
       "267     lu   test  \n",
       "268     lu   test  \n",
       "269     lu   test  \n",
       "270     lu   test  \n",
       "271     lu   test  \n",
       "\n",
       "[11264 rows x 7 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##### Start Running ig (1 of 6) #####\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3763019/3763019 [04:01<00:00, 15576.52it/s]\n",
      "100%|██████████| 3763019/3763019 [00:02<00:00, 1525155.80it/s]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (7,) + inhomogeneous part.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 72\u001b[0m\n\u001b[1;32m     60\u001b[0m     count_users \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(df_sep_comments\u001b[38;5;241m.\u001b[39mUser_ID\u001b[38;5;241m.\u001b[39munique())\n\u001b[1;32m     62\u001b[0m     new_row \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m     63\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTarget\u001b[39m\u001b[38;5;124m\"\u001b[39m: target,\n\u001b[1;32m     64\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAgainst\u001b[39m\u001b[38;5;124m\"\u001b[39m: n_against,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     69\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mW/Tweet\u001b[39m\u001b[38;5;124m\"\u001b[39m: df_sep_comments\u001b[38;5;241m.\u001b[39mtokens_count\u001b[38;5;241m.\u001b[39msum()\u001b[38;5;241m/\u001b[39m\u001b[38;5;28mlen\u001b[39m(df_sep_comments)\n\u001b[1;32m     70\u001b[0m     }\n\u001b[0;32m---> 72\u001b[0m     \u001b[43mdf_anl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloc\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdf_anl\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m new_row\n\u001b[1;32m     74\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     75\u001b[0m     \n\u001b[1;32m     76\u001b[0m     \u001b[38;5;66;03m# create column with tokens\u001b[39;00m\n\u001b[1;32m     77\u001b[0m     df_target[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtokens\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df_target[column]\u001b[38;5;241m.\u001b[39mprogress_apply(\u001b[38;5;28;01mlambda\u001b[39;00m x: word_tokenize(x, language\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mportuguese\u001b[39m\u001b[38;5;124m'\u001b[39m))\n",
      "File \u001b[0;32m~/anaconda3/envs/env-stance-pred/lib/python3.12/site-packages/pandas/core/indexing.py:911\u001b[0m, in \u001b[0;36m_LocationIndexer.__setitem__\u001b[0;34m(self, key, value)\u001b[0m\n\u001b[1;32m    908\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_has_valid_setitem_indexer(key)\n\u001b[1;32m    910\u001b[0m iloc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miloc\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39miloc\n\u001b[0;32m--> 911\u001b[0m \u001b[43miloc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_setitem_with_indexer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/env-stance-pred/lib/python3.12/site-packages/pandas/core/indexing.py:1812\u001b[0m, in \u001b[0;36m_iLocIndexer._setitem_with_indexer\u001b[0;34m(self, indexer, value, name)\u001b[0m\n\u001b[1;32m   1810\u001b[0m     val \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(value\u001b[38;5;241m.\u001b[39mvalues()) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value, \u001b[38;5;28mdict\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m value\n\u001b[1;32m   1811\u001b[0m     arr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39m_mgr\u001b[38;5;241m.\u001b[39marrays[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m-> 1812\u001b[0m     take_split_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[43mcan_hold_element\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1813\u001b[0m \u001b[43m        \u001b[49m\u001b[43marr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextract_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mval\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextract_numpy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m   1814\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1816\u001b[0m \u001b[38;5;66;03m# if we have any multi-indexes that have non-trivial slices\u001b[39;00m\n\u001b[1;32m   1817\u001b[0m \u001b[38;5;66;03m# (not null slices) then we must take the split path, xref\u001b[39;00m\n\u001b[1;32m   1818\u001b[0m \u001b[38;5;66;03m# GH 10360, GH 27841\u001b[39;00m\n\u001b[1;32m   1819\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(indexer, \u001b[38;5;28mtuple\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(indexer) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39maxes):\n",
      "File \u001b[0;32m~/anaconda3/envs/env-stance-pred/lib/python3.12/site-packages/pandas/core/dtypes/cast.py:1754\u001b[0m, in \u001b[0;36mcan_hold_element\u001b[0;34m(arr, element)\u001b[0m\n\u001b[1;32m   1751\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m   1753\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1754\u001b[0m     \u001b[43mnp_can_hold_element\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43melement\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1755\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m   1756\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m (\u001b[38;5;167;01mTypeError\u001b[39;00m, LossySetitemError):\n",
      "File \u001b[0;32m~/anaconda3/envs/env-stance-pred/lib/python3.12/site-packages/pandas/core/dtypes/cast.py:1780\u001b[0m, in \u001b[0;36mnp_can_hold_element\u001b[0;34m(dtype, element)\u001b[0m\n\u001b[1;32m   1777\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dtype \u001b[38;5;241m==\u001b[39m _dtype_obj:\n\u001b[1;32m   1778\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m element\n\u001b[0;32m-> 1780\u001b[0m tipo \u001b[38;5;241m=\u001b[39m \u001b[43m_maybe_infer_dtype_type\u001b[49m\u001b[43m(\u001b[49m\u001b[43melement\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1782\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dtype\u001b[38;5;241m.\u001b[39mkind \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124miu\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m   1783\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(element, \u001b[38;5;28mrange\u001b[39m):\n",
      "File \u001b[0;32m~/anaconda3/envs/env-stance-pred/lib/python3.12/site-packages/pandas/core/dtypes/cast.py:951\u001b[0m, in \u001b[0;36m_maybe_infer_dtype_type\u001b[0;34m(element)\u001b[0m\n\u001b[1;32m    949\u001b[0m     tipo \u001b[38;5;241m=\u001b[39m element\u001b[38;5;241m.\u001b[39mdtype\n\u001b[1;32m    950\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m is_list_like(element):\n\u001b[0;32m--> 951\u001b[0m     element \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43masarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43melement\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    952\u001b[0m     tipo \u001b[38;5;241m=\u001b[39m element\u001b[38;5;241m.\u001b[39mdtype\n\u001b[1;32m    953\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m tipo\n",
      "\u001b[0;31mValueError\u001b[0m: setting an array element with a sequence. The requested array has an inhomogeneous shape after 1 dimensions. The detected shape was (7,) + inhomogeneous part."
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "dict_config = {\n",
    "    'top_mentioned_timelines':{\n",
    "        'data': data_tmt,\n",
    "        'columns': {\n",
    "            'Texts': 1\n",
    "        }\n",
    "    },\n",
    "    'users':{\n",
    "        'data': data_users,\n",
    "        'columns':{\n",
    "            'Timeline': 1,\n",
    "            'Stance': 0\n",
    "        }\n",
    "    }\n",
    "    \n",
    "}\n",
    "\n",
    "\n",
    "dict_results = {}\n",
    "\n",
    "for name, config in dict_config.items():\n",
    "    \n",
    "    \n",
    "    data = config[\"data\"]\n",
    "    \n",
    "    for column, multiple_comments in config[\"columns\"].items():\n",
    "        \n",
    "        \n",
    "        df_anl = pd.DataFrame({\n",
    "            \"Target\": [],\n",
    "            \"Against\": [],\n",
    "            \"For\": [],\n",
    "            \"All\": [],\n",
    "            \"Words\": [],\n",
    "            \"Comments/User\": [],\n",
    "            \"W/Tweet\": []\n",
    "        })\n",
    "        \n",
    "        for i, target in enumerate(target_list):\n",
    "            \n",
    "            print(f'##### Start Running {target} ({i+1} of {len(target_list)}) #####')\n",
    "            \n",
    "            df_target = data[data.target == target]\n",
    "            \n",
    "            counts_target = df_target.Polarity.value_counts()\n",
    "            \n",
    "            n_against = counts_target['against']\n",
    "            n_for = counts_target['for']\n",
    "            \n",
    "            if multiple_comments:\n",
    "                # separate comments and drop the duplicates (the comments that appears in more the one user)\n",
    "                df_sep_comments = separate_comments(df_target, Texts_col = column).drop_duplicates(subset=[column])\n",
    "            \n",
    "                # create column with tokens\n",
    "                df_sep_comments['tokens'] = df_sep_comments[column].progress_apply(lambda x: word_tokenize(x, language='portuguese'))\n",
    "                # create column with count of tokens\n",
    "                df_sep_comments['tokens_count'] = df_sep_comments.tokens.progress_apply(len)\n",
    "                \n",
    "                gpby_userid = df_sep_comments.groupby('User_ID')\n",
    "                count_users = len(df_sep_comments.User_ID.unique())\n",
    "            \n",
    "                new_row = {\n",
    "                    \"Target\": target,\n",
    "                    \"Against\": n_against,\n",
    "                    \"For\": n_for,\n",
    "                    \"All\": n_against + n_for,\n",
    "                    \"Words\": df_sep_comments.tokens_count.sum(),\n",
    "                    \"Comments/User\": gpby_userid.size().sum() / count_users,\n",
    "                    \"W/Tweet\": df_sep_comments.tokens_count.sum()/len(df_sep_comments)\n",
    "                }\n",
    "                \n",
    "                df_anl.loc[len(df_anl)] = new_row\n",
    "                \n",
    "            else:\n",
    "                \n",
    "                # create column with tokens\n",
    "                df_target['tokens'] = df_target[column].progress_apply(lambda x: word_tokenize(x, language='portuguese'))\n",
    "                # create column with count of tokens\n",
    "                df_target['tokens_count'] = df_target.tokens.progress_apply(len)\n",
    "            \n",
    "                new_row = {\n",
    "                    \"Target\": target,\n",
    "                    \"Against\": n_against,\n",
    "                    \"For\": n_for,\n",
    "                    \"All\": n_against + n_for,\n",
    "                    \"Words\": df_sep_comments.tokens_count.sum(),\n",
    "                    \"Comments/User\": \"nsa\",\n",
    "                    \"W/Tweet\": df_sep_comments.tokens_count.sum()/len(df_sep_comments)\n",
    "                }\n",
    "                \n",
    "                df_anl.loc[len(df_anl)] = new_row\n",
    "                \n",
    "            \n",
    "            print(f'##### End Running {target} ({i+1} of {len(target_list)}) #####')\n",
    "            \n",
    "        df_anl.Target = df_anl.Target.map(dict_cp)\n",
    "\n",
    "        \n",
    "        counts_target = data.Polarity.value_counts()\n",
    "\n",
    "        n_against = counts_target['against']\n",
    "        n_for = counts_target['for']\n",
    "\n",
    "\n",
    "        new_row = {\n",
    "            \"Target\": \"Overall\",\n",
    "            \"Against\": n_against,\n",
    "            \"For\": n_for,\n",
    "            \"All\": n_against + n_for,\n",
    "            \"Words\": df_anl.Words.sum(),\n",
    "            \"W/Tweet\": df_anl[\"W/Tweet\"].sum()/len(df_anl)\n",
    "        }\n",
    "\n",
    "        df_anl.loc[len(df_anl)] = new_row\n",
    "        df_anl = df_anl.round(2)\n",
    "        \n",
    "        \n",
    "        dict_results.update({f\"{name}_{column}\":df_anl})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1874.9471848530145"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Polarity</th>\n",
       "      <th>Texts</th>\n",
       "      <th>target</th>\n",
       "      <th>split</th>\n",
       "      <th>tokens</th>\n",
       "      <th>tokens_count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>User_ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>r2_ig_1</th>\n",
       "      <td>0.436971</td>\n",
       "      <td>0.436971</td>\n",
       "      <td>0.436971</td>\n",
       "      <td>0.436971</td>\n",
       "      <td>0.436971</td>\n",
       "      <td>0.436971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>r2_ig_10</th>\n",
       "      <td>0.045341</td>\n",
       "      <td>0.045341</td>\n",
       "      <td>0.045341</td>\n",
       "      <td>0.045341</td>\n",
       "      <td>0.045341</td>\n",
       "      <td>0.045341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>r2_ig_100</th>\n",
       "      <td>2.314898</td>\n",
       "      <td>2.314898</td>\n",
       "      <td>2.314898</td>\n",
       "      <td>2.314898</td>\n",
       "      <td>2.314898</td>\n",
       "      <td>2.314898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>r2_ig_1000</th>\n",
       "      <td>0.904335</td>\n",
       "      <td>0.904335</td>\n",
       "      <td>0.904335</td>\n",
       "      <td>0.904335</td>\n",
       "      <td>0.904335</td>\n",
       "      <td>0.904335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>r2_ig_1002</th>\n",
       "      <td>0.910314</td>\n",
       "      <td>0.910314</td>\n",
       "      <td>0.910314</td>\n",
       "      <td>0.910314</td>\n",
       "      <td>0.910314</td>\n",
       "      <td>0.910314</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>r2_ig_994</th>\n",
       "      <td>0.562531</td>\n",
       "      <td>0.562531</td>\n",
       "      <td>0.562531</td>\n",
       "      <td>0.562531</td>\n",
       "      <td>0.562531</td>\n",
       "      <td>0.562531</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>r2_ig_995</th>\n",
       "      <td>0.882910</td>\n",
       "      <td>0.882910</td>\n",
       "      <td>0.882910</td>\n",
       "      <td>0.882910</td>\n",
       "      <td>0.882910</td>\n",
       "      <td>0.882910</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>r2_ig_996</th>\n",
       "      <td>0.743896</td>\n",
       "      <td>0.743896</td>\n",
       "      <td>0.743896</td>\n",
       "      <td>0.743896</td>\n",
       "      <td>0.743896</td>\n",
       "      <td>0.743896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>r2_ig_998</th>\n",
       "      <td>1.073244</td>\n",
       "      <td>1.073244</td>\n",
       "      <td>1.073244</td>\n",
       "      <td>1.073244</td>\n",
       "      <td>1.073244</td>\n",
       "      <td>1.073244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>r2_ig_999</th>\n",
       "      <td>0.308421</td>\n",
       "      <td>0.308421</td>\n",
       "      <td>0.308421</td>\n",
       "      <td>0.308421</td>\n",
       "      <td>0.308421</td>\n",
       "      <td>0.308421</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2007 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Polarity     Texts    target     split    tokens  tokens_count\n",
       "User_ID                                                                   \n",
       "r2_ig_1     0.436971  0.436971  0.436971  0.436971  0.436971      0.436971\n",
       "r2_ig_10    0.045341  0.045341  0.045341  0.045341  0.045341      0.045341\n",
       "r2_ig_100   2.314898  2.314898  2.314898  2.314898  2.314898      2.314898\n",
       "r2_ig_1000  0.904335  0.904335  0.904335  0.904335  0.904335      0.904335\n",
       "r2_ig_1002  0.910314  0.910314  0.910314  0.910314  0.910314      0.910314\n",
       "...              ...       ...       ...       ...       ...           ...\n",
       "r2_ig_994   0.562531  0.562531  0.562531  0.562531  0.562531      0.562531\n",
       "r2_ig_995   0.882910  0.882910  0.882910  0.882910  0.882910      0.882910\n",
       "r2_ig_996   0.743896  0.743896  0.743896  0.743896  0.743896      0.743896\n",
       "r2_ig_998   1.073244  1.073244  1.073244  1.073244  1.073244      1.073244\n",
       "r2_ig_999   0.308421  0.308421  0.308421  0.308421  0.308421      0.308421\n",
       "\n",
       "[2007 rows x 6 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_anl.loc[len(df_anl)] = new_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14.978454533447746"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sep_comments.tokens_count.sum()/len(df_sep_comments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top_mentioned_timelines_Texts\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Target</th>\n",
       "      <th>Against</th>\n",
       "      <th>For</th>\n",
       "      <th>All</th>\n",
       "      <th>Words</th>\n",
       "      <th>W/Tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Church</td>\n",
       "      <td>1354</td>\n",
       "      <td>1041</td>\n",
       "      <td>2395</td>\n",
       "      <td>56364209</td>\n",
       "      <td>14.98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bolsonaro</td>\n",
       "      <td>649</td>\n",
       "      <td>102</td>\n",
       "      <td>751</td>\n",
       "      <td>14608017</td>\n",
       "      <td>14.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hydrox.</td>\n",
       "      <td>1154</td>\n",
       "      <td>1141</td>\n",
       "      <td>2295</td>\n",
       "      <td>51770007</td>\n",
       "      <td>22.17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sinovac</td>\n",
       "      <td>1416</td>\n",
       "      <td>1677</td>\n",
       "      <td>3093</td>\n",
       "      <td>69421120</td>\n",
       "      <td>20.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Globo TV</td>\n",
       "      <td>668</td>\n",
       "      <td>974</td>\n",
       "      <td>1642</td>\n",
       "      <td>35004176</td>\n",
       "      <td>15.15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Lula</td>\n",
       "      <td>570</td>\n",
       "      <td>518</td>\n",
       "      <td>1088</td>\n",
       "      <td>25731928</td>\n",
       "      <td>18.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Overall</td>\n",
       "      <td>5811</td>\n",
       "      <td>5453</td>\n",
       "      <td>11264</td>\n",
       "      <td>252899457</td>\n",
       "      <td>17.61</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Target  Against   For    All      Words  W/Tweet\n",
       "0     Church     1354  1041   2395   56364209    14.98\n",
       "1  Bolsonaro      649   102    751   14608017    14.58\n",
       "2    Hydrox.     1154  1141   2295   51770007    22.17\n",
       "3    Sinovac     1416  1677   3093   69421120    20.58\n",
       "4   Globo TV      668   974   1642   35004176    15.15\n",
       "5       Lula      570   518   1088   25731928    18.24\n",
       "6    Overall     5811  5453  11264  252899457    17.61"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "users_Timeline\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Target</th>\n",
       "      <th>Against</th>\n",
       "      <th>For</th>\n",
       "      <th>All</th>\n",
       "      <th>Words</th>\n",
       "      <th>W/Tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Church</td>\n",
       "      <td>1354</td>\n",
       "      <td>1041</td>\n",
       "      <td>2395</td>\n",
       "      <td>140207645</td>\n",
       "      <td>58541.81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bolsonaro</td>\n",
       "      <td>649</td>\n",
       "      <td>102</td>\n",
       "      <td>751</td>\n",
       "      <td>41224425</td>\n",
       "      <td>54892.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hydrox.</td>\n",
       "      <td>1154</td>\n",
       "      <td>1141</td>\n",
       "      <td>2295</td>\n",
       "      <td>108484625</td>\n",
       "      <td>47269.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sinovac</td>\n",
       "      <td>1416</td>\n",
       "      <td>1677</td>\n",
       "      <td>3093</td>\n",
       "      <td>137333979</td>\n",
       "      <td>44401.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Globo TV</td>\n",
       "      <td>668</td>\n",
       "      <td>974</td>\n",
       "      <td>1642</td>\n",
       "      <td>93326479</td>\n",
       "      <td>56837.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Lula</td>\n",
       "      <td>570</td>\n",
       "      <td>518</td>\n",
       "      <td>1088</td>\n",
       "      <td>67569624</td>\n",
       "      <td>62104.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Overall</td>\n",
       "      <td>5811</td>\n",
       "      <td>5453</td>\n",
       "      <td>11264</td>\n",
       "      <td>588146777</td>\n",
       "      <td>54007.93</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Target  Against   For    All      Words   W/Tweet\n",
       "0     Church     1354  1041   2395  140207645  58541.81\n",
       "1  Bolsonaro      649   102    751   41224425  54892.71\n",
       "2    Hydrox.     1154  1141   2295  108484625  47269.99\n",
       "3    Sinovac     1416  1677   3093  137333979  44401.55\n",
       "4   Globo TV      668   974   1642   93326479  56837.08\n",
       "5       Lula      570   518   1088   67569624  62104.43\n",
       "6    Overall     5811  5453  11264  588146777  54007.93"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "users_Stance\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Target</th>\n",
       "      <th>Against</th>\n",
       "      <th>For</th>\n",
       "      <th>All</th>\n",
       "      <th>Words</th>\n",
       "      <th>W/Tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Church</td>\n",
       "      <td>1354</td>\n",
       "      <td>1041</td>\n",
       "      <td>2395</td>\n",
       "      <td>26567</td>\n",
       "      <td>24.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bolsonaro</td>\n",
       "      <td>649</td>\n",
       "      <td>102</td>\n",
       "      <td>751</td>\n",
       "      <td>26567</td>\n",
       "      <td>24.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hydrox.</td>\n",
       "      <td>1154</td>\n",
       "      <td>1141</td>\n",
       "      <td>2295</td>\n",
       "      <td>26567</td>\n",
       "      <td>24.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Sinovac</td>\n",
       "      <td>1416</td>\n",
       "      <td>1677</td>\n",
       "      <td>3093</td>\n",
       "      <td>26567</td>\n",
       "      <td>24.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Globo TV</td>\n",
       "      <td>668</td>\n",
       "      <td>974</td>\n",
       "      <td>1642</td>\n",
       "      <td>26567</td>\n",
       "      <td>24.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Lula</td>\n",
       "      <td>570</td>\n",
       "      <td>518</td>\n",
       "      <td>1088</td>\n",
       "      <td>26567</td>\n",
       "      <td>24.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Overall</td>\n",
       "      <td>5811</td>\n",
       "      <td>5453</td>\n",
       "      <td>11264</td>\n",
       "      <td>159402</td>\n",
       "      <td>24.42</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Target  Against   For    All   Words  W/Tweet\n",
       "0     Church     1354  1041   2395   26567    24.42\n",
       "1  Bolsonaro      649   102    751   26567    24.42\n",
       "2    Hydrox.     1154  1141   2295   26567    24.42\n",
       "3    Sinovac     1416  1677   3093   26567    24.42\n",
       "4   Globo TV      668   974   1642   26567    24.42\n",
       "5       Lula      570   518   1088   26567    24.42\n",
       "6    Overall     5811  5453  11264  159402    24.42"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for key, value in dict_results.items():\n",
    "    \n",
    "    print(key)\n",
    "    \n",
    "    display(value)\n",
    "    \n",
    "    value.to_csv(reports_path + f'describe/{key}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env-stance-pred",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
