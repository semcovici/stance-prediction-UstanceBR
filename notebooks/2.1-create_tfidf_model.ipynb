{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import LabelEncoder, MaxAbsScaler\n",
    "import numpy as np\n",
    "from imblearn.over_sampling import RandomOverSampler, SMOTE\n",
    "from imblearn.pipeline import Pipeline as IMBPipeline\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from nltk.corpus import stopwords\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.feature_selection import RFE\n",
    "from tsfresh.feature_extraction import MinimalFCParameters\n",
    "from tsfresh.feature_extraction import extract_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../src/')\n",
    "from models.classification_methods import process_classification "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_raw_data = '../data/raw/'\n",
    "path_processed_data = '../data/processed/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_target = ['ig','bo', 'cl', 'co', 'gl', 'lu']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = 'ig'\n",
    "model_name = 'facebook/fasttext-pt-vectors'\n",
    "model_name = 'neuralmind/bert-base-portuguese-cased'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top mentioned timelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a list of tuples with (data_train, data_test, target)\n",
    "\n",
    "list_tuples_top_ment = []\n",
    "\n",
    "for target in tqdm(list_target):\n",
    "    \n",
    "    path_data_train = path_raw_data + f'train_r3_{target}_top_mentioned_timelines.csv'\n",
    "    path_data_test = path_raw_data + f'test_r3_{target}_top_mentioned_timelines.csv'\n",
    "\n",
    "    data_train = pd.read_csv(\n",
    "        path_data_train, \n",
    "        sep = ';', \n",
    "        encoding='utf-8-sig'\n",
    "        )\n",
    "    data_test = pd.read_csv(\n",
    "        path_data_test, \n",
    "        sep = ';', \n",
    "        encoding='utf-8-sig'\n",
    "        )\n",
    "    \n",
    "    list_tuples_top_ment.append((data_train, data_test, target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_cols = 'Texts'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define pipeline steps \n",
    "text_vect = TfidfVectorizer(\n",
    "            stop_words = stopwords.words('portuguese'),\n",
    "            lowercase = True,\n",
    "            ngram_range = (1,3),\n",
    "            max_features=50000\n",
    "            \n",
    "            )\n",
    "sampling = None\n",
    "selection = None\n",
    "scaling = MaxAbsScaler()\n",
    "estimator = XGBClassifier(\n",
    "                random_state = 42,\n",
    "                verbosity = 3,\n",
    "                device = 'cuda',\n",
    "                tree_method = 'hist'\n",
    "                )\n",
    "\n",
    "\n",
    "# get results\n",
    "df_cr, df_test_results = process_classification(\n",
    "        estimator = estimator,\n",
    "        vectorizer = text_vect,\n",
    "        scaling = scaling,\n",
    "        selection= selection,\n",
    "        data_tuples = list_tuples_top_ment,\n",
    "        X_cols = X_cols\n",
    ")\n",
    "\n",
    "df_cr[df_cr['class'] == 'macro avg'].sort_values('f1-score')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a list of tuples with (data_train, data_test, target)\n",
    "\n",
    "list_tuples_users = []\n",
    "\n",
    "for target in tqdm(list_target):\n",
    "\n",
    "    path_data_train = path_raw_data + f'r3_{target}_train_users.csv'\n",
    "    path_data_test = path_raw_data + f'r3_{target}_test_users.csv'\n",
    "\n",
    "    data_train = pd.read_csv(\n",
    "        path_data_train, \n",
    "        sep = ';', \n",
    "        encoding='utf-8-sig'\n",
    "        )\n",
    "    data_test = pd.read_csv(\n",
    "        path_data_test, \n",
    "        sep = ';', \n",
    "        encoding='utf-8-sig'\n",
    "        )\n",
    "    \n",
    "    list_tuples_users.append((data_train, data_test, target))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Timelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_cols = 'Timeline'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define pipeline steps \n",
    "text_vect = TfidfVectorizer(\n",
    "            stop_words = stopwords.words('portuguese'),\n",
    "            lowercase = True,\n",
    "            ngram_range = (1,3),\n",
    "            max_features=50000\n",
    "            \n",
    "            )\n",
    "sampling = None\n",
    "selection = None\n",
    "scaling = MaxAbsScaler()\n",
    "estimator = XGBClassifier(\n",
    "                random_state = 42,\n",
    "                verbosity = 3,\n",
    "                device = 'cuda',\n",
    "                tree_method = 'hist'\n",
    "                )\n",
    "\n",
    "\n",
    "# get results\n",
    "df_cr, df_test_results = process_classification(\n",
    "        estimator = estimator,\n",
    "        vectorizer= text_vect,\n",
    "        scaling = scaling,\n",
    "        selection= selection,\n",
    "        data_tuples = list_tuples_users,\n",
    "        X_cols = X_cols\n",
    ")\n",
    "\n",
    "df_cr[df_cr['class'] == 'macro avg'].sort_values('f1-score')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_cols = 'Stance'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define pipeline steps \n",
    "text_vect = TfidfVectorizer(\n",
    "            stop_words = stopwords.words('portuguese'),\n",
    "            lowercase = True,\n",
    "            ngram_range = (1,3),\n",
    "            max_features=50000\n",
    "            \n",
    "            )\n",
    "sampling = None\n",
    "selection = None\n",
    "scaling = MaxAbsScaler()\n",
    "estimator = XGBClassifier(\n",
    "                random_state = 42,\n",
    "                verbosity = 3,\n",
    "                device = 'cuda',\n",
    "                tree_method = 'hist'\n",
    "                )\n",
    "\n",
    "\n",
    "# get results\n",
    "df_cr, df_test_results = process_classification(\n",
    "        estimator = estimator,\n",
    "        vectorizer= text_vect,\n",
    "        scaling = scaling,\n",
    "        selection= selection,\n",
    "        data_tuples = list_tuples_users,\n",
    "        X_cols = X_cols\n",
    ")\n",
    "\n",
    "df_cr[df_cr['class'] == 'macro avg'].sort_values('f1-score')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env-stance-pred",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
