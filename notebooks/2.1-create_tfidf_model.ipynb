{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import LabelEncoder, MaxAbsScaler\n",
    "import numpy as np\n",
    "from imblearn.over_sampling import RandomOverSampler, SMOTE\n",
    "from imblearn.pipeline import Pipeline as IMBPipeline\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from nltk.corpus import stopwords\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.feature_selection import RFE\n",
    "from tsfresh.feature_extraction import MinimalFCParameters\n",
    "from tsfresh.feature_extraction import extract_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/semcovici/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../src/')\n",
    "from models.classification_methods import process_classification "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_raw_data = '../data/raw/'\n",
    "path_processed_data = '../data/processed/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_target = ['ig','bo', 'cl', 'co', 'gl', 'lu']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = 'ig'\n",
    "model_name = 'facebook/fasttext-pt-vectors'\n",
    "model_name = 'neuralmind/bert-base-portuguese-cased'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Top mentioned timelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:21<00:00,  3.54s/it]\n"
     ]
    }
   ],
   "source": [
    "# create a list of tuples with (data_train, data_test, target)\n",
    "\n",
    "list_tuples_top_ment = []\n",
    "\n",
    "for target in tqdm(list_target):\n",
    "    \n",
    "    path_data_train = path_raw_data + f'train_r3_{target}_top_mentioned_timelines.csv'\n",
    "    path_data_test = path_raw_data + f'test_r3_{target}_top_mentioned_timelines.csv'\n",
    "\n",
    "    data_train = pd.read_csv(\n",
    "        path_data_train, \n",
    "        sep = ';', \n",
    "        encoding='utf-8-sig'\n",
    "        )\n",
    "    data_test = pd.read_csv(\n",
    "        path_data_test, \n",
    "        sep = ';', \n",
    "        encoding='utf-8-sig'\n",
    "        )\n",
    "    \n",
    "    list_tuples_top_ment.append((data_train, data_test, target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_cols = 'Texts'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ...\n",
      "[Pipeline] ........ (step 1 of 5) Processing vectorizer, total= 4.2min\n",
      "[Pipeline] .......... (step 2 of 5) Processing sampling, total=   0.0s\n",
      "[Pipeline] ........... (step 3 of 5) Processing scaling, total=   0.3s\n",
      "[Pipeline] ......... (step 4 of 5) Processing selection, total=   0.0s\n",
      "[14:14:45] ======== Monitor (0): HostSketchContainer ========\n",
      "[14:14:45] AllReduce: 0.05373s, 1 calls @ 53730us\n",
      "\n",
      "[14:14:45] MakeCuts: 0.121144s, 1 calls @ 121144us\n",
      "\n",
      "[14:14:45] DEBUG: /workspace/src/gbm/gbtree.cc:130: Using tree method: 3\n",
      "[14:14:45] DEBUG: /workspace/src/tree/updater_gpu_hist.cu:744: [GPU Hist]: Configure\n",
      "[14:14:45] ======== Monitor (0):  ========\n",
      "[14:14:45] InitCompressedData: 0.000664s, 1 calls @ 664us\n",
      "\n",
      "[14:14:45] DEBUG: /workspace/src/tree/gpu_hist/../../common/device_helpers.cuh:291: Skipping empty CUDA kernel.\n",
      "[14:14:45] DEBUG: /workspace/src/tree/gpu_hist/../../common/device_helpers.cuh:291: Skipping empty CUDA kernel.\n",
      "[14:14:45] DEBUG: /workspace/src/tree/gpu_hist/../../common/device_helpers.cuh:291: Skipping empty CUDA kernel.\n",
      "[14:14:45] DEBUG: /workspace/src/tree/gpu_hist/../../common/device_helpers.cuh:291: Skipping empty CUDA kernel.\n",
      "[14:14:48] ======== Monitor (0): Learner ========\n",
      "[14:14:48] Configure: 0.025635s, 1 calls @ 25635us\n",
      "\n",
      "[14:14:48] EvalOneIter: 0.000839s, 100 calls @ 839us\n",
      "\n",
      "[14:14:48] GetGradient: 0.004768s, 100 calls @ 4768us\n",
      "\n",
      "[14:14:48] PredictRaw: 0.000123s, 100 calls @ 123us\n",
      "\n",
      "[14:14:48] UpdateOneIter: 2.94749s, 100 calls @ 2947495us\n",
      "\n",
      "[14:14:48] ======== Monitor (0): GBTree ========\n",
      "[14:14:48] BoostNewTrees: 2.90869s, 100 calls @ 2908687us\n",
      "\n",
      "[14:14:48] CommitModel: 4.6e-05s, 100 calls @ 46us\n",
      "\n",
      "[14:14:48] ======== Device 0 Memory Allocations:  ========\n",
      "[14:14:48] Peak memory usage: 1575MiB\n",
      "[14:14:48] Number of allocations: 1472\n",
      "[14:14:48] ======== Monitor (0): updater_gpu_hist ========\n",
      "[14:14:48] InitData: 0.000529s, 100 calls @ 529us\n",
      "\n",
      "[14:14:48] InitDataOnce: 0.000516s, 1 calls @ 516us\n",
      "\n",
      "[14:14:48] Update: 2.90505s, 100 calls @ 2905046us\n",
      "\n",
      "[14:14:48] UpdatePredictionCache: 0.002913s, 100 calls @ 2913us\n",
      "\n",
      "[14:14:48] ======== Monitor (0): gradient_based_sampler ========\n",
      "[14:14:48] Sample: 0.028654s, 100 calls @ 28654us\n",
      "\n",
      "[14:14:48] ======== Monitor (0): GPUHistMakerDevice0 ========\n",
      "[14:14:48] AllReduce: 0.000108s, 105 calls @ 108us\n",
      "\n",
      "[14:14:48] BuildHist: 0.011354s, 6 calls @ 11354us\n",
      "\n",
      "[14:14:48] EvaluateSplits: 0.144061s, 6 calls @ 144061us\n",
      "\n",
      "[14:14:48] FinalisePosition: 0.006894s, 100 calls @ 6894us\n",
      "\n",
      "[14:14:48] InitRoot: 2.68602s, 100 calls @ 2686025us\n",
      "\n",
      "[14:14:48] Reset: 0.053572s, 100 calls @ 53572us\n",
      "\n",
      "[14:14:48] UpdatePosition: 0.001357s, 6 calls @ 1357us\n",
      "\n",
      "[Pipeline] ......... (step 5 of 5) Processing estimator, total=   4.0s\n",
      "[14:15:08] DEBUG: /workspace/src/gbm/gbtree.cc:130: Using tree method: 3\n",
      "[14:15:08] DEBUG: /workspace/src/tree/updater_gpu_hist.cu:744: [GPU Hist]: Configure\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/semcovici/anaconda3/envs/env-stance-pred/lib/python3.12/site-packages/xgboost/core.py:160: UserWarning: [14:15:08] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
      "Potential solutions:\n",
      "- Use a data structure that matches the device ordinal in the booster.\n",
      "- Set the device for booster before call to inplace_predict.\n",
      "\n",
      "This warning will only be shown once.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "/home/semcovici/anaconda3/envs/env-stance-pred/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/semcovici/anaconda3/envs/env-stance-pred/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/semcovici/anaconda3/envs/env-stance-pred/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ...\n",
      "[Pipeline] ........ (step 1 of 5) Processing vectorizer, total= 1.1min\n",
      "[Pipeline] .......... (step 2 of 5) Processing sampling, total=   0.0s\n",
      "[Pipeline] ........... (step 3 of 5) Processing scaling, total=   0.2s\n",
      "[Pipeline] ......... (step 4 of 5) Processing selection, total=   0.0s\n",
      "[14:16:38] ======== Monitor (0): HostSketchContainer ========\n",
      "[14:16:38] AllReduce: 0.008179s, 1 calls @ 8179us\n",
      "\n",
      "[14:16:38] MakeCuts: 0.020358s, 1 calls @ 20358us\n",
      "\n",
      "[14:16:38] DEBUG: /workspace/src/gbm/gbtree.cc:130: Using tree method: 3\n",
      "[14:16:38] DEBUG: /workspace/src/tree/updater_gpu_hist.cu:744: [GPU Hist]: Configure\n",
      "[14:16:38] ======== Monitor (0):  ========\n",
      "[14:16:38] InitCompressedData: 0.000459s, 1 calls @ 459us\n",
      "\n",
      "[14:16:38] DEBUG: /workspace/src/tree/gpu_hist/../../common/device_helpers.cuh:291: Skipping empty CUDA kernel.\n",
      "[14:16:39] ======== Monitor (0): Learner ========\n",
      "[14:16:39] Configure: 0.008361s, 1 calls @ 8361us\n",
      "\n",
      "[14:16:39] EvalOneIter: 0.000391s, 100 calls @ 391us\n",
      "\n",
      "[14:16:39] GetGradient: 0.003927s, 100 calls @ 3927us\n",
      "\n",
      "[14:16:39] PredictRaw: 8.1e-05s, 100 calls @ 81us\n",
      "\n",
      "[14:16:39] UpdateOneIter: 1.22583s, 100 calls @ 1225834us\n",
      "\n",
      "[14:16:39] ======== Monitor (0): GBTree ========\n",
      "[14:16:39] BoostNewTrees: 1.21132s, 100 calls @ 1211325us\n",
      "\n",
      "[14:16:39] CommitModel: 3.1e-05s, 100 calls @ 31us\n",
      "\n",
      "[14:16:39] ======== Device 0 Memory Allocations:  ========\n",
      "[14:16:39] Peak memory usage: 1575MiB\n",
      "[14:16:39] Number of allocations: 2940\n",
      "[14:16:39] ======== Monitor (0): updater_gpu_hist ========\n",
      "[14:16:39] InitData: 0.000217s, 100 calls @ 217us\n",
      "\n",
      "[14:16:39] InitDataOnce: 0.000205s, 1 calls @ 205us\n",
      "\n",
      "[14:16:39] Update: 1.20868s, 100 calls @ 1208679us\n",
      "\n",
      "[14:16:39] UpdatePredictionCache: 0.002186s, 100 calls @ 2186us\n",
      "\n",
      "[14:16:39] ======== Monitor (0): gradient_based_sampler ========\n",
      "[14:16:39] Sample: 0.009229s, 100 calls @ 9229us\n",
      "\n",
      "[14:16:39] ======== Monitor (0): GPUHistMakerDevice0 ========\n",
      "[14:16:39] AllReduce: 6.6e-05s, 102 calls @ 66us\n",
      "\n",
      "[14:16:39] BuildHist: 0.001456s, 2 calls @ 1456us\n",
      "\n",
      "[14:16:39] EvaluateSplits: 0.02833s, 2 calls @ 28330us\n",
      "\n",
      "[14:16:39] FinalisePosition: 0.004286s, 100 calls @ 4286us\n",
      "\n",
      "[14:16:39] InitRoot: 1.14262s, 100 calls @ 1142619us\n",
      "\n",
      "[14:16:39] Reset: 0.030435s, 100 calls @ 30435us\n",
      "\n",
      "[14:16:39] UpdatePosition: 0.000182s, 2 calls @ 182us\n",
      "\n",
      "[14:16:39] ======== Monitor (0): Learner ========\n",
      "[14:16:39] Configure: 0.008123s, 1 calls @ 8123us\n",
      "\n",
      "[14:16:39] ======== Monitor (0): GBTree ========\n",
      "[14:16:39] ======== Device 0 Memory Allocations:  ========\n",
      "[14:16:39] Peak memory usage: 1575MiB\n",
      "[14:16:39] Number of allocations: 2940\n",
      "[14:16:39] ======== Monitor (0): updater_gpu_hist ========\n",
      "[Pipeline] ......... (step 5 of 5) Processing estimator, total=   1.8s\n",
      "[14:16:46] DEBUG: /workspace/src/gbm/gbtree.cc:130: Using tree method: 3\n",
      "[14:16:46] DEBUG: /workspace/src/tree/updater_gpu_hist.cu:744: [GPU Hist]: Configure\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/semcovici/anaconda3/envs/env-stance-pred/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/semcovici/anaconda3/envs/env-stance-pred/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/semcovici/anaconda3/envs/env-stance-pred/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ...\n",
      "[Pipeline] ........ (step 1 of 5) Processing vectorizer, total= 4.7min\n",
      "[Pipeline] .......... (step 2 of 5) Processing sampling, total=   0.0s\n",
      "[Pipeline] ........... (step 3 of 5) Processing scaling, total=   0.5s\n",
      "[Pipeline] ......... (step 4 of 5) Processing selection, total=   0.0s\n",
      "[14:21:33] ======== Monitor (0): HostSketchContainer ========\n",
      "[14:21:33] AllReduce: 0.053086s, 1 calls @ 53086us\n",
      "\n",
      "[14:21:33] MakeCuts: 0.141634s, 1 calls @ 141634us\n",
      "\n",
      "[14:21:33] DEBUG: /workspace/src/gbm/gbtree.cc:130: Using tree method: 3\n",
      "[14:21:33] DEBUG: /workspace/src/tree/updater_gpu_hist.cu:744: [GPU Hist]: Configure\n",
      "[14:21:33] ======== Monitor (0):  ========\n",
      "[14:21:33] InitCompressedData: 0.001005s, 1 calls @ 1005us\n",
      "\n",
      "[14:21:33] DEBUG: /workspace/src/tree/gpu_hist/../../common/device_helpers.cuh:291: Skipping empty CUDA kernel.\n",
      "[14:21:34] DEBUG: /workspace/src/tree/gpu_hist/../../common/device_helpers.cuh:291: Skipping empty CUDA kernel.\n",
      "[14:21:34] DEBUG: /workspace/src/tree/gpu_hist/../../common/device_helpers.cuh:291: Skipping empty CUDA kernel.\n",
      "[14:21:34] DEBUG: /workspace/src/tree/gpu_hist/../../common/device_helpers.cuh:291: Skipping empty CUDA kernel.\n",
      "[14:21:34] DEBUG: /workspace/src/tree/gpu_hist/../../common/device_helpers.cuh:291: Skipping empty CUDA kernel.\n",
      "[14:21:37] ======== Monitor (0): Learner ========\n",
      "[14:21:37] Configure: 0.009501s, 1 calls @ 9501us\n",
      "\n",
      "[14:21:37] EvalOneIter: 0.000593s, 100 calls @ 593us\n",
      "\n",
      "[14:21:37] GetGradient: 0.00402s, 100 calls @ 4020us\n",
      "\n",
      "[14:21:37] PredictRaw: 0.000157s, 100 calls @ 157us\n",
      "\n",
      "[14:21:37] UpdateOneIter: 3.86436s, 100 calls @ 3864358us\n",
      "\n",
      "[14:21:37] ======== Monitor (0): GBTree ========\n",
      "[14:21:37] BoostNewTrees: 3.84894s, 100 calls @ 3848942us\n",
      "\n",
      "[14:21:37] CommitModel: 4.4e-05s, 100 calls @ 44us\n",
      "\n",
      "[14:21:37] ======== Device 0 Memory Allocations:  ========\n",
      "[14:21:37] Peak memory usage: 1575MiB\n",
      "[14:21:37] Number of allocations: 4451\n",
      "[14:21:37] ======== Monitor (0): updater_gpu_hist ========\n",
      "[14:21:37] InitData: 0.000475s, 100 calls @ 475us\n",
      "\n",
      "[14:21:37] InitDataOnce: 0.000463s, 1 calls @ 463us\n",
      "\n",
      "[14:21:37] Update: 3.84532s, 100 calls @ 3845322us\n",
      "\n",
      "[14:21:37] UpdatePredictionCache: 0.003031s, 100 calls @ 3031us\n",
      "\n",
      "[14:21:37] ======== Monitor (0): gradient_based_sampler ========\n",
      "[14:21:37] Sample: 0.023706s, 100 calls @ 23706us\n",
      "\n",
      "[14:21:37] ======== Monitor (0): GPUHistMakerDevice0 ========\n",
      "[14:21:37] AllReduce: 9.4e-05s, 107 calls @ 94us\n",
      "\n",
      "[14:21:37] BuildHist: 0.007531s, 8 calls @ 7531us\n",
      "\n",
      "[14:21:37] EvaluateSplits: 0.158778s, 8 calls @ 158778us\n",
      "\n",
      "[14:21:37] FinalisePosition: 0.004783s, 100 calls @ 4783us\n",
      "\n",
      "[14:21:37] InitRoot: 3.62431s, 100 calls @ 3624314us\n",
      "\n",
      "[14:21:37] Reset: 0.046369s, 100 calls @ 46369us\n",
      "\n",
      "[14:21:37] UpdatePosition: 0.001845s, 8 calls @ 1845us\n",
      "\n",
      "[14:21:37] ======== Monitor (0): Learner ========\n",
      "[14:21:37] Configure: 0.000579s, 1 calls @ 579us\n",
      "\n",
      "[14:21:37] ======== Monitor (0): GBTree ========\n",
      "[14:21:37] ======== Device 0 Memory Allocations:  ========\n",
      "[14:21:37] Peak memory usage: 1575MiB\n",
      "[14:21:37] Number of allocations: 4451\n",
      "[14:21:37] ======== Monitor (0): updater_gpu_hist ========\n",
      "[Pipeline] ......... (step 5 of 5) Processing estimator, total=   5.3s\n",
      "[14:22:10] DEBUG: /workspace/src/gbm/gbtree.cc:130: Using tree method: 3\n",
      "[14:22:10] DEBUG: /workspace/src/tree/updater_gpu_hist.cu:744: [GPU Hist]: Configure\n",
      "Training ...\n",
      "[Pipeline] ........ (step 1 of 5) Processing vectorizer, total= 7.1min\n",
      "[Pipeline] .......... (step 2 of 5) Processing sampling, total=   0.0s\n",
      "[Pipeline] ........... (step 3 of 5) Processing scaling, total=   0.7s\n",
      "[Pipeline] ......... (step 4 of 5) Processing selection, total=   0.0s\n",
      "[14:29:53] ======== Monitor (0): HostSketchContainer ========\n",
      "[14:29:53] AllReduce: 0.152843s, 1 calls @ 152843us\n",
      "\n",
      "[14:29:53] MakeCuts: 0.304335s, 1 calls @ 304335us\n",
      "\n",
      "[14:29:53] DEBUG: /workspace/src/gbm/gbtree.cc:130: Using tree method: 3\n",
      "[14:29:53] DEBUG: /workspace/src/tree/updater_gpu_hist.cu:744: [GPU Hist]: Configure\n",
      "[14:29:53] ======== Monitor (0):  ========\n",
      "[14:29:53] InitCompressedData: 0.000989s, 1 calls @ 989us\n",
      "\n",
      "[14:29:58] ======== Monitor (0): Learner ========\n",
      "[14:29:58] Configure: 0.017509s, 1 calls @ 17509us\n",
      "\n",
      "[14:29:58] EvalOneIter: 0.001377s, 100 calls @ 1377us\n",
      "\n",
      "[14:29:58] GetGradient: 0.005654s, 100 calls @ 5654us\n",
      "\n",
      "[14:29:58] PredictRaw: 0.000154s, 100 calls @ 154us\n",
      "\n",
      "[14:29:58] UpdateOneIter: 4.54237s, 100 calls @ 4542375us\n",
      "\n",
      "[14:29:58] ======== Monitor (0): GBTree ========\n",
      "[14:29:58] BoostNewTrees: 4.51578s, 100 calls @ 4515777us\n",
      "\n",
      "[14:29:58] CommitModel: 4.8e-05s, 100 calls @ 48us\n",
      "\n",
      "[14:29:58] ======== Device 0 Memory Allocations:  ========\n",
      "[14:29:58] Peak memory usage: 1575MiB\n",
      "[14:29:58] Number of allocations: 5920\n",
      "[14:29:58] ======== Monitor (0): updater_gpu_hist ========\n",
      "[14:29:58] InitData: 0.001513s, 100 calls @ 1513us\n",
      "\n",
      "[14:29:58] InitDataOnce: 0.001501s, 1 calls @ 1501us\n",
      "\n",
      "[14:29:58] Update: 4.51208s, 100 calls @ 4512082us\n",
      "\n",
      "[14:29:58] UpdatePredictionCache: 0.002996s, 100 calls @ 2996us\n",
      "\n",
      "[14:29:58] ======== Monitor (0): gradient_based_sampler ========\n",
      "[14:29:58] Sample: 0.02653s, 100 calls @ 26530us\n",
      "\n",
      "[14:29:58] ======== Monitor (0): GPUHistMakerDevice0 ========\n",
      "[14:29:58] AllReduce: 9.4e-05s, 102 calls @ 94us\n",
      "\n",
      "[14:29:58] BuildHist: 0.004555s, 2 calls @ 4555us\n",
      "\n",
      "[14:29:58] EvaluateSplits: 0.106485s, 2 calls @ 106485us\n",
      "\n",
      "[14:29:58] FinalisePosition: 0.005045s, 100 calls @ 5045us\n",
      "\n",
      "[14:29:58] InitRoot: 4.34276s, 100 calls @ 4342760us\n",
      "\n",
      "[14:29:58] Reset: 0.04988s, 100 calls @ 49880us\n",
      "\n",
      "[14:29:58] UpdatePosition: 0.000593s, 2 calls @ 593us\n",
      "\n",
      "[14:29:58] ======== Monitor (0): Learner ========\n",
      "[14:29:58] Configure: 0.008971s, 1 calls @ 8971us\n",
      "\n",
      "[14:29:58] ======== Monitor (0): GBTree ========\n",
      "[14:29:58] ======== Device 0 Memory Allocations:  ========\n",
      "[14:29:58] Peak memory usage: 1575MiB\n",
      "[14:29:58] Number of allocations: 5920\n",
      "[14:29:58] ======== Monitor (0): updater_gpu_hist ========\n",
      "[Pipeline] ......... (step 5 of 5) Processing estimator, total=   6.6s\n",
      "[14:30:47] DEBUG: /workspace/src/gbm/gbtree.cc:130: Using tree method: 3\n",
      "[14:30:47] DEBUG: /workspace/src/tree/updater_gpu_hist.cu:744: [GPU Hist]: Configure\n",
      "Training ...\n",
      "[Pipeline] ........ (step 1 of 5) Processing vectorizer, total= 2.9min\n",
      "[Pipeline] .......... (step 2 of 5) Processing sampling, total=   0.0s\n",
      "[Pipeline] ........... (step 3 of 5) Processing scaling, total=   0.2s\n",
      "[Pipeline] ......... (step 4 of 5) Processing selection, total=   0.0s\n",
      "[14:34:31] ======== Monitor (0): HostSketchContainer ========\n",
      "[14:34:31] AllReduce: 0.028019s, 1 calls @ 28019us\n",
      "\n",
      "[14:34:31] MakeCuts: 0.049956s, 1 calls @ 49956us\n",
      "\n",
      "[14:34:31] DEBUG: /workspace/src/gbm/gbtree.cc:130: Using tree method: 3\n",
      "[14:34:31] DEBUG: /workspace/src/tree/updater_gpu_hist.cu:744: [GPU Hist]: Configure\n",
      "[14:34:31] ======== Monitor (0):  ========\n",
      "[14:34:31] InitCompressedData: 0.000361s, 1 calls @ 361us\n",
      "\n",
      "[14:34:31] DEBUG: /workspace/src/tree/gpu_hist/../../common/device_helpers.cuh:291: Skipping empty CUDA kernel.\n",
      "[14:34:32] ======== Monitor (0): Learner ========\n",
      "[14:34:32] Configure: 0.01053s, 1 calls @ 10530us\n",
      "\n",
      "[14:34:32] EvalOneIter: 0.000459s, 100 calls @ 459us\n",
      "\n",
      "[14:34:32] GetGradient: 0.0046s, 100 calls @ 4600us\n",
      "\n",
      "[14:34:32] PredictRaw: 9.5e-05s, 100 calls @ 95us\n",
      "\n",
      "[14:34:32] UpdateOneIter: 1.81273s, 100 calls @ 1812732us\n",
      "\n",
      "[14:34:32] ======== Monitor (0): GBTree ========\n",
      "[14:34:32] BoostNewTrees: 1.79537s, 100 calls @ 1795368us\n",
      "\n",
      "[14:34:32] CommitModel: 3.3e-05s, 100 calls @ 33us\n",
      "\n",
      "[14:34:32] ======== Device 0 Memory Allocations:  ========\n",
      "[14:34:32] Peak memory usage: 1575MiB\n",
      "[14:34:32] Number of allocations: 7389\n",
      "[14:34:32] ======== Monitor (0): updater_gpu_hist ========\n",
      "[14:34:32] InitData: 0.000448s, 100 calls @ 448us\n",
      "\n",
      "[14:34:32] InitDataOnce: 0.000436s, 1 calls @ 436us\n",
      "\n",
      "[14:34:32] Update: 1.79082s, 100 calls @ 1790821us\n",
      "\n",
      "[14:34:32] UpdatePredictionCache: 0.004059s, 100 calls @ 4059us\n",
      "\n",
      "[14:34:32] ======== Monitor (0): gradient_based_sampler ========\n",
      "[14:34:32] Sample: 0.010695s, 100 calls @ 10695us\n",
      "\n",
      "[14:34:32] ======== Monitor (0): GPUHistMakerDevice0 ========\n",
      "[14:34:32] AllReduce: 7.1e-05s, 102 calls @ 71us\n",
      "\n",
      "[14:34:32] BuildHist: 0.002846s, 2 calls @ 2846us\n",
      "\n",
      "[14:34:32] EvaluateSplits: 0.044872s, 2 calls @ 44872us\n",
      "\n",
      "[14:34:32] FinalisePosition: 0.003458s, 100 calls @ 3458us\n",
      "\n",
      "[14:34:32] InitRoot: 1.7044s, 100 calls @ 1704396us\n",
      "\n",
      "[14:34:32] Reset: 0.033505s, 100 calls @ 33505us\n",
      "\n",
      "[14:34:32] UpdatePosition: 0.000187s, 2 calls @ 187us\n",
      "\n",
      "[14:34:32] ======== Monitor (0): Learner ========\n",
      "[14:34:32] Configure: 0.008101s, 1 calls @ 8101us\n",
      "\n",
      "[14:34:32] ======== Monitor (0): GBTree ========\n",
      "[14:34:32] ======== Device 0 Memory Allocations:  ========\n",
      "[14:34:32] Peak memory usage: 1575MiB\n",
      "[14:34:32] Number of allocations: 7389\n",
      "[14:34:32] ======== Monitor (0): updater_gpu_hist ========\n",
      "[Pipeline] ......... (step 5 of 5) Processing estimator, total=   2.5s\n",
      "[14:34:51] DEBUG: /workspace/src/gbm/gbtree.cc:130: Using tree method: 3\n",
      "[14:34:51] DEBUG: /workspace/src/tree/updater_gpu_hist.cu:744: [GPU Hist]: Configure\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/semcovici/anaconda3/envs/env-stance-pred/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/semcovici/anaconda3/envs/env-stance-pred/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/semcovici/anaconda3/envs/env-stance-pred/lib/python3.12/site-packages/sklearn/metrics/_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ...\n",
      "[Pipeline] ........ (step 1 of 5) Processing vectorizer, total= 2.0min\n",
      "[Pipeline] .......... (step 2 of 5) Processing sampling, total=   0.0s\n",
      "[Pipeline] ........... (step 3 of 5) Processing scaling, total=   0.2s\n",
      "[Pipeline] ......... (step 4 of 5) Processing selection, total=   0.0s\n",
      "[14:37:09] ======== Monitor (0): HostSketchContainer ========\n",
      "[14:37:09] AllReduce: 0.019305s, 1 calls @ 19305us\n",
      "\n",
      "[14:37:09] MakeCuts: 0.036242s, 1 calls @ 36242us\n",
      "\n",
      "[14:37:09] DEBUG: /workspace/src/gbm/gbtree.cc:130: Using tree method: 3\n",
      "[14:37:09] DEBUG: /workspace/src/tree/updater_gpu_hist.cu:744: [GPU Hist]: Configure\n",
      "[14:37:09] ======== Monitor (0):  ========\n",
      "[14:37:09] InitCompressedData: 0.00059s, 1 calls @ 590us\n",
      "\n",
      "[14:37:09] DEBUG: /workspace/src/tree/gpu_hist/../../common/device_helpers.cuh:291: Skipping empty CUDA kernel.\n",
      "[14:37:10] ======== Monitor (0): Learner ========\n",
      "[14:37:10] Configure: 0.008639s, 1 calls @ 8639us\n",
      "\n",
      "[14:37:10] EvalOneIter: 0.000464s, 100 calls @ 464us\n",
      "\n",
      "[14:37:10] GetGradient: 0.004233s, 100 calls @ 4233us\n",
      "\n",
      "[14:37:10] PredictRaw: 8.8e-05s, 100 calls @ 88us\n",
      "\n",
      "[14:37:10] UpdateOneIter: 1.61189s, 100 calls @ 1611893us\n",
      "\n",
      "[14:37:10] ======== Monitor (0): GBTree ========\n",
      "[14:37:10] BoostNewTrees: 1.59773s, 100 calls @ 1597734us\n",
      "\n",
      "[14:37:10] CommitModel: 3.5e-05s, 100 calls @ 35us\n",
      "\n",
      "[14:37:10] ======== Device 0 Memory Allocations:  ========\n",
      "[14:37:10] Peak memory usage: 1575MiB\n",
      "[14:37:10] Number of allocations: 8857\n",
      "[14:37:10] ======== Monitor (0): updater_gpu_hist ========\n",
      "[14:37:10] InitData: 0.000224s, 100 calls @ 224us\n",
      "\n",
      "[14:37:10] InitDataOnce: 0.000212s, 1 calls @ 212us\n",
      "\n",
      "[14:37:10] Update: 1.59485s, 100 calls @ 1594851us\n",
      "\n",
      "[14:37:10] UpdatePredictionCache: 0.002402s, 100 calls @ 2402us\n",
      "\n",
      "[14:37:10] ======== Monitor (0): gradient_based_sampler ========\n",
      "[14:37:10] Sample: 0.010611s, 100 calls @ 10611us\n",
      "\n",
      "[14:37:10] ======== Monitor (0): GPUHistMakerDevice0 ========\n",
      "[14:37:10] AllReduce: 7.6e-05s, 102 calls @ 76us\n",
      "\n",
      "[14:37:10] BuildHist: 0.002019s, 2 calls @ 2019us\n",
      "\n",
      "[14:37:10] EvaluateSplits: 0.03743s, 2 calls @ 37430us\n",
      "\n",
      "[14:37:10] FinalisePosition: 0.004958s, 100 calls @ 4958us\n",
      "\n",
      "[14:37:10] InitRoot: 1.51653s, 100 calls @ 1516529us\n",
      "\n",
      "[14:37:10] Reset: 0.032402s, 100 calls @ 32402us\n",
      "\n",
      "[14:37:10] UpdatePosition: 0.000189s, 2 calls @ 189us\n",
      "\n",
      "[14:37:10] ======== Monitor (0): Learner ========\n",
      "[14:37:10] Configure: 0.010149s, 1 calls @ 10149us\n",
      "\n",
      "[14:37:10] ======== Monitor (0): GBTree ========\n",
      "[14:37:10] ======== Device 0 Memory Allocations:  ========\n",
      "[14:37:10] Peak memory usage: 1575MiB\n",
      "[14:37:10] Number of allocations: 8857\n",
      "[14:37:10] ======== Monitor (0): updater_gpu_hist ========\n",
      "[Pipeline] ......... (step 5 of 5) Processing estimator, total=   2.2s\n",
      "[14:37:22] DEBUG: /workspace/src/gbm/gbtree.cc:130: Using tree method: 3\n",
      "[14:37:22] DEBUG: /workspace/src/tree/updater_gpu_hist.cu:744: [GPU Hist]: Configure\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "      <th>corpus</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>macro avg</td>\n",
       "      <td>0.498208</td>\n",
       "      <td>0.499806</td>\n",
       "      <td>0.354818</td>\n",
       "      <td>574.0</td>\n",
       "      <td>cl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>macro avg</td>\n",
       "      <td>0.282972</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.361407</td>\n",
       "      <td>599.0</td>\n",
       "      <td>ig</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>macro avg</td>\n",
       "      <td>0.296837</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.372519</td>\n",
       "      <td>411.0</td>\n",
       "      <td>gl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>macro avg</td>\n",
       "      <td>0.536691</td>\n",
       "      <td>0.518838</td>\n",
       "      <td>0.460963</td>\n",
       "      <td>272.0</td>\n",
       "      <td>lu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>macro avg</td>\n",
       "      <td>0.430851</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.462857</td>\n",
       "      <td>188.0</td>\n",
       "      <td>bo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>macro avg</td>\n",
       "      <td>0.648479</td>\n",
       "      <td>0.644532</td>\n",
       "      <td>0.634779</td>\n",
       "      <td>774.0</td>\n",
       "      <td>co</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       class  precision    recall  f1-score  support corpus\n",
       "2  macro avg   0.498208  0.499806  0.354818    574.0     cl\n",
       "3  macro avg   0.282972  0.500000  0.361407    599.0     ig\n",
       "3  macro avg   0.296837  0.500000  0.372519    411.0     gl\n",
       "3  macro avg   0.536691  0.518838  0.460963    272.0     lu\n",
       "3  macro avg   0.430851  0.500000  0.462857    188.0     bo\n",
       "2  macro avg   0.648479  0.644532  0.634779    774.0     co"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define pipeline steps \n",
    "text_vect = TfidfVectorizer(\n",
    "            stop_words = stopwords.words('portuguese'),\n",
    "            lowercase = True,\n",
    "            ngram_range = (1,3),\n",
    "            max_features=50000\n",
    "            \n",
    "            )\n",
    "sampling = None\n",
    "selection = None\n",
    "scaling = MaxAbsScaler()\n",
    "estimator = XGBClassifier(\n",
    "                random_state = 42,\n",
    "                verbosity = 3,\n",
    "                device = 'cuda',\n",
    "                tree_method = 'hist'\n",
    "                )\n",
    "\n",
    "\n",
    "# get results\n",
    "df_cr, df_test_results = process_classification(\n",
    "        estimator = estimator,\n",
    "        vectorizer = text_vect,\n",
    "        scaling = scaling,\n",
    "        selection= selection,\n",
    "        data_tuples = list_tuples_top_ment,\n",
    "        X_cols = X_cols\n",
    ")\n",
    "\n",
    "df_cr[df_cr['class'] == 'macro avg'].sort_values('f1-score')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6/6 [00:32<00:00,  5.48s/it]\n"
     ]
    }
   ],
   "source": [
    "# create a list of tuples with (data_train, data_test, target)\n",
    "\n",
    "list_tuples_users = []\n",
    "\n",
    "for target in tqdm(list_target):\n",
    "\n",
    "    path_data_train = path_raw_data + f'r3_{target}_train_users.csv'\n",
    "    path_data_test = path_raw_data + f'r3_{target}_test_users.csv'\n",
    "\n",
    "    data_train = pd.read_csv(\n",
    "        path_data_train, \n",
    "        sep = ';', \n",
    "        encoding='utf-8-sig'\n",
    "        )\n",
    "    data_test = pd.read_csv(\n",
    "        path_data_test, \n",
    "        sep = ';', \n",
    "        encoding='utf-8-sig'\n",
    "        )\n",
    "    \n",
    "    list_tuples_users.append((data_train, data_test, target))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Timelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_cols = 'Timeline'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ...\n"
     ]
    }
   ],
   "source": [
    "# define pipeline steps \n",
    "text_vect = TfidfVectorizer(\n",
    "            stop_words = stopwords.words('portuguese'),\n",
    "            lowercase = True,\n",
    "            ngram_range = (1,3),\n",
    "            max_features=50000\n",
    "            \n",
    "            )\n",
    "sampling = None\n",
    "selection = None\n",
    "scaling = MaxAbsScaler()\n",
    "estimator = XGBClassifier(\n",
    "                random_state = 42,\n",
    "                verbosity = 3,\n",
    "                device = 'cuda',\n",
    "                tree_method = 'hist'\n",
    "                )\n",
    "\n",
    "\n",
    "# get results\n",
    "df_cr, df_test_results = process_classification(\n",
    "        estimator = estimator,\n",
    "        vectorizer= text_vect,\n",
    "        scaling = scaling,\n",
    "        selection= selection,\n",
    "        data_tuples = list_tuples_users,\n",
    "        X_cols = X_cols\n",
    ")\n",
    "\n",
    "df_cr[df_cr['class'] == 'macro avg'].sort_values('f1-score')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Stance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_cols = 'Stance'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ...\n",
      "[Pipeline] ........ (step 1 of 5) Processing vectorizer, total=   0.1s\n",
      "[Pipeline] .......... (step 2 of 5) Processing sampling, total=   0.0s\n",
      "[Pipeline] ........... (step 3 of 5) Processing scaling, total=   0.0s\n",
      "[Pipeline] ......... (step 4 of 5) Processing selection, total=   0.0s\n",
      "[14:22:15] ======== Monitor (0): HostSketchContainer ========\n",
      "[14:22:15] AllReduce: 0.000964s, 1 calls @ 964us\n",
      "\n",
      "[14:22:15] MakeCuts: 0.002772s, 1 calls @ 2772us\n",
      "\n",
      "[14:22:15] DEBUG: /workspace/src/gbm/gbtree.cc:130: Using tree method: 3\n",
      "[14:22:15] DEBUG: /workspace/src/tree/updater_gpu_hist.cu:744: [GPU Hist]: Configure\n",
      "[14:22:15] ======== Monitor (0):  ========\n",
      "[14:22:15] InitCompressedData: 9.2e-05s, 1 calls @ 92us\n",
      "\n",
      "[14:22:15] DEBUG: /workspace/src/tree/gpu_hist/../../common/device_helpers.cuh:291: Skipping empty CUDA kernel.\n",
      "[14:22:15] DEBUG: /workspace/src/tree/gpu_hist/../../common/device_helpers.cuh:291: Skipping empty CUDA kernel.\n",
      "[14:22:15] DEBUG: /workspace/src/tree/gpu_hist/../../common/device_helpers.cuh:291: Skipping empty CUDA kernel.\n",
      "[14:22:15] DEBUG: /workspace/src/tree/gpu_hist/../../common/device_helpers.cuh:291: Skipping empty CUDA kernel.\n",
      "[14:22:15] DEBUG: /workspace/src/tree/gpu_hist/../../common/device_helpers.cuh:291: Skipping empty CUDA kernel.\n",
      "[14:22:15] DEBUG: /workspace/src/tree/gpu_hist/../../common/device_helpers.cuh:291: Skipping empty CUDA kernel.\n",
      "[14:22:15] DEBUG: /workspace/src/tree/gpu_hist/../../common/device_helpers.cuh:291: Skipping empty CUDA kernel.\n",
      "[14:22:15] DEBUG: /workspace/src/tree/gpu_hist/../../common/device_helpers.cuh:291: Skipping empty CUDA kernel.\n",
      "[14:22:15] DEBUG: /workspace/src/tree/gpu_hist/../../common/device_helpers.cuh:291: Skipping empty CUDA kernel.\n",
      "[14:22:15] DEBUG: /workspace/src/tree/gpu_hist/../../common/device_helpers.cuh:291: Skipping empty CUDA kernel.\n",
      "[14:22:15] DEBUG: /workspace/src/tree/gpu_hist/../../common/device_helpers.cuh:291: Skipping empty CUDA kernel.\n",
      "[14:22:15] DEBUG: /workspace/src/tree/gpu_hist/../../common/device_helpers.cuh:291: Skipping empty CUDA kernel.\n",
      "[14:22:15] DEBUG: /workspace/src/tree/gpu_hist/../../common/device_helpers.cuh:291: Skipping empty CUDA kernel.\n",
      "[14:22:15] DEBUG: /workspace/src/tree/gpu_hist/../../common/device_helpers.cuh:291: Skipping empty CUDA kernel.\n",
      "[14:22:15] DEBUG: /workspace/src/tree/gpu_hist/../../common/device_helpers.cuh:291: Skipping empty CUDA kernel.\n",
      "[14:22:15] ======== Monitor (0): Learner ========\n",
      "[14:22:15] Configure: 0.009645s, 1 calls @ 9645us\n",
      "\n",
      "[14:22:15] EvalOneIter: 0.000396s, 100 calls @ 396us\n",
      "\n",
      "[14:22:15] GetGradient: 0.004561s, 100 calls @ 4561us\n",
      "\n",
      "[14:22:15] PredictRaw: 9.6e-05s, 100 calls @ 96us\n",
      "\n",
      "[14:22:15] UpdateOneIter: 0.579503s, 100 calls @ 579503us\n",
      "\n",
      "[14:22:15] ======== Monitor (0): GBTree ========\n",
      "[14:22:15] BoostNewTrees: 0.563635s, 100 calls @ 563635us\n",
      "\n",
      "[14:22:15] CommitModel: 3.4e-05s, 100 calls @ 34us\n",
      "\n",
      "[14:22:15] ======== Device 0 Memory Allocations:  ========\n",
      "[14:22:15] Peak memory usage: 99MiB\n",
      "[14:22:15] Number of allocations: 15488\n",
      "[14:22:15] ======== Monitor (0): updater_gpu_hist ========\n",
      "[14:22:15] InitData: 0.000269s, 100 calls @ 269us\n",
      "\n",
      "[14:22:15] InitDataOnce: 0.000252s, 1 calls @ 252us\n",
      "\n",
      "[14:22:15] Update: 0.559736s, 100 calls @ 559736us\n",
      "\n",
      "[14:22:15] UpdatePredictionCache: 0.003458s, 100 calls @ 3458us\n",
      "\n",
      "[14:22:15] ======== Monitor (0): gradient_based_sampler ========\n",
      "[14:22:15] Sample: 0.000977s, 100 calls @ 977us\n",
      "\n",
      "[14:22:15] ======== Monitor (0): GPUHistMakerDevice0 ========\n",
      "[14:22:15] AllReduce: 0.000113s, 149 calls @ 113us\n",
      "\n",
      "[14:22:15] BuildHist: 0.001668s, 58 calls @ 1668us\n",
      "\n",
      "[14:22:15] EvaluateSplits: 0.333334s, 58 calls @ 333334us\n",
      "\n",
      "[14:22:15] FinalisePosition: 0.006197s, 100 calls @ 6197us\n",
      "\n",
      "[14:22:15] InitRoot: 0.186274s, 100 calls @ 186274us\n",
      "\n",
      "[14:22:15] Reset: 0.022076s, 100 calls @ 22076us\n",
      "\n",
      "[14:22:15] UpdatePosition: 0.008422s, 58 calls @ 8422us\n",
      "\n",
      "[Pipeline] ......... (step 5 of 5) Processing estimator, total=   0.6s\n",
      "[14:22:15] DEBUG: /workspace/src/gbm/gbtree.cc:130: Using tree method: 3\n",
      "[14:22:15] DEBUG: /workspace/src/tree/updater_gpu_hist.cu:744: [GPU Hist]: Configure\n",
      "Training ...\n",
      "[Pipeline] ........ (step 1 of 5) Processing vectorizer, total=   0.0s\n",
      "[Pipeline] .......... (step 2 of 5) Processing sampling, total=   0.0s\n",
      "[Pipeline] ........... (step 3 of 5) Processing scaling, total=   0.0s\n",
      "[Pipeline] ......... (step 4 of 5) Processing selection, total=   0.0s\n",
      "[14:22:15] ======== Monitor (0): HostSketchContainer ========\n",
      "[14:22:15] AllReduce: 0.000365s, 1 calls @ 365us\n",
      "\n",
      "[14:22:15] MakeCuts: 0.001016s, 1 calls @ 1016us\n",
      "\n",
      "[14:22:15] DEBUG: /workspace/src/gbm/gbtree.cc:130: Using tree method: 3\n",
      "[14:22:15] DEBUG: /workspace/src/tree/updater_gpu_hist.cu:744: [GPU Hist]: Configure\n",
      "[14:22:15] ======== Monitor (0):  ========\n",
      "[14:22:15] InitCompressedData: 1.8e-05s, 1 calls @ 18us\n",
      "\n",
      "[14:22:15] DEBUG: /workspace/src/tree/gpu_hist/../../common/device_helpers.cuh:291: Skipping empty CUDA kernel.\n",
      "[14:22:15] DEBUG: /workspace/src/tree/gpu_hist/../../common/device_helpers.cuh:291: Skipping empty CUDA kernel.\n",
      "[14:22:15] DEBUG: /workspace/src/tree/gpu_hist/../../common/device_helpers.cuh:291: Skipping empty CUDA kernel.\n",
      "[14:22:15] DEBUG: /workspace/src/tree/gpu_hist/../../common/device_helpers.cuh:291: Skipping empty CUDA kernel.\n",
      "[14:22:15] DEBUG: /workspace/src/tree/gpu_hist/../../common/device_helpers.cuh:291: Skipping empty CUDA kernel.\n",
      "[14:22:15] DEBUG: /workspace/src/tree/gpu_hist/../../common/device_helpers.cuh:291: Skipping empty CUDA kernel.\n",
      "[14:22:15] DEBUG: /workspace/src/tree/gpu_hist/../../common/device_helpers.cuh:291: Skipping empty CUDA kernel.\n",
      "[14:22:15] DEBUG: /workspace/src/tree/gpu_hist/../../common/device_helpers.cuh:291: Skipping empty CUDA kernel.\n",
      "[14:22:15] DEBUG: /workspace/src/tree/gpu_hist/../../common/device_helpers.cuh:291: Skipping empty CUDA kernel.\n",
      "[14:22:15] DEBUG: /workspace/src/tree/gpu_hist/../../common/device_helpers.cuh:291: Skipping empty CUDA kernel.\n",
      "[14:22:15] DEBUG: /workspace/src/tree/gpu_hist/../../common/device_helpers.cuh:291: Skipping empty CUDA kernel.\n",
      "[14:22:15] DEBUG: /workspace/src/tree/gpu_hist/../../common/device_helpers.cuh:291: Skipping empty CUDA kernel.\n",
      "[14:22:15] DEBUG: /workspace/src/tree/gpu_hist/../../common/device_helpers.cuh:291: Skipping empty CUDA kernel.\n",
      "[14:22:15] DEBUG: /workspace/src/tree/gpu_hist/../../common/device_helpers.cuh:291: Skipping empty CUDA kernel.\n",
      "[14:22:15] DEBUG: /workspace/src/tree/gpu_hist/../../common/device_helpers.cuh:291: Skipping empty CUDA kernel.\n",
      "[14:22:15] DEBUG: /workspace/src/tree/gpu_hist/../../common/device_helpers.cuh:291: Skipping empty CUDA kernel.\n",
      "[14:22:15] DEBUG: /workspace/src/tree/gpu_hist/../../common/device_helpers.cuh:291: Skipping empty CUDA kernel.\n",
      "[14:22:15] DEBUG: /workspace/src/tree/gpu_hist/../../common/device_helpers.cuh:291: Skipping empty CUDA kernel.\n",
      "[14:22:15] DEBUG: /workspace/src/tree/gpu_hist/../../common/device_helpers.cuh:291: Skipping empty CUDA kernel.\n",
      "[14:22:15] DEBUG: /workspace/src/tree/gpu_hist/../../common/device_helpers.cuh:291: Skipping empty CUDA kernel.\n",
      "[14:22:16] DEBUG: /workspace/src/tree/gpu_hist/../../common/device_helpers.cuh:291: Skipping empty CUDA kernel.\n",
      "[14:22:16] DEBUG: /workspace/src/tree/gpu_hist/../../common/device_helpers.cuh:291: Skipping empty CUDA kernel.\n",
      "[14:22:16] DEBUG: /workspace/src/tree/gpu_hist/../../common/device_helpers.cuh:291: Skipping empty CUDA kernel.\n",
      "[14:22:16] DEBUG: /workspace/src/tree/gpu_hist/../../common/device_helpers.cuh:291: Skipping empty CUDA kernel.\n",
      "[14:22:16] DEBUG: /workspace/src/tree/gpu_hist/../../common/device_helpers.cuh:291: Skipping empty CUDA kernel.\n",
      "[14:22:16] DEBUG: /workspace/src/tree/gpu_hist/../../common/device_helpers.cuh:291: Skipping empty CUDA kernel.\n",
      "[14:22:16] DEBUG: /workspace/src/tree/gpu_hist/../../common/device_helpers.cuh:291: Skipping empty CUDA kernel.\n",
      "[14:22:16] DEBUG: /workspace/src/tree/gpu_hist/../../common/device_helpers.cuh:291: Skipping empty CUDA kernel.\n",
      "[14:22:16] DEBUG: /workspace/src/tree/gpu_hist/../../common/device_helpers.cuh:291: Skipping empty CUDA kernel.\n",
      "[14:22:16] DEBUG: /workspace/src/tree/gpu_hist/../../common/device_helpers.cuh:291: Skipping empty CUDA kernel.\n",
      "[14:22:16] DEBUG: /workspace/src/tree/gpu_hist/../../common/device_helpers.cuh:291: Skipping empty CUDA kernel.\n",
      "[14:22:16] DEBUG: /workspace/src/tree/gpu_hist/../../common/device_helpers.cuh:291: Skipping empty CUDA kernel.\n",
      "[14:22:16] DEBUG: /workspace/src/tree/gpu_hist/../../common/device_helpers.cuh:291: Skipping empty CUDA kernel.\n",
      "[14:22:16] DEBUG: /workspace/src/tree/gpu_hist/../../common/device_helpers.cuh:291: Skipping empty CUDA kernel.\n",
      "[14:22:16] DEBUG: /workspace/src/tree/gpu_hist/../../common/device_helpers.cuh:291: Skipping empty CUDA kernel.\n",
      "[14:22:16] DEBUG: /workspace/src/tree/gpu_hist/../../common/device_helpers.cuh:291: Skipping empty CUDA kernel.\n",
      "[14:22:16] DEBUG: /workspace/src/tree/gpu_hist/../../common/device_helpers.cuh:291: Skipping empty CUDA kernel.\n",
      "[14:22:16] DEBUG: /workspace/src/tree/gpu_hist/../../common/device_helpers.cuh:291: Skipping empty CUDA kernel.\n",
      "[14:22:16] DEBUG: /workspace/src/tree/gpu_hist/../../common/device_helpers.cuh:291: Skipping empty CUDA kernel.\n",
      "[14:22:16] DEBUG: /workspace/src/tree/gpu_hist/../../common/device_helpers.cuh:291: Skipping empty CUDA kernel.\n",
      "[14:22:16] DEBUG: /workspace/src/tree/gpu_hist/../../common/device_helpers.cuh:291: Skipping empty CUDA kernel.\n",
      "[14:22:16] DEBUG: /workspace/src/tree/gpu_hist/../../common/device_helpers.cuh:291: Skipping empty CUDA kernel.\n",
      "[14:22:16] DEBUG: /workspace/src/tree/gpu_hist/../../common/device_helpers.cuh:291: Skipping empty CUDA kernel.\n",
      "[14:22:16] DEBUG: /workspace/src/tree/gpu_hist/../../common/device_helpers.cuh:291: Skipping empty CUDA kernel.\n",
      "[14:22:16] DEBUG: /workspace/src/tree/gpu_hist/../../common/device_helpers.cuh:291: Skipping empty CUDA kernel.\n",
      "[14:22:16] DEBUG: /workspace/src/tree/gpu_hist/../../common/device_helpers.cuh:291: Skipping empty CUDA kernel.\n",
      "[14:22:16] DEBUG: /workspace/src/tree/gpu_hist/../../common/device_helpers.cuh:291: Skipping empty CUDA kernel.\n",
      "[14:22:16] DEBUG: /workspace/src/tree/gpu_hist/../../common/device_helpers.cuh:291: Skipping empty CUDA kernel.\n",
      "[14:22:16] DEBUG: /workspace/src/tree/gpu_hist/../../common/device_helpers.cuh:291: Skipping empty CUDA kernel.\n",
      "[14:22:16] DEBUG: /workspace/src/tree/gpu_hist/../../common/device_helpers.cuh:291: Skipping empty CUDA kernel.\n",
      "[14:22:16] DEBUG: /workspace/src/tree/gpu_hist/../../common/device_helpers.cuh:291: Skipping empty CUDA kernel.\n",
      "[14:22:16] DEBUG: /workspace/src/tree/gpu_hist/../../common/device_helpers.cuh:291: Skipping empty CUDA kernel.\n",
      "[14:22:16] DEBUG: /workspace/src/tree/gpu_hist/../../common/device_helpers.cuh:291: Skipping empty CUDA kernel.\n",
      "[14:22:16] DEBUG: /workspace/src/tree/gpu_hist/../../common/device_helpers.cuh:291: Skipping empty CUDA kernel.\n",
      "[14:22:16] DEBUG: /workspace/src/tree/gpu_hist/../../common/device_helpers.cuh:291: Skipping empty CUDA kernel.\n",
      "[14:22:16] DEBUG: /workspace/src/tree/gpu_hist/../../common/device_helpers.cuh:291: Skipping empty CUDA kernel.\n",
      "[14:22:16] DEBUG: /workspace/src/tree/gpu_hist/../../common/device_helpers.cuh:291: Skipping empty CUDA kernel.\n",
      "[14:22:16] DEBUG: /workspace/src/tree/gpu_hist/../../common/device_helpers.cuh:291: Skipping empty CUDA kernel.\n",
      "[14:22:16] DEBUG: /workspace/src/tree/gpu_hist/../../common/device_helpers.cuh:291: Skipping empty CUDA kernel.\n",
      "[14:22:16] DEBUG: /workspace/src/tree/gpu_hist/../../common/device_helpers.cuh:291: Skipping empty CUDA kernel.\n",
      "[14:22:16] DEBUG: /workspace/src/tree/gpu_hist/../../common/device_helpers.cuh:291: Skipping empty CUDA kernel.\n",
      "[14:22:16] DEBUG: /workspace/src/tree/gpu_hist/../../common/device_helpers.cuh:291: Skipping empty CUDA kernel.\n",
      "[14:22:16] DEBUG: /workspace/src/tree/gpu_hist/../../common/device_helpers.cuh:291: Skipping empty CUDA kernel.\n",
      "[14:22:16] DEBUG: /workspace/src/tree/gpu_hist/../../common/device_helpers.cuh:291: Skipping empty CUDA kernel.\n",
      "[14:22:16] DEBUG: /workspace/src/tree/gpu_hist/../../common/device_helpers.cuh:291: Skipping empty CUDA kernel.\n",
      "[14:22:16] DEBUG: /workspace/src/tree/gpu_hist/../../common/device_helpers.cuh:291: Skipping empty CUDA kernel.\n",
      "[14:22:16] DEBUG: /workspace/src/tree/gpu_hist/../../common/device_helpers.cuh:291: Skipping empty CUDA kernel.\n",
      "[14:22:16] DEBUG: /workspace/src/tree/gpu_hist/../../common/device_helpers.cuh:291: Skipping empty CUDA kernel.\n",
      "[14:22:16] DEBUG: /workspace/src/tree/gpu_hist/../../common/device_helpers.cuh:291: Skipping empty CUDA kernel.\n",
      "[14:22:16] DEBUG: /workspace/src/tree/gpu_hist/../../common/device_helpers.cuh:291: Skipping empty CUDA kernel.\n",
      "[14:22:16] DEBUG: /workspace/src/tree/gpu_hist/../../common/device_helpers.cuh:291: Skipping empty CUDA kernel.\n",
      "[14:22:16] DEBUG: /workspace/src/tree/gpu_hist/../../common/device_helpers.cuh:291: Skipping empty CUDA kernel.\n",
      "[14:22:16] DEBUG: /workspace/src/tree/gpu_hist/../../common/device_helpers.cuh:291: Skipping empty CUDA kernel.\n",
      "[14:22:16] DEBUG: /workspace/src/tree/gpu_hist/../../common/device_helpers.cuh:291: Skipping empty CUDA kernel.\n",
      "[14:22:16] DEBUG: /workspace/src/tree/gpu_hist/../../common/device_helpers.cuh:291: Skipping empty CUDA kernel.\n",
      "[14:22:16] DEBUG: /workspace/src/tree/gpu_hist/../../common/device_helpers.cuh:291: Skipping empty CUDA kernel.\n",
      "[14:22:16] DEBUG: /workspace/src/tree/gpu_hist/../../common/device_helpers.cuh:291: Skipping empty CUDA kernel.\n",
      "[14:22:16] DEBUG: /workspace/src/tree/gpu_hist/../../common/device_helpers.cuh:291: Skipping empty CUDA kernel.\n",
      "[14:22:16] DEBUG: /workspace/src/tree/gpu_hist/../../common/device_helpers.cuh:291: Skipping empty CUDA kernel.\n",
      "[14:22:16] DEBUG: /workspace/src/tree/gpu_hist/../../common/device_helpers.cuh:291: Skipping empty CUDA kernel.\n",
      "[14:22:16] DEBUG: /workspace/src/tree/gpu_hist/../../common/device_helpers.cuh:291: Skipping empty CUDA kernel.\n",
      "[14:22:16] DEBUG: /workspace/src/tree/gpu_hist/../../common/device_helpers.cuh:291: Skipping empty CUDA kernel.\n",
      "[14:22:16] DEBUG: /workspace/src/tree/gpu_hist/../../common/device_helpers.cuh:291: Skipping empty CUDA kernel.\n",
      "[14:22:16] DEBUG: /workspace/src/tree/gpu_hist/../../common/device_helpers.cuh:291: Skipping empty CUDA kernel.\n",
      "[14:22:16] DEBUG: /workspace/src/tree/gpu_hist/../../common/device_helpers.cuh:291: Skipping empty CUDA kernel.\n",
      "[14:22:16] DEBUG: /workspace/src/tree/gpu_hist/../../common/device_helpers.cuh:291: Skipping empty CUDA kernel.\n",
      "[14:22:16] DEBUG: /workspace/src/tree/gpu_hist/../../common/device_helpers.cuh:291: Skipping empty CUDA kernel.\n",
      "[14:22:16] DEBUG: /workspace/src/tree/gpu_hist/../../common/device_helpers.cuh:291: Skipping empty CUDA kernel.\n",
      "[14:22:16] DEBUG: /workspace/src/tree/gpu_hist/../../common/device_helpers.cuh:291: Skipping empty CUDA kernel.\n",
      "[14:22:16] DEBUG: /workspace/src/tree/gpu_hist/../../common/device_helpers.cuh:291: Skipping empty CUDA kernel.\n",
      "[14:22:16] DEBUG: /workspace/src/tree/gpu_hist/../../common/device_helpers.cuh:291: Skipping empty CUDA kernel.\n",
      "[14:22:16] DEBUG: /workspace/src/tree/gpu_hist/../../common/device_helpers.cuh:291: Skipping empty CUDA kernel.\n",
      "[14:22:16] DEBUG: /workspace/src/tree/gpu_hist/../../common/device_helpers.cuh:291: Skipping empty CUDA kernel.\n",
      "[14:22:16] DEBUG: /workspace/src/tree/gpu_hist/../../common/device_helpers.cuh:291: Skipping empty CUDA kernel.\n",
      "[14:22:16] DEBUG: /workspace/src/tree/gpu_hist/../../common/device_helpers.cuh:291: Skipping empty CUDA kernel.\n",
      "[14:22:16] DEBUG: /workspace/src/tree/gpu_hist/../../common/device_helpers.cuh:291: Skipping empty CUDA kernel.\n",
      "[14:22:16] DEBUG: /workspace/src/tree/gpu_hist/../../common/device_helpers.cuh:291: Skipping empty CUDA kernel.\n",
      "[14:22:16] DEBUG: /workspace/src/tree/gpu_hist/../../common/device_helpers.cuh:291: Skipping empty CUDA kernel.\n",
      "[14:22:16] DEBUG: /workspace/src/tree/gpu_hist/../../common/device_helpers.cuh:291: Skipping empty CUDA kernel.\n",
      "[14:22:16] DEBUG: /workspace/src/tree/gpu_hist/../../common/device_helpers.cuh:291: Skipping empty CUDA kernel.\n",
      "[14:22:16] DEBUG: /workspace/src/tree/gpu_hist/../../common/device_helpers.cuh:291: Skipping empty CUDA kernel.\n",
      "[14:22:16] DEBUG: /workspace/src/tree/gpu_hist/../../common/device_helpers.cuh:291: Skipping empty CUDA kernel.\n",
      "[14:22:16] DEBUG: /workspace/src/tree/gpu_hist/../../common/device_helpers.cuh:291: Skipping empty CUDA kernel.\n",
      "[14:22:16] DEBUG: /workspace/src/tree/gpu_hist/../../common/device_helpers.cuh:291: Skipping empty CUDA kernel.\n",
      "[14:22:16] DEBUG: /workspace/src/tree/gpu_hist/../../common/device_helpers.cuh:291: Skipping empty CUDA kernel.\n",
      "[14:22:16] DEBUG: /workspace/src/tree/gpu_hist/../../common/device_helpers.cuh:291: Skipping empty CUDA kernel.\n",
      "[14:22:16] DEBUG: /workspace/src/tree/gpu_hist/../../common/device_helpers.cuh:291: Skipping empty CUDA kernel.\n",
      "[14:22:16] DEBUG: /workspace/src/tree/gpu_hist/../../common/device_helpers.cuh:291: Skipping empty CUDA kernel.\n",
      "[14:22:16] DEBUG: /workspace/src/tree/gpu_hist/../../common/device_helpers.cuh:291: Skipping empty CUDA kernel.\n",
      "[14:22:16] DEBUG: /workspace/src/tree/gpu_hist/../../common/device_helpers.cuh:291: Skipping empty CUDA kernel.\n",
      "[14:22:16] DEBUG: /workspace/src/tree/gpu_hist/../../common/device_helpers.cuh:291: Skipping empty CUDA kernel.\n",
      "[14:22:16] DEBUG: /workspace/src/tree/gpu_hist/../../common/device_helpers.cuh:291: Skipping empty CUDA kernel.\n",
      "[14:22:16] DEBUG: /workspace/src/tree/gpu_hist/../../common/device_helpers.cuh:291: Skipping empty CUDA kernel.\n",
      "[14:22:16] DEBUG: /workspace/src/tree/gpu_hist/../../common/device_helpers.cuh:291: Skipping empty CUDA kernel.\n",
      "[14:22:16] DEBUG: /workspace/src/tree/gpu_hist/../../common/device_helpers.cuh:291: Skipping empty CUDA kernel.\n",
      "[14:22:16] DEBUG: /workspace/src/tree/gpu_hist/../../common/device_helpers.cuh:291: Skipping empty CUDA kernel.\n",
      "[14:22:16] DEBUG: /workspace/src/tree/gpu_hist/../../common/device_helpers.cuh:291: Skipping empty CUDA kernel.\n",
      "[14:22:16] DEBUG: /workspace/src/tree/gpu_hist/../../common/device_helpers.cuh:291: Skipping empty CUDA kernel.\n",
      "[14:22:16] DEBUG: /workspace/src/tree/gpu_hist/../../common/device_helpers.cuh:291: Skipping empty CUDA kernel.\n",
      "[14:22:16] DEBUG: /workspace/src/tree/gpu_hist/../../common/device_helpers.cuh:291: Skipping empty CUDA kernel.\n",
      "[14:22:16] DEBUG: /workspace/src/tree/gpu_hist/../../common/device_helpers.cuh:291: Skipping empty CUDA kernel.\n",
      "[14:22:16] DEBUG: /workspace/src/tree/gpu_hist/../../common/device_helpers.cuh:291: Skipping empty CUDA kernel.\n",
      "[14:22:16] DEBUG: /workspace/src/tree/gpu_hist/../../common/device_helpers.cuh:291: Skipping empty CUDA kernel.\n",
      "[14:22:16] DEBUG: /workspace/src/tree/gpu_hist/../../common/device_helpers.cuh:291: Skipping empty CUDA kernel.\n",
      "[14:22:16] DEBUG: /workspace/src/tree/gpu_hist/../../common/device_helpers.cuh:291: Skipping empty CUDA kernel.\n",
      "[14:22:16] DEBUG: /workspace/src/tree/gpu_hist/../../common/device_helpers.cuh:291: Skipping empty CUDA kernel.\n",
      "[14:22:16] DEBUG: /workspace/src/tree/gpu_hist/../../common/device_helpers.cuh:291: Skipping empty CUDA kernel.\n",
      "[14:22:16] DEBUG: /workspace/src/tree/gpu_hist/../../common/device_helpers.cuh:291: Skipping empty CUDA kernel.\n",
      "[14:22:16] DEBUG: /workspace/src/tree/gpu_hist/../../common/device_helpers.cuh:291: Skipping empty CUDA kernel.\n",
      "[14:22:16] DEBUG: /workspace/src/tree/gpu_hist/../../common/device_helpers.cuh:291: Skipping empty CUDA kernel.\n",
      "[14:22:16] DEBUG: /workspace/src/tree/gpu_hist/../../common/device_helpers.cuh:291: Skipping empty CUDA kernel.\n",
      "[14:22:16] DEBUG: /workspace/src/tree/gpu_hist/../../common/device_helpers.cuh:291: Skipping empty CUDA kernel.\n",
      "[14:22:16] DEBUG: /workspace/src/tree/gpu_hist/../../common/device_helpers.cuh:291: Skipping empty CUDA kernel.\n",
      "[14:22:16] DEBUG: /workspace/src/tree/gpu_hist/../../common/device_helpers.cuh:291: Skipping empty CUDA kernel.\n",
      "[14:22:16] DEBUG: /workspace/src/tree/gpu_hist/../../common/device_helpers.cuh:291: Skipping empty CUDA kernel.\n",
      "[14:22:16] DEBUG: /workspace/src/tree/gpu_hist/../../common/device_helpers.cuh:291: Skipping empty CUDA kernel.\n",
      "[14:22:16] DEBUG: /workspace/src/tree/gpu_hist/../../common/device_helpers.cuh:291: Skipping empty CUDA kernel.\n",
      "[14:22:16] DEBUG: /workspace/src/tree/gpu_hist/../../common/device_helpers.cuh:291: Skipping empty CUDA kernel.\n",
      "[14:22:16] DEBUG: /workspace/src/tree/gpu_hist/../../common/device_helpers.cuh:291: Skipping empty CUDA kernel.\n",
      "[14:22:16] DEBUG: /workspace/src/tree/gpu_hist/../../common/device_helpers.cuh:291: Skipping empty CUDA kernel.\n",
      "[14:22:16] DEBUG: /workspace/src/tree/gpu_hist/../../common/device_helpers.cuh:291: Skipping empty CUDA kernel.\n",
      "[14:22:16] DEBUG: /workspace/src/tree/gpu_hist/../../common/device_helpers.cuh:291: Skipping empty CUDA kernel.\n",
      "[14:22:16] DEBUG: /workspace/src/tree/gpu_hist/../../common/device_helpers.cuh:291: Skipping empty CUDA kernel.\n",
      "[14:22:16] DEBUG: /workspace/src/tree/gpu_hist/../../common/device_helpers.cuh:291: Skipping empty CUDA kernel.\n",
      "[14:22:16] DEBUG: /workspace/src/tree/gpu_hist/../../common/device_helpers.cuh:291: Skipping empty CUDA kernel.\n",
      "[14:22:16] DEBUG: /workspace/src/tree/gpu_hist/../../common/device_helpers.cuh:291: Skipping empty CUDA kernel.\n",
      "[14:22:16] DEBUG: /workspace/src/tree/gpu_hist/../../common/device_helpers.cuh:291: Skipping empty CUDA kernel.\n",
      "[14:22:16] DEBUG: /workspace/src/tree/gpu_hist/../../common/device_helpers.cuh:291: Skipping empty CUDA kernel.\n",
      "[14:22:16] DEBUG: /workspace/src/tree/gpu_hist/../../common/device_helpers.cuh:291: Skipping empty CUDA kernel.\n",
      "[14:22:16] DEBUG: /workspace/src/tree/gpu_hist/../../common/device_helpers.cuh:291: Skipping empty CUDA kernel.\n",
      "[14:22:16] DEBUG: /workspace/src/tree/gpu_hist/../../common/device_helpers.cuh:291: Skipping empty CUDA kernel.\n",
      "[14:22:16] DEBUG: /workspace/src/tree/gpu_hist/../../common/device_helpers.cuh:291: Skipping empty CUDA kernel.\n",
      "[14:22:16] DEBUG: /workspace/src/tree/gpu_hist/../../common/device_helpers.cuh:291: Skipping empty CUDA kernel.\n",
      "[14:22:16] DEBUG: /workspace/src/tree/gpu_hist/../../common/device_helpers.cuh:291: Skipping empty CUDA kernel.\n",
      "[14:22:16] DEBUG: /workspace/src/tree/gpu_hist/../../common/device_helpers.cuh:291: Skipping empty CUDA kernel.\n",
      "[14:22:16] DEBUG: /workspace/src/tree/gpu_hist/../../common/device_helpers.cuh:291: Skipping empty CUDA kernel.\n",
      "[14:22:16] DEBUG: /workspace/src/tree/gpu_hist/../../common/device_helpers.cuh:291: Skipping empty CUDA kernel.\n",
      "[14:22:16] DEBUG: /workspace/src/tree/gpu_hist/../../common/device_helpers.cuh:291: Skipping empty CUDA kernel.\n",
      "[14:22:16] DEBUG: /workspace/src/tree/gpu_hist/../../common/device_helpers.cuh:291: Skipping empty CUDA kernel.\n",
      "[14:22:16] DEBUG: /workspace/src/tree/gpu_hist/../../common/device_helpers.cuh:291: Skipping empty CUDA kernel.\n",
      "[14:22:16] DEBUG: /workspace/src/tree/gpu_hist/../../common/device_helpers.cuh:291: Skipping empty CUDA kernel.\n",
      "[14:22:16] DEBUG: /workspace/src/tree/gpu_hist/../../common/device_helpers.cuh:291: Skipping empty CUDA kernel.\n",
      "[14:22:16] DEBUG: /workspace/src/tree/gpu_hist/../../common/device_helpers.cuh:291: Skipping empty CUDA kernel.\n",
      "[14:22:16] DEBUG: /workspace/src/tree/gpu_hist/../../common/device_helpers.cuh:291: Skipping empty CUDA kernel.\n",
      "[14:22:16] DEBUG: /workspace/src/tree/gpu_hist/../../common/device_helpers.cuh:291: Skipping empty CUDA kernel.\n",
      "[14:22:16] DEBUG: /workspace/src/tree/gpu_hist/../../common/device_helpers.cuh:291: Skipping empty CUDA kernel.\n",
      "[14:22:16] DEBUG: /workspace/src/tree/gpu_hist/../../common/device_helpers.cuh:291: Skipping empty CUDA kernel.\n",
      "[14:22:16] DEBUG: /workspace/src/tree/gpu_hist/../../common/device_helpers.cuh:291: Skipping empty CUDA kernel.\n",
      "[14:22:16] DEBUG: /workspace/src/tree/gpu_hist/../../common/device_helpers.cuh:291: Skipping empty CUDA kernel.\n",
      "[14:22:16] DEBUG: /workspace/src/tree/gpu_hist/../../common/device_helpers.cuh:291: Skipping empty CUDA kernel.\n",
      "[14:22:16] DEBUG: /workspace/src/tree/gpu_hist/../../common/device_helpers.cuh:291: Skipping empty CUDA kernel.\n",
      "[14:22:16] DEBUG: /workspace/src/tree/gpu_hist/../../common/device_helpers.cuh:291: Skipping empty CUDA kernel.\n",
      "[14:22:16] DEBUG: /workspace/src/tree/gpu_hist/../../common/device_helpers.cuh:291: Skipping empty CUDA kernel.\n",
      "[14:22:16] DEBUG: /workspace/src/tree/gpu_hist/../../common/device_helpers.cuh:291: Skipping empty CUDA kernel.\n",
      "[14:22:16] DEBUG: /workspace/src/tree/gpu_hist/../../common/device_helpers.cuh:291: Skipping empty CUDA kernel.\n",
      "[14:22:16] DEBUG: /workspace/src/tree/gpu_hist/../../common/device_helpers.cuh:291: Skipping empty CUDA kernel.\n",
      "[14:22:16] DEBUG: /workspace/src/tree/gpu_hist/../../common/device_helpers.cuh:291: Skipping empty CUDA kernel.\n",
      "[14:22:16] DEBUG: /workspace/src/tree/gpu_hist/../../common/device_helpers.cuh:291: Skipping empty CUDA kernel.\n",
      "[14:22:16] DEBUG: /workspace/src/tree/gpu_hist/../../common/device_helpers.cuh:291: Skipping empty CUDA kernel.\n",
      "[14:22:16] DEBUG: /workspace/src/tree/gpu_hist/../../common/device_helpers.cuh:291: Skipping empty CUDA kernel.\n",
      "[14:22:16] DEBUG: /workspace/src/tree/gpu_hist/../../common/device_helpers.cuh:291: Skipping empty CUDA kernel.\n",
      "[14:22:16] DEBUG: /workspace/src/tree/gpu_hist/../../common/device_helpers.cuh:291: Skipping empty CUDA kernel.\n",
      "[14:22:16] DEBUG: /workspace/src/tree/gpu_hist/../../common/device_helpers.cuh:291: Skipping empty CUDA kernel.\n",
      "[14:22:16] DEBUG: /workspace/src/tree/gpu_hist/../../common/device_helpers.cuh:291: Skipping empty CUDA kernel.\n",
      "[14:22:16] DEBUG: /workspace/src/tree/gpu_hist/../../common/device_helpers.cuh:291: Skipping empty CUDA kernel.\n",
      "[14:22:16] DEBUG: /workspace/src/tree/gpu_hist/../../common/device_helpers.cuh:291: Skipping empty CUDA kernel.\n",
      "[14:22:16] DEBUG: /workspace/src/tree/gpu_hist/../../common/device_helpers.cuh:291: Skipping empty CUDA kernel.\n",
      "[14:22:16] DEBUG: /workspace/src/tree/gpu_hist/../../common/device_helpers.cuh:291: Skipping empty CUDA kernel.\n",
      "[14:22:16] DEBUG: /workspace/src/tree/gpu_hist/../../common/device_helpers.cuh:291: Skipping empty CUDA kernel.\n",
      "[14:22:16] DEBUG: /workspace/src/tree/gpu_hist/../../common/device_helpers.cuh:291: Skipping empty CUDA kernel.\n",
      "[14:22:16] DEBUG: /workspace/src/tree/gpu_hist/../../common/device_helpers.cuh:291: Skipping empty CUDA kernel.\n",
      "[14:22:16] DEBUG: /workspace/src/tree/gpu_hist/../../common/device_helpers.cuh:291: Skipping empty CUDA kernel.\n",
      "[14:22:16] DEBUG: /workspace/src/tree/gpu_hist/../../common/device_helpers.cuh:291: Skipping empty CUDA kernel.\n",
      "[14:22:16] DEBUG: /workspace/src/tree/gpu_hist/../../common/device_helpers.cuh:291: Skipping empty CUDA kernel.\n",
      "[14:22:16] DEBUG: /workspace/src/tree/gpu_hist/../../common/device_helpers.cuh:291: Skipping empty CUDA kernel.\n",
      "[14:22:16] DEBUG: /workspace/src/tree/gpu_hist/../../common/device_helpers.cuh:291: Skipping empty CUDA kernel.\n",
      "[14:22:16] DEBUG: /workspace/src/tree/gpu_hist/../../common/device_helpers.cuh:291: Skipping empty CUDA kernel.\n",
      "[14:22:16] DEBUG: /workspace/src/tree/gpu_hist/../../common/device_helpers.cuh:291: Skipping empty CUDA kernel.\n",
      "[14:22:16] DEBUG: /workspace/src/tree/gpu_hist/../../common/device_helpers.cuh:291: Skipping empty CUDA kernel.\n",
      "[14:22:16] DEBUG: /workspace/src/tree/gpu_hist/../../common/device_helpers.cuh:291: Skipping empty CUDA kernel.\n",
      "[14:22:16] DEBUG: /workspace/src/tree/gpu_hist/../../common/device_helpers.cuh:291: Skipping empty CUDA kernel.\n",
      "[14:22:16] DEBUG: /workspace/src/tree/gpu_hist/../../common/device_helpers.cuh:291: Skipping empty CUDA kernel.\n",
      "[14:22:16] DEBUG: /workspace/src/tree/gpu_hist/../../common/device_helpers.cuh:291: Skipping empty CUDA kernel.\n",
      "[14:22:16] DEBUG: /workspace/src/tree/gpu_hist/../../common/device_helpers.cuh:291: Skipping empty CUDA kernel.\n",
      "[14:22:16] DEBUG: /workspace/src/tree/gpu_hist/../../common/device_helpers.cuh:291: Skipping empty CUDA kernel.\n",
      "[14:22:16] DEBUG: /workspace/src/tree/gpu_hist/../../common/device_helpers.cuh:291: Skipping empty CUDA kernel.\n",
      "[14:22:16] DEBUG: /workspace/src/tree/gpu_hist/../../common/device_helpers.cuh:291: Skipping empty CUDA kernel.\n",
      "[14:22:16] DEBUG: /workspace/src/tree/gpu_hist/../../common/device_helpers.cuh:291: Skipping empty CUDA kernel.\n",
      "[14:22:16] DEBUG: /workspace/src/tree/gpu_hist/../../common/device_helpers.cuh:291: Skipping empty CUDA kernel.\n",
      "[14:22:16] DEBUG: /workspace/src/tree/gpu_hist/../../common/device_helpers.cuh:291: Skipping empty CUDA kernel.\n",
      "[14:22:16] DEBUG: /workspace/src/tree/gpu_hist/../../common/device_helpers.cuh:291: Skipping empty CUDA kernel.\n",
      "[14:22:16] DEBUG: /workspace/src/tree/gpu_hist/../../common/device_helpers.cuh:291: Skipping empty CUDA kernel.\n",
      "[14:22:16] DEBUG: /workspace/src/tree/gpu_hist/../../common/device_helpers.cuh:291: Skipping empty CUDA kernel.\n",
      "[14:22:16] DEBUG: /workspace/src/tree/gpu_hist/../../common/device_helpers.cuh:291: Skipping empty CUDA kernel.\n",
      "[14:22:16] DEBUG: /workspace/src/tree/gpu_hist/../../common/device_helpers.cuh:291: Skipping empty CUDA kernel.\n",
      "[14:22:16] DEBUG: /workspace/src/tree/gpu_hist/../../common/device_helpers.cuh:291: Skipping empty CUDA kernel.\n",
      "[14:22:16] DEBUG: /workspace/src/tree/gpu_hist/../../common/device_helpers.cuh:291: Skipping empty CUDA kernel.\n",
      "[14:22:16] DEBUG: /workspace/src/tree/gpu_hist/../../common/device_helpers.cuh:291: Skipping empty CUDA kernel.\n",
      "[14:22:16] DEBUG: /workspace/src/tree/gpu_hist/../../common/device_helpers.cuh:291: Skipping empty CUDA kernel.\n",
      "[14:22:16] DEBUG: /workspace/src/tree/gpu_hist/../../common/device_helpers.cuh:291: Skipping empty CUDA kernel.\n",
      "[14:22:16] DEBUG: /workspace/src/tree/gpu_hist/../../common/device_helpers.cuh:291: Skipping empty CUDA kernel.\n",
      "[14:22:16] DEBUG: /workspace/src/tree/gpu_hist/../../common/device_helpers.cuh:291: Skipping empty CUDA kernel.\n",
      "[14:22:16] DEBUG: /workspace/src/tree/gpu_hist/../../common/device_helpers.cuh:291: Skipping empty CUDA kernel.\n",
      "[14:22:16] DEBUG: /workspace/src/tree/gpu_hist/../../common/device_helpers.cuh:291: Skipping empty CUDA kernel.\n",
      "[14:22:16] DEBUG: /workspace/src/tree/gpu_hist/../../common/device_helpers.cuh:291: Skipping empty CUDA kernel.\n",
      "[14:22:16] DEBUG: /workspace/src/tree/gpu_hist/../../common/device_helpers.cuh:291: Skipping empty CUDA kernel.\n",
      "[14:22:16] DEBUG: /workspace/src/tree/gpu_hist/../../common/device_helpers.cuh:291: Skipping empty CUDA kernel.\n",
      "[14:22:16] ======== Monitor (0): Learner ========\n",
      "[14:22:16] Configure: 0.000662s, 1 calls @ 662us\n",
      "\n",
      "[14:22:16] EvalOneIter: 0.000421s, 100 calls @ 421us\n",
      "\n",
      "[14:22:16] GetGradient: 0.004751s, 100 calls @ 4751us\n",
      "\n",
      "[14:22:16] PredictRaw: 0.000112s, 100 calls @ 112us\n",
      "\n",
      "[14:22:16] UpdateOneIter: 0.744618s, 100 calls @ 744618us\n",
      "\n",
      "[14:22:16] ======== Monitor (0): GBTree ========\n",
      "[14:22:16] BoostNewTrees: 0.737602s, 100 calls @ 737602us\n",
      "\n",
      "[14:22:16] CommitModel: 4.2e-05s, 100 calls @ 42us\n",
      "\n",
      "[14:22:16] ======== Device 0 Memory Allocations:  ========\n",
      "[14:22:16] Peak memory usage: 99MiB\n",
      "[14:22:16] Number of allocations: 20477\n",
      "[14:22:16] ======== Monitor (0): updater_gpu_hist ========\n",
      "[14:22:16] InitData: 0.000224s, 100 calls @ 224us\n",
      "\n",
      "[14:22:16] InitDataOnce: 0.000206s, 1 calls @ 206us\n",
      "\n",
      "[14:22:16] Update: 0.732894s, 100 calls @ 732894us\n",
      "\n",
      "[14:22:16] UpdatePredictionCache: 0.004143s, 100 calls @ 4143us\n",
      "\n",
      "[14:22:16] ======== Monitor (0): gradient_based_sampler ========\n",
      "[14:22:16] Sample: 0.000392s, 100 calls @ 392us\n",
      "\n",
      "[14:22:16] ======== Monitor (0): GPUHistMakerDevice0 ========\n",
      "[14:22:16] AllReduce: 0.000292s, 530 calls @ 292us\n",
      "\n",
      "[14:22:16] BuildHist: 0.007913s, 488 calls @ 7913us\n",
      "\n",
      "[14:22:16] EvaluateSplits: 0.577354s, 488 calls @ 577354us\n",
      "\n",
      "[14:22:16] FinalisePosition: 0.00949s, 100 calls @ 9490us\n",
      "\n",
      "[14:22:16] InitRoot: 0.074413s, 100 calls @ 74413us\n",
      "\n",
      "[14:22:16] Reset: 0.014862s, 100 calls @ 14862us\n",
      "\n",
      "[14:22:16] UpdatePosition: 0.045843s, 488 calls @ 45843us\n",
      "\n",
      "[14:22:16] ======== Monitor (0): Learner ========\n",
      "[14:22:16] Configure: 0.00052s, 1 calls @ 520us\n",
      "\n",
      "[14:22:16] ======== Monitor (0): GBTree ========\n",
      "[14:22:16] ======== Device 0 Memory Allocations:  ========\n",
      "[14:22:16] Peak memory usage: 99MiB\n",
      "[14:22:16] Number of allocations: 20477\n",
      "[14:22:16] ======== Monitor (0): updater_gpu_hist ========\n",
      "[Pipeline] ......... (step 5 of 5) Processing estimator, total=   0.8s\n",
      "[14:22:16] DEBUG: /workspace/src/gbm/gbtree.cc:130: Using tree method: 3\n",
      "[14:22:16] DEBUG: /workspace/src/tree/updater_gpu_hist.cu:744: [GPU Hist]: Configure\n",
      "Training ...\n",
      "[Pipeline] ........ (step 1 of 5) Processing vectorizer, total=   0.1s\n",
      "[Pipeline] .......... (step 2 of 5) Processing sampling, total=   0.0s\n",
      "[Pipeline] ........... (step 3 of 5) Processing scaling, total=   0.0s\n",
      "[Pipeline] ......... (step 4 of 5) Processing selection, total=   0.0s\n",
      "[14:22:16] ======== Monitor (0): HostSketchContainer ========\n",
      "[14:22:16] AllReduce: 0.002565s, 1 calls @ 2565us\n",
      "\n",
      "[14:22:16] MakeCuts: 0.004662s, 1 calls @ 4662us\n",
      "\n",
      "[14:22:16] DEBUG: /workspace/src/gbm/gbtree.cc:130: Using tree method: 3\n",
      "[14:22:16] DEBUG: /workspace/src/tree/updater_gpu_hist.cu:744: [GPU Hist]: Configure\n",
      "[14:22:16] ======== Monitor (0):  ========\n",
      "[14:22:16] InitCompressedData: 4.5e-05s, 1 calls @ 45us\n",
      "\n",
      "[14:22:16] DEBUG: /workspace/src/tree/gpu_hist/../../common/device_helpers.cuh:291: Skipping empty CUDA kernel.\n",
      "[14:22:16] DEBUG: /workspace/src/tree/gpu_hist/../../common/device_helpers.cuh:291: Skipping empty CUDA kernel.\n",
      "[14:22:16] DEBUG: /workspace/src/tree/gpu_hist/../../common/device_helpers.cuh:291: Skipping empty CUDA kernel.\n",
      "[14:22:16] DEBUG: /workspace/src/tree/gpu_hist/../../common/device_helpers.cuh:291: Skipping empty CUDA kernel.\n",
      "[14:22:16] DEBUG: /workspace/src/tree/gpu_hist/../../common/device_helpers.cuh:291: Skipping empty CUDA kernel.\n",
      "[14:22:16] DEBUG: /workspace/src/tree/gpu_hist/../../common/device_helpers.cuh:291: Skipping empty CUDA kernel.\n",
      "[14:22:16] DEBUG: /workspace/src/tree/gpu_hist/../../common/device_helpers.cuh:291: Skipping empty CUDA kernel.\n",
      "[14:22:16] DEBUG: /workspace/src/tree/gpu_hist/../../common/device_helpers.cuh:291: Skipping empty CUDA kernel.\n",
      "[14:22:16] DEBUG: /workspace/src/tree/gpu_hist/../../common/device_helpers.cuh:291: Skipping empty CUDA kernel.\n",
      "[14:22:16] DEBUG: /workspace/src/tree/gpu_hist/../../common/device_helpers.cuh:291: Skipping empty CUDA kernel.\n",
      "[14:22:16] DEBUG: /workspace/src/tree/gpu_hist/../../common/device_helpers.cuh:291: Skipping empty CUDA kernel.\n",
      "[14:22:16] DEBUG: /workspace/src/tree/gpu_hist/../../common/device_helpers.cuh:291: Skipping empty CUDA kernel.\n",
      "[14:22:16] DEBUG: /workspace/src/tree/gpu_hist/../../common/device_helpers.cuh:291: Skipping empty CUDA kernel.\n",
      "[14:22:16] DEBUG: /workspace/src/tree/gpu_hist/../../common/device_helpers.cuh:291: Skipping empty CUDA kernel.\n",
      "[14:22:17] DEBUG: /workspace/src/tree/gpu_hist/../../common/device_helpers.cuh:291: Skipping empty CUDA kernel.\n",
      "[14:22:17] DEBUG: /workspace/src/tree/gpu_hist/../../common/device_helpers.cuh:291: Skipping empty CUDA kernel.\n",
      "[14:22:17] DEBUG: /workspace/src/tree/gpu_hist/../../common/device_helpers.cuh:291: Skipping empty CUDA kernel.\n",
      "[14:22:17] ======== Monitor (0): Learner ========\n",
      "[14:22:17] Configure: 0.000673s, 1 calls @ 673us\n",
      "\n",
      "[14:22:17] EvalOneIter: 0.000334s, 100 calls @ 334us\n",
      "\n",
      "[14:22:17] GetGradient: 0.004506s, 100 calls @ 4506us\n",
      "\n",
      "[14:22:17] PredictRaw: 8.9e-05s, 100 calls @ 89us\n",
      "\n",
      "[14:22:17] UpdateOneIter: 0.433278s, 100 calls @ 433278us\n",
      "\n",
      "[14:22:17] ======== Monitor (0): GBTree ========\n",
      "[14:22:17] BoostNewTrees: 0.426814s, 100 calls @ 426814us\n",
      "\n",
      "[14:22:17] CommitModel: 3.2e-05s, 100 calls @ 32us\n",
      "\n",
      "[14:22:17] ======== Device 0 Memory Allocations:  ========\n",
      "[14:22:17] Peak memory usage: 99MiB\n",
      "[14:22:17] Number of allocations: 22197\n",
      "[14:22:17] ======== Monitor (0): updater_gpu_hist ========\n",
      "[14:22:17] InitData: 0.000281s, 100 calls @ 281us\n",
      "\n",
      "[14:22:17] InitDataOnce: 0.000264s, 1 calls @ 264us\n",
      "\n",
      "[14:22:17] Update: 0.423287s, 100 calls @ 423287us\n",
      "\n",
      "[14:22:17] UpdatePredictionCache: 0.003117s, 100 calls @ 3117us\n",
      "\n",
      "[14:22:17] ======== Monitor (0): gradient_based_sampler ========\n",
      "[14:22:17] Sample: 0.000744s, 100 calls @ 744us\n",
      "\n",
      "[14:22:17] ======== Monitor (0): GPUHistMakerDevice0 ========\n",
      "[14:22:17] AllReduce: 9.5e-05s, 133 calls @ 95us\n",
      "\n",
      "[14:22:17] BuildHist: 0.001406s, 38 calls @ 1406us\n",
      "\n",
      "[14:22:17] EvaluateSplits: 0.17754s, 38 calls @ 177540us\n",
      "\n",
      "[14:22:17] FinalisePosition: 0.008266s, 100 calls @ 8266us\n",
      "\n",
      "[14:22:17] InitRoot: 0.205924s, 100 calls @ 205924us\n",
      "\n",
      "[14:22:17] Reset: 0.023s, 100 calls @ 23000us\n",
      "\n",
      "[14:22:17] UpdatePosition: 0.005448s, 38 calls @ 5448us\n",
      "\n",
      "[14:22:17] ======== Monitor (0): Learner ========\n",
      "[14:22:17] Configure: 0.000518s, 1 calls @ 518us\n",
      "\n",
      "[14:22:17] ======== Monitor (0): GBTree ========\n",
      "[14:22:17] ======== Device 0 Memory Allocations:  ========\n",
      "[14:22:17] Peak memory usage: 99MiB\n",
      "[14:22:17] Number of allocations: 22197\n",
      "[14:22:17] ======== Monitor (0): updater_gpu_hist ========\n",
      "[Pipeline] ......... (step 5 of 5) Processing estimator, total=   0.5s\n",
      "[14:22:17] DEBUG: /workspace/src/gbm/gbtree.cc:130: Using tree method: 3\n",
      "[14:22:17] DEBUG: /workspace/src/tree/updater_gpu_hist.cu:744: [GPU Hist]: Configure\n",
      "Training ...\n",
      "[Pipeline] ........ (step 1 of 5) Processing vectorizer, total=   0.2s\n",
      "[Pipeline] .......... (step 2 of 5) Processing sampling, total=   0.0s\n",
      "[Pipeline] ........... (step 3 of 5) Processing scaling, total=   0.0s\n",
      "[Pipeline] ......... (step 4 of 5) Processing selection, total=   0.0s\n",
      "[14:22:17] ======== Monitor (0): HostSketchContainer ========\n",
      "[14:22:17] AllReduce: 0.001522s, 1 calls @ 1522us\n",
      "\n",
      "[14:22:17] MakeCuts: 0.004997s, 1 calls @ 4997us\n",
      "\n",
      "[14:22:17] DEBUG: /workspace/src/gbm/gbtree.cc:130: Using tree method: 3\n",
      "[14:22:17] DEBUG: /workspace/src/tree/updater_gpu_hist.cu:744: [GPU Hist]: Configure\n",
      "[14:22:17] ======== Monitor (0):  ========\n",
      "[14:22:17] InitCompressedData: 0.000126s, 1 calls @ 126us\n",
      "\n",
      "[14:22:17] DEBUG: /workspace/src/tree/gpu_hist/../../common/device_helpers.cuh:291: Skipping empty CUDA kernel.\n",
      "[14:22:17] DEBUG: /workspace/src/tree/gpu_hist/../../common/device_helpers.cuh:291: Skipping empty CUDA kernel.\n",
      "[14:22:17] DEBUG: /workspace/src/tree/gpu_hist/../../common/device_helpers.cuh:291: Skipping empty CUDA kernel.\n",
      "[14:22:17] DEBUG: /workspace/src/tree/gpu_hist/../../common/device_helpers.cuh:291: Skipping empty CUDA kernel.\n",
      "[14:22:17] DEBUG: /workspace/src/tree/gpu_hist/../../common/device_helpers.cuh:291: Skipping empty CUDA kernel.\n",
      "[14:22:17] DEBUG: /workspace/src/tree/gpu_hist/../../common/device_helpers.cuh:291: Skipping empty CUDA kernel.\n",
      "[14:22:17] DEBUG: /workspace/src/tree/gpu_hist/../../common/device_helpers.cuh:291: Skipping empty CUDA kernel.\n",
      "[14:22:17] DEBUG: /workspace/src/tree/gpu_hist/../../common/device_helpers.cuh:291: Skipping empty CUDA kernel.\n",
      "[14:22:17] DEBUG: /workspace/src/tree/gpu_hist/../../common/device_helpers.cuh:291: Skipping empty CUDA kernel.\n",
      "[14:22:17] DEBUG: /workspace/src/tree/gpu_hist/../../common/device_helpers.cuh:291: Skipping empty CUDA kernel.\n",
      "[14:22:17] DEBUG: /workspace/src/tree/gpu_hist/../../common/device_helpers.cuh:291: Skipping empty CUDA kernel.\n",
      "[14:22:18] ======== Monitor (0): Learner ========\n",
      "[14:22:18] Configure: 0.000665s, 1 calls @ 665us\n",
      "\n",
      "[14:22:18] EvalOneIter: 0.000333s, 100 calls @ 333us\n",
      "\n",
      "[14:22:18] GetGradient: 0.004125s, 100 calls @ 4125us\n",
      "\n",
      "[14:22:18] PredictRaw: 9.3e-05s, 100 calls @ 93us\n",
      "\n",
      "[14:22:18] UpdateOneIter: 0.46212s, 100 calls @ 462120us\n",
      "\n",
      "[14:22:18] ======== Monitor (0): GBTree ========\n",
      "[14:22:18] BoostNewTrees: 0.456083s, 100 calls @ 456083us\n",
      "\n",
      "[14:22:18] CommitModel: 3.1e-05s, 100 calls @ 31us\n",
      "\n",
      "[14:22:18] ======== Device 0 Memory Allocations:  ========\n",
      "[14:22:18] Peak memory usage: 104MiB\n",
      "[14:22:18] Number of allocations: 23844\n",
      "[14:22:18] ======== Monitor (0): updater_gpu_hist ========\n",
      "[14:22:18] InitData: 0.000326s, 100 calls @ 326us\n",
      "\n",
      "[14:22:18] InitDataOnce: 0.000308s, 1 calls @ 308us\n",
      "\n",
      "[14:22:18] Update: 0.452974s, 100 calls @ 452974us\n",
      "\n",
      "[14:22:18] UpdatePredictionCache: 0.002701s, 100 calls @ 2701us\n",
      "\n",
      "[14:22:18] ======== Monitor (0): gradient_based_sampler ========\n",
      "[14:22:18] Sample: 0.000854s, 100 calls @ 854us\n",
      "\n",
      "[14:22:18] ======== Monitor (0): GPUHistMakerDevice0 ========\n",
      "[14:22:18] AllReduce: 8e-05s, 124 calls @ 80us\n",
      "\n",
      "[14:22:18] BuildHist: 0.00145s, 28 calls @ 1450us\n",
      "\n",
      "[14:22:18] EvaluateSplits: 0.168503s, 28 calls @ 168503us\n",
      "\n",
      "[14:22:18] FinalisePosition: 0.006509s, 100 calls @ 6509us\n",
      "\n",
      "[14:22:18] InitRoot: 0.247154s, 100 calls @ 247154us\n",
      "\n",
      "[14:22:18] Reset: 0.024794s, 100 calls @ 24794us\n",
      "\n",
      "[14:22:18] UpdatePosition: 0.002963s, 28 calls @ 2963us\n",
      "\n",
      "[14:22:18] ======== Monitor (0): Learner ========\n",
      "[14:22:18] Configure: 0.000513s, 1 calls @ 513us\n",
      "\n",
      "[14:22:18] ======== Monitor (0): GBTree ========\n",
      "[14:22:18] ======== Device 0 Memory Allocations:  ========\n",
      "[14:22:18] Peak memory usage: 104MiB\n",
      "[14:22:18] Number of allocations: 23844\n",
      "[14:22:18] ======== Monitor (0): updater_gpu_hist ========\n",
      "[Pipeline] ......... (step 5 of 5) Processing estimator, total=   0.5s\n",
      "[14:22:18] DEBUG: /workspace/src/gbm/gbtree.cc:130: Using tree method: 3\n",
      "[14:22:18] DEBUG: /workspace/src/tree/updater_gpu_hist.cu:744: [GPU Hist]: Configure\n",
      "Training ...\n",
      "[Pipeline] ........ (step 1 of 5) Processing vectorizer, total=   0.1s\n",
      "[Pipeline] .......... (step 2 of 5) Processing sampling, total=   0.0s\n",
      "[Pipeline] ........... (step 3 of 5) Processing scaling, total=   0.0s\n",
      "[Pipeline] ......... (step 4 of 5) Processing selection, total=   0.0s\n",
      "[14:22:18] ======== Monitor (0): HostSketchContainer ========\n",
      "[14:22:18] AllReduce: 0.000633s, 1 calls @ 633us\n",
      "\n",
      "[14:22:18] MakeCuts: 0.001503s, 1 calls @ 1503us\n",
      "\n",
      "[14:22:18] DEBUG: /workspace/src/gbm/gbtree.cc:130: Using tree method: 3\n",
      "[14:22:18] DEBUG: /workspace/src/tree/updater_gpu_hist.cu:744: [GPU Hist]: Configure\n",
      "[14:22:18] ======== Monitor (0):  ========\n",
      "[14:22:18] InitCompressedData: 2e-05s, 1 calls @ 20us\n",
      "\n",
      "[14:22:18] DEBUG: /workspace/src/tree/gpu_hist/../../common/device_helpers.cuh:291: Skipping empty CUDA kernel.\n",
      "[14:22:18] DEBUG: /workspace/src/tree/gpu_hist/../../common/device_helpers.cuh:291: Skipping empty CUDA kernel.\n",
      "[14:22:18] DEBUG: /workspace/src/tree/gpu_hist/../../common/device_helpers.cuh:291: Skipping empty CUDA kernel.\n",
      "[14:22:18] DEBUG: /workspace/src/tree/gpu_hist/../../common/device_helpers.cuh:291: Skipping empty CUDA kernel.\n",
      "[14:22:18] DEBUG: /workspace/src/tree/gpu_hist/../../common/device_helpers.cuh:291: Skipping empty CUDA kernel.\n",
      "[14:22:18] DEBUG: /workspace/src/tree/gpu_hist/../../common/device_helpers.cuh:291: Skipping empty CUDA kernel.\n",
      "[14:22:18] DEBUG: /workspace/src/tree/gpu_hist/../../common/device_helpers.cuh:291: Skipping empty CUDA kernel.\n",
      "[14:22:18] DEBUG: /workspace/src/tree/gpu_hist/../../common/device_helpers.cuh:291: Skipping empty CUDA kernel.\n",
      "[14:22:18] DEBUG: /workspace/src/tree/gpu_hist/../../common/device_helpers.cuh:291: Skipping empty CUDA kernel.\n",
      "[14:22:18] DEBUG: /workspace/src/tree/gpu_hist/../../common/device_helpers.cuh:291: Skipping empty CUDA kernel.\n",
      "[14:22:18] DEBUG: /workspace/src/tree/gpu_hist/../../common/device_helpers.cuh:291: Skipping empty CUDA kernel.\n",
      "[14:22:18] ======== Monitor (0): Learner ========\n",
      "[14:22:18] Configure: 0.00064s, 1 calls @ 640us\n",
      "\n",
      "[14:22:18] EvalOneIter: 0.000302s, 100 calls @ 302us\n",
      "\n",
      "[14:22:18] GetGradient: 0.004174s, 100 calls @ 4174us\n",
      "\n",
      "[14:22:18] PredictRaw: 8.2e-05s, 100 calls @ 82us\n",
      "\n",
      "[14:22:18] UpdateOneIter: 0.233645s, 100 calls @ 233645us\n",
      "\n",
      "[14:22:18] ======== Monitor (0): GBTree ========\n",
      "[14:22:18] BoostNewTrees: 0.227658s, 100 calls @ 227658us\n",
      "\n",
      "[14:22:18] CommitModel: 2.7e-05s, 100 calls @ 27us\n",
      "\n",
      "[14:22:18] ======== Device 0 Memory Allocations:  ========\n",
      "[14:22:18] Peak memory usage: 104MiB\n",
      "[14:22:18] Number of allocations: 25573\n",
      "[14:22:18] ======== Monitor (0): updater_gpu_hist ========\n",
      "[14:22:18] InitData: 0.000247s, 100 calls @ 247us\n",
      "\n",
      "[14:22:18] InitDataOnce: 0.00023s, 1 calls @ 230us\n",
      "\n",
      "[14:22:18] Update: 0.224899s, 100 calls @ 224899us\n",
      "\n",
      "[14:22:18] UpdatePredictionCache: 0.0024s, 100 calls @ 2400us\n",
      "\n",
      "[14:22:18] ======== Monitor (0): gradient_based_sampler ========\n",
      "[14:22:18] Sample: 0.000415s, 100 calls @ 415us\n",
      "\n",
      "[14:22:18] ======== Monitor (0): GPUHistMakerDevice0 ========\n",
      "[14:22:18] AllReduce: 7.5e-05s, 134 calls @ 75us\n",
      "\n",
      "[14:22:18] BuildHist: 0.000833s, 38 calls @ 833us\n",
      "\n",
      "[14:22:18] EvaluateSplits: 0.098723s, 38 calls @ 98723us\n",
      "\n",
      "[14:22:18] FinalisePosition: 0.004054s, 100 calls @ 4054us\n",
      "\n",
      "[14:22:18] InitRoot: 0.099236s, 100 calls @ 99236us\n",
      "\n",
      "[14:22:18] Reset: 0.014979s, 100 calls @ 14979us\n",
      "\n",
      "[14:22:18] UpdatePosition: 0.005502s, 38 calls @ 5502us\n",
      "\n",
      "[14:22:18] ======== Monitor (0): Learner ========\n",
      "[14:22:18] Configure: 0.000594s, 1 calls @ 594us\n",
      "\n",
      "[14:22:18] ======== Monitor (0): GBTree ========\n",
      "[14:22:18] ======== Device 0 Memory Allocations:  ========\n",
      "[14:22:18] Peak memory usage: 104MiB\n",
      "[14:22:18] Number of allocations: 25573\n",
      "[14:22:18] ======== Monitor (0): updater_gpu_hist ========\n",
      "[Pipeline] ......... (step 5 of 5) Processing estimator, total=   0.3s\n",
      "[14:22:18] DEBUG: /workspace/src/gbm/gbtree.cc:130: Using tree method: 3\n",
      "[14:22:18] DEBUG: /workspace/src/tree/updater_gpu_hist.cu:744: [GPU Hist]: Configure\n",
      "Training ...\n",
      "[Pipeline] ........ (step 1 of 5) Processing vectorizer, total=   0.0s\n",
      "[Pipeline] .......... (step 2 of 5) Processing sampling, total=   0.0s\n",
      "[Pipeline] ........... (step 3 of 5) Processing scaling, total=   0.0s\n",
      "[Pipeline] ......... (step 4 of 5) Processing selection, total=   0.0s\n",
      "[14:22:18] ======== Monitor (0): HostSketchContainer ========\n",
      "[14:22:18] AllReduce: 0.000441s, 1 calls @ 441us\n",
      "\n",
      "[14:22:18] MakeCuts: 0.001224s, 1 calls @ 1224us\n",
      "\n",
      "[14:22:18] DEBUG: /workspace/src/gbm/gbtree.cc:130: Using tree method: 3\n",
      "[14:22:18] DEBUG: /workspace/src/tree/updater_gpu_hist.cu:744: [GPU Hist]: Configure\n",
      "[14:22:18] ======== Monitor (0):  ========\n",
      "[14:22:18] InitCompressedData: 2e-05s, 1 calls @ 20us\n",
      "\n",
      "[14:22:18] DEBUG: /workspace/src/tree/gpu_hist/../../common/device_helpers.cuh:291: Skipping empty CUDA kernel.\n",
      "[14:22:18] DEBUG: /workspace/src/tree/gpu_hist/../../common/device_helpers.cuh:291: Skipping empty CUDA kernel.\n",
      "[14:22:18] DEBUG: /workspace/src/tree/gpu_hist/../../common/device_helpers.cuh:291: Skipping empty CUDA kernel.\n",
      "[14:22:18] DEBUG: /workspace/src/tree/gpu_hist/../../common/device_helpers.cuh:291: Skipping empty CUDA kernel.\n",
      "[14:22:18] DEBUG: /workspace/src/tree/gpu_hist/../../common/device_helpers.cuh:291: Skipping empty CUDA kernel.\n",
      "[14:22:18] DEBUG: /workspace/src/tree/gpu_hist/../../common/device_helpers.cuh:291: Skipping empty CUDA kernel.\n",
      "[14:22:18] DEBUG: /workspace/src/tree/gpu_hist/../../common/device_helpers.cuh:291: Skipping empty CUDA kernel.\n",
      "[14:22:18] DEBUG: /workspace/src/tree/gpu_hist/../../common/device_helpers.cuh:291: Skipping empty CUDA kernel.\n",
      "[14:22:18] DEBUG: /workspace/src/tree/gpu_hist/../../common/device_helpers.cuh:291: Skipping empty CUDA kernel.\n",
      "[14:22:18] DEBUG: /workspace/src/tree/gpu_hist/../../common/device_helpers.cuh:291: Skipping empty CUDA kernel.\n",
      "[14:22:18] DEBUG: /workspace/src/tree/gpu_hist/../../common/device_helpers.cuh:291: Skipping empty CUDA kernel.\n",
      "[14:22:18] DEBUG: /workspace/src/tree/gpu_hist/../../common/device_helpers.cuh:291: Skipping empty CUDA kernel.\n",
      "[14:22:18] ======== Monitor (0): Learner ========\n",
      "[14:22:18] Configure: 0.000626s, 1 calls @ 626us\n",
      "\n",
      "[14:22:18] EvalOneIter: 0.000303s, 100 calls @ 303us\n",
      "\n",
      "[14:22:18] GetGradient: 0.003459s, 100 calls @ 3459us\n",
      "\n",
      "[14:22:18] PredictRaw: 8.3e-05s, 100 calls @ 83us\n",
      "\n",
      "[14:22:18] UpdateOneIter: 0.211502s, 100 calls @ 211502us\n",
      "\n",
      "[14:22:18] ======== Monitor (0): GBTree ========\n",
      "[14:22:18] BoostNewTrees: 0.206279s, 100 calls @ 206279us\n",
      "\n",
      "[14:22:18] CommitModel: 2.8e-05s, 100 calls @ 28us\n",
      "\n",
      "[14:22:18] ======== Device 0 Memory Allocations:  ========\n",
      "[14:22:18] Peak memory usage: 104MiB\n",
      "[14:22:18] Number of allocations: 27294\n",
      "[14:22:18] ======== Monitor (0): updater_gpu_hist ========\n",
      "[14:22:18] InitData: 0.000253s, 100 calls @ 253us\n",
      "\n",
      "[14:22:18] InitDataOnce: 0.000237s, 1 calls @ 237us\n",
      "\n",
      "[14:22:18] Update: 0.202562s, 100 calls @ 202562us\n",
      "\n",
      "[14:22:18] UpdatePredictionCache: 0.003344s, 100 calls @ 3344us\n",
      "\n",
      "[14:22:18] ======== Monitor (0): gradient_based_sampler ========\n",
      "[14:22:18] Sample: 0.000391s, 100 calls @ 391us\n",
      "\n",
      "[14:22:18] ======== Monitor (0): GPUHistMakerDevice0 ========\n",
      "[14:22:18] AllReduce: 7.7e-05s, 133 calls @ 77us\n",
      "\n",
      "[14:22:18] BuildHist: 0.000756s, 39 calls @ 756us\n",
      "\n",
      "[14:22:18] EvaluateSplits: 0.084439s, 39 calls @ 84439us\n",
      "\n",
      "[14:22:18] FinalisePosition: 0.005101s, 100 calls @ 5101us\n",
      "\n",
      "[14:22:18] InitRoot: 0.090765s, 100 calls @ 90765us\n",
      "\n",
      "[14:22:18] Reset: 0.015859s, 100 calls @ 15859us\n",
      "\n",
      "[14:22:18] UpdatePosition: 0.004087s, 39 calls @ 4087us\n",
      "\n",
      "[14:22:18] ======== Monitor (0): Learner ========\n",
      "[14:22:18] Configure: 0.00056s, 1 calls @ 560us\n",
      "\n",
      "[14:22:18] ======== Monitor (0): GBTree ========\n",
      "[14:22:18] ======== Device 0 Memory Allocations:  ========\n",
      "[14:22:18] Peak memory usage: 104MiB\n",
      "[14:22:18] Number of allocations: 27294\n",
      "[14:22:18] ======== Monitor (0): updater_gpu_hist ========\n",
      "[Pipeline] ......... (step 5 of 5) Processing estimator, total=   0.2s\n",
      "[14:22:18] DEBUG: /workspace/src/gbm/gbtree.cc:130: Using tree method: 3\n",
      "[14:22:18] DEBUG: /workspace/src/tree/updater_gpu_hist.cu:744: [GPU Hist]: Configure\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "      <th>corpus</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>macro avg</td>\n",
       "      <td>0.512963</td>\n",
       "      <td>0.500379</td>\n",
       "      <td>0.351459</td>\n",
       "      <td>272.0</td>\n",
       "      <td>lu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>macro avg</td>\n",
       "      <td>0.642871</td>\n",
       "      <td>0.508820</td>\n",
       "      <td>0.359875</td>\n",
       "      <td>574.0</td>\n",
       "      <td>cl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>macro avg</td>\n",
       "      <td>0.516899</td>\n",
       "      <td>0.504944</td>\n",
       "      <td>0.380169</td>\n",
       "      <td>774.0</td>\n",
       "      <td>co</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>macro avg</td>\n",
       "      <td>0.466654</td>\n",
       "      <td>0.494157</td>\n",
       "      <td>0.388301</td>\n",
       "      <td>599.0</td>\n",
       "      <td>ig</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>macro avg</td>\n",
       "      <td>0.675248</td>\n",
       "      <td>0.513866</td>\n",
       "      <td>0.408320</td>\n",
       "      <td>411.0</td>\n",
       "      <td>gl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>macro avg</td>\n",
       "      <td>0.937838</td>\n",
       "      <td>0.557692</td>\n",
       "      <td>0.570307</td>\n",
       "      <td>188.0</td>\n",
       "      <td>bo</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       class  precision    recall  f1-score  support corpus\n",
       "3  macro avg   0.512963  0.500379  0.351459    272.0     lu\n",
       "3  macro avg   0.642871  0.508820  0.359875    574.0     cl\n",
       "2  macro avg   0.516899  0.504944  0.380169    774.0     co\n",
       "3  macro avg   0.466654  0.494157  0.388301    599.0     ig\n",
       "3  macro avg   0.675248  0.513866  0.408320    411.0     gl\n",
       "3  macro avg   0.937838  0.557692  0.570307    188.0     bo"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# define pipeline steps \n",
    "text_vect = TfidfVectorizer(\n",
    "            stop_words = stopwords.words('portuguese'),\n",
    "            lowercase = True,\n",
    "            ngram_range = (1,3)\n",
    "            \n",
    "            )\n",
    "sampling = None\n",
    "selection = None\n",
    "scaling = MaxAbsScaler()\n",
    "estimator = XGBClassifier(\n",
    "                random_state = 42,\n",
    "                verbosity = 3,\n",
    "                device = 'cuda',\n",
    "                tree_method = 'hist'\n",
    "                )\n",
    "\n",
    "\n",
    "# get results\n",
    "df_cr, df_test_results = process_classification(\n",
    "        estimator = estimator,\n",
    "        vectorizer= text_vect,\n",
    "        scaling = scaling,\n",
    "        selection= selection,\n",
    "        data_tuples = list_tuples_users,\n",
    "        X_cols = X_cols\n",
    ")\n",
    "\n",
    "df_cr[df_cr['class'] == 'macro avg'].sort_values('f1-score')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env-stance-pred",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
