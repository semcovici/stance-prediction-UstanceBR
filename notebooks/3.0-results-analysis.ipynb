{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.metrics import classification_report\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_results_path = '../reports/test_results/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['llama3_filteredTimeline_prompt2_Timeline_test_results.csv',\n",
       " 'llama3_filtered_Texts_prompt2_Texts_test_results.csv']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_df_t = os.listdir(test_results_path)\n",
    "list_df_t.sort()\n",
    "list_df_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "###############################################\n",
      "# ../reports/test_results/llama3_filteredTimeline_prompt2_Timeline_test_results.csv\n",
      "###############################################\n",
      "############# Church #############\n",
      "number of NaNs:  0\n",
      "total:  599\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.72      0.68       339\n",
      "           1       0.56      0.47      0.51       260\n",
      "\n",
      "    accuracy                           0.61       599\n",
      "   macro avg       0.60      0.59      0.59       599\n",
      "weighted avg       0.61      0.61      0.61       599\n",
      "\n",
      "############# Bolsonaro #############\n",
      "number of NaNs:  0\n",
      "total:  188\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.78      0.83       162\n",
      "           1       0.25      0.46      0.32        26\n",
      "\n",
      "    accuracy                           0.73       188\n",
      "   macro avg       0.57      0.62      0.58       188\n",
      "weighted avg       0.81      0.73      0.76       188\n",
      "\n",
      "############# Hidroxicloroquina #############\n",
      "number of NaNs:  0\n",
      "total:  574\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.61      0.62       289\n",
      "           1       0.62      0.64      0.63       285\n",
      "\n",
      "    accuracy                           0.62       574\n",
      "   macro avg       0.62      0.62      0.62       574\n",
      "weighted avg       0.62      0.62      0.62       574\n",
      "\n",
      "############# Sinovac #############\n",
      "number of NaNs:  0\n",
      "total:  774\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.49      0.68      0.57       354\n",
      "           1       0.60      0.40      0.48       420\n",
      "\n",
      "    accuracy                           0.53       774\n",
      "   macro avg       0.54      0.54      0.52       774\n",
      "weighted avg       0.55      0.53      0.52       774\n",
      "\n",
      "############# Globo TV #############\n",
      "number of NaNs:  0\n",
      "total:  411\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.39      0.54      0.45       167\n",
      "           1       0.57      0.43      0.49       244\n",
      "\n",
      "    accuracy                           0.47       411\n",
      "   macro avg       0.48      0.48      0.47       411\n",
      "weighted avg       0.50      0.47      0.47       411\n",
      "\n",
      "############# Lula #############\n",
      "number of NaNs:  0\n",
      "total:  272\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.64      0.59       143\n",
      "           1       0.51      0.41      0.45       129\n",
      "\n",
      "    accuracy                           0.53       272\n",
      "   macro avg       0.53      0.53      0.52       272\n",
      "weighted avg       0.53      0.53      0.53       272\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "###############################################\n",
      "# ../reports/test_results/llama3_filtered_Texts_prompt2_Texts_test_results.csv\n",
      "###############################################\n",
      "############# Church #############\n",
      "number of NaNs:  0\n",
      "total:  599\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.29      0.39       339\n",
      "           1       0.45      0.75      0.56       260\n",
      "\n",
      "    accuracy                           0.49       599\n",
      "   macro avg       0.52      0.52      0.48       599\n",
      "weighted avg       0.53      0.49      0.47       599\n",
      "\n",
      "############# Bolsonaro #############\n",
      "number of NaNs:  0\n",
      "total:  188\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.12      0.21       162\n",
      "           1       0.14      0.92      0.25        26\n",
      "\n",
      "    accuracy                           0.23       188\n",
      "   macro avg       0.52      0.52      0.23       188\n",
      "weighted avg       0.80      0.23      0.21       188\n",
      "\n",
      "############# Hidroxicloroquina #############\n",
      "number of NaNs:  1\n",
      "total:  574\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.08      0.14       289\n",
      "           1       0.51      0.98      0.67       284\n",
      "\n",
      "    accuracy                           0.52       573\n",
      "   macro avg       0.65      0.53      0.40       573\n",
      "weighted avg       0.65      0.52      0.40       573\n",
      "\n",
      "############# Sinovac #############\n",
      "number of NaNs:  0\n",
      "total:  774\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.48      0.09      0.16       354\n",
      "           1       0.54      0.91      0.68       420\n",
      "\n",
      "    accuracy                           0.54       774\n",
      "   macro avg       0.51      0.50      0.42       774\n",
      "weighted avg       0.51      0.54      0.44       774\n",
      "\n",
      "############# Globo TV #############\n",
      "number of NaNs:  0\n",
      "total:  411\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      0.13      0.18       167\n",
      "           1       0.58      0.83      0.68       244\n",
      "\n",
      "    accuracy                           0.54       411\n",
      "   macro avg       0.46      0.48      0.43       411\n",
      "weighted avg       0.48      0.54      0.48       411\n",
      "\n",
      "############# Lula #############\n",
      "number of NaNs:  0\n",
      "total:  272\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.17      0.27       143\n",
      "           1       0.49      0.87      0.62       129\n",
      "\n",
      "    accuracy                           0.50       272\n",
      "   macro avg       0.54      0.52      0.45       272\n",
      "weighted avg       0.54      0.50      0.44       272\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_results = pd.DataFrame({})\n",
    "for file_name in list_df_t:\n",
    "    \n",
    "    full_file_name = test_results_path + file_name\n",
    "    \n",
    "    results = pd.read_csv(full_file_name)\n",
    "    print(f\"\"\"\n",
    "###############################################\n",
    "# {full_file_name}\n",
    "###############################################\"\"\") \n",
    "    \n",
    "    for target in results.target.unique():\n",
    "        \n",
    "        print(f'############# {target} #############')\n",
    "\n",
    "        \n",
    "        results_aux = results[results['target'] == target] \n",
    "        \n",
    "        print('number of NaNs: ', results_aux['y_pred'].isna().sum())\n",
    "        print('total: ', len(results_aux))\n",
    "        \n",
    "        results_aux.dropna(subset= ['y_pred'], inplace=True)\n",
    "        \n",
    "        if len(results_aux) == 0: continue\n",
    "    \n",
    "        cr = classification_report(results_aux.y_test, results_aux.y_pred)\n",
    "    \n",
    "        print(cr)\n",
    "    \n",
    "    print('\\n\\n')\n",
    "    \n",
    "    # df_results = pd.concat([results, df_results])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env-stance-pred",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
