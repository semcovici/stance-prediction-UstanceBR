{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from sklearn.metrics import classification_report\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_results_path = '../reports/test_results/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['llama3_filteredTimeline15_prompt2_Timeline_test_results.csv',\n",
       " 'llama3_filteredTimeline5_prompt2_Timeline_test_results.csv',\n",
       " 'llama3_filteredTimeline_prompt2_Timeline_test_results.csv',\n",
       " 'llama3_filtered_Texts15_prompt2_Texts_test_results.csv',\n",
       " 'llama3_filtered_Texts5_prompt2_Texts_test_results.csv',\n",
       " 'llama3_filtered_Texts_prompt2_Texts_test_results.csv']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_df_t = os.listdir(test_results_path)\n",
    "list_df_t.sort()\n",
    "list_df_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "###############################################\n",
      "# ../reports/test_results/llama3_filteredTimeline15_prompt2_Timeline_test_results.csv\n",
      "###############################################\n",
      "############# Church #############\n",
      "number of NaNs:  0\n",
      "total:  599\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.73      0.67       339\n",
      "           1       0.55      0.44      0.49       260\n",
      "\n",
      "    accuracy                           0.60       599\n",
      "   macro avg       0.59      0.58      0.58       599\n",
      "weighted avg       0.59      0.60      0.59       599\n",
      "\n",
      "############# Bolsonaro #############\n",
      "number of NaNs:  0\n",
      "total:  188\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.69      0.77       162\n",
      "           1       0.15      0.35      0.21        26\n",
      "\n",
      "    accuracy                           0.64       188\n",
      "   macro avg       0.51      0.52      0.49       188\n",
      "weighted avg       0.77      0.64      0.69       188\n",
      "\n",
      "############# Hidroxicloroquina #############\n",
      "number of NaNs:  1\n",
      "total:  574\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.60      0.63       289\n",
      "           1       0.62      0.67      0.65       284\n",
      "\n",
      "    accuracy                           0.64       573\n",
      "   macro avg       0.64      0.64      0.64       573\n",
      "weighted avg       0.64      0.64      0.64       573\n",
      "\n",
      "############# Sinovac #############\n",
      "number of NaNs:  0\n",
      "total:  774\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.48      0.63      0.55       354\n",
      "           1       0.58      0.44      0.50       420\n",
      "\n",
      "    accuracy                           0.52       774\n",
      "   macro avg       0.53      0.53      0.52       774\n",
      "weighted avg       0.54      0.52      0.52       774\n",
      "\n",
      "############# Globo TV #############\n",
      "number of NaNs:  1\n",
      "total:  411\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.40      0.58      0.47       166\n",
      "           1       0.59      0.40      0.48       244\n",
      "\n",
      "    accuracy                           0.48       410\n",
      "   macro avg       0.49      0.49      0.48       410\n",
      "weighted avg       0.51      0.48      0.48       410\n",
      "\n",
      "############# Lula #############\n",
      "number of NaNs:  0\n",
      "total:  272\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.56      0.54       143\n",
      "           1       0.46      0.41      0.43       129\n",
      "\n",
      "    accuracy                           0.49       272\n",
      "   macro avg       0.48      0.49      0.48       272\n",
      "weighted avg       0.49      0.49      0.49       272\n",
      "\n",
      "mean\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.64      0.60      1453\n",
      "           1       0.55      0.48      0.51      1363\n",
      "\n",
      "    accuracy                           0.56      2816\n",
      "   macro avg       0.56      0.56      0.56      2816\n",
      "weighted avg       0.56      0.56      0.56      2816\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "###############################################\n",
      "# ../reports/test_results/llama3_filteredTimeline5_prompt2_Timeline_test_results.csv\n",
      "###############################################\n",
      "############# Church #############\n",
      "number of NaNs:  1\n",
      "total:  599\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.56      0.60       338\n",
      "           1       0.51      0.60      0.55       260\n",
      "\n",
      "    accuracy                           0.58       598\n",
      "   macro avg       0.58      0.58      0.58       598\n",
      "weighted avg       0.59      0.58      0.58       598\n",
      "\n",
      "############# Bolsonaro #############\n",
      "number of NaNs:  0\n",
      "total:  188\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.65      0.75       162\n",
      "           1       0.20      0.54      0.29        26\n",
      "\n",
      "    accuracy                           0.63       188\n",
      "   macro avg       0.55      0.59      0.52       188\n",
      "weighted avg       0.80      0.63      0.69       188\n",
      "\n",
      "############# Hidroxicloroquina #############\n",
      "number of NaNs:  0\n",
      "total:  574\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.59      0.61       289\n",
      "           1       0.61      0.65      0.63       285\n",
      "\n",
      "    accuracy                           0.62       574\n",
      "   macro avg       0.62      0.62      0.62       574\n",
      "weighted avg       0.62      0.62      0.62       574\n",
      "\n",
      "############# Sinovac #############\n",
      "number of NaNs:  0\n",
      "total:  774\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.47      0.64      0.54       354\n",
      "           1       0.56      0.39      0.46       420\n",
      "\n",
      "    accuracy                           0.50       774\n",
      "   macro avg       0.51      0.51      0.50       774\n",
      "weighted avg       0.52      0.50      0.49       774\n",
      "\n",
      "############# Globo TV #############\n",
      "number of NaNs:  0\n",
      "total:  411\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.45      0.50      0.47       167\n",
      "           1       0.63      0.57      0.60       244\n",
      "\n",
      "    accuracy                           0.55       411\n",
      "   macro avg       0.54      0.54      0.54       411\n",
      "weighted avg       0.55      0.55      0.55       411\n",
      "\n",
      "############# Lula #############\n",
      "number of NaNs:  0\n",
      "total:  272\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.50      0.53       143\n",
      "           1       0.50      0.57      0.53       129\n",
      "\n",
      "    accuracy                           0.53       272\n",
      "   macro avg       0.53      0.53      0.53       272\n",
      "weighted avg       0.53      0.53      0.53       272\n",
      "\n",
      "mean\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.58      0.58      1453\n",
      "           1       0.55      0.53      0.54      1364\n",
      "\n",
      "    accuracy                           0.56      2817\n",
      "   macro avg       0.56      0.56      0.56      2817\n",
      "weighted avg       0.56      0.56      0.56      2817\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "###############################################\n",
      "# ../reports/test_results/llama3_filteredTimeline_prompt2_Timeline_test_results.csv\n",
      "###############################################\n",
      "############# Church #############\n",
      "number of NaNs:  0\n",
      "total:  599\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.72      0.68       339\n",
      "           1       0.56      0.47      0.51       260\n",
      "\n",
      "    accuracy                           0.61       599\n",
      "   macro avg       0.60      0.59      0.59       599\n",
      "weighted avg       0.61      0.61      0.61       599\n",
      "\n",
      "############# Bolsonaro #############\n",
      "number of NaNs:  0\n",
      "total:  188\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.78      0.83       162\n",
      "           1       0.25      0.46      0.32        26\n",
      "\n",
      "    accuracy                           0.73       188\n",
      "   macro avg       0.57      0.62      0.58       188\n",
      "weighted avg       0.81      0.73      0.76       188\n",
      "\n",
      "############# Hidroxicloroquina #############\n",
      "number of NaNs:  0\n",
      "total:  574\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.63      0.61      0.62       289\n",
      "           1       0.62      0.64      0.63       285\n",
      "\n",
      "    accuracy                           0.62       574\n",
      "   macro avg       0.62      0.62      0.62       574\n",
      "weighted avg       0.62      0.62      0.62       574\n",
      "\n",
      "############# Sinovac #############\n",
      "number of NaNs:  0\n",
      "total:  774\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.49      0.68      0.57       354\n",
      "           1       0.60      0.40      0.48       420\n",
      "\n",
      "    accuracy                           0.53       774\n",
      "   macro avg       0.54      0.54      0.52       774\n",
      "weighted avg       0.55      0.53      0.52       774\n",
      "\n",
      "############# Globo TV #############\n",
      "number of NaNs:  0\n",
      "total:  411\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.39      0.54      0.45       167\n",
      "           1       0.57      0.43      0.49       244\n",
      "\n",
      "    accuracy                           0.47       411\n",
      "   macro avg       0.48      0.48      0.47       411\n",
      "weighted avg       0.50      0.47      0.47       411\n",
      "\n",
      "############# Lula #############\n",
      "number of NaNs:  0\n",
      "total:  272\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.64      0.59       143\n",
      "           1       0.51      0.41      0.45       129\n",
      "\n",
      "    accuracy                           0.53       272\n",
      "   macro avg       0.53      0.53      0.52       272\n",
      "weighted avg       0.53      0.53      0.53       272\n",
      "\n",
      "mean\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.67      0.62      1454\n",
      "           1       0.57      0.47      0.51      1364\n",
      "\n",
      "    accuracy                           0.57      2818\n",
      "   macro avg       0.57      0.57      0.57      2818\n",
      "weighted avg       0.57      0.57      0.57      2818\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "###############################################\n",
      "# ../reports/test_results/llama3_filtered_Texts15_prompt2_Texts_test_results.csv\n",
      "###############################################\n",
      "############# Church #############\n",
      "number of NaNs:  0\n",
      "total:  599\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.32      0.40       339\n",
      "           1       0.43      0.67      0.52       260\n",
      "\n",
      "    accuracy                           0.47       599\n",
      "   macro avg       0.49      0.49      0.46       599\n",
      "weighted avg       0.50      0.47      0.45       599\n",
      "\n",
      "############# Bolsonaro #############\n",
      "number of NaNs:  0\n",
      "total:  188\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.12      0.21       162\n",
      "           1       0.14      0.88      0.24        26\n",
      "\n",
      "    accuracy                           0.22       188\n",
      "   macro avg       0.50      0.50      0.22       188\n",
      "weighted avg       0.76      0.22      0.21       188\n",
      "\n",
      "############# Hidroxicloroquina #############\n",
      "number of NaNs:  1\n",
      "total:  574\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.05      0.10       289\n",
      "           1       0.50      0.98      0.67       284\n",
      "\n",
      "    accuracy                           0.51       573\n",
      "   macro avg       0.61      0.52      0.38       573\n",
      "weighted avg       0.61      0.51      0.38       573\n",
      "\n",
      "############# Sinovac #############\n",
      "number of NaNs:  0\n",
      "total:  774\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.39      0.08      0.13       354\n",
      "           1       0.54      0.90      0.67       420\n",
      "\n",
      "    accuracy                           0.52       774\n",
      "   macro avg       0.46      0.49      0.40       774\n",
      "weighted avg       0.47      0.52      0.42       774\n",
      "\n",
      "############# Globo TV #############\n",
      "number of NaNs:  0\n",
      "total:  411\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.50      0.14      0.22       167\n",
      "           1       0.61      0.90      0.72       244\n",
      "\n",
      "    accuracy                           0.59       411\n",
      "   macro avg       0.55      0.52      0.47       411\n",
      "weighted avg       0.56      0.59      0.52       411\n",
      "\n",
      "############# Lula #############\n",
      "number of NaNs:  0\n",
      "total:  272\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.11      0.19       143\n",
      "           1       0.49      0.94      0.64       129\n",
      "\n",
      "    accuracy                           0.50       272\n",
      "   macro avg       0.58      0.52      0.42       272\n",
      "weighted avg       0.58      0.50      0.41       272\n",
      "\n",
      "mean\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.14      0.23      1454\n",
      "           1       0.49      0.87      0.63      1363\n",
      "\n",
      "    accuracy                           0.50      2817\n",
      "   macro avg       0.52      0.51      0.43      2817\n",
      "weighted avg       0.52      0.50      0.42      2817\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "###############################################\n",
      "# ../reports/test_results/llama3_filtered_Texts5_prompt2_Texts_test_results.csv\n",
      "###############################################\n",
      "############# Church #############\n",
      "number of NaNs:  0\n",
      "total:  599\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.55      0.22      0.32       339\n",
      "           1       0.43      0.77      0.55       260\n",
      "\n",
      "    accuracy                           0.46       599\n",
      "   macro avg       0.49      0.49      0.43       599\n",
      "weighted avg       0.50      0.46      0.42       599\n",
      "\n",
      "############# Bolsonaro #############\n",
      "number of NaNs:  0\n",
      "total:  188\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.10      0.19       162\n",
      "           1       0.14      0.88      0.24        26\n",
      "\n",
      "    accuracy                           0.21       188\n",
      "   macro avg       0.49      0.49      0.21       188\n",
      "weighted avg       0.75      0.21      0.19       188\n",
      "\n",
      "############# Hidroxicloroquina #############\n",
      "number of NaNs:  0\n",
      "total:  574\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.16      0.25       289\n",
      "           1       0.50      0.84      0.63       285\n",
      "\n",
      "    accuracy                           0.50       574\n",
      "   macro avg       0.50      0.50      0.44       574\n",
      "weighted avg       0.50      0.50      0.43       574\n",
      "\n",
      "############# Sinovac #############\n",
      "number of NaNs:  0\n",
      "total:  774\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.47      0.22      0.30       354\n",
      "           1       0.55      0.79      0.65       420\n",
      "\n",
      "    accuracy                           0.53       774\n",
      "   macro avg       0.51      0.51      0.47       774\n",
      "weighted avg       0.51      0.53      0.49       774\n",
      "\n",
      "############# Globo TV #############\n",
      "number of NaNs:  0\n",
      "total:  411\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.44      0.15      0.22       167\n",
      "           1       0.60      0.87      0.71       244\n",
      "\n",
      "    accuracy                           0.58       411\n",
      "   macro avg       0.52      0.51      0.47       411\n",
      "weighted avg       0.53      0.58      0.51       411\n",
      "\n",
      "############# Lula #############\n",
      "number of NaNs:  0\n",
      "total:  272\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.48      0.10      0.16       143\n",
      "           1       0.47      0.88      0.61       129\n",
      "\n",
      "    accuracy                           0.47       272\n",
      "   macro avg       0.48      0.49      0.39       272\n",
      "weighted avg       0.48      0.47      0.38       272\n",
      "\n",
      "mean\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.51      0.18      0.26      1454\n",
      "           1       0.48      0.82      0.61      1364\n",
      "\n",
      "    accuracy                           0.49      2818\n",
      "   macro avg       0.50      0.50      0.44      2818\n",
      "weighted avg       0.50      0.49      0.43      2818\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "###############################################\n",
      "# ../reports/test_results/llama3_filtered_Texts_prompt2_Texts_test_results.csv\n",
      "###############################################\n",
      "############# Church #############\n",
      "number of NaNs:  0\n",
      "total:  599\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.29      0.39       339\n",
      "           1       0.45      0.75      0.56       260\n",
      "\n",
      "    accuracy                           0.49       599\n",
      "   macro avg       0.52      0.52      0.48       599\n",
      "weighted avg       0.53      0.49      0.47       599\n",
      "\n",
      "############# Bolsonaro #############\n",
      "number of NaNs:  0\n",
      "total:  188\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.12      0.21       162\n",
      "           1       0.14      0.92      0.25        26\n",
      "\n",
      "    accuracy                           0.23       188\n",
      "   macro avg       0.52      0.52      0.23       188\n",
      "weighted avg       0.80      0.23      0.21       188\n",
      "\n",
      "############# Hidroxicloroquina #############\n",
      "number of NaNs:  1\n",
      "total:  574\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.08      0.14       289\n",
      "           1       0.51      0.98      0.67       284\n",
      "\n",
      "    accuracy                           0.52       573\n",
      "   macro avg       0.65      0.53      0.40       573\n",
      "weighted avg       0.65      0.52      0.40       573\n",
      "\n",
      "############# Sinovac #############\n",
      "number of NaNs:  0\n",
      "total:  774\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.48      0.09      0.16       354\n",
      "           1       0.54      0.91      0.68       420\n",
      "\n",
      "    accuracy                           0.54       774\n",
      "   macro avg       0.51      0.50      0.42       774\n",
      "weighted avg       0.51      0.54      0.44       774\n",
      "\n",
      "############# Globo TV #############\n",
      "number of NaNs:  0\n",
      "total:  411\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      0.13      0.18       167\n",
      "           1       0.58      0.83      0.68       244\n",
      "\n",
      "    accuracy                           0.54       411\n",
      "   macro avg       0.46      0.48      0.43       411\n",
      "weighted avg       0.48      0.54      0.48       411\n",
      "\n",
      "############# Lula #############\n",
      "number of NaNs:  0\n",
      "total:  272\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.17      0.27       143\n",
      "           1       0.49      0.87      0.62       129\n",
      "\n",
      "    accuracy                           0.50       272\n",
      "   macro avg       0.54      0.52      0.45       272\n",
      "weighted avg       0.54      0.50      0.44       272\n",
      "\n",
      "mean\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.56      0.15      0.24      1454\n",
      "           1       0.49      0.88      0.63      1363\n",
      "\n",
      "    accuracy                           0.50      2817\n",
      "   macro avg       0.53      0.51      0.43      2817\n",
      "weighted avg       0.53      0.50      0.43      2817\n",
      "\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_results = pd.DataFrame({})\n",
    "for file_name in list_df_t:\n",
    "    \n",
    "    full_file_name = test_results_path + file_name\n",
    "    \n",
    "    results = pd.read_csv(full_file_name)\n",
    "    print(f\"\"\"\n",
    "###############################################\n",
    "# {full_file_name}\n",
    "###############################################\"\"\") \n",
    "    \n",
    "    for target in results.target.unique():\n",
    "        \n",
    "        print(f'############# {target} #############')\n",
    "\n",
    "        \n",
    "        results_aux = results[results['target'] == target] \n",
    "        \n",
    "        print('number of NaNs: ', results_aux['y_pred'].isna().sum())\n",
    "        print('total: ', len(results_aux))\n",
    "        \n",
    "        results_aux.dropna(subset= ['y_pred'], inplace=True)\n",
    "        \n",
    "        if len(results_aux) == 0: continue\n",
    "    \n",
    "        cr = classification_report(results_aux.y_test, results_aux.y_pred)\n",
    "    \n",
    "        print(cr)\n",
    "        \n",
    "    print('mean')\n",
    "    results.dropna(subset= ['y_pred'], inplace=True)\n",
    "    print(classification_report(results.y_test, results.y_pred))\n",
    "    \n",
    "    print('\\n\\n')\n",
    "    \n",
    "    # df_results = pd.concat([results, df_results])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env-stance-pred",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
