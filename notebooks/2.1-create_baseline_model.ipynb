{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.preprocessing import MaxAbsScaler\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.corpus import stopwords\n",
    "from tqdm import tqdm\n",
    "import nltk\n",
    "from sklearn.compose import ColumnTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../src/')\n",
    "from models.ClassificationPipeline import ClassificationPipeline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/semcovici/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_classification_report(y_test, y_pred):\n",
    "    '''Source: https://stackoverflow.com/questions/39662398/scikit-learn-output-metrics-classification-report-into-csv-tab-delimited-format'''\n",
    "    report = classification_report(y_test, y_pred, output_dict=True)\n",
    "    df_classification_report = pd.DataFrame(report).transpose()\n",
    "    df_classification_report = df_classification_report.sort_values(by=['f1-score'], ascending=False)\n",
    "    return df_classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_seed = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_raw_data = '../data/raw/'\n",
    "path_processed_data = '../data/processed/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = 'ig'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "### read data\n",
    "data = pd.read_csv(path_processed_data + f'train_r3_{corpus}_filtered.csv', index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User_ID</th>\n",
       "      <th>Polarity</th>\n",
       "      <th>Texts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>r2_ig_1</td>\n",
       "      <td>against</td>\n",
       "      <td>PQP ESSE DORAMA É MUITO FOADA(Sassy GoGo(Cheer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>r2_ig_4</td>\n",
       "      <td>for</td>\n",
       "      <td>Golaço!!!!!!!!! # Manda geral do time principa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>r2_ig_7</td>\n",
       "      <td>against</td>\n",
       "      <td>@gabycunha86 Amanhã vou aí, deixa pra terça # ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>r2_ig_8</td>\n",
       "      <td>for</td>\n",
       "      <td>3.4- O Centro de Coordenação da Operação está ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>r2_ig_10</td>\n",
       "      <td>for</td>\n",
       "      <td>Me arrependi de excluir meu outro tt, agora ti...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    User_ID Polarity                                              Texts\n",
       "0   r2_ig_1  against  PQP ESSE DORAMA É MUITO FOADA(Sassy GoGo(Cheer...\n",
       "1   r2_ig_4      for  Golaço!!!!!!!!! # Manda geral do time principa...\n",
       "2   r2_ig_7  against  @gabycunha86 Amanhã vou aí, deixa pra terça # ...\n",
       "3   r2_ig_8      for  3.4- O Centro de Coordenação da Operação está ...\n",
       "4  r2_ig_10      for  Me arrependi de excluir meu outro tt, agora ti..."
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data['Texts']\n",
    "y = data.Polarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    PQP ESSE DORAMA É MUITO FOADA(Sassy GoGo(Cheer...\n",
       "1    Golaço!!!!!!!!! # Manda geral do time principa...\n",
       "2    @gabycunha86 Amanhã vou aí, deixa pra terça # ...\n",
       "3    3.4- O Centro de Coordenação da Operação está ...\n",
       "4    Me arrependi de excluir meu outro tt, agora ti...\n",
       "Name: Texts, dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       0\n",
       "1       1\n",
       "2       0\n",
       "3       1\n",
       "4       1\n",
       "       ..\n",
       "1790    0\n",
       "1792    0\n",
       "1793    0\n",
       "1794    0\n",
       "1795    0\n",
       "Name: Polarity, Length: 1522, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# encode label\n",
    "y_encoded = y.map({'against': 0, 'for': 1})\n",
    "y_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42, stratify=y_encoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sem oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_vect = TfidfVectorizer(\n",
    "            stop_words = stopwords.words('portuguese'),\n",
    "            lowercase = True,\n",
    "            ngram_range = (1,3),\n",
    "            max_features=30000\n",
    "            \n",
    "            )\n",
    "sampling = None\n",
    "scaling = MaxAbsScaler()\n",
    "\n",
    "classifier = XGBClassifier(\n",
    "            random_state = 42,\n",
    "            verbosity = 3,\n",
    "            # device = 'cuda',\n",
    "            # tree_method = 'hist'\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ........ (step 1 of 4) Processing vectorizer, total= 3.3min\n",
      "[Pipeline] .......... (step 2 of 4) Processing sampling, total=   0.0s\n",
      "[Pipeline] ........... (step 3 of 4) Processing scaling, total=   0.2s\n",
      "[19:05:25] ======== Monitor (0): HostSketchContainer ========\n",
      "[19:05:25] AllReduce: 0.031764s, 1 calls @ 31764us\n",
      "\n",
      "[19:05:25] MakeCuts: 0.065356s, 1 calls @ 65356us\n",
      "\n",
      "[19:05:25] DEBUG: /workspace/src/gbm/gbtree.cc:130: Using tree method: 0\n",
      "[19:06:31] ======== Monitor (0): Learner ========\n",
      "[19:06:31] Configure: 0.00252s, 1 calls @ 2520us\n",
      "\n",
      "[19:06:31] EvalOneIter: 0.001215s, 100 calls @ 1215us\n",
      "\n",
      "[19:06:31] GetGradient: 0.115392s, 100 calls @ 115392us\n",
      "\n",
      "[19:06:31] PredictRaw: 0.000142s, 100 calls @ 142us\n",
      "\n",
      "[19:06:31] UpdateOneIter: 65.9791s, 100 calls @ 65979132us\n",
      "\n",
      "[19:06:31] ======== Monitor (0): GBTree ========\n",
      "[19:06:31] BoostNewTrees: 65.8596s, 100 calls @ 65859645us\n",
      "\n",
      "[19:06:31] CommitModel: 7.9e-05s, 100 calls @ 79us\n",
      "\n",
      "[19:06:31] ======== Monitor (0): HistUpdater ========\n",
      "[19:06:31] BuildHistogram: 27.7277s, 483 calls @ 27727652us\n",
      "\n",
      "[19:06:31] EvaluateSplits: 27.5139s, 583 calls @ 27513896us\n",
      "\n",
      "[19:06:31] InitData: 0.11024s, 100 calls @ 110240us\n",
      "\n",
      "[19:06:31] InitRoot: 11.0042s, 100 calls @ 11004167us\n",
      "\n",
      "[19:06:31] LeafPartition: 4.2e-05s, 100 calls @ 42us\n",
      "\n",
      "[19:06:31] UpdatePosition: 1.96685s, 551 calls @ 1966847us\n",
      "\n",
      "[19:06:31] UpdatePredictionCache: 0.103525s, 100 calls @ 103525us\n",
      "\n",
      "[19:06:31] UpdateTree: 65.7545s, 100 calls @ 65754489us\n",
      "\n",
      "[Pipeline] ......... (step 4 of 4) Processing estimator, total= 1.1min\n",
      "[19:06:40] DEBUG: /workspace/src/gbm/gbtree.cc:130: Using tree method: 0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.660819</td>\n",
       "      <td>0.680723</td>\n",
       "      <td>0.670623</td>\n",
       "      <td>166.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.636066</td>\n",
       "      <td>0.636066</td>\n",
       "      <td>0.636066</td>\n",
       "      <td>0.636066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.635142</td>\n",
       "      <td>0.636066</td>\n",
       "      <td>0.635433</td>\n",
       "      <td>305.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.632648</td>\n",
       "      <td>0.631728</td>\n",
       "      <td>0.632015</td>\n",
       "      <td>305.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.604478</td>\n",
       "      <td>0.582734</td>\n",
       "      <td>0.593407</td>\n",
       "      <td>139.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              precision    recall  f1-score     support\n",
       "0              0.660819  0.680723  0.670623  166.000000\n",
       "accuracy       0.636066  0.636066  0.636066    0.636066\n",
       "weighted avg   0.635142  0.636066  0.635433  305.000000\n",
       "macro avg      0.632648  0.631728  0.632015  305.000000\n",
       "1              0.604478  0.582734  0.593407  139.000000"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_pipe = ClassificationPipeline(\n",
    "    vectorizer=text_vect,\n",
    "    sampling = sampling,\n",
    "    scaling =scaling, \n",
    "    estimator= classifier\n",
    ")\n",
    "\n",
    "clf_pipe.train(X_train, y_train)\n",
    "\n",
    "y_pred, y_pred_proba = clf_pipe.predict(X_test)\n",
    "\n",
    "df_classification_report = get_classification_report(y_test, y_pred)\n",
    "\n",
    "df_classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### com oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_vect = TfidfVectorizer(\n",
    "            stop_words = stopwords.words('portuguese'),\n",
    "            lowercase = True,\n",
    "            ngram_range = (1,3),\n",
    "            max_features=30000\n",
    "            \n",
    "            )\n",
    "sampling = RandomOverSampler(random_state=random_seed)\n",
    "scaling = MaxAbsScaler()\n",
    "\n",
    "classifier = XGBClassifier(\n",
    "            random_state = 42,\n",
    "            verbosity = 3,\n",
    "            # device = 'cuda',\n",
    "            # tree_method = 'hist'\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ........ (step 1 of 4) Processing vectorizer, total= 3.2min\n",
      "[Pipeline] .......... (step 2 of 4) Processing sampling, total=   0.0s\n",
      "[Pipeline] ........... (step 3 of 4) Processing scaling, total=   0.2s\n",
      "[19:10:05] ======== Monitor (0): HostSketchContainer ========\n",
      "[19:10:05] AllReduce: 0.04035s, 1 calls @ 40350us\n",
      "\n",
      "[19:10:05] MakeCuts: 0.066544s, 1 calls @ 66544us\n",
      "\n",
      "[19:10:05] DEBUG: /workspace/src/gbm/gbtree.cc:130: Using tree method: 0\n",
      "[19:11:12] ======== Monitor (0): Learner ========\n",
      "[19:11:12] Configure: 0.000331s, 1 calls @ 331us\n",
      "\n",
      "[19:11:12] EvalOneIter: 0.001106s, 100 calls @ 1106us\n",
      "\n",
      "[19:11:12] GetGradient: 0.121384s, 100 calls @ 121384us\n",
      "\n",
      "[19:11:12] PredictRaw: 0.000148s, 100 calls @ 148us\n",
      "\n",
      "[19:11:12] UpdateOneIter: 67.1137s, 100 calls @ 67113677us\n",
      "\n",
      "[19:11:12] ======== Monitor (0): GBTree ========\n",
      "[19:11:12] BoostNewTrees: 66.9907s, 100 calls @ 66990683us\n",
      "\n",
      "[19:11:12] CommitModel: 8.8e-05s, 100 calls @ 88us\n",
      "\n",
      "[19:11:12] ======== Monitor (0): HistUpdater ========\n",
      "[19:11:12] BuildHistogram: 27.8145s, 483 calls @ 27814487us\n",
      "\n",
      "[19:11:12] EvaluateSplits: 27.8319s, 583 calls @ 27831948us\n",
      "\n",
      "[19:11:12] InitData: 0.137498s, 100 calls @ 137498us\n",
      "\n",
      "[19:11:12] InitRoot: 12.0574s, 100 calls @ 12057381us\n",
      "\n",
      "[19:11:12] LeafPartition: 3.9e-05s, 100 calls @ 39us\n",
      "\n",
      "[19:11:12] UpdatePosition: 1.54945s, 556 calls @ 1549454us\n",
      "\n",
      "[19:11:12] UpdatePredictionCache: 0.155958s, 100 calls @ 155958us\n",
      "\n",
      "[19:11:12] UpdateTree: 66.8333s, 100 calls @ 66833333us\n",
      "\n",
      "[Pipeline] ......... (step 4 of 4) Processing estimator, total= 1.1min\n",
      "[19:11:21] DEBUG: /workspace/src/gbm/gbtree.cc:130: Using tree method: 0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.674556</td>\n",
       "      <td>0.686747</td>\n",
       "      <td>0.680597</td>\n",
       "      <td>166.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.649180</td>\n",
       "      <td>0.649180</td>\n",
       "      <td>0.649180</td>\n",
       "      <td>0.64918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.648621</td>\n",
       "      <td>0.649180</td>\n",
       "      <td>0.648838</td>\n",
       "      <td>305.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.646102</td>\n",
       "      <td>0.645532</td>\n",
       "      <td>0.645753</td>\n",
       "      <td>305.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.617647</td>\n",
       "      <td>0.604317</td>\n",
       "      <td>0.610909</td>\n",
       "      <td>139.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              precision    recall  f1-score    support\n",
       "0              0.674556  0.686747  0.680597  166.00000\n",
       "accuracy       0.649180  0.649180  0.649180    0.64918\n",
       "weighted avg   0.648621  0.649180  0.648838  305.00000\n",
       "macro avg      0.646102  0.645532  0.645753  305.00000\n",
       "1              0.617647  0.604317  0.610909  139.00000"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_pipe = ClassificationPipeline(\n",
    "    vectorizer=text_vect,\n",
    "    sampling = sampling,\n",
    "    scaling =scaling, \n",
    "    estimator= classifier\n",
    ")\n",
    "\n",
    "clf_pipe.train(X_train, y_train)\n",
    "\n",
    "y_pred, y_pred_proba = clf_pipe.predict(X_test)\n",
    "\n",
    "df_classification_report = get_classification_report(y_test, y_pred)\n",
    "\n",
    "df_classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Com feature indicando a quantidade de textos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User_ID</th>\n",
       "      <th>Polarity</th>\n",
       "      <th>Texts</th>\n",
       "      <th>n_comments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>r2_ig_1</td>\n",
       "      <td>against</td>\n",
       "      <td>PQP ESSE DORAMA É MUITO FOADA(Sassy GoGo(Cheer...</td>\n",
       "      <td>878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>r2_ig_4</td>\n",
       "      <td>for</td>\n",
       "      <td>Golaço!!!!!!!!! # Manda geral do time principa...</td>\n",
       "      <td>533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>r2_ig_7</td>\n",
       "      <td>against</td>\n",
       "      <td>@gabycunha86 Amanhã vou aí, deixa pra terça # ...</td>\n",
       "      <td>956</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>r2_ig_8</td>\n",
       "      <td>for</td>\n",
       "      <td>3.4- O Centro de Coordenação da Operação está ...</td>\n",
       "      <td>1153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>r2_ig_10</td>\n",
       "      <td>for</td>\n",
       "      <td>Me arrependi de excluir meu outro tt, agora ti...</td>\n",
       "      <td>91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1790</th>\n",
       "      <td>r2_ig_2395</td>\n",
       "      <td>against</td>\n",
       "      <td>ontem a rafaela me abandonou e eu fui pro omeg...</td>\n",
       "      <td>312</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1792</th>\n",
       "      <td>r2_ig_2398</td>\n",
       "      <td>against</td>\n",
       "      <td>Em todos os 0 estados dos EUA a partir de hoje...</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1793</th>\n",
       "      <td>r2_ig_2399</td>\n",
       "      <td>against</td>\n",
       "      <td>isso daqui so eu jogando prime 0 # se rolar ví...</td>\n",
       "      <td>2579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1794</th>\n",
       "      <td>r2_ig_2400</td>\n",
       "      <td>against</td>\n",
       "      <td>@amndwz_ nao acredito! # @amndwz_ MUDANÇA # @a...</td>\n",
       "      <td>2129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1795</th>\n",
       "      <td>r2_ig_2402</td>\n",
       "      <td>against</td>\n",
       "      <td>@bmazzeo Vamos mudar isso, Bruno! Estamos espe...</td>\n",
       "      <td>431</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1522 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         User_ID Polarity                                              Texts  \\\n",
       "0        r2_ig_1  against  PQP ESSE DORAMA É MUITO FOADA(Sassy GoGo(Cheer...   \n",
       "1        r2_ig_4      for  Golaço!!!!!!!!! # Manda geral do time principa...   \n",
       "2        r2_ig_7  against  @gabycunha86 Amanhã vou aí, deixa pra terça # ...   \n",
       "3        r2_ig_8      for  3.4- O Centro de Coordenação da Operação está ...   \n",
       "4       r2_ig_10      for  Me arrependi de excluir meu outro tt, agora ti...   \n",
       "...          ...      ...                                                ...   \n",
       "1790  r2_ig_2395  against  ontem a rafaela me abandonou e eu fui pro omeg...   \n",
       "1792  r2_ig_2398  against  Em todos os 0 estados dos EUA a partir de hoje...   \n",
       "1793  r2_ig_2399  against  isso daqui so eu jogando prime 0 # se rolar ví...   \n",
       "1794  r2_ig_2400  against  @amndwz_ nao acredito! # @amndwz_ MUDANÇA # @a...   \n",
       "1795  r2_ig_2402  against  @bmazzeo Vamos mudar isso, Bruno! Estamos espe...   \n",
       "\n",
       "      n_comments  \n",
       "0            878  \n",
       "1            533  \n",
       "2            956  \n",
       "3           1153  \n",
       "4             91  \n",
       "...          ...  \n",
       "1790         312  \n",
       "1792          94  \n",
       "1793        2579  \n",
       "1794        2129  \n",
       "1795         431  \n",
       "\n",
       "[1522 rows x 4 columns]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['n_comments'] = data.Texts.apply(lambda x: len(x.split(' # ')))\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data[['Texts','n_comments']]\n",
    "y = data.Polarity\n",
    "y_encoded = y.map({'against': 0, 'for': 1})\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42, stratify=y_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_vect = TfidfVectorizer(\n",
    "            stop_words = stopwords.words('portuguese'),\n",
    "            lowercase = True,\n",
    "            ngram_range = (1,3),\n",
    "            max_features=30000\n",
    "            \n",
    "            )\n",
    "sampling = RandomOverSampler(random_state=random_seed)\n",
    "scaling = MaxAbsScaler()\n",
    "\n",
    "classifier = XGBClassifier(\n",
    "            random_state = 42,\n",
    "            verbosity = 3,\n",
    "            # device = 'cuda',\n",
    "            # tree_method = 'hist'\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('Texts', text_vect , 'Texts'),\n",
    "        ('n_comments', 'passthrough',['n_comments'])\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ........ (step 1 of 4) Processing vectorizer, total= 3.2min\n",
      "[Pipeline] .......... (step 2 of 4) Processing sampling, total=   0.0s\n",
      "[Pipeline] ........... (step 3 of 4) Processing scaling, total=   0.2s\n",
      "[19:19:57] ======== Monitor (0): HostSketchContainer ========\n",
      "[19:19:57] AllReduce: 0.05322s, 1 calls @ 53220us\n",
      "\n",
      "[19:19:57] MakeCuts: 0.092076s, 1 calls @ 92076us\n",
      "\n",
      "[19:19:57] DEBUG: /workspace/src/gbm/gbtree.cc:130: Using tree method: 0\n",
      "[19:21:07] ======== Monitor (0): Learner ========\n",
      "[19:21:07] Configure: 0.000706s, 1 calls @ 706us\n",
      "\n",
      "[19:21:07] EvalOneIter: 0.001146s, 100 calls @ 1146us\n",
      "\n",
      "[19:21:07] GetGradient: 0.092159s, 100 calls @ 92159us\n",
      "\n",
      "[19:21:07] PredictRaw: 0.000135s, 100 calls @ 135us\n",
      "\n",
      "[19:21:07] UpdateOneIter: 69.4355s, 100 calls @ 69435540us\n",
      "\n",
      "[19:21:07] ======== Monitor (0): GBTree ========\n",
      "[19:21:07] BoostNewTrees: 69.341s, 100 calls @ 69340959us\n",
      "\n",
      "[19:21:07] CommitModel: 8.2e-05s, 100 calls @ 82us\n",
      "\n",
      "[19:21:07] ======== Monitor (0): HistUpdater ========\n",
      "[19:21:07] BuildHistogram: 27.6426s, 483 calls @ 27642623us\n",
      "\n",
      "[19:21:07] EvaluateSplits: 30.1437s, 583 calls @ 30143700us\n",
      "\n",
      "[19:21:07] InitData: 0.078161s, 100 calls @ 78161us\n",
      "\n",
      "[19:21:07] InitRoot: 12.371s, 100 calls @ 12370955us\n",
      "\n",
      "[19:21:07] LeafPartition: 4.8e-05s, 100 calls @ 48us\n",
      "\n",
      "[19:21:07] UpdatePosition: 2.32696s, 556 calls @ 2326963us\n",
      "\n",
      "[19:21:07] UpdatePredictionCache: 0.10046s, 100 calls @ 100460us\n",
      "\n",
      "[19:21:07] UpdateTree: 69.2391s, 100 calls @ 69239114us\n",
      "\n",
      "[Pipeline] ......... (step 4 of 4) Processing estimator, total= 1.2min\n",
      "[19:21:17] DEBUG: /workspace/src/gbm/gbtree.cc:130: Using tree method: 0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.674556</td>\n",
       "      <td>0.686747</td>\n",
       "      <td>0.680597</td>\n",
       "      <td>166.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.649180</td>\n",
       "      <td>0.649180</td>\n",
       "      <td>0.649180</td>\n",
       "      <td>0.64918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.648621</td>\n",
       "      <td>0.649180</td>\n",
       "      <td>0.648838</td>\n",
       "      <td>305.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.646102</td>\n",
       "      <td>0.645532</td>\n",
       "      <td>0.645753</td>\n",
       "      <td>305.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.617647</td>\n",
       "      <td>0.604317</td>\n",
       "      <td>0.610909</td>\n",
       "      <td>139.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              precision    recall  f1-score    support\n",
       "0              0.674556  0.686747  0.680597  166.00000\n",
       "accuracy       0.649180  0.649180  0.649180    0.64918\n",
       "weighted avg   0.648621  0.649180  0.648838  305.00000\n",
       "macro avg      0.646102  0.645532  0.645753  305.00000\n",
       "1              0.617647  0.604317  0.610909  139.00000"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_pipe = ClassificationPipeline(\n",
    "    vectorizer=preprocessor,\n",
    "    sampling = sampling,\n",
    "    scaling =scaling, \n",
    "    estimator= classifier\n",
    ")\n",
    "\n",
    "clf_pipe.train(X_train, y_train)\n",
    "\n",
    "y_pred, y_pred_proba = clf_pipe.predict(X_test)\n",
    "\n",
    "df_classification_report = get_classification_report(y_test, y_pred)\n",
    "\n",
    "df_classification_report"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env-stance-pred",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
