{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.preprocessing import MaxAbsScaler\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.corpus import stopwords\n",
    "from tqdm import tqdm\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../src/')\n",
    "from models.ClassificationPipeline import ClassificationPipeline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/semcovici/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_classification_report(y_test, y_pred):\n",
    "    '''Source: https://stackoverflow.com/questions/39662398/scikit-learn-output-metrics-classification-report-into-csv-tab-delimited-format'''\n",
    "    report = classification_report(y_test, y_pred, output_dict=True)\n",
    "    df_classification_report = pd.DataFrame(report).transpose()\n",
    "    df_classification_report = df_classification_report.sort_values(by=['f1-score'], ascending=False)\n",
    "    return df_classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_seed = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_raw_data = '../data/raw/'\n",
    "path_processed_data = '../data/processed/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = 'ig'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_vect = TfidfVectorizer(\n",
    "            stop_words = stopwords.words('portuguese'),\n",
    "            lowercase = True,\n",
    "            ngram_range = (1,3),\n",
    "            max_features=30000\n",
    "            \n",
    "            )\n",
    "sampling = RandomOverSampler(random_state=random_seed)\n",
    "scaling = MaxAbsScaler()\n",
    "\n",
    "classifier = XGBClassifier(\n",
    "            random_state = 42,\n",
    "            verbosity = 3,\n",
    "            # device = 'cuda',\n",
    "            # tree_method = 'hist'\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "### read data\n",
    "data = pd.read_csv(path_processed_data + f'train_r3_{corpus}_filtered.csv', index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User_ID</th>\n",
       "      <th>Polarity</th>\n",
       "      <th>Texts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>r2_ig_1</td>\n",
       "      <td>against</td>\n",
       "      <td>PQP ESSE DORAMA É MUITO FOADA(Sassy GoGo(Cheer...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>r2_ig_4</td>\n",
       "      <td>for</td>\n",
       "      <td>Golaço!!!!!!!!! # Manda geral do time principa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>r2_ig_7</td>\n",
       "      <td>against</td>\n",
       "      <td>@gabycunha86 Amanhã vou aí, deixa pra terça # ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>r2_ig_8</td>\n",
       "      <td>for</td>\n",
       "      <td>3.4- O Centro de Coordenação da Operação está ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>r2_ig_10</td>\n",
       "      <td>for</td>\n",
       "      <td>Me arrependi de excluir meu outro tt, agora ti...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    User_ID Polarity                                              Texts\n",
       "0   r2_ig_1  against  PQP ESSE DORAMA É MUITO FOADA(Sassy GoGo(Cheer...\n",
       "1   r2_ig_4      for  Golaço!!!!!!!!! # Manda geral do time principa...\n",
       "2   r2_ig_7  against  @gabycunha86 Amanhã vou aí, deixa pra terça # ...\n",
       "3   r2_ig_8      for  3.4- O Centro de Coordenação da Operação está ...\n",
       "4  r2_ig_10      for  Me arrependi de excluir meu outro tt, agora ti..."
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data['Texts']\n",
    "y = data.Polarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    PQP ESSE DORAMA É MUITO FOADA(Sassy GoGo(Cheer...\n",
       "1    Golaço!!!!!!!!! # Manda geral do time principa...\n",
       "2    @gabycunha86 Amanhã vou aí, deixa pra terça # ...\n",
       "3    3.4- O Centro de Coordenação da Operação está ...\n",
       "4    Me arrependi de excluir meu outro tt, agora ti...\n",
       "Name: Texts, dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       0\n",
       "1       1\n",
       "2       0\n",
       "3       1\n",
       "4       1\n",
       "       ..\n",
       "1790    0\n",
       "1792    0\n",
       "1793    0\n",
       "1794    0\n",
       "1795    0\n",
       "Name: Polarity, Length: 1522, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# encode label\n",
    "y_encoded = y.map({'against': 0, 'for': 1})\n",
    "y_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42, stratify=y_encoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Pipeline] ........ (step 1 of 4) Processing vectorizer, total= 3.4min\n",
      "[Pipeline] .......... (step 2 of 4) Processing sampling, total=   0.0s\n",
      "[Pipeline] ........... (step 3 of 4) Processing scaling, total=   0.2s\n",
      "[01:30:11] ======== Monitor (0): HostSketchContainer ========\n",
      "[01:30:11] AllReduce: 0.037871s, 1 calls @ 37871us\n",
      "\n",
      "[01:30:11] MakeCuts: 0.072468s, 1 calls @ 72468us\n",
      "\n",
      "[01:30:11] DEBUG: /workspace/src/gbm/gbtree.cc:130: Using tree method: 0\n",
      "[01:31:24] ======== Monitor (0): Learner ========\n",
      "[01:31:24] Configure: 0.002297s, 1 calls @ 2297us\n",
      "\n",
      "[01:31:24] EvalOneIter: 0.00143s, 100 calls @ 1430us\n",
      "\n",
      "[01:31:24] GetGradient: 0.299058s, 100 calls @ 299058us\n",
      "\n",
      "[01:31:24] PredictRaw: 0.000151s, 100 calls @ 151us\n",
      "\n",
      "[01:31:24] UpdateOneIter: 73.752s, 100 calls @ 73752041us\n",
      "\n",
      "[01:31:24] ======== Monitor (0): GBTree ========\n",
      "[01:31:24] BoostNewTrees: 73.4149s, 100 calls @ 73414899us\n",
      "\n",
      "[01:31:24] CommitModel: 8e-05s, 100 calls @ 80us\n",
      "\n",
      "[01:31:24] ======== Monitor (0): HistUpdater ========\n",
      "[01:31:24] BuildHistogram: 30.1989s, 483 calls @ 30198864us\n",
      "\n",
      "[01:31:24] EvaluateSplits: 28.9595s, 583 calls @ 28959452us\n",
      "\n",
      "[01:31:24] InitData: 0.318034s, 100 calls @ 318034us\n",
      "\n",
      "[01:31:24] InitRoot: 12.4795s, 100 calls @ 12479469us\n",
      "\n",
      "[01:31:24] LeafPartition: 4.4e-05s, 100 calls @ 44us\n",
      "\n",
      "[01:31:24] UpdatePosition: 3.8844s, 556 calls @ 3884402us\n",
      "\n",
      "[01:31:24] UpdatePredictionCache: 0.308919s, 100 calls @ 308919us\n",
      "\n",
      "[01:31:24] UpdateTree: 73.1038s, 100 calls @ 73103818us\n",
      "\n",
      "[Pipeline] ......... (step 4 of 4) Processing estimator, total= 1.2min\n",
      "[01:31:34] DEBUG: /workspace/src/gbm/gbtree.cc:130: Using tree method: 0\n"
     ]
    }
   ],
   "source": [
    "clf_pipe = ClassificationPipeline(\n",
    "    vectorizer=text_vect,\n",
    "    sampling = sampling,\n",
    "    scaling =scaling, \n",
    "    estimator= classifier\n",
    ")\n",
    "\n",
    "clf_pipe.train(X_train, y_train)\n",
    "\n",
    "y_pred, y_pred_proba = clf_pipe.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_classification_report = get_classification_report(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.674556</td>\n",
       "      <td>0.686747</td>\n",
       "      <td>0.680597</td>\n",
       "      <td>166.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.649180</td>\n",
       "      <td>0.649180</td>\n",
       "      <td>0.649180</td>\n",
       "      <td>0.64918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.648621</td>\n",
       "      <td>0.649180</td>\n",
       "      <td>0.648838</td>\n",
       "      <td>305.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.646102</td>\n",
       "      <td>0.645532</td>\n",
       "      <td>0.645753</td>\n",
       "      <td>305.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.617647</td>\n",
       "      <td>0.604317</td>\n",
       "      <td>0.610909</td>\n",
       "      <td>139.00000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              precision    recall  f1-score    support\n",
       "0              0.674556  0.686747  0.680597  166.00000\n",
       "accuracy       0.649180  0.649180  0.649180    0.64918\n",
       "weighted avg   0.648621  0.649180  0.648838  305.00000\n",
       "macro avg      0.646102  0.645532  0.645753  305.00000\n",
       "1              0.617647  0.604317  0.610909  139.00000"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_classification_report"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env-stance-pred",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
