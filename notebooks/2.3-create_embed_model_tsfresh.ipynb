{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import LabelEncoder, MaxAbsScaler\n",
    "import numpy as np\n",
    "from imblearn.over_sampling import RandomOverSampler, SMOTE\n",
    "from imblearn.pipeline import Pipeline as IMBPipeline\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from nltk.corpus import stopwords\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.feature_selection import RFE\n",
    "from tsfresh.feature_extraction import MinimalFCParameters\n",
    "from tsfresh.feature_extraction import extract_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_classification_report(y_test, y_pred):\n",
    "    '''Source: https://stackoverflow.com/questions/39662398/scikit-learn-output-metrics-classification-report-into-csv-tab-delimited-format'''\n",
    "    report = classification_report(y_test, y_pred, output_dict=True)\n",
    "    df_classification_report = pd.DataFrame(report).transpose()\n",
    "    df_classification_report = df_classification_report.sort_values(by=['f1-score'], ascending=False)\n",
    "    return df_classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/semcovici/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_raw_data = '../data/raw/'\n",
    "path_processed_data = '../data/processed/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = 'ig'\n",
    "model_name = 'facebook/fasttext-pt-vectors'\n",
    "model_name = 'neuralmind/bert-base-portuguese-cased'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_data = path_processed_data + f'train_r3_{corpus}_separated_comments_{model_name.replace(\"/\", \"_\")}_tsfresh.parquet'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_parquet(path_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1800, 7682)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User_ID</th>\n",
       "      <th>emb_1__sum_values</th>\n",
       "      <th>emb_1__median</th>\n",
       "      <th>emb_1__mean</th>\n",
       "      <th>emb_1__length</th>\n",
       "      <th>emb_1__standard_deviation</th>\n",
       "      <th>emb_1__variance</th>\n",
       "      <th>emb_1__root_mean_square</th>\n",
       "      <th>emb_1__maximum</th>\n",
       "      <th>emb_1__absolute_maximum</th>\n",
       "      <th>...</th>\n",
       "      <th>emb_768__median</th>\n",
       "      <th>emb_768__mean</th>\n",
       "      <th>emb_768__length</th>\n",
       "      <th>emb_768__standard_deviation</th>\n",
       "      <th>emb_768__variance</th>\n",
       "      <th>emb_768__root_mean_square</th>\n",
       "      <th>emb_768__maximum</th>\n",
       "      <th>emb_768__absolute_maximum</th>\n",
       "      <th>emb_768__minimum</th>\n",
       "      <th>Polarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>r2_ig_1</td>\n",
       "      <td>-21.394181</td>\n",
       "      <td>-0.029887</td>\n",
       "      <td>-0.024367</td>\n",
       "      <td>878.0</td>\n",
       "      <td>0.134303</td>\n",
       "      <td>0.018037</td>\n",
       "      <td>0.136496</td>\n",
       "      <td>0.671440</td>\n",
       "      <td>0.671440</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.224691</td>\n",
       "      <td>-0.222255</td>\n",
       "      <td>878.0</td>\n",
       "      <td>0.129926</td>\n",
       "      <td>0.016881</td>\n",
       "      <td>0.257446</td>\n",
       "      <td>0.250205</td>\n",
       "      <td>0.686336</td>\n",
       "      <td>-0.686336</td>\n",
       "      <td>against</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>r2_ig_10</td>\n",
       "      <td>1.394637</td>\n",
       "      <td>0.016590</td>\n",
       "      <td>0.015326</td>\n",
       "      <td>91.0</td>\n",
       "      <td>0.132188</td>\n",
       "      <td>0.017474</td>\n",
       "      <td>0.133074</td>\n",
       "      <td>0.345923</td>\n",
       "      <td>0.345923</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.178725</td>\n",
       "      <td>-0.195514</td>\n",
       "      <td>91.0</td>\n",
       "      <td>0.137983</td>\n",
       "      <td>0.019039</td>\n",
       "      <td>0.239301</td>\n",
       "      <td>0.044307</td>\n",
       "      <td>0.725221</td>\n",
       "      <td>-0.725221</td>\n",
       "      <td>for</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>r2_ig_100</td>\n",
       "      <td>129.244744</td>\n",
       "      <td>0.026289</td>\n",
       "      <td>0.025766</td>\n",
       "      <td>5016.0</td>\n",
       "      <td>0.126746</td>\n",
       "      <td>0.016065</td>\n",
       "      <td>0.129339</td>\n",
       "      <td>0.523251</td>\n",
       "      <td>0.523251</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.228821</td>\n",
       "      <td>-0.232339</td>\n",
       "      <td>5016.0</td>\n",
       "      <td>0.143872</td>\n",
       "      <td>0.020699</td>\n",
       "      <td>0.273277</td>\n",
       "      <td>0.264378</td>\n",
       "      <td>0.745202</td>\n",
       "      <td>-0.745202</td>\n",
       "      <td>against</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>r2_ig_101</td>\n",
       "      <td>13.903916</td>\n",
       "      <td>-0.000133</td>\n",
       "      <td>0.010753</td>\n",
       "      <td>1293.0</td>\n",
       "      <td>0.144235</td>\n",
       "      <td>0.020804</td>\n",
       "      <td>0.144636</td>\n",
       "      <td>0.520573</td>\n",
       "      <td>0.592314</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.260851</td>\n",
       "      <td>-0.260714</td>\n",
       "      <td>1293.0</td>\n",
       "      <td>0.140515</td>\n",
       "      <td>0.019744</td>\n",
       "      <td>0.296170</td>\n",
       "      <td>0.243582</td>\n",
       "      <td>0.732912</td>\n",
       "      <td>-0.732912</td>\n",
       "      <td>for</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>r2_ig_102</td>\n",
       "      <td>-0.538206</td>\n",
       "      <td>-0.012598</td>\n",
       "      <td>-0.000312</td>\n",
       "      <td>1723.0</td>\n",
       "      <td>0.139171</td>\n",
       "      <td>0.019369</td>\n",
       "      <td>0.139172</td>\n",
       "      <td>0.576313</td>\n",
       "      <td>0.576313</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.244546</td>\n",
       "      <td>-0.241903</td>\n",
       "      <td>1723.0</td>\n",
       "      <td>0.134479</td>\n",
       "      <td>0.018085</td>\n",
       "      <td>0.276770</td>\n",
       "      <td>0.267556</td>\n",
       "      <td>0.804279</td>\n",
       "      <td>-0.804279</td>\n",
       "      <td>for</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 7682 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     User_ID  emb_1__sum_values  emb_1__median  emb_1__mean  emb_1__length  \\\n",
       "0    r2_ig_1         -21.394181      -0.029887    -0.024367          878.0   \n",
       "1   r2_ig_10           1.394637       0.016590     0.015326           91.0   \n",
       "2  r2_ig_100         129.244744       0.026289     0.025766         5016.0   \n",
       "3  r2_ig_101          13.903916      -0.000133     0.010753         1293.0   \n",
       "4  r2_ig_102          -0.538206      -0.012598    -0.000312         1723.0   \n",
       "\n",
       "   emb_1__standard_deviation  emb_1__variance  emb_1__root_mean_square  \\\n",
       "0                   0.134303         0.018037                 0.136496   \n",
       "1                   0.132188         0.017474                 0.133074   \n",
       "2                   0.126746         0.016065                 0.129339   \n",
       "3                   0.144235         0.020804                 0.144636   \n",
       "4                   0.139171         0.019369                 0.139172   \n",
       "\n",
       "   emb_1__maximum  emb_1__absolute_maximum  ...  emb_768__median  \\\n",
       "0        0.671440                 0.671440  ...        -0.224691   \n",
       "1        0.345923                 0.345923  ...        -0.178725   \n",
       "2        0.523251                 0.523251  ...        -0.228821   \n",
       "3        0.520573                 0.592314  ...        -0.260851   \n",
       "4        0.576313                 0.576313  ...        -0.244546   \n",
       "\n",
       "   emb_768__mean  emb_768__length  emb_768__standard_deviation  \\\n",
       "0      -0.222255            878.0                     0.129926   \n",
       "1      -0.195514             91.0                     0.137983   \n",
       "2      -0.232339           5016.0                     0.143872   \n",
       "3      -0.260714           1293.0                     0.140515   \n",
       "4      -0.241903           1723.0                     0.134479   \n",
       "\n",
       "   emb_768__variance  emb_768__root_mean_square  emb_768__maximum  \\\n",
       "0           0.016881                   0.257446          0.250205   \n",
       "1           0.019039                   0.239301          0.044307   \n",
       "2           0.020699                   0.273277          0.264378   \n",
       "3           0.019744                   0.296170          0.243582   \n",
       "4           0.018085                   0.276770          0.267556   \n",
       "\n",
       "   emb_768__absolute_maximum  emb_768__minimum  Polarity  \n",
       "0                   0.686336         -0.686336   against  \n",
       "1                   0.725221         -0.725221       for  \n",
       "2                   0.745202         -0.745202   against  \n",
       "3                   0.732912         -0.732912       for  \n",
       "4                   0.804279         -0.804279       for  \n",
       "\n",
       "[5 rows x 7682 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data[[col for col in data.columns if 'emb' in col]]\n",
    "y = data.Polarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      0\n",
       "1      1\n",
       "2      0\n",
       "3      1\n",
       "4      1\n",
       "      ..\n",
       "175    0\n",
       "176    0\n",
       "177    0\n",
       "178    0\n",
       "179    0\n",
       "Name: Polarity, Length: 1800, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_encoded = y.map({'against': 0, 'for': 1})\n",
    "y_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42, stratify=y_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ...\n",
      "[Pipeline] ........... (step 1 of 3) Processing scaling, total=   0.1s\n",
      "Fitting estimator with 7680 features.\n",
      "Fitting estimator with 7630 features.\n",
      "Fitting estimator with 7580 features.\n",
      "Fitting estimator with 7530 features.\n",
      "Fitting estimator with 7480 features.\n",
      "Fitting estimator with 7430 features.\n",
      "Fitting estimator with 7380 features.\n",
      "Fitting estimator with 7330 features.\n",
      "Fitting estimator with 7280 features.\n",
      "Fitting estimator with 7230 features.\n",
      "Fitting estimator with 7180 features.\n",
      "Fitting estimator with 7130 features.\n",
      "Fitting estimator with 7080 features.\n",
      "Fitting estimator with 7030 features.\n",
      "Fitting estimator with 6980 features.\n",
      "Fitting estimator with 6930 features.\n",
      "Fitting estimator with 6880 features.\n",
      "Fitting estimator with 6830 features.\n",
      "Fitting estimator with 6780 features.\n",
      "Fitting estimator with 6730 features.\n",
      "Fitting estimator with 6680 features.\n",
      "Fitting estimator with 6630 features.\n",
      "Fitting estimator with 6580 features.\n",
      "Fitting estimator with 6530 features.\n",
      "Fitting estimator with 6480 features.\n",
      "Fitting estimator with 6430 features.\n",
      "Fitting estimator with 6380 features.\n",
      "Fitting estimator with 6330 features.\n",
      "Fitting estimator with 6280 features.\n",
      "Fitting estimator with 6230 features.\n",
      "Fitting estimator with 6180 features.\n",
      "Fitting estimator with 6130 features.\n",
      "Fitting estimator with 6080 features.\n",
      "Fitting estimator with 6030 features.\n",
      "Fitting estimator with 5980 features.\n",
      "Fitting estimator with 5930 features.\n",
      "Fitting estimator with 5880 features.\n",
      "Fitting estimator with 5830 features.\n",
      "Fitting estimator with 5780 features.\n",
      "Fitting estimator with 5730 features.\n",
      "Fitting estimator with 5680 features.\n",
      "Fitting estimator with 5630 features.\n",
      "Fitting estimator with 5580 features.\n",
      "Fitting estimator with 5530 features.\n",
      "Fitting estimator with 5480 features.\n",
      "Fitting estimator with 5430 features.\n",
      "Fitting estimator with 5380 features.\n",
      "Fitting estimator with 5330 features.\n",
      "Fitting estimator with 5280 features.\n",
      "Fitting estimator with 5230 features.\n",
      "Fitting estimator with 5180 features.\n",
      "Fitting estimator with 5130 features.\n",
      "Fitting estimator with 5080 features.\n",
      "Fitting estimator with 5030 features.\n",
      "Fitting estimator with 4980 features.\n",
      "Fitting estimator with 4930 features.\n",
      "Fitting estimator with 4880 features.\n",
      "Fitting estimator with 4830 features.\n",
      "Fitting estimator with 4780 features.\n",
      "Fitting estimator with 4730 features.\n",
      "Fitting estimator with 4680 features.\n",
      "Fitting estimator with 4630 features.\n",
      "Fitting estimator with 4580 features.\n",
      "Fitting estimator with 4530 features.\n",
      "Fitting estimator with 4480 features.\n",
      "Fitting estimator with 4430 features.\n",
      "Fitting estimator with 4380 features.\n",
      "Fitting estimator with 4330 features.\n",
      "Fitting estimator with 4280 features.\n",
      "Fitting estimator with 4230 features.\n",
      "Fitting estimator with 4180 features.\n",
      "Fitting estimator with 4130 features.\n",
      "Fitting estimator with 4080 features.\n",
      "Fitting estimator with 4030 features.\n",
      "Fitting estimator with 3980 features.\n",
      "Fitting estimator with 3930 features.\n",
      "Fitting estimator with 3880 features.\n",
      "[Pipeline] ......... (step 2 of 3) Processing selection, total=12.7min\n",
      "[20:44:43] ======== Monitor (0): HostSketchContainer ========\n",
      "[20:44:43] AllReduce: 0.038907s, 1 calls @ 38907us\n",
      "\n",
      "[20:44:43] MakeCuts: 0.045915s, 1 calls @ 45915us\n",
      "\n",
      "[20:44:43] DEBUG: /workspace/src/gbm/gbtree.cc:130: Using tree method: 0\n",
      "[20:45:11] ======== Monitor (0): Learner ========\n",
      "[20:45:11] Configure: 0.001984s, 1 calls @ 1984us\n",
      "\n",
      "[20:45:11] EvalOneIter: 0.001051s, 100 calls @ 1051us\n",
      "\n",
      "[20:45:11] GetGradient: 0.094959s, 100 calls @ 94959us\n",
      "\n",
      "[20:45:11] PredictRaw: 0.000135s, 100 calls @ 135us\n",
      "\n",
      "[20:45:11] UpdateOneIter: 28.6036s, 100 calls @ 28603615us\n",
      "\n",
      "[20:45:11] ======== Monitor (0): GBTree ========\n",
      "[20:45:11] BoostNewTrees: 28.5056s, 100 calls @ 28505568us\n",
      "\n",
      "[20:45:11] CommitModel: 7.6e-05s, 100 calls @ 76us\n",
      "\n",
      "[20:45:11] ======== Monitor (0): HistUpdater ========\n",
      "[20:45:11] BuildHistogram: 12.5665s, 500 calls @ 12566540us\n",
      "\n",
      "[20:45:11] EvaluateSplits: 10.1569s, 600 calls @ 10156853us\n",
      "\n",
      "[20:45:11] InitData: 0.077409s, 100 calls @ 77409us\n",
      "\n",
      "[20:45:11] InitRoot: 3.49697s, 100 calls @ 3496966us\n",
      "\n",
      "[20:45:11] LeafPartition: 4.3e-05s, 100 calls @ 43us\n",
      "\n",
      "[20:45:11] UpdatePosition: 2.7043s, 600 calls @ 2704299us\n",
      "\n",
      "[20:45:11] UpdatePredictionCache: 0.124236s, 100 calls @ 124236us\n",
      "\n",
      "[20:45:11] UpdateTree: 28.3764s, 100 calls @ 28376366us\n",
      "\n",
      "[Pipeline] ......... (step 3 of 3) Processing estimator, total=  29.0s\n",
      "[20:45:11] DEBUG: /workspace/src/gbm/gbtree.cc:130: Using tree method: 0\n"
     ]
    }
   ],
   "source": [
    "pipe = IMBPipeline(\n",
    "    steps = [\n",
    "        ('scaling', MaxAbsScaler()),\n",
    "        ('selection', RFE(\n",
    "            estimator = RandomForestClassifier(),\n",
    "            step = 50,\n",
    "            verbose = 4\n",
    "            )),\n",
    "        ('estimator', XGBClassifier(\n",
    "            random_state = 42,\n",
    "            verbosity = 3,\n",
    "            # device = 'cuda',\n",
    "            # tree_method = 'hist'\n",
    "            ))\n",
    "    ],\n",
    "    verbose = True\n",
    "    )\n",
    "\n",
    "print('Training ...')\n",
    "pipe_trained = pipe.fit(X_train, y_train)\n",
    "\n",
    "y_pred = pipe_trained.predict(X_test)\n",
    "y_pred_proba = pipe_trained.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_classification_report = get_classification_report(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50     1\n",
       "37     0\n",
       "97     1\n",
       "45     0\n",
       "161    0\n",
       "      ..\n",
       "40     1\n",
       "173    1\n",
       "130    0\n",
       "128    0\n",
       "79     1\n",
       "Name: Polarity, Length: 360, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1,\n",
       "       1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1,\n",
       "       1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0,\n",
       "       0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0,\n",
       "       0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0,\n",
       "       1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0,\n",
       "       1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1,\n",
       "       0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0,\n",
       "       0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1,\n",
       "       0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1,\n",
       "       1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0,\n",
       "       1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0,\n",
       "       0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0,\n",
       "       0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
       "       0, 1, 1, 1, 1, 0, 0, 1])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0,\n",
       "       1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0,\n",
       "       1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0,\n",
       "       1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0,\n",
       "       0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0,\n",
       "       0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "       1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1,\n",
       "       0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0,\n",
       "       1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1,\n",
       "       1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0,\n",
       "       0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1,\n",
       "       0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1,\n",
       "       0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0,\n",
       "       0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0,\n",
       "       1, 0, 1, 1, 0, 0, 1, 1])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.668142</td>\n",
       "      <td>0.743842</td>\n",
       "      <td>0.703963</td>\n",
       "      <td>203.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.647222</td>\n",
       "      <td>0.647222</td>\n",
       "      <td>0.647222</td>\n",
       "      <td>0.647222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.643632</td>\n",
       "      <td>0.647222</td>\n",
       "      <td>0.642738</td>\n",
       "      <td>360.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.640041</td>\n",
       "      <td>0.633068</td>\n",
       "      <td>0.633768</td>\n",
       "      <td>360.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.611940</td>\n",
       "      <td>0.522293</td>\n",
       "      <td>0.563574</td>\n",
       "      <td>157.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              precision    recall  f1-score     support\n",
       "0              0.668142  0.743842  0.703963  203.000000\n",
       "accuracy       0.647222  0.647222  0.647222    0.647222\n",
       "weighted avg   0.643632  0.647222  0.642738  360.000000\n",
       "macro avg      0.640041  0.633068  0.633768  360.000000\n",
       "1              0.611940  0.522293  0.563574  157.000000"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_encoded.value_counts()/len(y_encoded)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env-stance-pred",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
