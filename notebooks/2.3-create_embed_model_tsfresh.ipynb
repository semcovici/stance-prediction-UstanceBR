{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import LabelEncoder, MaxAbsScaler\n",
    "import numpy as np\n",
    "from imblearn.over_sampling import RandomOverSampler, SMOTE\n",
    "from imblearn.pipeline import Pipeline as IMBPipeline\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from nltk.corpus import stopwords\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.feature_selection import RFE\n",
    "from tsfresh.feature_extraction import MinimalFCParameters\n",
    "from tsfresh.feature_extraction import extract_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_classification_report(y_test, y_pred):\n",
    "    '''Source: https://stackoverflow.com/questions/39662398/scikit-learn-output-metrics-classification-report-into-csv-tab-delimited-format'''\n",
    "    report = classification_report(y_test, y_pred, output_dict=True)\n",
    "    df_classification_report = pd.DataFrame(report).transpose()\n",
    "    df_classification_report = df_classification_report.sort_values(by=['f1-score'], ascending=False)\n",
    "    return df_classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/semcovici/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_raw_data = '../data/raw/'\n",
    "path_processed_data = '../data/processed/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = 'ig'\n",
    "model_name = 'facebook/fasttext-pt-vectors'\n",
    "model_name = 'neuralmind/bert-base-portuguese-cased'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_data = path_processed_data + f'train_r3_{corpus}_top_mentioned_timelines_separated_comments_{model_name.replace(\"/\", \"_\")}_tsfresh.parquet'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_parquet(path_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data[[col for col in data.columns if 'emb' in col]]\n",
    "y = data.Polarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "0    1\n",
       "0    0\n",
       "0    1\n",
       "0    1\n",
       "    ..\n",
       "0    0\n",
       "0    0\n",
       "0    0\n",
       "0    0\n",
       "0    0\n",
       "Name: Polarity, Length: 1522, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_encoded = y.map({'against': 0, 'for': 1})\n",
    "y_encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42, stratify=y_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training ...\n",
      "[Pipeline] ........... (step 1 of 2) Processing scaling, total=   0.1s\n",
      "[15:46:52] ======== Monitor (0): HostSketchContainer ========\n",
      "[15:46:52] AllReduce: 0.071451s, 1 calls @ 71451us\n",
      "\n",
      "[15:46:52] MakeCuts: 0.085878s, 1 calls @ 85878us\n",
      "\n",
      "[15:46:52] DEBUG: /workspace/src/gbm/gbtree.cc:130: Using tree method: 3\n",
      "[15:46:52] DEBUG: /workspace/src/tree/updater_gpu_hist.cu:744: [GPU Hist]: Configure\n",
      "[15:46:52] ======== Monitor (0):  ========\n",
      "[15:46:52] InitCompressedData: 0.000262s, 1 calls @ 262us\n",
      "\n",
      "[15:47:01] ======== Monitor (0): Learner ========\n",
      "[15:47:01] Configure: 0.026183s, 1 calls @ 26183us\n",
      "\n",
      "[15:47:01] EvalOneIter: 0.00086s, 100 calls @ 860us\n",
      "\n",
      "[15:47:01] GetGradient: 0.004765s, 100 calls @ 4765us\n",
      "\n",
      "[15:47:01] PredictRaw: 0.00013s, 100 calls @ 130us\n",
      "\n",
      "[15:47:01] UpdateOneIter: 9.55167s, 100 calls @ 9551666us\n",
      "\n",
      "[15:47:01] ======== Monitor (0): GBTree ========\n",
      "[15:47:01] BoostNewTrees: 9.51033s, 100 calls @ 9510333us\n",
      "\n",
      "[15:47:01] CommitModel: 6.3e-05s, 100 calls @ 63us\n",
      "\n",
      "[15:47:01] ======== Device 0 Memory Allocations:  ========\n",
      "[15:47:01] Peak memory usage: 2542MiB\n",
      "[15:47:01] Number of allocations: 5173\n",
      "[15:47:01] ======== Monitor (0): updater_gpu_hist ========\n",
      "[15:47:01] InitData: 0.000478s, 100 calls @ 478us\n",
      "\n",
      "[15:47:01] InitDataOnce: 0.000464s, 1 calls @ 464us\n",
      "\n",
      "[15:47:01] Update: 9.50337s, 100 calls @ 9503371us\n",
      "\n",
      "[15:47:01] UpdatePredictionCache: 0.0062s, 100 calls @ 6200us\n",
      "\n",
      "[15:47:01] ======== Monitor (0): gradient_based_sampler ========\n",
      "[15:47:01] Sample: 0.017381s, 100 calls @ 17381us\n",
      "\n",
      "[15:47:01] ======== Monitor (0): GPUHistMakerDevice0 ========\n",
      "[15:47:01] AllReduce: 0.000448s, 555 calls @ 448us\n",
      "\n",
      "[15:47:01] BuildHist: 0.031298s, 508 calls @ 31298us\n",
      "\n",
      "[15:47:01] EvaluateSplits: 8.12528s, 508 calls @ 8125280us\n",
      "\n",
      "[15:47:01] FinalisePosition: 0.021408s, 100 calls @ 21408us\n",
      "\n",
      "[15:47:01] InitRoot: 1.20318s, 100 calls @ 1203181us\n",
      "\n",
      "[15:47:01] Reset: 0.03448s, 100 calls @ 34480us\n",
      "\n",
      "[15:47:01] UpdatePosition: 0.082805s, 508 calls @ 82805us\n",
      "\n",
      "[Pipeline] ......... (step 2 of 2) Processing estimator, total=  10.1s\n",
      "[15:47:01] DEBUG: /workspace/src/gbm/gbtree.cc:130: Using tree method: 3\n",
      "[15:47:01] DEBUG: /workspace/src/tree/updater_gpu_hist.cu:744: [GPU Hist]: Configure\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/semcovici/anaconda3/envs/env-stance-pred/lib/python3.12/site-packages/xgboost/core.py:160: UserWarning: [15:47:01] WARNING: /workspace/src/common/error_msg.cc:58: Falling back to prediction using DMatrix due to mismatched devices. This might lead to higher memory usage and slower performance. XGBoost is running on: cuda:0, while the input data is on: cpu.\n",
      "Potential solutions:\n",
      "- Use a data structure that matches the device ordinal in the booster.\n",
      "- Set the device for booster before call to inplace_predict.\n",
      "\n",
      "This warning will only be shown once.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "pipe = IMBPipeline(\n",
    "    steps = [\n",
    "        ('scaling', MaxAbsScaler()),\n",
    "        # ('selection', RFE(\n",
    "        #     estimator = RandomForestClassifier(),\n",
    "        #     step = 50,\n",
    "        #     verbose = 4\n",
    "        #     )),\n",
    "        ('estimator', XGBClassifier(\n",
    "            random_state = 42,\n",
    "            verbosity = 3,\n",
    "            device = 'cuda',\n",
    "            tree_method = 'hist'\n",
    "            ))\n",
    "    ],\n",
    "    verbose = True\n",
    "    )\n",
    "\n",
    "print('Training ...')\n",
    "pipe_trained = pipe.fit(X_train, y_train)\n",
    "\n",
    "y_pred = pipe_trained.predict(X_test)\n",
    "y_pred_proba = pipe_trained.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_classification_report = get_classification_report(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "0    1\n",
       "0    0\n",
       "0    1\n",
       "0    0\n",
       "    ..\n",
       "0    1\n",
       "0    0\n",
       "0    0\n",
       "0    0\n",
       "0    0\n",
       "Name: Polarity, Length: 305, dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0,\n",
       "       0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1,\n",
       "       1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1,\n",
       "       1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1,\n",
       "       0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1,\n",
       "       1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0,\n",
       "       1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0,\n",
       "       0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0,\n",
       "       0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
       "       0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0,\n",
       "       1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0,\n",
       "       0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0,\n",
       "       0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1,\n",
       "       0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0,\n",
       "       1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1,\n",
       "       0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0,\n",
       "       1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1,\n",
       "       0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1,\n",
       "       1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1,\n",
       "       1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1,\n",
       "       0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0,\n",
       "       0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1,\n",
       "       1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0,\n",
       "       0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1,\n",
       "       1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0,\n",
       "       1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0,\n",
       "       1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>support</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.618497</td>\n",
       "      <td>0.644578</td>\n",
       "      <td>0.631268</td>\n",
       "      <td>166.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>accuracy</th>\n",
       "      <td>0.590164</td>\n",
       "      <td>0.590164</td>\n",
       "      <td>0.590164</td>\n",
       "      <td>0.590164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weighted avg</th>\n",
       "      <td>0.588661</td>\n",
       "      <td>0.590164</td>\n",
       "      <td>0.589102</td>\n",
       "      <td>305.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>macro avg</th>\n",
       "      <td>0.585764</td>\n",
       "      <td>0.584879</td>\n",
       "      <td>0.585007</td>\n",
       "      <td>305.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.553030</td>\n",
       "      <td>0.525180</td>\n",
       "      <td>0.538745</td>\n",
       "      <td>139.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              precision    recall  f1-score     support\n",
       "0              0.618497  0.644578  0.631268  166.000000\n",
       "accuracy       0.590164  0.590164  0.590164    0.590164\n",
       "weighted avg   0.588661  0.590164  0.589102  305.000000\n",
       "macro avg      0.585764  0.584879  0.585007  305.000000\n",
       "1              0.553030  0.525180  0.538745  139.000000"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Polarity\n",
       "0    0.544021\n",
       "1    0.455979\n",
       "Name: count, dtype: float64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_encoded.value_counts()/len(y_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env-stance-pred",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
